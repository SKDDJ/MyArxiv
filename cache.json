{"2024-11-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2407.10964v2","updated":"2024-11-06T18:58:03Z","published":"2024-07-15T17:58:42Z","title":"No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen\n  Representations","summary":"  This paper introduces FUNGI, Features from UNsupervised GradIents, a method\nto enhance the features of transformer encoders by leveraging self-supervised\ngradients. Our method is simple: given any pretrained model, we first compute\ngradients from various self-supervised objectives for each input. These\ngradients are projected to a lower dimension and then concatenated with the\nmodel's output embedding. The resulting features are evaluated on k-nearest\nneighbor classification over 11 datasets from vision, 5 from natural language\nprocessing, and 2 from audio. Across backbones spanning various sizes and\npretraining strategies, FUNGI features provide consistent performance\nimprovements over the embeddings. We also show that using FUNGI features can\nbenefit linear classification, clustering and image retrieval, and that they\nsignificantly improve the retrieval-based in-context scene understanding\nabilities of pretrained models, for example improving upon DINO by +17% for\nsemantic segmentation - without any training.\n","authors":["Walter Simoncini","Spyros Gidaris","Andrei Bursuc","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2407.10964v2.pdf","comment":"NeurIPS 2024. Code available at\n  https://github.com/WalterSimoncini/fungivision"},{"id":"http://arxiv.org/abs/2411.04118v1","updated":"2024-11-06T18:51:02Z","published":"2024-11-06T18:51:02Z","title":"Medical Adaptation of Large Language and Vision-Language Models: Are We\n  Making Progress?","summary":"  Several recent works seek to develop foundation models specifically for\nmedical applications, adapting general-purpose large language models (LLMs) and\nvision-language models (VLMs) via continued pretraining on publicly available\nbiomedical corpora. These works typically claim that such domain-adaptive\npretraining (DAPT) improves performance on downstream medical tasks, such as\nanswering medical licensing exam questions. In this paper, we compare seven\npublic \"medical\" LLMs and two VLMs against their corresponding base models,\narriving at a different conclusion: all medical VLMs and nearly all medical\nLLMs fail to consistently improve over their base models in the zero-/few-shot\nprompting regime for medical question-answering (QA) tasks. For instance,\nacross the tasks and model pairs we consider in the 3-shot setting, medical\nLLMs only outperform their base models in 12.1% of cases, reach a (statistical)\ntie in 49.8% of cases, and are significantly worse than their base models in\nthe remaining 38.2% of cases. Our conclusions are based on (i) comparing each\nmedical model head-to-head, directly against the corresponding base model; (ii)\noptimizing the prompts for each model separately; and (iii) accounting for\nstatistical uncertainty in comparisons. While these basic practices are not\nconsistently adopted in the literature, our ablations show that they\nsubstantially impact conclusions. Our findings suggest that state-of-the-art\ngeneral-domain models may already exhibit strong medical knowledge and\nreasoning capabilities, and offer recommendations to strengthen the conclusions\nof future studies.\n","authors":["Daniel P. Jeong","Saurabh Garg","Zachary C. Lipton","Michael Oberst"],"pdf_url":"https://arxiv.org/pdf/2411.04118v1.pdf","comment":"Accepted to EMNLP 2024 Main Conference as Long Paper (Oral)"},{"id":"http://arxiv.org/abs/2411.04109v1","updated":"2024-11-06T18:36:22Z","published":"2024-11-06T18:36:22Z","title":"Self-Consistency Preference Optimization","summary":"  Self-alignment, whereby models learn to improve themselves without human\nannotation, is a rapidly growing research area. However, existing techniques\noften fail to improve complex reasoning tasks due to the difficulty of\nassigning correct rewards. An orthogonal approach that is known to improve\ncorrectness is self-consistency, a method applied at inference time based on\nmultiple sampling in order to find the most consistent answer. In this work, we\nextend the self-consistency concept to help train models. We thus introduce\nself-consistency preference optimization (ScPO), which iteratively trains\nconsistent answers to be preferred over inconsistent ones on unsupervised new\nproblems. We show ScPO leads to large improvements over conventional reward\nmodel training on reasoning tasks such as GSM8K and MATH, closing the gap with\nsupervised training with gold answers or preferences, and that combining ScPO\nwith standard supervised learning improves results even further. On ZebraLogic,\nScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and\nClaude-3 Haiku.\n","authors":["Archiki Prasad","Weizhe Yuan","Richard Yuanzhe Pang","Jing Xu","Maryam Fazel-Zarandi","Mohit Bansal","Sainbayar Sukhbaatar","Jason Weston","Jane Yu"],"pdf_url":"https://arxiv.org/pdf/2411.04109v1.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.04105v1","updated":"2024-11-06T18:35:32Z","published":"2024-11-06T18:35:32Z","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic\n  Analysis","summary":"  Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve, but we can train a small\ntransformer to achieve perfect accuracy. Building on our set-up, we then pursue\nan understanding of precisely how a three-layer transformer, trained from\nscratch, solves this problem. We are able to identify certain \"planning\" and\n\"reasoning\" circuits in the network that necessitate cooperation between the\nattention blocks to implement the desired logic. To expand our findings, we\nthen study a larger model, Mistral 7B. Using activation patching, we\ncharacterize internal components that are critical in solving our logic\nproblem. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.\n","authors":["Guan Zhe Hong","Nishanth Dikkala","Enming Luo","Cyrus Rashtchian","Rina Panigrahy"],"pdf_url":"https://arxiv.org/pdf/2411.04105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04093v1","updated":"2024-11-06T18:14:48Z","published":"2024-11-06T18:14:48Z","title":"Summarization of Opinionated Political Documents with Varied\n  Perspectives","summary":"  Global partisan hostility and polarization has increased, and this\npolarization is heightened around presidential elections. Models capable of\ngenerating accurate summaries of diverse perspectives can help reduce such\npolarization by exposing users to alternative perspectives. In this work, we\nintroduce a novel dataset and task for independently summarizing each political\nperspective in a set of passages from opinionated news articles. For this task,\nwe propose a framework for evaluating different dimensions of perspective\nsummary performance. We benchmark 10 models of varying sizes and architectures\nthrough both automatic and human evaluation. While recent models like GPT-4o\nperform well on this task, we find that all models struggle to generate\nsummaries faithful to the intended perspective. Our analysis of summaries\nfocuses on how extraction behavior depends on the features of the input\ndocuments.\n","authors":["Nicholas Deas","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2411.04093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04090v1","updated":"2024-11-06T18:08:57Z","published":"2024-11-06T18:08:57Z","title":"A Collaborative Content Moderation Framework for Toxicity Detection\n  based on Conformalized Estimates of Annotation Disagreement","summary":"  Content moderation typically combines the efforts of human moderators and\nmachine learning models.However, these systems often rely on data where\nsignificant disagreement occurs during moderation, reflecting the subjective\nnature of toxicity perception.Rather than dismissing this disagreement as\nnoise, we interpret it as a valuable signal that highlights the inherent\nambiguity of the content,an insight missed when only the majority label is\nconsidered.In this work, we introduce a novel content moderation framework that\nemphasizes the importance of capturing annotation disagreement. Our approach\nuses multitask learning, where toxicity classification serves as the primary\ntask and annotation disagreement is addressed as an auxiliary\ntask.Additionally, we leverage uncertainty estimation techniques, specifically\nConformal Prediction, to account for both the ambiguity in comment annotations\nand the model's inherent uncertainty in predicting toxicity and\ndisagreement.The framework also allows moderators to adjust thresholds for\nannotation disagreement, offering flexibility in determining when ambiguity\nshould trigger a review.We demonstrate that our joint approach enhances model\nperformance, calibration, and uncertainty estimation, while offering greater\nparameter efficiency and improving the review process in comparison to\nsingle-task methods.\n","authors":["Guillermo Villate-Castillo","Javier Del Ser","Borja Sanz"],"pdf_url":"https://arxiv.org/pdf/2411.04090v1.pdf","comment":"35 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.11832v2","updated":"2024-11-06T18:07:03Z","published":"2024-08-06T15:49:58Z","title":"OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs","summary":"  The increased use of large language models (LLMs) across a variety of\nreal-world applications calls for automatic tools to check the factual accuracy\nof their outputs, as LLMs often hallucinate. This is difficult as it requires\nassessing the factuality of free-form open-domain responses. While there has\nbeen a lot of research on this topic, different papers use different evaluation\nbenchmarks and measures, which makes them hard to compare and hampers future\nprogress. To mitigate these issues, we developed OpenFactCheck, a unified\nframework, with three modules: (i) RESPONSEEVAL, which allows users to easily\ncustomize an automatic fact-checking system and to assess the factuality of all\nclaims in an input document using that system, (ii) LLMEVAL, which assesses the\noverall factuality of an LLM, and (iii) CHECKEREVAL, a module to evaluate\nautomatic fact-checking systems. OpenFactCheck is open-sourced\n(https://github.com/mbzuai-nlp/openfactcheck) and publicly released as a Python\nlibrary (https://pypi.org/project/openfactcheck/) and also as a web service\n(http://app.openfactcheck.com). A video describing the system is available at\nhttps://youtu.be/-i9VKL0HleI.\n","authors":["Hasan Iqbal","Yuxia Wang","Minghan Wang","Georgi Georgiev","Jiahui Geng","Iryna Gurevych","Preslav Nakov"],"pdf_url":"https://arxiv.org/pdf/2408.11832v2.pdf","comment":"11 pages, 4 Figures, 3 Tables, Accepted at EMNLP 2024 System\n  Demonstration. arXiv admin note: substantial text overlap with\n  arXiv:2405.05583"},{"id":"http://arxiv.org/abs/2411.04075v1","updated":"2024-11-06T17:52:01Z","published":"2024-11-06T17:52:01Z","title":"M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for\n  Evaluating Foundation Models","summary":"  Existing benchmarks for evaluating foundation models mainly focus on\nsingle-document, text-only tasks. However, they often fail to fully capture the\ncomplexity of research workflows, which typically involve interpreting\nnon-textual data and gathering information across multiple documents. To\naddress this gap, we introduce M3SciQA, a multi-modal, multi-document\nscientific question answering benchmark designed for a more comprehensive\nevaluation of foundation models. M3SciQA consists of 1,452 expert-annotated\nquestions spanning 70 natural language processing paper clusters, where each\ncluster represents a primary paper along with all its cited documents,\nmirroring the workflow of comprehending a single paper by requiring multi-modal\nand multi-document data. With M3SciQA, we conduct a comprehensive evaluation of\n18 foundation models. Our results indicate that current foundation models still\nsignificantly underperform compared to human experts in multi-modal information\nretrieval and in reasoning across multiple scientific documents. Additionally,\nwe explore the implications of these findings for the future advancement of\napplying foundation models in multi-modal scientific literature analysis.\n","authors":["Chuhan Li","Ziyao Shangguan","Yilun Zhao","Deyuan Li","Yixin Liu","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.04075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17027v2","updated":"2024-11-06T17:20:42Z","published":"2024-09-25T15:30:24Z","title":"Counterfactual Token Generation in Large Language Models","summary":"  \"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm\nof her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]\nLyra's eyes welled up with tears as she realized the bitter truth - she had\nsacrificed everything for fleeting riches, and lost the love of her crew, her\nfamily, and herself.\" Although this story, generated by a large language model,\nis captivating, one may wonder -- how would the story have unfolded if the\nmodel had chosen \"Captain Maeve\" as the protagonist instead? We cannot know.\nState-of-the-art large language models are stateless -- they maintain no\ninternal memory or state. Given a prompt, they generate a sequence of tokens as\nan output using an autoregressive process. As a consequence, they cannot reason\nabout counterfactual alternatives to tokens they have generated in the past. In\nthis work, our goal is to enhance them with this functionality. To this end, we\ndevelop a causal model of token generation that builds upon the Gumbel-Max\nstructural causal model. Our model allows any large language model to perform\ncounterfactual token generation at almost no cost in comparison with vanilla\ntoken generation, it is embarrassingly simple to implement, and it does not\nrequire any fine-tuning nor prompt engineering. We implement our model on Llama\n3 8B-Instruct and Ministral-8B-Instruct and conduct a qualitative and a\nquantitative analysis of counterfactually generated text. We conclude with a\ndemonstrative application of counterfactual token generation for bias\ndetection, unveiling interesting insights about the model of the world\nconstructed by large language models.\n","authors":["Ivi Chatzi","Nina Corvelo Benz","Eleni Straitouri","Stratis Tsirtsis","Manuel Gomez-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2409.17027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01483v3","updated":"2024-11-06T17:04:36Z","published":"2024-11-03T08:49:55Z","title":"Teaching Models to Improve on Tape","summary":"  Large Language Models (LLMs) often struggle when prompted to generate content\nunder specific constraints. However, in such cases it is often easy to check\nwhether these constraints are satisfied or violated. Recent works have shown\nthat LLMs can benefit from such \"corrective feedback\". Here we claim that this\nskill of LLMs can be significantly enhanced via training. We introduce an RL\nframework for teaching models to use such rewards, by simulating interaction\nsessions, and rewarding the model according to its ability to satisfy the\nconstraints. We refer to our method as CORGI (Controlled Generation with RL for\nGuided Interaction), and evaluate it on a variety of controlled generation\ntasks using unlabeled training data. We find that CORGI consistently\noutperforms the baseline reinforcement learning method that does not\nincorporate conversational feedback. Furthermore, CORGI's interactive framework\nenables meta-learning, allowing the LLM to generalize better to guided\ninteraction in new tasks. Our results clearly show that conversational\noptimization, when combined with reinforcement learning, significantly improves\nthe effectiveness of LLMs in controlled generation contexts.\n","authors":["Liat Bezalel","Eyal Orgad","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2411.01483v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14632v2","updated":"2024-11-06T16:54:48Z","published":"2024-10-18T17:32:22Z","title":"Diverging Preferences: When do Annotators Disagree and do Models Know?","summary":"  We examine diverging preferences in human-labeled preference datasets. We\ndevelop a taxonomy of disagreement sources spanning 10 categories across four\nhigh-level classes -- task underspecification, response style, refusals, and\nannotation errors. We find that the majority of disagreements are in opposition\nwith standard reward modeling approaches, which are designed with the\nassumption that annotator disagreement is noise. We then explore how these\nfindings impact two areas of LLM development: reward modeling and evaluation.\nIn our experiments, we demonstrate how standard reward modeling methods, like\nthe Bradley-Terry model, fail to differentiate whether a given preference\njudgment is the result of unanimous agreement among annotators or the majority\nopinion among diverging user preferences. We also find that these tendencies\nare also echoed by popular LLM-as-Judge evaluation methods, which consistently\nidentify a winning response in cases of diverging preferences. These findings\nhighlight remaining challenges in LLM evaluations, which are greatly influenced\nby divisive features like response style, and in developing pluralistically\naligned LLMs. To address these issues, we develop methods for identifying\ndiverging preferences to mitigate their influence on evaluation and training.\n","authors":["Michael JQ Zhang","Zhilin Wang","Jena D. Hwang","Yi Dong","Olivier Delalleau","Yejin Choi","Eunsol Choi","Xiang Ren","Valentina Pyatkin"],"pdf_url":"https://arxiv.org/pdf/2410.14632v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04032v1","updated":"2024-11-06T16:31:28Z","published":"2024-11-06T16:31:28Z","title":"Beemo: Benchmark of Expert-edited Machine-generated Outputs","summary":"  The rapid proliferation of large language models (LLMs) has increased the\nvolume of machine-generated texts (MGTs) and blurred text authorship in various\ndomains. However, most existing MGT benchmarks include single-author texts\n(human-written and machine-generated). This conventional design fails to\ncapture more practical multi-author scenarios, where the user refines the LLM\nresponse for natural flow, coherence, and factual correctness. Our paper\nintroduces the Benchmark of Expert-edited Machine-generated Outputs (Beemo),\nwhich includes 6.5k texts written by humans, generated by ten\ninstruction-finetuned LLMs, and edited by experts for various use cases,\nranging from creative writing to summarization. Beemo additionally comprises\n13.1k machine-generated and LLM-edited texts, allowing for diverse MGT\ndetection evaluation across various edit types. We document Beemo's creation\nprotocol and present the results of benchmarking 33 configurations of MGT\ndetectors in different experimental setups. We find that expert-based editing\nevades MGT detection, while LLM-edited texts are unlikely to be recognized as\nhuman-written. Beemo and all materials are publicly available.\n","authors":["Ekaterina Artemova","Jason Lucas","Saranya Venkatraman","Jooyoung Lee","Sergei Tilga","Adaku Uchendu","Vladislav Mikhailov"],"pdf_url":"https://arxiv.org/pdf/2411.04032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04025v1","updated":"2024-11-06T16:20:37Z","published":"2024-11-06T16:20:37Z","title":"Prompt Engineering Using GPT for Word-Level Code-Mixed Language\n  Identification in Low-Resource Dravidian Languages","summary":"  Language Identification (LI) is crucial for various natural language\nprocessing tasks, serving as a foundational step in applications such as\nsentiment analysis, machine translation, and information retrieval. In\nmultilingual societies like India, particularly among the youth engaging on\nsocial media, text often exhibits code-mixing, blending local languages with\nEnglish at different linguistic levels. This phenomenon presents formidable\nchallenges for LI systems, especially when languages intermingle within single\nwords. Dravidian languages, prevalent in southern India, possess rich\nmorphological structures yet suffer from under-representation in digital\nplatforms, leading to the adoption of Roman or hybrid scripts for\ncommunication. This paper introduces a prompt based method for a shared task\naimed at addressing word-level LI challenges in Dravidian languages. In this\nwork, we leveraged GPT-3.5 Turbo to understand whether the large language\nmodels is able to correctly classify words into correct categories. Our\nfindings show that the Kannada model consistently outperformed the Tamil model\nacross most metrics, indicating a higher accuracy and reliability in\nidentifying and categorizing Kannada language instances. In contrast, the Tamil\nmodel showed moderate performance, particularly needing improvement in\nprecision and recall.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.04025v1.pdf","comment":"Accepted at FIRE 2024 (Track: Word-level Language Identification in\n  Dravidian Languages)"},{"id":"http://arxiv.org/abs/2404.08262v3","updated":"2024-11-06T16:19:24Z","published":"2024-04-12T06:21:48Z","title":"Pretraining and Updates of Domain-Specific LLM: A Case Study in the\n  Japanese Business Domain","summary":"  The development of Large Language Models (LLMs) in various languages has been\nadvancing, but the combination of non-English languages with domain-specific\ncontexts remains underexplored. This paper presents our findings from training\nand evaluating a Japanese business domain-specific LLM designed to better\nunderstand business-related documents, such as the news on current affairs,\ntechnical reports, and patents. Additionally, LLMs in this domain require\nregular updates to incorporate the most recent knowledge. Therefore, we also\nreport our findings from the first experiments and evaluations involving\nupdates to this LLM using the latest article data, which is an important\nproblem setting that has not been addressed in previous research. From our\nexperiments on a newly created benchmark dataset for question answering in the\ntarget domain, we found that (1) our pretrained model improves QA accuracy\nwithout losing general knowledge, and (2) a proper mixture of the latest and\nolder texts in the training data for the update is necessary. Our pretrained\nmodel and business domain benchmark are publicly available to support further\nstudies.\n","authors":["Kosuke Takahashi","Takahiro Omi","Kosuke Arima","Tatsuya Ishigaki"],"pdf_url":"https://arxiv.org/pdf/2404.08262v3.pdf","comment":"Accepted at PACLIC 38"},{"id":"http://arxiv.org/abs/2410.07520v2","updated":"2024-11-06T16:17:21Z","published":"2024-10-10T01:21:48Z","title":"News Reporter: A Multi-lingual LLM Framework for Broadcast T.V News","summary":"  Large Language Models (LLMs) have fast become an essential tools to many\nconversational chatbots due to their ability to provide coherent answers for\nvaried queries. Datasets used to train these LLMs are often a mix of generic\nand synthetic samples, thus lacking the verification needed to provide correct\nand verifiable answers for T.V. News.\n  We collect and share a large collection of QA pairs extracted from\ntranscripts of news recordings from various news-channels across the United\nStates. Resultant QA pairs are then used to fine-tune an off-the-shelf LLM\nmodel. Our model surpasses base models of similar size on several open LLM\nbenchmarks. We further integrate and propose a RAG method to improve\ncontextualization of our answers and also point it to a verifiable news\nrecording.\n","authors":["Tarun Jain","Yufei Gao","Sridhar Vanga","Karan Singla"],"pdf_url":"https://arxiv.org/pdf/2410.07520v2.pdf","comment":"5 pages, under review at ICASSP 2025"},{"id":"http://arxiv.org/abs/2407.14916v2","updated":"2024-11-06T16:11:18Z","published":"2024-07-20T16:05:17Z","title":"Improving Context-Aware Preference Modeling for Language Models","summary":"  While finetuning language models from pairwise preferences has proven\nremarkably effective, the underspecified nature of natural language presents\ncritical challenges. Direct preference feedback is uninterpretable, difficult\nto provide where multidimensional criteria may apply, and often inconsistent,\neither because it is based on incomplete instructions or provided by diverse\nprincipals. To address these challenges, we consider the two-step preference\nmodeling procedure that first resolves the under-specification by selecting a\ncontext, and then evaluates preference with respect to the chosen context. We\ndecompose reward modeling error according to these two steps, which suggests\nthat supervising context in addition to context-specific preference may be a\nviable approach to aligning models with diverse human preferences. For this to\nwork, the ability of models to evaluate context-specific preference is\ncritical. To this end, we contribute context-conditioned preference datasets\nand accompanying experiments that investigate the ability of language models to\nevaluate context-specific preference. We use our datasets to (1) show that\nexisting preference models benefit from, but fail to fully consider, added\ncontext, (2) finetune a context-aware reward model with context-specific\nperformance exceeding that of GPT-4 and Llama 3 70B on tested datasets, and (3)\ninvestigate the value of context-aware preference modeling.\n","authors":["Silviu Pitis","Ziang Xiao","Nicolas Le Roux","Alessandro Sordoni"],"pdf_url":"https://arxiv.org/pdf/2407.14916v2.pdf","comment":"NeurIPS 2024. 10 pages (29 with references and appendix)"},{"id":"http://arxiv.org/abs/2405.17537v3","updated":"2024-11-06T15:56:04Z","published":"2024-05-27T17:57:48Z","title":"CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale","summary":"  Measuring biodiversity is crucial for understanding ecosystem health. While\nprior works have developed machine learning models for taxonomic classification\nof photographic images and DNA separately, in this work, we introduce a\nmultimodal approach combining both, using CLIP-style contrastive learning to\nalign images, barcode DNA, and text-based representations of taxonomic labels\nin a unified embedding space. This allows for accurate classification of both\nknown and unknown insect species without task-specific fine-tuning, leveraging\ncontrastive learning for the first time to fuse DNA and image data. Our method\nsurpasses previous single-modality approaches in accuracy by over 8% on\nzero-shot learning tasks, showcasing its effectiveness in biodiversity studies.\n","authors":["ZeMing Gong","Austin T. Wang","Xiaoliang Huo","Joakim Bruslund Haurum","Scott C. Lowe","Graham W. Taylor","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2405.17537v3.pdf","comment":"25 pages with 11 figures"},{"id":"http://arxiv.org/abs/2410.16676v3","updated":"2024-11-06T15:49:30Z","published":"2024-10-22T04:18:19Z","title":"Improving Causal Reasoning in Large Language Models: A Survey","summary":"  Causal reasoning (CR) is a crucial aspect of intelligence, essential for\nproblem-solving, decision-making, and understanding the world. While large\nlanguage models (LLMs) can generate rationales for their outputs, their ability\nto reliably perform causal reasoning remains uncertain, often falling short in\ntasks requiring a deep understanding of causality. In this survey, we provide a\ncomprehensive review of research aimed at enhancing LLMs for causal reasoning.\nWe categorize existing methods based on the role of LLMs: either as reasoning\nengines or as helpers providing knowledge or data to traditional CR methods,\nfollowed by a detailed discussion of the methodologies in each category. We\nthen evaluate the performance of LLMs on various causal reasoning tasks,\nproviding key findings and in-depth analysis. Finally, we provide insights from\ncurrent studies and highlight promising directions for future research. We aim\nfor this work to serve as a comprehensive resource, fostering further\nadvancements in causal reasoning with LLMs. Resources are available at\nhttps://github.com/chendl02/Awesome-LLM-causal-reasoning.\n","authors":["Longxuan Yu","Delin Chen","Siheng Xiong","Qingyang Wu","Qingzhen Liu","Dawei Li","Zhikai Chen","Xiaoze Liu","Liangming Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16676v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03966v1","updated":"2024-11-06T15:03:47Z","published":"2024-11-06T15:03:47Z","title":"WorryWords: Norms of Anxiety Association for over 44k English Words","summary":"  Anxiety, the anticipatory unease about a potential negative outcome, is a\ncommon and beneficial human emotion. However, there is still much that is not\nknown, such as how anxiety relates to our body and how it manifests in\nlanguage. This is especially pertinent given the increasing impact of\nanxiety-related disorders. In this work, we introduce WorryWords, the first\nlarge-scale repository of manually derived word--anxiety associations for over\n44,450 English words. We show that the anxiety associations are highly\nreliable. We use WorryWords to study the relationship between anxiety and other\nemotion constructs, as well as the rate at which children acquire anxiety words\nwith age. Finally, we show that using WorryWords alone, one can accurately\ntrack the change of anxiety in streams of text. The lexicon enables a wide\nvariety of anxiety-related research in psychology, NLP, public health, and\nsocial sciences. WorryWords (and its translations to over 100 languages) is\nfreely available. http://saifmohammad.com/worrywords.html\n","authors":["Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2411.03966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03964v1","updated":"2024-11-06T14:54:19Z","published":"2024-11-06T14:54:19Z","title":"What Really is Commonsense Knowledge?","summary":"  Commonsense datasets have been well developed in Natural Language Processing,\nmainly through crowdsource human annotation. However, there are debates on the\ngenuineness of commonsense reasoning benchmarks. In specific, a significant\nportion of instances in some commonsense benchmarks do not concern commonsense\nknowledge. That problem would undermine the measurement of the true commonsense\nreasoning ability of evaluated models. It is also suggested that the problem\noriginated from a blurry concept of commonsense knowledge, as distinguished\nfrom other types of knowledge. To demystify all of the above claims, in this\nstudy, we survey existing definitions of commonsense knowledge, ground into the\nthree frameworks for defining concepts, and consolidate them into a\nmulti-framework unified definition of commonsense knowledge (so-called\nconsolidated definition). We then use the consolidated definition for\nannotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets\nto examine the above claims. Our study shows that there exists a large portion\nof non-commonsense-knowledge instances in the two datasets, and a large\nperformance gap on these two subsets where Large Language Models (LLMs) perform\nworse on commonsense-knowledge instances.\n","authors":["Quyet V. Do","Junze Li","Tung-Duong Vuong","Zhaowei Wang","Yangqiu Song","Xiaojuan Ma"],"pdf_url":"https://arxiv.org/pdf/2411.03964v1.pdf","comment":"Code and data will be released together with the next version of the\n  paper"},{"id":"http://arxiv.org/abs/2411.03962v1","updated":"2024-11-06T14:51:02Z","published":"2024-11-06T14:51:02Z","title":"How Does A Text Preprocessing Pipeline Affect Ontology Syntactic\n  Matching?","summary":"  The generic text preprocessing pipeline, comprising Tokenisation,\nNormalisation, Stop Words Removal, and Stemming/Lemmatisation, has been\nimplemented in many ontology matching (OM) systems. However, the lack of\nstandardisation in text preprocessing creates diversity in mapping results. In\nthis paper, we investigate the effect of the text preprocessing pipeline on OM\ntasks at syntactic levels. Our experiments on 8 Ontology Alignment Evaluation\nInitiative (OAEI) track repositories with 49 distinct alignments indicate: (1)\nTokenisation and Normalisation are currently more effective than Stop Words\nRemoval and Stemming/Lemmatisation; and (2) The selection of Lemmatisation and\nStemming is task-specific. We recommend standalone Lemmatisation or Stemming\nwith post-hoc corrections. We find that (3) Porter Stemmer and Snowball Stemmer\nperform better than Lancaster Stemmer; and that (4) Part-of-Speech (POS)\nTagging does not help Lemmatisation. To repair less effective Stop Words\nRemoval and Stemming/Lemmatisation used in OM tasks, we propose a novel\ncontext-based pipeline repair approach that significantly improves matching\ncorrectness and overall matching performance. We also discuss the use of text\npreprocessing pipeline in the new era of large language models (LLMs).\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03962v1.pdf","comment":"13 pages, 26 figures, 4 tables"},{"id":"http://arxiv.org/abs/2406.10149v2","updated":"2024-11-06T14:50:40Z","published":"2024-06-14T16:00:29Z","title":"BABILong: Testing the Limits of LLMs with Long Context\n  Reasoning-in-a-Haystack","summary":"  In recent years, the input context sizes of large language models (LLMs) have\nincreased dramatically. However, existing evaluation methods have not kept\npace, failing to comprehensively assess the efficiency of models in handling\nlong contexts. To bridge this gap, we introduce the BABILong benchmark,\ndesigned to test language models' ability to reason across facts distributed in\nextremely long documents. BABILong includes a diverse set of 20 reasoning\ntasks, including fact chaining, simple induction, deduction, counting, and\nhandling lists/sets. These tasks are challenging on their own, and even more\ndemanding when the required facts are scattered across long natural text. Our\nevaluations show that popular LLMs effectively utilize only 10-20\\% of the\ncontext and their performance declines sharply with increased reasoning\ncomplexity. Among alternatives to in-context reasoning, Retrieval-Augmented\nGeneration methods achieve a modest 60\\% accuracy on single-fact question\nanswering, independent of context length. Among context extension methods, the\nhighest performance is demonstrated by recurrent memory transformers after\nfine-tuning, enabling the processing of lengths up to 50 million tokens. The\nBABILong benchmark is extendable to any length to support the evaluation of new\nupcoming models with increased capabilities, and we provide splits up to 10\nmillion token lengths.\n","authors":["Yuri Kuratov","Aydar Bulatov","Petr Anokhin","Ivan Rodkin","Dmitry Sorokin","Artyom Sorokin","Mikhail Burtsev"],"pdf_url":"https://arxiv.org/pdf/2406.10149v2.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2410.12656v2","updated":"2024-11-06T14:14:58Z","published":"2024-10-16T15:17:20Z","title":"Evaluating Morphological Compositional Generalization in Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated significant progress in\nvarious natural language generation and understanding tasks. However, their\nlinguistic generalization capabilities remain questionable, raising doubts\nabout whether these models learn language similarly to humans. While humans\nexhibit compositional generalization and linguistic creativity in language use,\nthe extent to which LLMs replicate these abilities, particularly in morphology,\nis under-explored. In this work, we systematically investigate the\nmorphological generalization abilities of LLMs through the lens of\ncompositionality. We define morphemes as compositional primitives and design a\nnovel suite of generative and discriminative tasks to assess morphological\nproductivity and systematicity. Focusing on agglutinative languages such as\nTurkish and Finnish, we evaluate several state-of-the-art instruction-finetuned\nmultilingual models, including GPT-4 and Gemini. Our analysis shows that LLMs\nstruggle with morphological compositional generalization particularly when\napplied to novel word roots, with performance declining sharply as\nmorphological complexity increases. While models can identify individual\nmorphological combinations better than chance, their performance lacks\nsystematicity, leading to significant accuracy gaps compared to humans.\n","authors":["Mete Ismayilzada","Defne Circi","Jonne Sälevä","Hale Sirin","Abdullatif Köksal","Bhuwan Dhingra","Antoine Bosselut","Lonneke van der Plas","Duygu Ataman"],"pdf_url":"https://arxiv.org/pdf/2410.12656v2.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2411.03934v1","updated":"2024-11-06T14:11:39Z","published":"2024-11-06T14:11:39Z","title":"Interactions Across Blocks in Post-Training Quantization of Large\n  Language Models","summary":"  Post-training quantization is widely employed to reduce the computational\ndemands of neural networks. Typically, individual substructures, such as layers\nor blocks of layers, are quantized with the objective of minimizing\nquantization errors in their pre-activations by fine-tuning the corresponding\nweights. Deriving this local objective from the global objective of minimizing\ntask loss involves two key simplifications: assuming substructures are mutually\nindependent and ignoring the knowledge of subsequent substructures as well as\nthe task loss. In this work, we assess the effects of these simplifications on\nweight-only quantization of large language models. We introduce two multi-block\nfine-tuning strategies and compare them against the baseline of fine-tuning\nsingle transformer blocks. The first captures correlations of weights across\nblocks by jointly optimizing multiple quantized blocks. The second incorporates\nknowledge of subsequent blocks by minimizing the error in downstream\npre-activations rather than focusing solely on the quantized block. Our\nfindings indicate that the effectiveness of these methods depends on the\nspecific network model, with no impact on some models but demonstrating\nsignificant benefits for others.\n","authors":["Khasmamad Shabanovi","Lukas Wiest","Vladimir Golkov","Daniel Cremers","Thomas Pfeil"],"pdf_url":"https://arxiv.org/pdf/2411.03934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07001v4","updated":"2024-11-06T13:56:28Z","published":"2024-05-11T12:33:46Z","title":"ChartInsights: Evaluating Multimodal Large Language Models for Low-Level\n  Chart Question Answering","summary":"  Chart question answering (ChartQA) tasks play a critical role in interpreting\nand extracting insights from visualization charts. While recent advancements in\nmultimodal large language models (MLLMs) like GPT-4o have shown promise in\nhigh-level ChartQA tasks, such as chart captioning, their effectiveness in\nlow-level ChartQA tasks (e.g., identifying correlations) remains underexplored.\nIn this paper, we address this gap by evaluating MLLMs on low-level ChartQA\nusing a newly curated dataset, ChartInsights, which consists of 22,347 (chart,\ntask, query, answer) covering 10 data analysis tasks across 7 chart types. We\nsystematically evaluate 19 advanced MLLMs, including 12 open-source and 7\nclosed-source models. The average accuracy rate across these models is 39.8%,\nwith GPT-4o achieving the highest accuracy at 69.17%. To further explore the\nlimitations of MLLMs in low-level ChartQA, we conduct experiments that alter\nvisual elements of charts (e.g., changing color schemes, adding image noise) to\nassess their impact on the task effectiveness. Furthermore, we propose a new\ntextual prompt strategy, Chain-of-Charts, tailored for low-level ChartQA tasks,\nwhich boosts performance by 14.41%, achieving an accuracy of 83.58%. Finally,\nincorporating a visual prompt strategy that directs attention to relevant\nvisual elements further improves accuracy to 84.32%.\n","authors":["Yifan Wu","Lutao Yan","Leixian Shen","Yunhai Wang","Nan Tang","Yuyu Luo"],"pdf_url":"https://arxiv.org/pdf/2405.07001v4.pdf","comment":"EMNLP 2024 Conference Paper"},{"id":"http://arxiv.org/abs/2411.03923v1","updated":"2024-11-06T13:54:08Z","published":"2024-11-06T13:54:08Z","title":"Evaluation data contamination in LLMs: how do we measure it and (when)\n  does it matter?","summary":"  Hampering the interpretation of benchmark scores, evaluation data\ncontamination has become a growing concern in the evaluation of LLMs, and an\nactive area of research studies its effects. While evaluation data\ncontamination is easily understood intuitively, it is surprisingly difficult to\ndefine precisely which samples should be considered contaminated and,\nconsequently, how it impacts benchmark scores. We propose that these questions\nshould be addressed together and that contamination metrics can be assessed\nbased on whether models benefit from the examples they mark contaminated. We\npropose a novel analysis method called ConTAM, and show with a large scale\nsurvey of existing and novel n-gram based contamination metrics across 13\nbenchmarks and 7 models from 2 different families that ConTAM can be used to\nbetter understand evaluation data contamination and its effects. We find that\ncontamination may have a much larger effect than reported in recent LLM\nreleases and benefits models differently at different scales. We also find that\nconsidering only the longest contaminated substring provides a better signal\nthan considering a union of all contaminated substrings, and that doing model\nand benchmark specific threshold analysis greatly increases the specificity of\nthe results. Lastly, we investigate the impact of hyperparameter choices,\nfinding that, among other things, both using larger values of n and\ndisregarding matches that are infrequent in the pre-training data lead to many\nfalse negatives. With ConTAM, we provide a method to empirically ground\nevaluation data contamination metrics in downstream effects. With our\nexploration, we shed light on how evaluation data contamination can impact LLMs\nand provide insight into the considerations important when doing contamination\nanalysis. We end our paper by discussing these in more detail and providing\nconcrete suggestions for future work.\n","authors":["Aaditya K. Singh","Muhammed Yusuf Kocyigit","Andrew Poulton","David Esiobu","Maria Lomeli","Gergely Szilvasy","Dieuwke Hupkes"],"pdf_url":"https://arxiv.org/pdf/2411.03923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03920v1","updated":"2024-11-06T13:51:42Z","published":"2024-11-06T13:51:42Z","title":"RAGulator: Lightweight Out-of-Context Detectors for Grounded Text\n  Generation","summary":"  Real-time detection of out-of-context LLM outputs is crucial for enterprises\nlooking to safely adopt RAG applications. In this work, we train lightweight\nmodels to discriminate LLM-generated text that is semantically out-of-context\nfrom retrieved text documents. We preprocess a combination of summarisation and\nsemantic textual similarity datasets to construct training data using minimal\nresources. We find that DeBERTa is not only the best-performing model under\nthis pipeline, but it is also fast and does not require additional text\npreprocessing or feature engineering. While emerging work demonstrates that\ngenerative LLMs can also be fine-tuned and used in complex data pipelines to\nachieve state-of-the-art performance, we note that speed and resource limits\nare important considerations for on-premise deployment.\n","authors":["Ian Poey","Jiajun Liu","Qishuai Zhong","Adrien Chenailler"],"pdf_url":"https://arxiv.org/pdf/2411.03920v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02937v2","updated":"2024-11-06T13:40:25Z","published":"2024-11-05T09:27:21Z","title":"Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA\n  Dataset and Self-adaptive Planning Agent","summary":"  Multimodal Retrieval Augmented Generation (mRAG) plays an important role in\nmitigating the \"hallucination\" issue inherent in multimodal large language\nmodels (MLLMs). Although promising, existing heuristic mRAGs typically\npredefined fixed retrieval processes, which causes two issues: (1) Non-adaptive\nRetrieval Queries. (2) Overloaded Retrieval Queries. However, these flaws\ncannot be adequately reflected by current knowledge-seeking visual question\nanswering (VQA) datasets, since the most required knowledge can be readily\nobtained with a standard two-step retrieval. To bridge the dataset gap, we\nfirst construct Dyn-VQA dataset, consisting of three types of \"dynamic\"\nquestions, which require complex knowledge retrieval strategies variable in\nquery, tool, and time: (1) Questions with rapidly changing answers. (2)\nQuestions requiring multi-modal knowledge. (3) Multi-hop questions. Experiments\non Dyn-VQA reveal that existing heuristic mRAGs struggle to provide sufficient\nand precisely relevant knowledge for dynamic questions due to their rigid\nretrieval processes. Hence, we further propose the first self-adaptive planning\nagent for multimodal retrieval, OmniSearch. The underlying idea is to emulate\nthe human behavior in question solution which dynamically decomposes complex\nmultimodal questions into sub-question chains with retrieval action. Extensive\nexperiments prove the effectiveness of our OmniSearch, also provide direction\nfor advancing mRAG. The code and dataset will be open-sourced at\nhttps://github.com/Alibaba-NLP/OmniSearch.\n","authors":["Yangning Li","Yinghui Li","Xinyu Wang","Yong Jiang","Zhen Zhang","Xinran Zheng","Hui Wang","Hai-Tao Zheng","Pengjun Xie","Philip S. Yu","Fei Huang","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.02937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03906v1","updated":"2024-11-06T13:37:28Z","published":"2024-11-06T13:37:28Z","title":"Lexicalization Is All You Need: Examining the Impact of Lexical\n  Knowledge in a Compositional QALD System","summary":"  In this paper, we examine the impact of lexicalization on Question Answering\nover Linked Data (QALD). It is well known that one of the key challenges in\ninterpreting natural language questions with respect to SPARQL lies in bridging\nthe lexical gap, that is mapping the words in the query to the correct\nvocabulary elements. We argue in this paper that lexicalization, that is\nexplicit knowledge about the potential interpretations of a word with respect\nto the given vocabulary, significantly eases the task and increases the\nperformance of QA systems. Towards this goal, we present a compositional QA\nsystem that can leverage explicit lexical knowledge in a compositional manner\nto infer the meaning of a question in terms of a SPARQL query. We show that\nsuch a system, given lexical knowledge, has a performance well beyond current\nQA systems, achieving up to a $35.8\\%$ increase in the micro $F_1$ score\ncompared to the best QA system on QALD-9. This shows the importance and\npotential of including explicit lexical knowledge. In contrast, we show that\nLLMs have limited abilities to exploit lexical knowledge, with only marginal\nimprovements compared to a version without lexical knowledge. This shows that\nLLMs have no ability to compositionally interpret a question on the basis of\nthe meaning of its parts, a key feature of compositional approaches. Taken\ntogether, our work shows new avenues for QALD research, emphasizing the\nimportance of lexicalization and compositionality.\n","authors":["David Maria Schmidt","Mohammad Fazleh Elahi","Philipp Cimiano"],"pdf_url":"https://arxiv.org/pdf/2411.03906v1.pdf","comment":"24th International Conference on Knowledge Engineering and Knowledge\n  Management (EKAW 2024), November 26-28, 2024, Amsterdam, The Netherlands"},{"id":"http://arxiv.org/abs/2411.03895v1","updated":"2024-11-06T13:13:33Z","published":"2024-11-06T13:13:33Z","title":"Computational Analysis of Gender Depiction in the Comedias of Calderón\n  de la Barca","summary":"  In theatre, playwrights use the portrayal of characters to explore culturally\nbased gender norms. In this paper, we develop quantitative methods to study\ngender depiction in the non-religious works (comedias) of Pedro Calder\\'on de\nla Barca, a prolific Spanish 17th century author. We gather insights from a\ncorpus of more than 100 plays by using a gender classifier and applying model\nexplainability (attribution) methods to determine which text features are most\ninfluential in the model's decision to classify speech as 'male' or 'female',\nindicating the most gendered elements of dialogue in Calder\\'on's comedias in a\nhuman accessible manner. We find that female and male characters are portrayed\ndifferently and can be identified by the gender prediction model at practically\nuseful accuracies (up to f=0.83). Analysis reveals semantic aspects of gender\nportrayal, and demonstrates that the model is even useful in providing a\nrelatively accurate scene-by-scene prediction of cross-dressing characters.\n","authors":["Allison Keith","Antonio Rojas Castro","Sebastian Padó"],"pdf_url":"https://arxiv.org/pdf/2411.03895v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03888v1","updated":"2024-11-06T13:06:43Z","published":"2024-11-06T13:06:43Z","title":"Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech\n  Detection with Vision-Language Models","summary":"  Warning: this paper contains content that may be offensive or upsetting\n  Hate speech moderation on global platforms poses unique challenges due to the\nmultimodal and multilingual nature of content, along with the varying cultural\nperceptions. How well do current vision-language models (VLMs) navigate these\nnuances? To investigate this, we create the first multimodal and multilingual\nparallel hate speech dataset, annotated by a multicultural set of annotators,\ncalled Multi3Hate. It contains 300 parallel meme samples across 5 languages:\nEnglish, German, Spanish, Hindi, and Mandarin. We demonstrate that cultural\nbackground significantly affects multimodal hate speech annotation in our\ndataset. The average pairwise agreement among countries is just 74%,\nsignificantly lower than that of randomly selected annotator groups. Our\nqualitative analysis indicates that the lowest pairwise label agreement-only\n67% between the USA and India-can be attributed to cultural factors. We then\nconduct experiments with 5 large VLMs in a zero-shot setting, finding that\nthese models align more closely with annotations from the US than with those\nfrom other cultures, even when the memes and prompts are presented in the\ndominant language of the other culture. Code and dataset are available at\nhttps://github.com/MinhDucBui/Multi3Hate.\n","authors":["Minh Duc Bui","Katharina von der Wense","Anne Lauscher"],"pdf_url":"https://arxiv.org/pdf/2411.03888v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.20746v3","updated":"2024-11-06T13:05:51Z","published":"2024-10-28T05:25:50Z","title":"ElectionSim: Massive Population Election Simulation Powered by Large\n  Language Model Driven Agents","summary":"  The massive population election simulation aims to model the preferences of\nspecific groups in particular election scenarios. It has garnered significant\nattention for its potential to forecast real-world social trends. Traditional\nagent-based modeling (ABM) methods are constrained by their ability to\nincorporate complex individual background information and provide interactive\nprediction results. In this paper, we introduce ElectionSim, an innovative\nelection simulation framework based on large language models, designed to\nsupport accurate voter simulations and customized distributions, together with\nan interactive platform to dialogue with simulated voters. We present a\nmillion-level voter pool sampled from social media platforms to support\naccurate individual simulation. We also introduce PPE, a poll-based\npresidential election benchmark to assess the performance of our framework\nunder the U.S. presidential election scenario. Through extensive experiments\nand analyses, we demonstrate the effectiveness and robustness of our framework\nin U.S. presidential election simulations.\n","authors":["Xinnong Zhang","Jiayu Lin","Libo Sun","Weihong Qi","Yihang Yang","Yue Chen","Hanjia Lyu","Xinyi Mou","Siming Chen","Jiebo Luo","Xuanjing Huang","Shiping Tang","Zhongyu Wei"],"pdf_url":"https://arxiv.org/pdf/2410.20746v3.pdf","comment":"42 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.03884v1","updated":"2024-11-06T13:00:34Z","published":"2024-11-06T13:00:34Z","title":"Polynomial Composition Activations: Unleashing the Dynamics of Large\n  Language Models","summary":"  Transformers have found extensive applications across various domains due to\nthe powerful fitting capabilities. This success can be partially attributed to\ntheir inherent nonlinearity. Thus, in addition to the ReLU function employed in\nthe original transformer architecture, researchers have explored alternative\nmodules such as GeLU and SwishGLU to enhance nonlinearity and thereby augment\nrepresentational capacity. In this paper, we propose a novel category of\npolynomial composition activations (PolyCom), designed to optimize the dynamics\nof transformers. Theoretically, we provide a comprehensive mathematical\nanalysis of PolyCom, highlighting its enhanced expressivity and efficacy\nrelative to other activation functions. Notably, we demonstrate that networks\nincorporating PolyCom achieve the $\\textbf{optimal approximation rate}$,\nindicating that PolyCom networks require minimal parameters to approximate\ngeneral smooth functions in Sobolev spaces. We conduct empirical experiments on\nthe pre-training configurations of large language models (LLMs), including both\ndense and sparse architectures. By substituting conventional activation\nfunctions with PolyCom, we enable LLMs to capture higher-order interactions\nwithin the data, thus improving performance metrics in terms of accuracy and\nconvergence rates. Extensive experimental results demonstrate the effectiveness\nof our method, showing substantial improvements over other activation\nfunctions. Code is available at https://github.com/BryceZhuo/PolyCom.\n","authors":["Zhijian Zhuo","Ya Wang","Yutao Zeng","Xiaoqing Li","Xun Zhou","Jinwen Ma"],"pdf_url":"https://arxiv.org/pdf/2411.03884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03883v1","updated":"2024-11-06T12:57:58Z","published":"2024-11-06T12:57:58Z","title":"MEG: Medical Knowledge-Augmented Large Language Models for Question\n  Answering","summary":"  Question answering is a natural language understanding task that involves\nreasoning over both explicit context and unstated, relevant domain knowledge.\nLarge language models (LLMs), which underpin most contemporary question\nanswering systems, struggle to induce how concepts relate in specialized\ndomains such as medicine. Existing medical LLMs are also costly to train. In\nthis work, we present MEG, a parameter-efficient approach for medical\nknowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate\ngraph embeddings into the LLM, enabling it to leverage external knowledge in a\ncost-effective way. We evaluate our method on four popular medical\nmultiple-choice datasets and show that LLMs greatly benefit from the factual\ngrounding provided by knowledge graph embeddings. MEG attains an average of\n+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized\nmodels like BioMistral. We also show results based on Llama-3. Finally, we show\nthat MEG's performance remains robust to the choice of graph encoder.\n","authors":["Laura Cabello","Carmen Martin-Turrero","Uchenna Akujuobi","Anders Søgaard","Carlos Bobed"],"pdf_url":"https://arxiv.org/pdf/2411.03883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10499v3","updated":"2024-11-06T12:35:37Z","published":"2024-07-15T07:43:55Z","title":"CIBench: Evaluating Your LLMs with a Code Interpreter Plugin","summary":"  While LLM-Based agents, which use external tools to solve complex problems,\nhave made significant progress, benchmarking their ability is challenging,\nthereby hindering a clear understanding of their limitations. In this paper, we\npropose an interactive evaluation framework, named CIBench, to comprehensively\nassess LLMs' ability to utilize code interpreters for data science tasks. Our\nevaluation framework includes an evaluation dataset and two evaluation modes.\nThe evaluation dataset is constructed using an LLM-human cooperative approach\nand simulates an authentic workflow by leveraging consecutive and interactive\nIPython sessions. The two evaluation modes assess LLMs' ability with and\nwithout human assistance. We conduct extensive experiments to analyze the\nability of 24 LLMs on CIBench and provide valuable insights for future LLMs in\ncode interpreter utilization.\n","authors":["Chuyu Zhang","Songyang Zhang","Yingfan Hu","Haowen Shen","Kuikun Liu","Zerun Ma","Fengzhe Zhou","Wenwei Zhang","Xuming He","Dahua Lin","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2407.10499v3.pdf","comment":"Under review. The first three authors contribute equally, and\n  Songyang Zhang is the project leader"},{"id":"http://arxiv.org/abs/2411.03866v1","updated":"2024-11-06T12:22:04Z","published":"2024-11-06T12:22:04Z","title":"Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the\n  Way Forward","summary":"  Recent research has demonstrated that training a linear connector between\nspeech foundation encoders and large language models (LLMs) enables this\narchitecture to achieve strong ASR capabilities. Despite the impressive\nresults, it remains unclear whether these simple approaches are robust enough\nacross different scenarios and speech conditions, such as domain shifts and\ndifferent speech perturbations. In this paper, we address these questions by\nconducting various ablation experiments using a recent and widely adopted\napproach called SLAM-ASR. We present novel empirical findings that offer\ninsights on how to effectively utilize the SLAM-ASR architecture across a wide\nrange of settings. Our main findings indicate that the SLAM-ASR exhibits poor\nperformance in cross-domain evaluation settings. Additionally, speech\nperturbations within in-domain data, such as changes in speed or the presence\nof additive noise, can significantly impact performance. Our findings offer\ncritical insights for fine-tuning and configuring robust LLM-based ASR models,\ntailored to different data characteristics and computational resources.\n","authors":["Shashi Kumar","Iuliia Thorbecke","Sergio Burdisso","Esaú Villatoro-Tello","Manjunath K E","Kadri Hacioğlu","Pradeep Rangappa","Petr Motlicek","Aravind Ganapathiraju","Andreas Stolcke"],"pdf_url":"https://arxiv.org/pdf/2411.03866v1.pdf","comment":"Submitted to ICASSP 2025 SALMA Workshop"},{"id":"http://arxiv.org/abs/2404.01204v3","updated":"2024-11-06T12:02:52Z","published":"2024-04-01T16:00:01Z","title":"The Fine Line: Navigating Large Language Model Pretraining with\n  Down-streaming Capability Analysis","summary":"  Uncovering early-stage metrics that reflect final model performance is one\ncore principle for large-scale pretraining. The existing scaling law\ndemonstrates the power-law correlation between pretraining loss and training\nflops, which serves as an important indicator of the current training state for\nlarge language models. However, this principle only focuses on the model's\ncompression properties on the training data, resulting in an inconsistency with\nthe ability improvements on the downstream tasks. Some follow-up works\nattempted to extend the scaling-law to more complex metrics (such as\nhyperparameters), but still lacked a comprehensive analysis of the dynamic\ndifferences among various capabilities during pretraining. To address the\naforementioned limitations, this paper undertakes a comprehensive comparison of\nmodel capabilities at various pretraining intermediate checkpoints. Through\nthis analysis, we confirm that specific downstream metrics exhibit similar\ntraining dynamics across models of different sizes, up to 67 billion\nparameters. In addition to our core findings, we've reproduced Amber and\nOpenLLaMA, releasing their intermediate checkpoints. This initiative offers\nvaluable resources to the research community and facilitates the verification\nand exploration of LLM pretraining by open-source researchers. Besides, we\nprovide empirical summaries, including performance comparisons of different\nmodels and capabilities, and tuition of key metrics for different training\nphases. Based on these findings, we provide a more user-friendly strategy for\nevaluating the optimization state, offering guidance for establishing a stable\npretraining process.\n","authors":["Chen Yang","Junzhuo Li","Xinyao Niu","Xinrun Du","Songyang Gao","Haoran Zhang","Zhaoliang Chen","Xingwei Qu","Ruibin Yuan","Yizhi Li","Jiaheng Liu","Stephen W. Huang","Shawn Yue","Ge Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.01204v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03855v1","updated":"2024-11-06T11:57:55Z","published":"2024-11-06T11:57:55Z","title":"MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba","summary":"  An ecosystem of Transformer-based models has been established by building\nlarge models with extensive data. Parameter-efficient fine-tuning (PEFT) is a\ncrucial technology for deploying these models to downstream tasks with minimal\ncost while achieving effective performance. Recently, Mamba, a State Space\nModel (SSM)-based model, has attracted attention as a potential alternative to\nTransformers. While many large-scale Mamba-based models have been proposed,\nefficiently adapting pre-trained Mamba-based models to downstream tasks remains\nunexplored. In this paper, we conduct an exploratory analysis of PEFT methods\nfor Mamba. We investigate the effectiveness of existing PEFT methods for\nTransformers when applied to Mamba. We also modify these methods to better\nalign with the Mamba architecture. Additionally, we propose new Mamba-specific\nPEFT methods that leverage the distinctive structure of Mamba. Our experiments\nindicate that PEFT performs more effectively for Mamba than Transformers.\nLastly, we demonstrate how to effectively combine multiple PEFT methods and\nprovide a framework that outperforms previous works. To ensure reproducibility,\nwe will release the code after publication.\n","authors":["Masakazu Yoshimura","Teruaki Hayashi","Yota Maeda"],"pdf_url":"https://arxiv.org/pdf/2411.03855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19453v2","updated":"2024-11-06T11:49:10Z","published":"2024-10-25T10:28:59Z","title":"ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based\n  Contrastive Framework","summary":"  Although fine-tuning Large Language Models (LLMs) with multilingual data can\nrapidly enhance the multilingual capabilities of LLMs, they still exhibit a\nperformance gap between the dominant language (e.g., English) and non-dominant\nones due to the imbalance of training data across languages. To further enhance\nthe performance of non-dominant languages, we propose ShifCon, a Shift-based\nContrastive framework that aligns the internal forward process of other\nlanguages toward that of the dominant one. Specifically, it shifts the\nrepresentations of non-dominant languages into the dominant language subspace,\nallowing them to access relatively rich information encoded in the model\nparameters. The enriched representations are then shifted back into their\noriginal language subspace before generation. Moreover, we introduce a subspace\ndistance metric to pinpoint the optimal layer area for shifting representations\nand employ multilingual contrastive learning to further enhance the alignment\nof representations within this area. Experiments demonstrate that our ShifCon\nframework significantly enhances the performance of non-dominant languages,\nparticularly for low-resource ones. Further analysis offers extra insights to\nverify the effectiveness of ShifCon and propel future research\n","authors":["Hengyuan Zhang","Chenming Shang","Sizhe Wang","Dongdong Zhang","Renliang Sun","Yiyao Yu","Yujiu Yang","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2410.19453v2.pdf","comment":"23 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.02832v2","updated":"2024-11-06T11:19:42Z","published":"2024-11-05T06:11:17Z","title":"PersianRAG: A Retrieval-Augmented Generation System for Persian Language","summary":"  Retrieval augmented generation (RAG) models, which integrate large-scale\npre-trained generative models with external retrieval mechanisms, have shown\nsignificant success in various natural language processing (NLP) tasks.\nHowever, applying RAG models in Persian language as a low-resource language,\nposes distinct challenges. These challenges primarily involve the\npreprocessing, embedding, retrieval, prompt construction, language modeling,\nand response evaluation of the system. In this paper, we address the challenges\ntowards implementing a real-world RAG system for Persian language called\nPersianRAG. We propose novel solutions to overcome these obstacles and evaluate\nour approach using several Persian benchmark datasets. Our experimental results\ndemonstrate the capability of the PersianRAG framework to enhance question\nanswering task in Persian.\n","authors":["Hossein Hosseini","Mohammad Sobhan Zare","Amir Hossein Mohammadi","Arefeh Kazemi","Zahra Zojaji","Mohammad Ali Nematbakhsh"],"pdf_url":"https://arxiv.org/pdf/2411.02832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01192v2","updated":"2024-11-06T11:19:01Z","published":"2024-11-02T09:39:49Z","title":"Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and\n  Cross-Cultural Embedding Models and Benchmarks","summary":"  We introduce {\\bf Swan}, a family of embedding models centred around the\nArabic language, addressing both small-scale and large-scale use cases. Swan\nincludes two variants: Swan-Small, based on ARBERTv2, and Swan-Large, built on\nArMistral, a pretrained Arabic large language model. To evaluate these models,\nwe propose ArabicMTEB, a comprehensive benchmark suite that assesses\ncross-lingual, multi-dialectal, multi-domain, and multi-cultural Arabic text\nembedding performance, covering eight diverse tasks and spanning 94 datasets.\nSwan-Large achieves state-of-the-art results, outperforming\nMultilingual-E5-large in most Arabic tasks, while the Swan-Small consistently\nsurpasses Multilingual-E5-base. Our extensive evaluations demonstrate that Swan\nmodels are both dialectally and culturally aware, excelling across various\nArabic domains while offering significant monetary efficiency. This work\nsignificantly advances the field of Arabic language modelling and provides\nvaluable resources for future research and applications in Arabic natural\nlanguage processing. Our models and benchmark will be made publicly accessible\nfor research.\n","authors":["Gagan Bhatia","El Moatez Billah Nagoudi","Abdellah El Mekki","Fakhraddin Alwajih","Muhammad Abdul-Mageed"],"pdf_url":"https://arxiv.org/pdf/2411.01192v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03817v1","updated":"2024-11-06T10:35:11Z","published":"2024-11-06T10:35:11Z","title":"From Novice to Expert: LLM Agent Policy Optimization via Step-wise\n  Reinforcement Learning","summary":"  The outstanding capabilities of large language models (LLMs) render them a\ncrucial component in various autonomous agent systems. While traditional\nmethods depend on the inherent knowledge of LLMs without fine-tuning, more\nrecent approaches have shifted toward the reinforcement learning strategy to\nfurther enhance agents' ability to solve complex interactive tasks with\nenvironments and tools. However, previous approaches are constrained by the\nsparse reward issue, where existing datasets solely provide a final scalar\nreward for each multi-step reasoning chain, potentially leading to\nineffectiveness and inefficiency in policy learning. In this paper, we\nintroduce StepAgent, which utilizes step-wise reward to optimize the agent's\nreinforcement learning process. Inheriting the spirit of novice-to-expert\ntheory, we first compare the actions of the expert and the agent to\nautomatically generate intermediate rewards for fine-grained optimization.\nAdditionally, we propose implicit-reward and inverse reinforcement learning\ntechniques to facilitate agent reflection and policy adjustment. Further\ntheoretical analysis demonstrates that the action distribution of the agent can\nconverge toward the expert action distribution over multiple training cycles.\nExperimental results across various datasets indicate that StepAgent\noutperforms existing baseline methods.\n","authors":["Zhirui Deng","Zhicheng Dou","Yutao Zhu","Ji-Rong Wen","Ruibin Xiong","Mang Wang","Weipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2411.03817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03814v1","updated":"2024-11-06T10:32:09Z","published":"2024-11-06T10:32:09Z","title":"MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue","summary":"  Large Language Models (LLMs) demonstrate outstanding performance in their\nreservoir of knowledge and understanding capabilities, but they have also been\nshown to be prone to illegal or unethical reactions when subjected to jailbreak\nattacks. To ensure their responsible deployment in critical applications, it is\ncrucial to understand the safety capabilities and vulnerabilities of LLMs.\nPrevious works mainly focus on jailbreak in single-round dialogue, overlooking\nthe potential jailbreak risks in multi-round dialogues, which are a vital way\nhumans interact with and extract information from LLMs. Some studies have\nincreasingly concentrated on the risks associated with jailbreak in multi-round\ndialogues. These efforts typically involve the use of manually crafted\ntemplates or prompt engineering techniques. However, due to the inherent\ncomplexity of multi-round dialogues, their jailbreak performance is limited. To\nsolve this problem, we propose a novel multi-round dialogue jailbreaking agent,\nemphasizing the importance of stealthiness in identifying and mitigating\npotential threats to human values posed by LLMs. We propose a risk\ndecomposition strategy that distributes risks across multiple rounds of queries\nand utilizes psychological strategies to enhance attack strength. Extensive\nexperiments show that our proposed method surpasses other attack methods and\nachieves state-of-the-art attack success rate. We will make the corresponding\ncode and dataset available for future research. The code will be released soon.\n","authors":["Fengxiang Wang","Ranjie Duan","Peng Xiao","Xiaojun Jia","YueFeng Chen","Chongwen Wang","Jialing Tao","Hang Su","Jun Zhu","Hui Xue"],"pdf_url":"https://arxiv.org/pdf/2411.03814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18680v3","updated":"2024-11-06T10:27:05Z","published":"2024-09-27T12:06:53Z","title":"Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large\n  Language Models","summary":"  Various audio-LLMs (ALLMs) have been explored recently for tackling different\naudio tasks simultaneously using a single, unified model. While existing\nevaluations of ALLMs primarily focus on single-audio tasks, real-world\napplications often involve processing multiple audio streams simultaneously. To\nbridge this gap, we propose the first multi-audio evaluation (MAE) benchmark\nthat consists of 20 datasets from 11 multi-audio tasks encompassing both speech\nand sound scenarios. Comprehensive experiments on MAE demonstrate that the\nexisting ALLMs, while being powerful in comprehending primary audio elements in\nindividual audio inputs, struggling to handle multi-audio scenarios. To this\nend, we propose a novel multi-audio-LLM (MALLM) to capture audio context among\nmultiple similar audios using discriminative learning on our proposed synthetic\ndata. The results demonstrate that the proposed MALLM outperforms all baselines\nand achieves high data efficiency using synthetic data without requiring human\nannotations. The proposed MALLM opens the door for ALLMs towards multi-audio\nprocessing era and brings us closer to replicating human auditory capabilities\nin machines.\n","authors":["Yiming Chen","Xianghu Yue","Xiaoxue Gao","Chen Zhang","Luis Fernando D'Haro","Robby T. Tan","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2409.18680v3.pdf","comment":"EMNLP24 Findings. Data available at\n  https://github.com/MatthewCYM/MALLM"},{"id":"http://arxiv.org/abs/2411.03811v1","updated":"2024-11-06T10:14:58Z","published":"2024-11-06T10:14:58Z","title":"The natural stability of autonomous morphology","summary":"  Autonomous morphology, such as inflection class systems and paradigmatic\ndistribution patterns, is widespread and diachronically resilient in natural\nlanguage. Why this should be so has remained unclear given that autonomous\nmorphology imposes learning costs, offers no clear benefit relative to its\nabsence and could easily be removed by the analogical forces which are\nconstantly reshaping it. Here we propose an explanation for the resilience of\nautonomous morphology, in terms of a diachronic dynamic of attraction and\nrepulsion between morphomic categories, which emerges spontaneously from a\nsimple paradigm cell filling process. Employing computational evolutionary\nmodels, our key innovation is to bring to light the role of `dissociative\nevidence', i.e., evidence for inflectional distinctiveness which a rational\nreasoner will have access to during analogical inference. Dissociative evidence\ncreates a repulsion dynamic which prevents morphomic classes from collapsing\ntogether entirely, i.e., undergoing complete levelling. As we probe alternative\nmodels, we reveal the limits of conditional entropy as a measure for\npredictability in systems that are undergoing change. Finally, we demonstrate\nthat autonomous morphology, far from being `unnatural' (e.g.\n\\citealt{Aronoff1994}), is rather the natural (emergent) consequence of a\nnatural (rational) process of inference applied to inflectional systems.\n","authors":["Erich Round","Louise Esher","Sacha Beniamine"],"pdf_url":"https://arxiv.org/pdf/2411.03811v1.pdf","comment":"Accepted for publication by the journal Morphology"},{"id":"http://arxiv.org/abs/2411.03806v1","updated":"2024-11-06T10:06:21Z","published":"2024-11-06T10:06:21Z","title":"Understanding the Effects of Human-written Paraphrases in LLM-generated\n  Text Detection","summary":"  Natural Language Generation has been rapidly developing with the advent of\nlarge language models (LLMs). While their usage has sparked significant\nattention from the general public, it is important for readers to be aware when\na piece of text is LLM-generated. This has brought about the need for building\nmodels that enable automated LLM-generated text detection, with the aim of\nmitigating potential negative outcomes of such content. Existing LLM-generated\ndetectors show competitive performances in telling apart LLM-generated and\nhuman-written text, but this performance is likely to deteriorate when\nparaphrased texts are considered. In this study, we devise a new data\ncollection strategy to collect Human & LLM Paraphrase Collection (HLPC), a\nfirst-of-its-kind dataset that incorporates human-written texts and\nparaphrases, as well as LLM-generated texts and paraphrases. With the aim of\nunderstanding the effects of human-written paraphrases on the performance of\nstate-of-the-art LLM-generated text detectors OpenAI RoBERTa and watermark\ndetectors, we perform classification experiments that incorporate human-written\nparaphrases, watermarked and non-watermarked LLM-generated documents from GPT\nand OPT, and LLM-generated paraphrases from DIPPER and BART. The results show\nthat the inclusion of human-written paraphrases has a significant impact of\nLLM-generated detector performance, promoting TPR@1%FPR with a possible\ntrade-off of AUROC and accuracy.\n","authors":["Hiu Ting Lau","Arkaitz Zubiaga"],"pdf_url":"https://arxiv.org/pdf/2411.03806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03805v1","updated":"2024-11-06T10:02:50Z","published":"2024-11-06T10:02:50Z","title":"A Comparative Study of Recent Large Language Models on Generating\n  Hospital Discharge Summaries for Lung Cancer Patients","summary":"  Generating discharge summaries is a crucial yet time-consuming task in\nclinical practice, essential for conveying pertinent patient information and\nfacilitating continuity of care. Recent advancements in large language models\n(LLMs) have significantly enhanced their capability in understanding and\nsummarizing complex medical texts. This research aims to explore how LLMs can\nalleviate the burden of manual summarization, streamline workflow efficiencies,\nand support informed decision-making in healthcare settings. Clinical notes\nfrom a cohort of 1,099 lung cancer patients were utilized, with a subset of 50\npatients for testing purposes, and 102 patients used for model fine-tuning.\nThis study evaluates the performance of multiple LLMs, including GPT-3.5,\nGPT-4, GPT-4o, and LLaMA 3 8b, in generating discharge summaries. Evaluation\nmetrics included token-level analysis (BLEU, ROUGE-1, ROUGE-2, ROUGE-L) and\nsemantic similarity scores between model-generated summaries and\nphysician-written gold standards. LLaMA 3 8b was further tested on clinical\nnotes of varying lengths to examine the stability of its performance. The study\nfound notable variations in summarization capabilities among LLMs. GPT-4o and\nfine-tuned LLaMA 3 demonstrated superior token-level evaluation metrics, while\nLLaMA 3 consistently produced concise summaries across different input lengths.\nSemantic similarity scores indicated GPT-4o and LLaMA 3 as leading models in\ncapturing clinical relevance. This study contributes insights into the efficacy\nof LLMs for generating discharge summaries, highlighting LLaMA 3's robust\nperformance in maintaining clarity and relevance across varying clinical\ncontexts. These findings underscore the potential of automated summarization\ntools to enhance documentation precision and efficiency, ultimately improving\npatient care and operational capability in healthcare settings.\n","authors":["Yiming Li","Fang Li","Kirk Roberts","Licong Cui","Cui Tao","Hua Xu"],"pdf_url":"https://arxiv.org/pdf/2411.03805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15306v3","updated":"2024-11-06T09:49:31Z","published":"2024-05-24T07:48:35Z","title":"DeTikZify: Synthesizing Graphics Programs for Scientific Figures and\n  Sketches with TikZ","summary":"  Creating high-quality scientific figures can be time-consuming and\nchallenging, even though sketching ideas on paper is relatively easy.\nFurthermore, recreating existing figures that are not stored in formats\npreserving semantic information is equally complex. To tackle this problem, we\nintroduce DeTikZify, a novel multimodal language model that automatically\nsynthesizes scientific figures as semantics-preserving TikZ graphics programs\nbased on sketches and existing figures. To achieve this, we create three new\ndatasets: DaTikZv2, the largest TikZ dataset to date, containing over 360k\nhuman-created TikZ graphics; SketchFig, a dataset that pairs hand-drawn\nsketches with their corresponding scientific figures; and MetaFig, a collection\nof diverse scientific figures and associated metadata. We train DeTikZify on\nMetaFig and DaTikZv2, along with synthetically generated sketches learned from\nSketchFig. We also introduce an MCTS-based inference algorithm that enables\nDeTikZify to iteratively refine its outputs without the need for additional\ntraining. Through both automatic and human evaluation, we demonstrate that\nDeTikZify outperforms commercial Claude 3 and GPT-4V in synthesizing TikZ\nprograms, with the MCTS algorithm effectively boosting its performance. We make\nour code, models, and datasets publicly available.\n","authors":["Jonas Belouadi","Simone Paolo Ponzetto","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2405.15306v3.pdf","comment":"Accepted at NeurIPS 2024 (spotlight); Project page:\n  https://github.com/potamides/DeTikZify"},{"id":"http://arxiv.org/abs/2411.03039v2","updated":"2024-11-06T09:28:25Z","published":"2024-11-05T12:22:51Z","title":"Self-Compositional Data Augmentation for Scientific Keyphrase Generation","summary":"  State-of-the-art models for keyphrase generation require large amounts of\ntraining data to achieve good performance. However, obtaining keyphrase-labeled\ndocuments can be challenging and costly. To address this issue, we present a\nself-compositional data augmentation method. More specifically, we measure the\nrelatedness of training documents based on their shared keyphrases, and combine\nsimilar documents to generate synthetic samples. The advantage of our method\nlies in its ability to create additional training samples that keep domain\ncoherence, without relying on external data or resources. Our results on\nmultiple datasets spanning three different domains, demonstrate that our method\nconsistently improves keyphrase generation. A qualitative analysis of the\ngenerated keyphrases for the Computer Science domain confirms this improvement\ntowards their representativity property.\n","authors":["Mael Houbre","Florian Boudin","Beatrice Daille","Akiko Aizawa"],"pdf_url":"https://arxiv.org/pdf/2411.03039v2.pdf","comment":"Accepted to JCDL 2024. This is the author's version of the work. It\n  is posted here for your personal use. Not for redistribution. The definitive\n  version was published in the proceedings of the 2024 ACM/IEEE Joint\n  Conference on Digital Libraries (JCDL 24)\n  https://doi.org/10.1145/3677389.3702504"},{"id":"http://arxiv.org/abs/2411.02265v3","updated":"2024-11-06T09:15:27Z","published":"2024-11-04T16:56:26Z","title":"Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated\n  Parameters by Tencent","summary":"  In this paper, we introduce Hunyuan-Large, which is currently the largest\nopen-source Transformer-based mixture of experts model, with a total of 389\nbillion parameters and 52 billion activation parameters, capable of handling up\nto 256K tokens. We conduct a thorough evaluation of Hunyuan-Large's superior\nperformance across various benchmarks including language understanding and\ngeneration, logical reasoning, mathematical problem-solving, coding,\nlong-context, and aggregated tasks, where it outperforms LLama3.1-70B and\nexhibits comparable performance when compared to the significantly larger\nLLama3.1-405B model. Key practice of Hunyuan-Large include large-scale\nsynthetic data that is orders larger than in previous literature, a mixed\nexpert routing strategy, a key-value cache compression technique, and an\nexpert-specific learning rate strategy. Additionally, we also investigate the\nscaling laws and learning rate schedule of mixture of experts models, providing\nvaluable insights and guidances for future model development and optimization.\nThe code and checkpoints of Hunyuan-Large are released to facilitate future\ninnovations and applications.\n  Codes: https://github.com/Tencent/Hunyuan-Large\n  Models: https://huggingface.co/tencent/Tencent-Hunyuan-Large\n","authors":["Xingwu Sun","Yanfeng Chen","Yiqing Huang","Ruobing Xie","Jiaqi Zhu","Kai Zhang","Shuaipeng Li","Zhen Yang","Jonny Han","Xiaobo Shu","Jiahao Bu","Zhongzhi Chen","Xuemeng Huang","Fengzong Lian","Saiyong Yang","Jianfeng Yan","Yuyuan Zeng","Xiaoqin Ren","Chao Yu","Lulu Wu","Yue Mao","Jun Xia","Tao Yang","Suncong Zheng","Kan Wu","Dian Jiao","Jinbao Xue","Xipeng Zhang","Decheng Wu","Kai Liu","Dengpeng Wu","Guanghui Xu","Shaohua Chen","Shuang Chen","Xiao Feng","Yigeng Hong","Junqiang Zheng","Chengcheng Xu","Zongwei Li","Xiong Kuang","Jianglu Hu","Yiqi Chen","Yuchi Deng","Guiyang Li","Ao Liu","Chenchen Zhang","Shihui Hu","Zilong Zhao","Zifan Wu","Yao Ding","Weichao Wang","Han Liu","Roberts Wang","Hao Fei","Peijie Yu","Ze Zhao","Xun Cao","Hai Wang","Fusheng Xiang","Mengyuan Huang","Zhiyuan Xiong","Bin Hu","Xuebin Hou","Lei Jiang","Jianqiang Ma","Jiajia Wu","Yaping Deng","Yi Shen","Qian Wang","Weijie Liu","Jie Liu","Meng Chen","Liang Dong","Weiwen Jia","Hu Chen","Feifei Liu","Rui Yuan","Huilin Xu","Zhenxiang Yan","Tengfei Cao","Zhichao Hu","Xinhua Feng","Dong Du","Tinghao Yu","Yangyu Tao","Feng Zhang","Jianchen Zhu","Chengzhong Xu","Xirui Li","Chong Zha","Wen Ouyang","Yinben Xia","Xiang Li","Zekun He","Rongpeng Chen","Jiawei Song","Ruibin Chen","Fan Jiang","Chongqing Zhao","Bo Wang","Hao Gong","Rong Gan","Winston Hu","Zhanhui Kang","Yong Yang","Yuhong Liu","Di Wang","Jie Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.02265v3.pdf","comment":"17 pages, 4 Figures"},{"id":"http://arxiv.org/abs/2411.03769v1","updated":"2024-11-06T09:05:17Z","published":"2024-11-06T09:05:17Z","title":"No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with\n  Captions in 28 Languages","summary":"  Research in vision and language has made considerable progress thanks to\nbenchmarks such as COCO. COCO captions focused on unambiguous facts in English;\nArtEmis introduced subjective emotions and ArtELingo introduced some\nmultilinguality (Chinese and Arabic). However we believe there should be more\nmultilinguality. Hence, we present ArtELingo-28, a vision-language benchmark\nthat spans $\\textbf{28}$ languages and encompasses approximately\n$\\textbf{200,000}$ annotations ($\\textbf{140}$ annotations per image).\nTraditionally, vision research focused on unambiguous class labels, whereas\nArtELingo-28 emphasizes diversity of opinions over languages and cultures. The\nchallenge is to build machine learning systems that assign emotional captions\nto images. Baseline results will be presented for three novel conditions:\nZero-Shot, Few-Shot and One-vs-All Zero-Shot. We find that cross-lingual\ntransfer is more successful for culturally-related languages. Data and code are\nprovided at www.artelingo.org.\n","authors":["Youssef Mohamed","Runjia Li","Ibrahim Said Ahmad","Kilichbek Haydarov","Philip Torr","Kenneth Ward Church","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2411.03769v1.pdf","comment":"9 pages, Accepted at EMNLP 24, for more details see www.artelingo.org"},{"id":"http://arxiv.org/abs/2411.03766v1","updated":"2024-11-06T08:59:44Z","published":"2024-11-06T08:59:44Z","title":"Number Cookbook: Number Understanding of Language Models and How to\n  Improve It","summary":"  Large language models (LLMs) can solve an increasing number of complex\nreasoning tasks while making surprising mistakes in basic numerical\nunderstanding and processing (such as 9.11 > 9.9). The latter ability is\nessential for tackling complex arithmetic and mathematical problems and serves\nas a foundation for most reasoning tasks, but previous work paid little\nattention to it or only discussed several restricted tasks (like integer\naddition). In this paper, we comprehensively investigate the numerical\nunderstanding and processing ability (NUPA) of LLMs. Firstly, we introduce a\nbenchmark covering four common numerical representations and 17 distinct\nnumerical tasks in four major categories, resulting in 41 meaningful\ncombinations in total. These tasks are derived from primary and secondary\neducation curricula, encompassing nearly all everyday numerical understanding\nand processing scenarios, and the rules of these tasks are very simple and\nclear. Through the benchmark, we find that current LLMs fail frequently in many\nof the tasks. To study the problem, we train small models with existing and\npotential techniques for enhancing NUPA (such as special tokenizers, PEs, and\nnumber formats), comprehensively evaluating their effectiveness using our\ntestbed. We also finetune practical-scale LLMs on our proposed NUPA tasks and\nfind that 1) naive finetuning can improve NUPA a lot on many but not all tasks,\nand 2) surprisingly, techniques designed to enhance NUPA prove ineffective for\nfinetuning pretrained models. We further explore the impact of chain-of-thought\ntechniques on NUPA. Our work takes a preliminary step towards understanding and\nimproving NUPA of LLMs. Our benchmark and code are released at\nhttps://github.com/GraphPKU/number_cookbook.\n","authors":["Haotong Yang","Yi Hu","Shijia Kang","Zhouchen Lin","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.03766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02603v2","updated":"2024-11-06T08:51:52Z","published":"2024-11-04T20:53:04Z","title":"FactTest: Factuality Testing in Large Language Models with Finite-Sample\n  and Distribution-Free Guarantees","summary":"  The propensity of Large Language Models (LLMs) to generate hallucinations and\nnon-factual content undermines their reliability in high-stakes domains, where\nrigorous control over Type I errors (the conditional probability of incorrectly\nclassifying hallucinations as truthful content) is essential. Despite its\nimportance, formal verification of LLM factuality with such guarantees remains\nlargely unexplored. In this paper, we introduce FactTest, a novel framework\nthat statistically assesses whether an LLM can confidently provide correct\nanswers to given questions with high-probability correctness guarantees. We\nformulate factuality testing as hypothesis testing problem to enforce an upper\nbound of Type I errors at user-specified significance levels. Notably, we prove\nthat our framework also ensures strong Type II error control under mild\nconditions and can be extended to maintain its effectiveness when covariate\nshifts exist. %These analyses are amenable to the principled NP framework. Our\napproach is distribution-free and works for any number of human-annotated\nsamples. It is model-agnostic and applies to any black-box or white-box LM.\nExtensive experiments on question-answering (QA) and multiple-choice benchmarks\ndemonstrate that \\approach effectively detects hallucinations and improves the\nmodel's ability to abstain from answering unknown questions, leading to an over\n40% accuracy improvement.\n","authors":["Fan Nie","Xiaotian Hou","Shuhang Lin","James Zou","Huaxiu Yao","Linjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.02603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13824v3","updated":"2024-11-06T08:29:22Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48% improvement on\nVisualWebBench and a 19.1% boost in element accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08081v3","updated":"2024-11-06T07:31:28Z","published":"2024-10-10T16:25:34Z","title":"Packing Analysis: Packing Is More Appropriate for Large Models or\n  Datasets in Supervised Fine-tuning","summary":"  Packing, initially utilized in the pre-training phase, is an optimization\ntechnique designed to maximize hardware resource efficiency by combining\ndifferent training sequences to fit the model's maximum input length. Although\nit has demonstrated effectiveness during pre-training, there remains a lack of\ncomprehensive analysis for the supervised fine-tuning (SFT) stage on the\nfollowing points: (1) whether packing can effectively enhance training\nefficiency while maintaining performance, (2) the suitable size of the model\nand dataset for fine-tuning with the packing method, and (3) whether packing\nunrelated or related training samples might cause the model to either\nexcessively disregard or over-rely on the context.\n  In this paper, we perform extensive comparisons between SFT methods using\npadding and packing, covering SFT datasets ranging from 69K to 1.2M and models\nfrom 8B to 70B. This provides the first comprehensive analysis of the\nadvantages and limitations of packing versus padding, as well as practical\nconsiderations for implementing packing in various training scenarios. Our\nanalysis covers various benchmarks, including knowledge, reasoning, and coding,\nas well as GPT-based evaluations, time efficiency, and other fine-tuning\nparameters. We also open-source our code for fine-tuning and evaluation and\nprovide checkpoints fine-tuned on datasets of different sizes, aiming to\nadvance future research on packing methods. Code is available at:\nhttps://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-file.\n","authors":["Shuhe Wang","Guoyin Wang","Yizhong Wang","Jiwei Li","Eduard Hovy","Chen Guo"],"pdf_url":"https://arxiv.org/pdf/2410.08081v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03700v1","updated":"2024-11-06T06:50:50Z","published":"2024-11-06T06:50:50Z","title":"The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms\n  in Aligned Language Models","summary":"  Natural-language assistants are designed to provide users with helpful\nresponses while avoiding harmful outputs, largely achieved through alignment to\nhuman preferences. Yet there is limited understanding of whether alignment\ntechniques may inadvertently perpetuate or even amplify harmful biases\ninherited from their pre-aligned base models. This issue is compounded by the\nchoice of bias evaluation benchmarks in popular preference-finetuned models,\nwhich predominantly focus on dominant social categories, such as binary gender,\nthereby limiting insights into biases affecting underrepresented groups.\nTowards addressing this gap, we center transgender, nonbinary, and other\ngender-diverse identities to investigate how alignment procedures interact with\npre-existing gender-diverse bias in LLMs. Our key contributions include: 1) a\ncomprehensive survey of bias evaluation modalities across leading\npreference-finetuned LLMs, highlighting critical gaps in gender-diverse\nrepresentation, 2) systematic evaluation of gender-diverse biases across 12\nmodels spanning Direct Preference Optimization (DPO) stages, uncovering harms\npopular bias benchmarks fail to detect, and 3) a flexible framework for\nmeasuring harmful biases in implicit reward signals applicable to other social\ncontexts. Our findings reveal that DPO-aligned models are particularly\nsensitive to supervised finetuning (SFT), and can amplify two forms of\nreal-world gender-diverse harms from their base models: stigmatization and\ngender non-affirmative language. We conclude with recommendations tailored to\nDPO and broader alignment practices, advocating for the adoption of\ncommunity-informed bias evaluation frameworks to more effectively identify and\naddress underrepresented harms in LLMs.\n","authors":["Anaelia Ovalle","Krunoslav Lehman Pavasovic","Louis Martin","Luke Zettlemoyer","Eric Michael Smith","Adina Williams","Levent Sagun"],"pdf_url":"https://arxiv.org/pdf/2411.03700v1.pdf","comment":"Accepted to 2024 Neurips Queer in AI Workshop"},{"id":"http://arxiv.org/abs/2405.01345v3","updated":"2024-11-06T06:28:45Z","published":"2024-05-02T14:49:50Z","title":"The Power of Question Translation Training in Multilingual Reasoning:\n  Broadened Scope and Deepened Insights","summary":"  Bridging the significant gap between large language model's English and\nnon-English performance presents a great challenge. While some previous studies\nattempt to mitigate this gap with translated training data, the recently\nproposed question alignment framework leverages the model's English expertise\nto improve multilingual performance with minimum usage of expensive,\nerror-prone translation. In this paper, we explore how broadly this method can\nbe applied by examining its effects in reasoning with and without\nchain-of-thought, as well as with program-of-thought. We also explore applying\nthis framework to extremely large language models in an efficient manner, such\nas through proxy-tuning. Experiment results on multilingual reasoning\nbenchmarks mGSM, mSVAMP, xCSQA and xNLI demonstrate that we can extend question\nalignment framework to boost multilingual performance across diverse reasoning\nscenarios, model families, and sizes. For instance, when applied to the LLaMA2\nmodels, it brings an average accuracy improvements of 12.2% on mGSM even with\nthe 70B model. To understand the mechanism of its success, we analyze\nrepresentation space, generated response and data scales, and reveal how\nquestion translation training strengthens language alignment within LLMs and\nshapes their working patterns.\n","authors":["Wenhao Zhu","Shujian Huang","Fei Yuan","Cheng Chen","Jiajun Chen","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2405.01345v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17812v2","updated":"2024-11-06T05:33:16Z","published":"2024-02-27T14:51:11Z","title":"DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping\n  Backward Propagation","summary":"  Large language models (LLMs) have achieved significant success across various\ndomains. However, training these LLMs typically involves substantial memory and\ncomputational costs during both forward and backward propagation. While\nparameter-efficient fine-tuning (PEFT) considerably reduces the training memory\nassociated with parameters, it does not address the significant computational\ncosts and activation memory. In this paper, we propose Dropping Backward\nPropagation (DropBP), a novel approach designed to reduce computational costs\nand activation memory while maintaining accuracy. DropBP randomly drops layers\nduring backward propagation, which is essentially equivalent to training\nshallow submodules generated by undropped layers and residual connections.\nAdditionally, DropBP calculates the sensitivity of each layer to assign an\nappropriate drop rate, thereby stabilizing the training process. DropBP is not\nonly applicable to full fine-tuning but can also be orthogonally integrated\nwith all types of PEFT by dropping layers during backward propagation.\nSpecifically, DropBP can reduce training time by 44% with comparable accuracy\nto the baseline, accelerate convergence to the same perplexity by 1.5x, and\nenable training with a sequence length 6.2x larger on a single NVIDIA-A100 GPU.\nFurthermore, our DropBP enabled a throughput increase of 79% on a NVIDIA A100\nGPU and 117% on an Intel Gaudi2 HPU. The code is available at\nhttps://github.com/WooSunghyeon/dropbp.\n","authors":["Sunghyeon Woo","Baeseong Park","Byeongwook Kim","Minjung Jo","Se Jung Kwon","Dongsuk Jeon","Dongsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2402.17812v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03675v1","updated":"2024-11-06T05:24:09Z","published":"2024-11-06T05:24:09Z","title":"QUILL: Quotation Generation Enhancement of Large Language Models","summary":"  While Large language models (LLMs) have become excellent writing assistants,\nthey still struggle with quotation generation. This is because they either\nhallucinate when providing factual quotations or fail to provide quotes that\nexceed human expectations. To bridge the gap, we systematically study how to\nevaluate and improve LLMs' performance in quotation generation tasks. We first\nestablish a holistic and automatic evaluation system for quotation generation\ntask, which consists of five criteria each with corresponding automatic metric.\nTo improve the LLMs' quotation generation abilities, we construct a bilingual\nknowledge base that is broad in scope and rich in dimensions, containing up to\n32,022 quotes. Moreover, guided by our critiria, we further design a\nquotation-specific metric to rerank the retrieved quotations from the knowledge\nbase. Extensive experiments show that our metrics strongly correlate with human\npreferences. Existing LLMs struggle to generate desired quotes, but our\nquotation knowledge base and reranking metric help narrow this gap. Our dataset\nand code are publicly available at https://github.com/GraceXiaoo/QUILL.\n","authors":["Jin Xiao","Bowei Zhang","Qianyu He","Jiaqing Liang","Feng Wei","Jinglei Chen","Zujie Liang","Deqing Yang","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2411.03675v1.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.03665v1","updated":"2024-11-06T04:52:38Z","published":"2024-11-06T04:52:38Z","title":"Evaluating Moral Beliefs across LLMs through a Pluralistic Framework","summary":"  Proper moral beliefs are fundamental for language models, yet assessing these\nbeliefs poses a significant challenge. This study introduces a novel\nthree-module framework to evaluate the moral beliefs of four prominent large\nlanguage models. Initially, we constructed a dataset containing 472 moral\nchoice scenarios in Chinese, derived from moral words. The decision-making\nprocess of the models in these scenarios reveals their moral principle\npreferences. By ranking these moral choices, we discern the varying moral\nbeliefs held by different language models. Additionally, through moral debates,\nwe investigate the firmness of these models to their moral choices. Our\nfindings indicate that English language models, namely ChatGPT and Gemini,\nclosely mirror moral decisions of the sample of Chinese university students,\ndemonstrating strong adherence to their choices and a preference for\nindividualistic moral beliefs. In contrast, Chinese models such as Ernie and\nChatGLM lean towards collectivist moral beliefs, exhibiting ambiguity in their\nmoral choices and debates. This study also uncovers gender bias embedded within\nthe moral beliefs of all examined language models. Our methodology offers an\ninnovative means to assess moral beliefs in both artificial and human\nintelligence, facilitating a comparison of moral values across different\ncultures.\n","authors":["Xuelin Liu","Yanfei Zhu","Shucheng Zhu","Pengyuan Liu","Ying Liu","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2411.03665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09324v3","updated":"2024-11-06T04:43:57Z","published":"2024-06-13T17:01:40Z","title":"Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs","summary":"  Although Large Language Models (LLMs) have demonstrated significant\ncapabilities in executing complex tasks in a zero-shot manner, they are\nsusceptible to jailbreak attacks and can be manipulated to produce harmful\noutputs. Recently, a growing body of research has categorized jailbreak attacks\ninto token-level and prompt-level attacks. However, previous work primarily\noverlooks the diverse key factors of jailbreak attacks, with most studies\nconcentrating on LLM vulnerabilities and lacking exploration of\ndefense-enhanced LLMs. To address these issues, we introduced\n$\\textbf{JailTrickBench}$ to evaluate the impact of various attack settings on\nLLM performance and provide a baseline for jailbreak attacks, encouraging the\nadoption of a standardized evaluation framework. Specifically, we evaluate the\neight key factors of implementing jailbreak attacks on LLMs from both\ntarget-level and attack-level perspectives. We further conduct seven\nrepresentative jailbreak attacks on six defense methods across two widely used\ndatasets, encompassing approximately 354 experiments with about 55,000 GPU\nhours on A800-80G. Our experimental results highlight the need for standardized\nbenchmarking to evaluate these attacks on defense-enhanced LLMs. Our code is\navailable at https://github.com/usail-hkust/JailTrickBench.\n","authors":["Zhao Xu","Fan Liu","Hao Liu"],"pdf_url":"https://arxiv.org/pdf/2406.09324v3.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2401.11505v2","updated":"2024-11-06T04:11:14Z","published":"2024-01-21T14:30:20Z","title":"CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray\n  Report Labeling","summary":"  Free-text radiology reports present a rich data source for various medical\ntasks, but effectively labeling these texts remains challenging. Traditional\nrule-based labeling methods fall short of capturing the nuances of diverse\nfree-text patterns. Moreover, models using expert-annotated data are limited by\ndata scarcity and pre-defined classes, impacting their performance, flexibility\nand scalability. To address these issues, our study offers three main\ncontributions: 1) We demonstrate the potential of GPT as an adept labeler using\ncarefully designed prompts. 2) Utilizing only the data labeled by GPT, we\ntrained a BERT-based labeler, CheX-GPT, which operates faster and more\nefficiently than its GPT counterpart. 3) To benchmark labeler performance, we\nintroduced a publicly available expert-annotated test set, MIMIC-500,\ncomprising 500 cases from the MIMIC validation set. Our findings demonstrate\nthat CheX-GPT not only excels in labeling accuracy over existing models, but\nalso showcases superior efficiency, flexibility, and scalability, supported by\nour introduction of the MIMIC-500 dataset for robust benchmarking. Code and\nmodels are available at https://github.com/Soombit-ai/CheXGPT.\n","authors":["Jawook Gu","Kihyun You","Han-Cheol Cho","Jiho Kim","Eun Kyoung Hong","Byungseok Roh"],"pdf_url":"https://arxiv.org/pdf/2401.11505v2.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.03644v1","updated":"2024-11-06T03:48:41Z","published":"2024-11-06T03:48:41Z","title":"Deploying Multi-task Online Server with Large Language Model","summary":"  In the industry, numerous tasks are deployed online. Traditional approaches\noften tackle each task separately by its own network, which leads to excessive\ncosts for developing and scaling models, especially in the context of large\nlanguage models. Although multi-task methods can save costs through parameter\nsharing, they often struggle to outperform single-task methods in real-world\napplications. To tackle these challenges, we present a three-stage multi-task\nlearning framework for large language models. It involves task filtering,\nfollowed by fine-tuning on high-resource tasks, and finally fine-tuning on all\ntasks. We conducted comprehensive experiments in single-task and multi-task\nsettings. Our approach, exemplified on different benchmarks, demonstrates that\nit is able to achieve performance comparable to the single-task method while\nreducing up to 90.9\\% of its overhead.\n","authors":["Yincen Qu","Chao Ma","Yiting Wu","Xiangying Dai","Hui Zhou","Hengyue Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03644v1.pdf","comment":"COLING2025 under submission"},{"id":"http://arxiv.org/abs/2411.02674v2","updated":"2024-11-06T03:11:35Z","published":"2024-11-04T23:21:12Z","title":"Wave Network: An Ultra-Small Language Model","summary":"  We propose an innovative token representation and update method in a new\nultra-small language model: the Wave network. Specifically, we use a complex\nvector to represent each token, encoding both global and local semantics of the\ninput text. A complex vector consists of two components: a magnitude vector\nrepresenting the global semantics of the input text, and a phase vector\ncapturing the relationships between individual tokens and global semantics.\nExperiments on the AG News text classification task demonstrate that, when\ngenerating complex vectors from randomly initialized token embeddings, our\nsingle-layer Wave Network achieves 90.91% accuracy with wave interference and\n91.66% with wave modulation - outperforming a single Transformer layer using\nBERT pre-trained embeddings by 19.23% and 19.98%, respectively, and approaching\nthe accuracy of the pre-trained and fine-tuned BERT base model (94.64%).\nAdditionally, compared to BERT base, the Wave Network reduces video memory\nusage and training time by 77.34% and 85.62% during wave modulation. In\nsummary, we used a 2.4-million-parameter small language model to achieve\naccuracy comparable to a 100-million-parameter BERT model in text\nclassification.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.02674v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01574v6","updated":"2024-11-06T02:54:00Z","published":"2024-06-03T17:53:00Z","title":"MMLU-Pro: A More Robust and Challenging Multi-Task Language\n  Understanding Benchmark","summary":"  In the age of large-scale language models, benchmarks like the Massive\nMultitask Language Understanding (MMLU) have been pivotal in pushing the\nboundaries of what AI can achieve in language comprehension and reasoning\nacross diverse domains. However, as models continue to improve, their\nperformance on these benchmarks has begun to plateau, making it increasingly\ndifficult to discern differences in model capabilities. This paper introduces\nMMLU-Pro, an enhanced dataset designed to extend the mostly knowledge-driven\nMMLU benchmark by integrating more challenging, reasoning-focused questions and\nexpanding the choice set from four to ten options. Additionally, MMLU-Pro\neliminates the trivial and noisy questions in MMLU. Our experimental results\nshow that MMLU-Pro not only raises the challenge, causing a significant drop in\naccuracy by 16% to 33% compared to MMLU but also demonstrates greater stability\nunder varying prompts. With 24 different prompt styles tested, the sensitivity\nof model scores to prompt variations decreased from 4-5% in MMLU to just 2% in\nMMLU-Pro. Additionally, we found that models utilizing Chain of Thought (CoT)\nreasoning achieved better performance on MMLU-Pro compared to direct answering,\nwhich is in stark contrast to the findings on the original MMLU, indicating\nthat MMLU-Pro includes more complex reasoning questions. Our assessments\nconfirm that MMLU-Pro is a more discriminative benchmark to better track\nprogress in the field.\n","authors":["Yubo Wang","Xueguang Ma","Ge Zhang","Yuansheng Ni","Abhranil Chandra","Shiguang Guo","Weiming Ren","Aaran Arulraj","Xuan He","Ziyan Jiang","Tianle Li","Max Ku","Kai Wang","Alex Zhuang","Rongqi Fan","Xiang Yue","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.01574v6.pdf","comment":"This version has been accepted and published at NeurIPS 2024 Track\n  Datasets and Benchmarks (Spotlight)"},{"id":"http://arxiv.org/abs/2409.19272v2","updated":"2024-11-06T01:58:20Z","published":"2024-09-28T07:13:33Z","title":"Perception Compressor:A training-free prompt compression method in long\n  context scenarios","summary":"  Large Language Models (LLMs) demonstrate exceptional capabilities in various\nscenarios. However, they suffer from much redundant information and are\nsensitive to the position of key information (relevant to the input question)\nin long context scenarios, leading to inferior performance. To address these\nchallenges, we present Perception Compressor, a training-free prompt\ncompression method. It includes a perception retriever that leverages guiding\nquestions and instruction to retrieve the most relevant demonstrations, a\ndual-slope ratio allocator to dynamically allocate compression ratios and\nopen-book ratios, and a semi-guided iterative compression that retains key\ninformation at the token level while removing tokens that distract the LLM. We\nconduct extensive experiments on long context benchmarks, i.e.,\nNaturalQuestions, LongBench, and MuSiQue. Experiment results show that\nPerception Compressor outperforms existing methods by a large margin, achieving\nstate-of-the-art performance.\n","authors":["Jiwei Tang","Jin Xu","Tingwei Lu","Zhicheng Zhang","Yiming Zhao","Lin Hai","Hai-Tao Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.19272v2.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.16020v4","updated":"2024-11-06T01:49:36Z","published":"2024-06-23T05:40:26Z","title":"AudioBench: A Universal Benchmark for Audio Large Language Models","summary":"  We introduce AudioBench, a universal benchmark designed to evaluate Audio\nLarge Language Models (AudioLLMs). It encompasses 8 distinct tasks and 26\ndatasets, among which, 7 are newly proposed datasets. The evaluation targets\nthree main aspects: speech understanding, audio scene understanding, and voice\nunderstanding (paralinguistic). Despite recent advancements, there lacks a\ncomprehensive benchmark for AudioLLMs on instruction following capabilities\nconditioned on audio signals. AudioBench addresses this gap by setting up\ndatasets as well as desired evaluation metrics. Besides, we also evaluated the\ncapabilities of five popular models and found that no single model excels\nconsistently across all tasks. We outline the research outlook for AudioLLMs\nand anticipate that our open-sourced evaluation toolkit, data, and leaderboard\nwill offer a robust testbed for future model developments.\n","authors":["Bin Wang","Xunlong Zou","Geyu Lin","Shuo Sun","Zhuohan Liu","Wenyu Zhang","Zhengyuan Liu","AiTi Aw","Nancy F. Chen"],"pdf_url":"https://arxiv.org/pdf/2406.16020v4.pdf","comment":"v4 - Add acknowledgment and slight update on structure; Code:\n  https://github.com/AudioLLMs/AudioBench"},{"id":"http://arxiv.org/abs/2411.01222v2","updated":"2024-11-06T01:40:27Z","published":"2024-11-02T12:01:44Z","title":"$B^4$: A Black-Box Scrubbing Attack on LLM Watermarks","summary":"  Watermarking has emerged as a prominent technique for LLM-generated content\ndetection by embedding imperceptible patterns. Despite supreme performance, its\nrobustness against adversarial attacks remains underexplored. Previous work\ntypically considers a grey-box attack setting, where the specific type of\nwatermark is already known. Some even necessitates knowledge about\nhyperparameters of the watermarking method. Such prerequisites are unattainable\nin real-world scenarios. Targeting at a more realistic black-box threat model\nwith fewer assumptions, we here propose $\\mathcal{B}^4$, a black-box scrubbing\nattack on watermarks. Specifically, we formulate the watermark scrubbing attack\nas a constrained optimization problem by capturing its objectives with two\ndistributions, a Watermark Distribution and a Fidelity Distribution. This\noptimization problem can be approximately solved using two proxy distributions.\nExperimental results across 12 different settings demonstrate the superior\nperformance of $\\mathcal{B}^4$ compared with other baselines.\n","authors":["Baizhou Huang","Xiao Pu","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2411.01222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23956v2","updated":"2024-11-06T01:35:36Z","published":"2024-10-31T14:09:50Z","title":"Multilingual Pretraining Using a Large Corpus Machine-Translated from a\n  Single Source Language","summary":"  English, as a very high-resource language, enables the pretraining of\nhigh-quality large language models (LLMs). The same cannot be said for most\nother languages, as leading LLMs still underperform for non-English languages,\nlikely due to a gap in the quality and diversity of the available multilingual\npretraining corpora. In this work, we find that machine-translated text from a\nsingle high-quality source language can contribute significantly to the\npretraining of multilingual LLMs. We translate FineWeb-Edu, a high-quality\nEnglish web dataset, into French, German, and Spanish, resulting in a final\n300B-token dataset, which we call TransWeb-Edu, and pretrain a 1.3B-parameter\nmodel, CuatroLLM, from scratch on this dataset. Across five non-English\nreasoning tasks, we show that CuatroLLM matches or outperforms state-of-the-art\nmultilingual models trained using closed data, such as Llama3.2 and Gemma2,\ndespite using an order of magnitude less data, such as about 6% of the tokens\nused for Llama3.2's training. We further demonstrate that with additional\ndomain-specific pretraining, amounting to less than 1% of TransWeb-Edu,\nCuatroLLM surpasses the state of the art in multilingual reasoning. To promote\nreproducibility, we release our corpus, models, and training pipeline under\nopen licenses at hf.co/britllm/CuatroLLM.\n","authors":["Jiayi Wang","Yao Lu","Maurice Weber","Max Ryabinin","Yihong Chen","Raphael Tang","Pontus Stenetorp"],"pdf_url":"https://arxiv.org/pdf/2410.23956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19687v3","updated":"2024-11-06T01:20:07Z","published":"2024-07-29T04:10:13Z","title":"Efficiently and Effectively: A Two-stage Approach to Balance Plaintext\n  and Encrypted Text for Traffic Classification","summary":"  Encrypted traffic classification is the task of identifying the application\nor service associated with encrypted network traffic. One effective approach\nfor this task is to use deep learning methods to encode the raw traffic bytes\ndirectly and automatically extract features for classification (byte-based\nmodels). However, current byte-based models input raw traffic bytes, whether\nplaintext or encrypted text, for automated feature extraction, neglecting the\ndistinct impacts of plaintext and encrypted text on downstream tasks.\nAdditionally, these models primarily focus on improving classification\naccuracy, with little emphasis on the efficiency of models. In this paper, for\nthe first time, we analyze the impact of plaintext and encrypted text on the\nmodel's effectiveness and efficiency. Based on our observations and findings,\nwe propose a two-phase approach to balance the trade-off between plaintext and\nencrypted text in traffic classification. Specifically, Stage one is to\nDetermine whether the Plain text is enough to be accurately Classified (DPC)\nusing the proposed DPC Selector. This stage quickly identifies samples that can\nbe classified using plaintext, leveraging explicit byte features in plaintext\nto enhance model's efficiency. Stage two aims to adaptively make a\nclassification with the result from stage one. This stage incorporates\nencrypted text information for samples that cannot be classified using\nplaintext alone, ensuring the model's effectiveness on traffic classification\ntasks. Experiments on two datasets demonstrate that our proposed model achieves\nstate-of-the-art results in both effectiveness and efficiency.\n","authors":["Wei Peng","Lei Cui","Wei Cai","Zhenquan Ding","Zhiyu Hao","Xiaochun Yun"],"pdf_url":"https://arxiv.org/pdf/2407.19687v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03590v1","updated":"2024-11-06T01:09:17Z","published":"2024-11-06T01:09:17Z","title":"From Medprompt to o1: Exploration of Run-Time Strategies for Medical\n  Challenge Problems and Beyond","summary":"  Run-time steering strategies like Medprompt are valuable for guiding large\nlanguage models (LLMs) to top performance on challenging tasks. Medprompt\ndemonstrates that a general LLM can be focused to deliver state-of-the-art\nperformance on specialized domains like medicine by using a prompt to elicit a\nrun-time strategy involving chain of thought reasoning and ensembling. OpenAI's\no1-preview model represents a new paradigm, where a model is designed to do\nrun-time reasoning before generating final responses. We seek to understand the\nbehavior of o1-preview on a diverse set of medical challenge problem\nbenchmarks. Following on the Medprompt study with GPT-4, we systematically\nevaluate the o1-preview model across various medical benchmarks. Notably, even\nwithout prompting techniques, o1-preview largely outperforms the GPT-4 series\nwith Medprompt. We further systematically study the efficacy of classic prompt\nengineering strategies, as represented by Medprompt, within the new paradigm of\nreasoning models. We found that few-shot prompting hinders o1's performance,\nsuggesting that in-context learning may no longer be an effective steering\napproach for reasoning-native models. While ensembling remains viable, it is\nresource-intensive and requires careful cost-performance optimization. Our cost\nand accuracy analysis across run-time strategies reveals a Pareto frontier,\nwith GPT-4o representing a more affordable option and o1-preview achieving\nstate-of-the-art performance at higher cost. Although o1-preview offers top\nperformance, GPT-4o with steering strategies like Medprompt retains value in\nspecific contexts. Moreover, we note that the o1-preview model has reached\nnear-saturation on many existing medical benchmarks, underscoring the need for\nnew, challenging benchmarks. We close with reflections on general directions\nfor inference-time computation with LLMs.\n","authors":["Harsha Nori","Naoto Usuyama","Nicholas King","Scott Mayer McKinney","Xavier Fernandes","Sheng Zhang","Eric Horvitz"],"pdf_url":"https://arxiv.org/pdf/2411.03590v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2410.20763v2","updated":"2024-11-06T00:20:32Z","published":"2024-10-28T05:56:51Z","title":"Evaluating LLMs for Targeted Concept Simplification for Domain-Specific\n  Texts","summary":"  One useful application of NLP models is to support people in reading complex\ntext from unfamiliar domains (e.g., scientific articles). Simplifying the\nentire text makes it understandable but sometimes removes important details. On\nthe contrary, helping adult readers understand difficult concepts in context\ncan enhance their vocabulary and knowledge. In a preliminary human study, we\nfirst identify that lack of context and unfamiliarity with difficult concepts\nis a major reason for adult readers' difficulty with domain-specific text. We\nthen introduce \"targeted concept simplification,\" a simplification task for\nrewriting text to help readers comprehend text containing unfamiliar concepts.\nWe also introduce WikiDomains, a new dataset of 22k definitions from 13\nacademic domains paired with a difficult concept within each definition. We\nbenchmark the performance of open-source and commercial LLMs and a simple\ndictionary baseline on this task across human judgments of ease of\nunderstanding and meaning preservation. Interestingly, our human judges\npreferred explanations about the difficult concept more than simplification of\nthe concept phrase. Further, no single model achieved superior performance\nacross all quality dimensions, and automated metrics also show low correlations\nwith human evaluations of concept simplification ($\\sim0.2$), opening up rich\navenues for research on personalized human reading comprehension support.\n","authors":["Sumit Asthana","Hannah Rashkin","Elizabeth Clark","Fantine Huot","Mirella Lapata"],"pdf_url":"https://arxiv.org/pdf/2410.20763v2.pdf","comment":"to appear in proceedings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.03568v1","updated":"2024-11-06T00:16:16Z","published":"2024-11-06T00:16:16Z","title":"The American Sign Language Knowledge Graph: Infusing ASL Models with\n  Linguistic Knowledge","summary":"  Language models for American Sign Language (ASL) could make language\ntechnologies substantially more accessible to those who sign. To train models\non tasks such as isolated sign recognition (ISR) and ASL-to-English\ntranslation, datasets provide annotated video examples of ASL signs. To\nfacilitate the generalizability and explainability of these models, we\nintroduce the American Sign Language Knowledge Graph (ASLKG), compiled from\ntwelve sources of expert linguistic knowledge. We use the ASLKG to train\nneuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of\n91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%\nfor classifying the topic of Youtube-ASL videos.\n","authors":["Lee Kezar","Nidhi Munikote","Zian Zeng","Zed Sehyr","Naomi Caselli","Jesse Thomason"],"pdf_url":"https://arxiv.org/pdf/2411.03568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21169v3","updated":"2024-11-06T00:11:08Z","published":"2024-10-28T16:11:35Z","title":"Document Parsing Unveiled: Techniques, Challenges, and Prospects for\n  Structured Information Extraction","summary":"  Document parsing is essential for converting unstructured and semi-structured\ndocuments-such as contracts, academic papers, and invoices-into structured,\nmachine-readable data. Document parsing extract reliable structured data from\nunstructured inputs, providing huge convenience for numerous applications.\nEspecially with recent achievements in Large Language Models, document parsing\nplays an indispensable role in both knowledge base construction and training\ndata generation. This survey presents a comprehensive review of the current\nstate of document parsing, covering key methodologies, from modular pipeline\nsystems to end-to-end models driven by large vision-language models. Core\ncomponents such as layout detection, content extraction (including text,\ntables, and mathematical expressions), and multi-modal data integration are\nexamined in detail. Additionally, this paper discusses the challenges faced by\nmodular document parsing systems and vision-language models in handling complex\nlayouts, integrating multiple modules, and recognizing high-density text. It\nemphasizes the importance of developing larger and more diverse datasets and\noutlines future research directions.\n","authors":["Qintong Zhang","Victor Shea-Jay Huang","Bin Wang","Junyuan Zhang","Zhengren Wang","Hao Liang","Shawn Wang","Matthieu Lin","Conghui He","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.21169v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04316v1","updated":"2024-11-06T23:41:18Z","published":"2024-11-06T23:41:18Z","title":"A Multilingual Sentiment Lexicon for Low-Resource Language Translation\n  using Large Languages Models and Explainable AI","summary":"  South Africa and the Democratic Republic of Congo (DRC) present a complex\nlinguistic landscape with languages such as Zulu, Sepedi, Afrikaans, French,\nEnglish, and Tshiluba (Ciluba), which creates unique challenges for AI-driven\ntranslation and sentiment analysis systems due to a lack of accurately labeled\ndata. This study seeks to address these challenges by developing a multilingual\nlexicon designed for French and Tshiluba, now expanded to include translations\nin English, Afrikaans, Sepedi, and Zulu. The lexicon enhances cultural\nrelevance in sentiment classification by integrating language-specific\nsentiment scores. A comprehensive testing corpus is created to support\ntranslation and sentiment analysis tasks, with machine learning models such as\nRandom Forest, Support Vector Machine (SVM), Decision Trees, and Gaussian Naive\nBayes (GNB) trained to predict sentiment across low resource languages (LRLs).\nAmong them, the Random Forest model performed particularly well, capturing\nsentiment polarity and handling language-specific nuances effectively.\nFurthermore, Bidirectional Encoder Representations from Transformers (BERT), a\nLarge Language Model (LLM), is applied to predict context-based sentiment with\nhigh accuracy, achieving 99% accuracy and 98% precision, outperforming other\nmodels. The BERT predictions were clarified using Explainable AI (XAI),\nimproving transparency and fostering confidence in sentiment classification.\nOverall, findings demonstrate that the proposed lexicon and machine learning\nmodels significantly enhance translation and sentiment analysis for LRLs in\nSouth Africa and the DRC, laying a foundation for future AI models that support\nunderrepresented languages, with applications across education, governance, and\nbusiness in multilingual contexts.\n","authors":["Melusi Malinga","Isaac Lupanda","Mike Wa Nkongolo","Phil van Deventer"],"pdf_url":"https://arxiv.org/pdf/2411.04316v1.pdf","comment":"This work is part of a PhD proposal in Information Technology at the\n  University of Pretoria, supervised by Dr. Mike Wa Nkongolo and co-supervised\n  by Dr. Phil van Deventer, under the Low-Resource Language Processing Lab in\n  the Department of Informatics"},{"id":"http://arxiv.org/abs/2411.02316v2","updated":"2024-11-06T23:27:24Z","published":"2024-11-04T17:40:39Z","title":"Evaluating Creative Short Story Generation in Humans and Large Language\n  Models","summary":"  Storytelling is a fundamental aspect of human communication, relying heavily\non creativity to produce narratives that are novel, appropriate, and\nsurprising. While large language models (LLMs) have recently demonstrated the\nability to generate high-quality stories, their creative capabilities remain\nunderexplored. Previous research has either focused on creativity tests\nrequiring short responses or primarily compared model performance in story\ngeneration to that of professional writers. However, the question of whether\nLLMs exhibit creativity in writing short stories on par with the average human\nremains unanswered. In this work, we conduct a systematic analysis of\ncreativity in short story generation across LLMs and everyday people. Using a\nfive-sentence creative story task, commonly employed in psychology to assess\nhuman creativity, we automatically evaluate model- and human-generated stories\nacross several dimensions of creativity, including novelty, surprise, and\ndiversity. Our findings reveal that while LLMs can generate stylistically\ncomplex stories, they tend to fall short in terms of creativity when compared\nto average human writers.\n","authors":["Mete Ismayilzada","Claire Stevenson","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2411.02316v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2411.04308v1","updated":"2024-11-06T23:16:25Z","published":"2024-11-06T23:16:25Z","title":"Improving Bilingual Capabilities of Language Models to Support Diverse\n  Linguistic Practices in Education","summary":"  Large language models (LLMs) offer promise in generating educational content,\nproviding instructor feedback, and reducing teacher workload on assessments.\nWhile prior studies have focused on studying LLM-powered learning analytics,\nlimited research has examined how effective LLMs are in a bilingual context. In\nthis paper, we study the effectiveness of multilingual large language models\n(MLLMs) across monolingual (English-only, Spanish-only) and bilingual\n(Spanglish) student writing. We present a learning analytics use case that\ndetails LLM performance in assessing acceptable and unacceptable explanations\nof Science and Social Science concepts. Our findings reveal a significant bias\nin the grading performance of pre-trained models for bilingual writing compared\nto English-only and Spanish-only writing. Following this, we fine-tune\nopen-source MLLMs including Llama 3.1 and Mistral NeMo using synthetic datasets\ngenerated in English, Spanish, and Spanglish. Our experiments indicate that the\nmodels perform significantly better for all three languages after fine-tuning\nwith bilingual data. This study highlights the potential of enhancing MLLM\neffectiveness to support authentic language practices amongst bilingual\nlearners. It also aims to illustrate the value of incorporating non-English\nlanguages into the design and implementation of language models in education.\n","authors":["Anand Syamkumar","Nora Tseng","Kaycie Barron","Shanglin Yang","Shamya Karumbaiah","Rheeya Uppal","Junjie Hu"],"pdf_url":"https://arxiv.org/pdf/2411.04308v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04298v1","updated":"2024-11-06T22:46:13Z","published":"2024-11-06T22:46:13Z","title":"A Capabilities Approach to Studying Bias and Harm in Language\n  Technologies","summary":"  Mainstream Natural Language Processing (NLP) research has ignored the\nmajority of the world's languages. In moving from excluding the majority of the\nworld's languages to blindly adopting what we make for English, we first risk\nimporting the same harms we have at best mitigated and at least measured for\nEnglish. However, in evaluating and mitigating harms arising from adopting new\ntechnologies into such contexts, we often disregard (1) the actual community\nneeds of Language Technologies, and (2) biases and fairness issues within the\ncontext of the communities. In this extended abstract, we consider fairness,\nbias, and inclusion in Language Technologies through the lens of the\nCapabilities Approach. The Capabilities Approach centers on what people are\ncapable of achieving, given their intersectional social, political, and\neconomic contexts instead of what resources are (theoretically) available to\nthem. We detail the Capabilities Approach, its relationship to multilingual and\nmulticultural evaluation, and how the framework affords meaningful\ncollaboration with community members in defining and measuring the harms of\nLanguage Technologies.\n","authors":["Hellina Hailu Nigatu","Zeerak Talat"],"pdf_url":"https://arxiv.org/pdf/2411.04298v1.pdf","comment":"Accepted to the New Perspectives on Bias and Discrimination in\n  Language Technology workshop"},{"id":"http://arxiv.org/abs/2411.00369v2","updated":"2024-11-06T22:41:31Z","published":"2024-11-01T05:14:03Z","title":"GRSQA -- Graph Reasoning-Structured Question Answering Dataset","summary":"  Large Language Models (LLMs) have excelled in multi-hop question-answering\n(M-QA) due to their advanced reasoning abilities. However, the impact of the\ninherent reasoning structures on LLM M-QA performance remains unclear, largely\ndue to the absence of QA datasets that provide fine-grained reasoning\nstructures. To address this gap, we introduce the Graph Reasoning-Structured\nQuestion Answering Dataset (GRS-QA), which includes both semantic contexts and\nreasoning structures for QA pairs. Unlike existing M-QA datasets, where\ndifferent reasoning structures are entangled together, GRS-QA explicitly\ncaptures intricate reasoning pathways by constructing reasoning graphs, where\nnodes represent textual contexts and edges denote logical flows. These\nreasoning graphs of different structures enable a fine-grained evaluation of\nLLM reasoning capabilities across various reasoning structures. Our empirical\nanalysis reveals that LLMs perform differently when handling questions with\nvarying reasoning structures. This finding facilitates the exploration of\ntextual structures as compared with semantics.\n","authors":["Anish Pahilajani","Devasha Trivedi","Jincen Shuai","Khin S. Yone","Samyak Rajesh Jain","Namyong Park","Ryan A. Rossi","Nesreen K. Ahmed","Franck Dernoncourt","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.00369v2.pdf","comment":"15 pages, 24 figures, 10 tables"},{"id":"http://arxiv.org/abs/2406.11944v2","updated":"2024-11-06T22:37:30Z","published":"2024-06-17T17:49:00Z","title":"Transcoders Find Interpretable LLM Feature Circuits","summary":"  A key goal in mechanistic interpretability is circuit analysis: finding\nsparse subgraphs of models corresponding to specific behaviors or capabilities.\nHowever, MLP sublayers make fine-grained circuit analysis on transformer-based\nlanguage models difficult. In particular, interpretable features -- such as\nthose found by sparse autoencoders (SAEs) -- are typically linear combinations\nof extremely many neurons, each with its own nonlinearity to account for.\nCircuit analysis in this setting thus either yields intractably large circuits\nor fails to disentangle local and global behavior. To address this we explore\ntranscoders, which seek to faithfully approximate a densely activating MLP\nlayer with a wider, sparsely-activating MLP layer. We introduce a novel method\nfor using transcoders to perform weights-based circuit analysis through MLP\nsublayers. The resulting circuits neatly factorize into input-dependent and\ninput-invariant terms. We then successfully train transcoders on language\nmodels with 120M, 410M, and 1.4B parameters, and find them to perform at least\non par with SAEs in terms of sparsity, faithfulness, and\nhuman-interpretability. Finally, we apply transcoders to reverse-engineer\nunknown circuits in the model, and we obtain novel insights regarding the\n\"greater-than circuit\" in GPT2-small. Our results suggest that transcoders can\nprove effective in decomposing model computations involving MLPs into\ninterpretable circuits. Code is available at\nhttps://github.com/jacobdunefsky/transcoder_circuits/.\n","authors":["Jacob Dunefsky","Philippe Chlenski","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.11944v2.pdf","comment":"29 pages, 6 figures, 4 tables, 2 algorithms. NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04291v1","updated":"2024-11-06T22:19:32Z","published":"2024-11-06T22:19:32Z","title":"Unfair Alignment: Examining Safety Alignment Across Vision Encoder\n  Layers in Vision-Language Models","summary":"  Vision-language models (VLMs) have improved significantly in multi-modal\ntasks, but their more complex architecture makes their safety alignment more\nchallenging than the alignment of large language models (LLMs). In this paper,\nwe reveal an unfair distribution of safety across the layers of VLM's vision\nencoder, with earlier and middle layers being disproportionately vulnerable to\nmalicious inputs compared to the more robust final layers. This 'cross-layer'\nvulnerability stems from the model's inability to generalize its safety\ntraining from the default architectural settings used during training to unseen\nor out-of-distribution scenarios, leaving certain layers exposed. We conduct a\ncomprehensive analysis by projecting activations from various intermediate\nlayers and demonstrate that these layers are more likely to generate harmful\noutputs when exposed to malicious inputs. Our experiments with LLaVA-1.5 and\nLlama 3.2 show discrepancies in attack success rates and toxicity scores across\nlayers, indicating that current safety alignment strategies focused on a single\ndefault layer are insufficient.\n","authors":["Saketh Bachu","Erfan Shayegani","Trishna Chakraborty","Rohit Lal","Arindam Dutta","Chengyu Song","Yue Dong","Nael Abu-Ghazaleh","Amit K. Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2411.04291v1.pdf","comment":"Preprint, Under Review"},{"id":"http://arxiv.org/abs/2406.15708v2","updated":"2024-11-06T22:07:17Z","published":"2024-06-22T02:07:10Z","title":"Teach Better or Show Smarter? On Instructions and Exemplars in Automatic\n  Prompt Optimization","summary":"  Large language models have demonstrated remarkable capabilities, but their\nperformance is heavily reliant on effective prompt engineering. Automatic\nprompt optimization (APO) methods are designed to automate this and can be\nbroadly categorized into those targeting instructions (instruction\noptimization, IO) vs. those targeting exemplars (exemplar optimization, EO).\nDespite their shared objective, these have evolved rather independently, with\nIO receiving more research attention recently. This paper seeks to bridge this\ngap by comprehensively comparing the performance of representative IO and EO\ntechniques both isolation and combination on a diverse set of challenging\ntasks. Our findings reveal that intelligently reusing model-generated\ninput-output pairs obtained from evaluating prompts on the validation set as\nexemplars, consistently improves performance on top of IO methods but is\ncurrently under-investigated. We also find that despite the recent focus on IO,\nhow we select exemplars can outweigh how we optimize instructions, with EO\nstrategies as simple as random search outperforming state-of-the-art IO methods\nwith seed instructions without any optimization. Moreover, we observe a synergy\nbetween EO and IO, with optimal combinations surpassing the individual\ncontributions. We conclude that studying exemplar optimization both as a\nstandalone method and its optimal combination with instruction optimization\nremain a crucial aspect of APO and deserve greater consideration in future\nresearch, even in the era of highly capable instruction-following models.\n","authors":["Xingchen Wan","Ruoxi Sun","Hootan Nakhost","Sercan O. Arik"],"pdf_url":"https://arxiv.org/pdf/2406.15708v2.pdf","comment":"Expanded version of the NeurIPS 2024 paper"},{"id":"http://arxiv.org/abs/2407.06004v3","updated":"2024-11-06T22:07:06Z","published":"2024-07-08T14:58:29Z","title":"Perceptions to Beliefs: Exploring Precursory Inferences for Theory of\n  Mind in Large Language Models","summary":"  While humans naturally develop theory of mind (ToM), the capability to\nunderstand other people's mental states and beliefs, state-of-the-art large\nlanguage models (LLMs) underperform on simple ToM benchmarks. We posit that we\ncan extend our understanding of LLMs' ToM abilities by evaluating key human ToM\nprecursors$-$perception inference and perception-to-belief inference$-$in LLMs.\nWe introduce two datasets, Percept-ToMi and Percept-FANToM, to evaluate these\nprecursory inferences for ToM in LLMs by annotating characters' perceptions on\nToMi and FANToM, respectively. Our evaluation of eight state-of-the-art LLMs\nreveals that the models generally perform well in perception inference while\nexhibiting limited capability in perception-to-belief inference (e.g., lack of\ninhibitory control). Based on these results, we present PercepToM, a novel ToM\nmethod leveraging LLMs' strong perception inference capability while\nsupplementing their limited perception-to-belief inference. Experimental\nresults demonstrate that PercepToM significantly enhances LLM's performance,\nespecially in false belief scenarios.\n","authors":["Chani Jung","Dongkwan Kim","Jiho Jin","Jiseon Kim","Yeon Seonwoo","Yejin Choi","Alice Oh","Hyunwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2407.06004v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07330v2","updated":"2024-11-06T22:03:18Z","published":"2024-07-10T02:58:37Z","title":"Interpretable Differential Diagnosis with Dual-Inference Large Language\n  Models","summary":"  Automatic differential diagnosis (DDx) is an essential medical task that\ngenerates a list of potential diseases as differentials based on patient\nsymptom descriptions. In practice, interpreting these differential diagnoses\nyields significant value but remains under-explored. Given the powerful\ncapabilities of large language models (LLMs), we investigated using LLMs for\ninterpretable DDx. Specifically, we curated the first DDx dataset with\nexpert-derived interpretation on 570 clinical notes. Besides, we proposed\nDual-Inf, a novel framework that enabled LLMs to conduct bidirectional\ninference (i.e., from symptoms to diagnoses and vice versa) for DDx\ninterpretation. Both human and automated evaluation validated its efficacy in\npredicting and elucidating differentials across four base LLMs. In addition,\nDual-Inf could reduce interpretation errors and hold promise for rare disease\nexplanations. To the best of our knowledge, it is the first work that\ncustomizes LLMs for DDx explanation and comprehensively evaluates their\ninterpretation performance. Overall, our study bridges a critical gap in DDx\ninterpretation and enhances clinical decision-making.\n","authors":["Shuang Zhou","Mingquan Lin","Sirui Ding","Jiashuo Wang","Genevieve B. Melton","James Zou","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.07330v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2411.04282v1","updated":"2024-11-06T22:02:30Z","published":"2024-11-06T22:02:30Z","title":"Language Models are Hidden Reasoners: Unlocking Latent Reasoning\n  Capabilities via Self-Rewarding","summary":"  Large language models (LLMs) have shown impressive capabilities, but still\nstruggle with complex reasoning tasks requiring multiple steps. While\nprompt-based methods like Chain-of-Thought (CoT) can improve LLM reasoning at\ninference time, optimizing reasoning capabilities during training remains\nchallenging. We introduce LaTent Reasoning Optimization (LaTRO), a principled\nframework that formulates reasoning as sampling from a latent distribution and\noptimizes it via variational approaches. LaTRO enables LLMs to concurrently\nimprove both their reasoning process and ability to evaluate reasoning quality,\nwithout requiring external feedback or reward models. We validate LaTRO through\nexperiments on GSM8K and ARC-Challenge datasets using multiple model\narchitectures. On GSM8K, LaTRO improves zero-shot accuracy by an average of\n12.5% over base models and 9.6% over supervised fine-tuning across\nPhi-3.5-mini, Mistral-7B, and Llama-3.1-8B. Our findings suggest that\npre-trained LLMs possess latent reasoning capabilities that can be unlocked and\nenhanced through our proposed optimization approach in a self-improvement\nmanner. The code of LaTRO is available at\n\\url{https://github.com/SalesforceAIResearch/LaTRO}.\n","authors":["Haolin Chen","Yihao Feng","Zuxin Liu","Weiran Yao","Akshara Prabhakar","Shelby Heinecke","Ricky Ho","Phil Mui","Silvio Savarese","Caiming Xiong","Huan Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15405v3","updated":"2024-11-06T21:18:59Z","published":"2023-05-24T17:59:05Z","title":"Textless Speech-to-Speech Translation With Limited Parallel Data","summary":"  Existing speech-to-speech translation (S2ST) models fall into two camps: they\neither leverage text as an intermediate step or require hundreds of hours of\nparallel speech data. Both approaches are incompatible with textless languages\nor language pairs with limited parallel data. We present PFB, a framework for\ntraining textless S2ST models that require just dozens of hours of parallel\nspeech data. We first pretrain a model on large-scale monolingual speech data,\nfinetune it with a small amount of parallel speech data (20-60 hours), and\nlastly train with an unsupervised backtranslation objective. We train and\nevaluate our models for English-to-German, German-to-English and\nMarathi-to-English translation on three different domains (European Parliament,\nCommon Voice, and All India Radio) with single-speaker synthesized speech.\nEvaluated using the ASR-BLEU metric, our models achieve reasonable performance\non all three domains, with some being within 1-2 points of our higher-resourced\ntopline.\n","authors":["Anuj Diwan","Anirudh Srinivasan","David Harwath","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2305.15405v3.pdf","comment":"Accepted to EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2407.12176v3","updated":"2024-11-06T20:38:48Z","published":"2024-07-16T21:03:14Z","title":"GPT-4V Cannot Generate Radiology Reports Yet","summary":"  GPT-4V's purported strong multimodal abilities raise interests in using it to\nautomate radiology report writing, but there lacks thorough evaluations. In\nthis work, we perform a systematic evaluation of GPT-4V in generating radiology\nreports on two chest X-ray report datasets: MIMIC-CXR and IU X-Ray. We attempt\nto directly generate reports using GPT-4V through different prompting\nstrategies and find that it fails terribly in both lexical metrics and clinical\nefficacy metrics. To understand the low performance, we decompose the task into\ntwo steps: 1) the medical image reasoning step of predicting medical condition\nlabels from images; and 2) the report synthesis step of generating reports from\n(groundtruth) conditions. We show that GPT-4V's performance in image reasoning\nis consistently low across different prompts. In fact, the distributions of\nmodel-predicted labels remain constant regardless of which groundtruth\nconditions are present on the image, suggesting that the model is not\ninterpreting chest X-rays meaningfully. Even when given groundtruth conditions\nin report synthesis, its generated reports are less correct and less\nnatural-sounding than a finetuned LLaMA-2. Altogether, our findings cast doubt\non the viability of using GPT-4V in a radiology workflow.\n","authors":["Yuyang Jiang","Chacha Chen","Dang Nguyen","Benjamin M. Mervak","Chenhao Tan"],"pdf_url":"https://arxiv.org/pdf/2407.12176v3.pdf","comment":"24 pages, 3 figures, code:\n  https://github.com/ChicagoHAI/cxr-eval-gpt-4v"},{"id":"http://arxiv.org/abs/2411.04223v1","updated":"2024-11-06T19:39:48Z","published":"2024-11-06T19:39:48Z","title":"Diversity Helps Jailbreak Large Language Models","summary":"  We have uncovered a powerful jailbreak technique that leverages large\nlanguage models' ability to diverge from prior context, enabling them to bypass\nsafety constraints and generate harmful outputs. By simply instructing the LLM\nto deviate and obfuscate previous attacks, our method dramatically outperforms\nexisting approaches, achieving up to a 62% higher success rate in compromising\nnine leading chatbots, including GPT-4, Gemini, and Llama, while using only 13%\nof the queries. This revelation exposes a critical flaw in current LLM safety\ntraining, suggesting that existing methods may merely mask vulnerabilities\nrather than eliminate them. Our findings sound an urgent alarm for the need to\nrevolutionize testing methodologies to ensure robust and reliable LLM security.\n","authors":["Weiliang Zhao","Daniel Ben-Levi","Junfeng Yang","Chengzhi Mao"],"pdf_url":"https://arxiv.org/pdf/2411.04223v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2312.02119"},{"id":"http://arxiv.org/abs/2411.02537v2","updated":"2024-11-06T19:27:10Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v2.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.04158v1","updated":"2024-11-06T13:50:50Z","published":"2024-11-06T13:50:50Z","title":"Analyzing Multimodal Features of Spontaneous Voice Assistant Commands\n  for Mild Cognitive Impairment Detection","summary":"  Mild cognitive impairment (MCI) is a major public health concern due to its\nhigh risk of progressing to dementia. This study investigates the potential of\ndetecting MCI with spontaneous voice assistant (VA) commands from 35 older\nadults in a controlled setting. Specifically, a command-generation task is\ndesigned with pre-defined intents for participants to freely generate commands\nthat are more associated with cognitive ability than read commands. We develop\nMCI classification and regression models with audio, textual, intent, and\nmultimodal fusion features. We find the command-generation task outperforms the\ncommand-reading task with an average classification accuracy of 82%, achieved\nby leveraging multimodal fusion features. In addition, generated commands\ncorrelate more strongly with memory and attention subdomains than read\ncommands. Our results confirm the effectiveness of the command-generation task\nand imply the promise of using longitudinal in-home commands for MCI detection.\n","authors":["Nana Lin","Youxiang Zhu","Xiaohui Liang","John A. Batsis","Caroline Summerour"],"pdf_url":"https://arxiv.org/pdf/2411.04158v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03823v1","updated":"2024-11-06T10:44:15Z","published":"2024-11-06T10:44:15Z","title":"Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM\n  Data Contamination","summary":"  The rapid progression of multimodal large language models (MLLMs) has\ndemonstrated superior performance on various multimodal benchmarks. However,\nthe issue of data contamination during training creates challenges in\nperformance evaluation and comparison. While numerous methods exist for\ndetecting dataset contamination in large language models (LLMs), they are less\neffective for MLLMs due to their various modalities and multiple training\nphases. In this study, we introduce a multimodal data contamination detection\nframework, MM-Detect, designed for MLLMs. Our experimental results indicate\nthat MM-Detect is sensitive to varying degrees of contamination and can\nhighlight significant performance improvements due to leakage of the training\nset of multimodal benchmarks. Furthermore, We also explore the possibility of\ncontamination originating from the pre-training phase of LLMs used by MLLMs and\nthe fine-tuning phase of MLLMs, offering new insights into the stages at which\ncontamination may be introduced.\n","authors":["Dingjie Song","Sicheng Lai","Shunian Chen","Lichao Sun","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04156v1","updated":"2024-11-06T10:28:46Z","published":"2024-11-06T10:28:46Z","title":"Crystal: Illuminating LLM Abilities on Language and Code","summary":"  Large Language Models (LLMs) specializing in code generation (which are also\noften referred to as code LLMs), e.g., StarCoder and Code Llama, play\nincreasingly critical roles in various software development scenarios. It is\nalso crucial for code LLMs to possess both code generation and natural language\nabilities for many specific applications, such as code snippet retrieval using\nnatural language or code explanations. The intricate interaction between\nacquiring language and coding skills complicates the development of strong code\nLLMs. Furthermore, there is a lack of thorough prior studies on the LLM\npretraining strategy that mixes code and natural language. In this work, we\npropose a pretraining strategy to enhance the integration of natural language\nand coding capabilities within a single LLM. Specifically, it includes two\nphases of training with appropriately adjusted code/language ratios. The\nresulting model, Crystal, demonstrates remarkable capabilities in both domains.\nSpecifically, it has natural language and coding performance comparable to that\nof Llama 2 and Code Llama, respectively. Crystal exhibits better data\nefficiency, using 1.4 trillion tokens compared to the more than 2 trillion\ntokens used by Llama 2 and Code Llama. We verify our pretraining strategy by\nanalyzing the training process and observe consistent improvements in most\nbenchmarks. We also adopted a typical application adaptation phase with a\ncode-centric data mixture, only to find that it did not lead to enhanced\nperformance or training efficiency, underlining the importance of a carefully\ndesigned data recipe. To foster research within the community, we commit to\nopen-sourcing every detail of the pretraining, including our training datasets,\ncode, loggings and 136 checkpoints throughout the training.\n","authors":["Tianhua Tao","Junbo Li","Bowen Tan","Hongyi Wang","William Marshall","Bhargav M Kanakiya","Joel Hestness","Natalia Vassilieva","Zhiqiang Shen","Eric P. Xing","Zhengzhong Liu"],"pdf_url":"https://arxiv.org/pdf/2411.04156v1.pdf","comment":"Published as a conference paper at COLM 2024"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.04125v1","updated":"2024-11-06T18:59:41Z","published":"2024-11-06T18:59:41Z","title":"Community Forensics: Using Thousands of Generators to Train Fake Image\n  Detectors","summary":"  One of the key challenges of detecting AI-generated images is spotting images\nthat have been created by previously unseen generative models. We argue that\nthe limited diversity of the training data is a major obstacle to addressing\nthis problem, and we propose a new dataset that is significantly larger and\nmore diverse than prior work. As part of creating this dataset, we\nsystematically download thousands of text-to-image latent diffusion models and\nsample images from them. We also collect images from dozens of popular open\nsource and commercial models. The resulting dataset contains 2.7M images that\nhave been sampled from 4803 different models. These images collectively capture\na wide range of scene content, generator architectures, and image processing\nsettings. Using this dataset, we study the generalization abilities of fake\nimage detectors. Our experiments suggest that detection performance improves as\nthe number of models in the training set increases, even when these models have\nsimilar architectures. We also find that detection performance improves as the\ndiversity of the models increases, and that our trained detectors generalize\nbetter than those trained on other datasets.\n","authors":["Jeongsoo Park","Andrew Owens"],"pdf_url":"https://arxiv.org/pdf/2411.04125v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2407.10964v2","updated":"2024-11-06T18:58:03Z","published":"2024-07-15T17:58:42Z","title":"No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen\n  Representations","summary":"  This paper introduces FUNGI, Features from UNsupervised GradIents, a method\nto enhance the features of transformer encoders by leveraging self-supervised\ngradients. Our method is simple: given any pretrained model, we first compute\ngradients from various self-supervised objectives for each input. These\ngradients are projected to a lower dimension and then concatenated with the\nmodel's output embedding. The resulting features are evaluated on k-nearest\nneighbor classification over 11 datasets from vision, 5 from natural language\nprocessing, and 2 from audio. Across backbones spanning various sizes and\npretraining strategies, FUNGI features provide consistent performance\nimprovements over the embeddings. We also show that using FUNGI features can\nbenefit linear classification, clustering and image retrieval, and that they\nsignificantly improve the retrieval-based in-context scene understanding\nabilities of pretrained models, for example improving upon DINO by +17% for\nsemantic segmentation - without any training.\n","authors":["Walter Simoncini","Spyros Gidaris","Andrei Bursuc","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2407.10964v2.pdf","comment":"NeurIPS 2024. Code available at\n  https://github.com/WalterSimoncini/fungivision"},{"id":"http://arxiv.org/abs/2411.04112v1","updated":"2024-11-06T18:44:09Z","published":"2024-11-06T18:44:09Z","title":"Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For\n  Autonomous Visual Robot Navigation","summary":"  Centralized learning requires data to be aggregated at a central server,\nwhich poses significant challenges in terms of data privacy and bandwidth\nconsumption. Federated learning presents a compelling alternative, however,\nvanilla federated learning methods deployed in robotics aim to learn a single\nglobal model across robots that works ideally for all. But in practice one\nmodel may not be well suited for robots deployed in various environments. This\npaper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated\nlearning framework that is deployed with vision based autonomous robot\nnavigation in diverse outdoor environments. The framework addresses the key\nfederated learning challenge of deteriorating model performance of a single\nglobal model due to the presence of non-IID data across real-world robots.\nExtensive real-world experiments validate that Fed-EC reduces the communication\nsize by 23x for each robot while matching the performance of centralized\nlearning for goal-oriented navigation and outperforms local learning. Fed-EC\ncan transfer previously learnt models to new robots that join the cluster.\n","authors":["Shreya Gummadi","Mateus V. Gasparino","Deepak Vasisht","Girish Chowdhary"],"pdf_url":"https://arxiv.org/pdf/2411.04112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.19863v4","updated":"2024-11-06T18:29:38Z","published":"2024-03-28T22:17:19Z","title":"DeNetDM: Debiasing by Network Depth Modulation","summary":"  Neural networks trained on biased datasets tend to inadvertently learn\nspurious correlations, hindering generalization. We formally prove that (1)\nsamples that exhibit spurious correlations lie on a lower rank manifold\nrelative to the ones that do not; and (2) the depth of a network acts as an\nimplicit regularizer on the rank of the attribute subspace that is encoded in\nits representations. Leveraging these insights, we present DeNetDM, a novel\ndebiasing method that uses network depth modulation as a way of developing\nrobustness to spurious correlations. Using a training paradigm derived from\nProduct of Experts, we create both biased and debiased branches with deep and\nshallow architectures and then distill knowledge to produce the target debiased\nmodel. Our method requires no bias annotations or explicit data augmentation\nwhile performing on par with approaches that require either or both. We\ndemonstrate that DeNetDM outperforms existing debiasing techniques on both\nsynthetic and real-world datasets by 5\\%. The project page is available at\nhttps://vssilpa.github.io/denetdm/.\n","authors":["Silpa Vadakkeeveetil Sreelatha","Adarsh Kappiyath","Abhra Chaudhuri","Anjan Dutta"],"pdf_url":"https://arxiv.org/pdf/2403.19863v4.pdf","comment":"Camera-ready version : NeurIPS 2024, * indicates these authors\n  contributed equally"},{"id":"http://arxiv.org/abs/2411.04097v1","updated":"2024-11-06T18:25:00Z","published":"2024-11-06T18:25:00Z","title":"RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned\n  Vision-Language Models","summary":"  Fine-tuned vision-language models (VLMs) often capture spurious correlations\nbetween image features and textual attributes, resulting in degraded zero-shot\nperformance at test time. Existing approaches for addressing spurious\ncorrelations (i) primarily operate at the global image-level rather than\nintervening directly on fine-grained image features and (ii) are predominantly\ndesigned for unimodal settings. In this work, we present RaVL, which takes a\nfine-grained perspective on VLM robustness by discovering and mitigating\nspurious correlations using local image features rather than operating at the\nglobal image level. Given a fine-tuned VLM, RaVL first discovers spurious\ncorrelations by leveraging a region-level clustering approach to identify\nprecise image features contributing to zero-shot classification errors. Then,\nRaVL mitigates the identified spurious correlation with a novel region-aware\nloss function that enables the VLM to focus on relevant regions and ignore\nspurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with\nvarious model architectures, data domains, and learned spurious correlations.\nOur results show that RaVL accurately discovers (191% improvement over the\nclosest baseline) and mitigates (8.2% improvement on worst-group image\nclassification accuracy) spurious correlations. Qualitative evaluations on\ngeneral-domain and medical-domain VLMs confirm our findings.\n","authors":["Maya Varma","Jean-Benoit Delbrouck","Zhihong Chen","Akshay Chaudhari","Curtis Langlotz"],"pdf_url":"https://arxiv.org/pdf/2411.04097v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.16147v3","updated":"2024-11-06T18:08:23Z","published":"2024-09-23T00:11:30Z","title":"Gaussian Deja-vu: Creating Controllable 3D Gaussian Head-Avatars with\n  Enhanced Generalization and Personalization Abilities","summary":"  Recent advancements in 3D Gaussian Splatting (3DGS) have unlocked significant\npotential for modeling 3D head avatars, providing greater flexibility than\nmesh-based methods and more efficient rendering compared to NeRF-based\napproaches. Despite these advancements, the creation of controllable 3DGS-based\nhead avatars remains time-intensive, often requiring tens of minutes to hours.\nTo expedite this process, we here introduce the \"Gaussian Deja-vu\" framework,\nwhich first obtains a generalized model of the head avatar and then\npersonalizes the result. The generalized model is trained on large 2D\n(synthetic and real) image datasets. This model provides a well-initialized 3D\nGaussian head that is further refined using a monocular video to achieve the\npersonalized head avatar. For personalizing, we propose learnable\nexpression-aware rectification blendmaps to correct the initial 3D Gaussians,\nensuring rapid convergence without the reliance on neural networks. Experiments\ndemonstrate that the proposed method meets its objectives. It outperforms\nstate-of-the-art 3D Gaussian head avatars in terms of photorealistic quality as\nwell as reduces training time consumption to at least a quarter of the existing\nmethods, producing the avatar in minutes.\n","authors":["Peizhi Yan","Rabab Ward","Qiang Tang","Shan Du"],"pdf_url":"https://arxiv.org/pdf/2409.16147v3.pdf","comment":"11 pages, Accepted by WACV 2025 in Round 1"},{"id":"http://arxiv.org/abs/2411.04079v1","updated":"2024-11-06T17:57:43Z","published":"2024-11-06T17:57:43Z","title":"Textual Decomposition Then Sub-motion-space Scattering for\n  Open-Vocabulary Motion Generation","summary":"  Text-to-motion generation is a crucial task in computer vision, which\ngenerates the target 3D motion by the given text. The existing annotated\ndatasets are limited in scale, resulting in most existing methods overfitting\nto the small datasets and unable to generalize to the motions of the open\ndomain. Some methods attempt to solve the open-vocabulary motion generation\nproblem by aligning to the CLIP space or using the Pretrain-then-Finetuning\nparadigm. However, the current annotated dataset's limited scale only allows\nthem to achieve mapping from sub-text-space to sub-motion-space, instead of\nmapping between full-text-space and full-motion-space (full mapping), which is\nthe key to attaining open-vocabulary motion generation. To this end, this paper\nproposes to leverage the atomic motion (simple body part motions over a short\ntime period) as an intermediate representation, and leverage two orderly\ncoupled steps, i.e., Textual Decomposition and Sub-motion-space Scattering, to\naddress the full mapping problem. For Textual Decomposition, we design a\nfine-grained description conversion algorithm, and combine it with the\ngeneralization ability of a large language model to convert any given motion\ntext into atomic texts. Sub-motion-space Scattering learns the compositional\nprocess from atomic motions to the target motions, to make the learned\nsub-motion-space scattered to form the full-motion-space. For a given motion of\nthe open domain, it transforms the extrapolation into interpolation and thereby\nsignificantly improves generalization. Our network, $DSO$-Net, combines textual\n$d$ecomposition and sub-motion-space $s$cattering to solve the\n$o$pen-vocabulary motion generation. Extensive experiments demonstrate that our\nDSO-Net achieves significant improvements over the state-of-the-art methods on\nopen-vocabulary motion generation. Code is available at\nhttps://vankouf.github.io/DSONet/.\n","authors":["Ke Fan","Jiangning Zhang","Ran Yi","Jingyu Gong","Yabiao Wang","Yating Wang","Xin Tan","Chengjie Wang","Lizhuang Ma"],"pdf_url":"https://arxiv.org/pdf/2411.04079v1.pdf","comment":"project page: https://vankouf.github.io/DSONet/"},{"id":"http://arxiv.org/abs/2411.04077v1","updated":"2024-11-06T17:55:37Z","published":"2024-11-06T17:55:37Z","title":"H-POPE: Hierarchical Polling-based Probing Evaluation of Hallucinations\n  in Large Vision-Language Models","summary":"  By leveraging both texts and images, large vision language models (LVLMs)\nhave shown significant progress in various multi-modal tasks. Nevertheless,\nthese models often suffer from hallucinations, e.g., they exhibit\ninconsistencies between the visual input and the textual output. To address\nthis, we propose H-POPE, a coarse-to-fine-grained benchmark that systematically\nassesses hallucination in object existence and attributes. Our evaluation shows\nthat models are prone to hallucinations on object existence, and even more so\non fine-grained attributes. We further investigate whether these models rely on\nvisual input to formulate the output texts.\n","authors":["Nhi Pham","Michael Schott"],"pdf_url":"https://arxiv.org/pdf/2411.04077v1.pdf","comment":"Poster at https://sites.google.com/berkeley.edu/bb-stat/home"},{"id":"http://arxiv.org/abs/2411.04059v1","updated":"2024-11-06T17:11:44Z","published":"2024-11-06T17:11:44Z","title":"Pseudo-labeling with Keyword Refining for Few-Supervised Video\n  Captioning","summary":"  Video captioning generate a sentence that describes the video content.\nExisting methods always require a number of captions (\\eg, 10 or 20) per video\nto train the model, which is quite costly. In this work, we explore the\npossibility of using only one or very few ground-truth sentences, and introduce\na new task named few-supervised video captioning. Specifically, we propose a\nfew-supervised video captioning framework that consists of lexically\nconstrained pseudo-labeling module and keyword-refined captioning module.\nUnlike the random sampling in natural language processing that may cause\ninvalid modifications (\\ie, edit words), the former module guides the model to\nedit words using some actions (\\eg, copy, replace, insert, and delete) by a\npretrained token-level classifier, and then fine-tunes candidate sentences by a\npretrained language model. Meanwhile, the former employs the repetition\npenalized sampling to encourage the model to yield concise pseudo-labeled\nsentences with less repetition, and selects the most relevant sentences upon a\npretrained video-text model. Moreover, to keep semantic consistency between\npseudo-labeled sentences and video content, we develop the transformer-based\nkeyword refiner with the video-keyword gated fusion strategy to emphasize more\non relevant words. Extensive experiments on several benchmarks demonstrate the\nadvantages of the proposed approach in both few-supervised and fully-supervised\nscenarios. The code implementation is available at\nhttps://github.com/mlvccn/PKG_VidCap\n","authors":["Ping Li","Tao Wang","Xinkui Zhao","Xianghua Xu","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2411.04059v1.pdf","comment":"12 figures, Accepted in Pattern Recognition"},{"id":"http://arxiv.org/abs/2410.23247v2","updated":"2024-11-06T17:07:53Z","published":"2024-10-30T17:30:35Z","title":"bit2bit: 1-bit quanta video reconstruction via self-supervised photon\n  prediction","summary":"  Quanta image sensors, such as SPAD arrays, are an emerging sensor technology,\nproducing 1-bit arrays representing photon detection events over exposures as\nshort as a few nanoseconds. In practice, raw data are post-processed using\nheavy spatiotemporal binning to create more useful and interpretable images at\nthe cost of degrading spatiotemporal resolution. In this work, we propose\nbit2bit, a new method for reconstructing high-quality image stacks at the\noriginal spatiotemporal resolution from sparse binary quanta image data.\nInspired by recent work on Poisson denoising, we developed an algorithm that\ncreates a dense image sequence from sparse binary photon data by predicting the\nphoton arrival location probability distribution. However, due to the binary\nnature of the data, we show that the assumption of a Poisson distribution is\ninadequate. Instead, we model the process with a Bernoulli lattice process from\nthe truncated Poisson. This leads to the proposal of a novel self-supervised\nsolution based on a masked loss function. We evaluate our method using both\nsimulated and real data. On simulated data from a conventional video, we\nachieve 34.35 mean PSNR with extremely photon-sparse binary input (<0.06\nphotons per pixel per frame). We also present a novel dataset containing a wide\nrange of real SPAD high-speed videos under various challenging imaging\nconditions. The scenes cover strong/weak ambient light, strong motion,\nultra-fast events, etc., which will be made available to the community, on\nwhich we demonstrate the promise of our approach. Both reconstruction quality\nand throughput substantially surpass the state-of-the-art methods (e.g., Quanta\nBurst Photography (QBP)). Our approach significantly enhances the visualization\nand usability of the data, enabling the application of existing analysis\ntechniques.\n","authors":["Yehe Liu","Alexander Krull","Hector Basevi","Ales Leonardis","Michael W. Jenkins"],"pdf_url":"https://arxiv.org/pdf/2410.23247v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04055v1","updated":"2024-11-06T16:59:51Z","published":"2024-11-06T16:59:51Z","title":"Multi-branch Spatio-Temporal Graph Neural Network For Efficient Ice\n  Layer Thickness Prediction","summary":"  Understanding spatio-temporal patterns in polar ice layers is essential for\ntracking changes in ice sheet balance and assessing ice dynamics. While\nconvolutional neural networks are widely used in learning ice layer patterns\nfrom raw echogram images captured by airborne snow radar sensors, noise in the\nechogram images prevents researchers from getting high-quality results.\nInstead, we focus on geometric deep learning using graph neural networks,\naiming to build a spatio-temporal graph neural network that learns from\nthickness information of the top ice layers and predicts for deeper layers. In\nthis paper, we developed a novel multi-branch spatio-temporal graph neural\nnetwork that used the GraphSAGE framework for spatio features learning and a\ntemporal convolution operation to capture temporal changes, enabling different\nbranches of the network to be more specialized and focusing on a single\nlearning task. We found that our proposed multi-branch network can consistently\noutperform the current fused spatio-temporal graph neural network in both\naccuracy and efficiency.\n","authors":["Zesheng Liu","Maryam Rahnemoonfar"],"pdf_url":"https://arxiv.org/pdf/2411.04055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08774v3","updated":"2024-11-06T16:57:36Z","published":"2024-02-13T20:16:31Z","title":"LDTrack: Dynamic People Tracking by Service Robots using Diffusion\n  Models","summary":"  Tracking of dynamic people in cluttered and crowded human-centered\nenvironments is a challenging robotics problem due to the presence of\nintraclass variations including occlusions, pose deformations, and lighting\nvariations. This paper introduces a novel deep learning architecture, using\nconditional latent diffusion models, the Latent Diffusion Track (LDTrack), for\ntracking multiple dynamic people under intraclass variations. By uniquely\nutilizing conditional latent diffusion models to capture temporal person\nembeddings, our architecture can adapt to appearance changes of people over\ntime. We incorporated a latent feature encoder network which enables the\ndiffusion process to operate within a high-dimensional latent space to allow\nfor the extraction and spatial-temporal refinement of such rich features as\nperson appearance, motion, location, identity, and contextual information.\nExtensive experiments demonstrate the effectiveness of LDTrack over other\nstate-of-the-art tracking methods in cluttered and crowded human-centered\nenvironments under intraclass variations. Namely, the results show our method\noutperforms existing deep learning robotic people tracking methods in both\ntracking accuracy and tracking precision with statistical significance.\nAdditionally, a comprehensive multi-object tracking comparison study was\nperformed against the state-of-the-art methods in urban environments,\ndemonstrating the generalizability of LDTrack. An ablation study was performed\nto validate the design choices of LDTrack.\n","authors":["Angus Fung","Beno Benhabib","Goldie Nejat"],"pdf_url":"https://arxiv.org/pdf/2402.08774v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16749v2","updated":"2024-11-06T16:55:39Z","published":"2024-05-27T01:38:30Z","title":"DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion\n  Models","summary":"  Pretrained diffusion models (DMs) have recently been popularly used in\nsolving inverse problems (IPs). The existing methods mostly interleave\niterative steps in the reverse diffusion process and iterative steps to bring\nthe iterates closer to satisfying the measurement constraint. However, such\ninterleaving methods struggle to produce final results that look like natural\nobjects of interest (i.e., manifold feasibility) and fit the measurement (i.e.,\nmeasurement feasibility), especially for nonlinear IPs. Moreover, their\ncapabilities to deal with noisy IPs with unknown types and levels of\nmeasurement noise are unknown. In this paper, we advocate viewing the reverse\nprocess in DMs as a function and propose a novel plug-in method for solving IPs\nusing pretrained DMs, dubbed DMPlug. DMPlug addresses the issues of manifold\nfeasibility and measurement feasibility in a principled manner, and also shows\ngreat potential for being robust to unknown types and levels of noise. Through\nextensive experiments across various IP tasks, including two linear and three\nnonlinear IPs, we demonstrate that DMPlug consistently outperforms\nstate-of-the-art methods, often by large margins especially for nonlinear IPs.\nThe code is available at https://github.com/sun-umn/DMPlug.\n","authors":["Hengkang Wang","Xu Zhang","Taihui Li","Yuxiang Wan","Tiancong Chen","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2405.16749v2.pdf","comment":"Published in NeurIPS 2024\n  (https://openreview.net/forum?id=81IFFsfQUj)"},{"id":"http://arxiv.org/abs/2410.05969v2","updated":"2024-11-06T16:28:58Z","published":"2024-10-08T12:16:30Z","title":"Deep neural network-based detection of counterfeit products from\n  smartphone images","summary":"  Counterfeit products such as drugs and vaccines as well as luxury items such\nas high-fashion handbags, watches, jewelry, garments, and cosmetics, represent\nsignificant direct losses of revenue to legitimate manufacturers and vendors,\nas well as indirect costs to societies at large. We present the world's first\npurely computer-vision-based system to combat such counterfeiting-one that does\nnot require special security tags or other alterations to the products or\nmodifications to supply chain tracking. Our deep neural network system shows\nhigh accuracy on branded garments from our first manufacturer tested (99.71%\nafter 3.06% rejections) using images captured under natural, weakly controlled\nconditions, such as in retail stores, customs checkpoints, warehouses, and\noutdoors. Our system, suitably transfer trained on a small number of fake and\ngenuine articles, should find application in additional product categories as\nwell, for example fashion accessories, perfume boxes, medicines, and more.\n","authors":["Hugo Garcia-Cotte","Dorra Mellouli","Abdul Rehman","Li Wang","David G. Stork"],"pdf_url":"https://arxiv.org/pdf/2410.05969v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17537v3","updated":"2024-11-06T15:56:04Z","published":"2024-05-27T17:57:48Z","title":"CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale","summary":"  Measuring biodiversity is crucial for understanding ecosystem health. While\nprior works have developed machine learning models for taxonomic classification\nof photographic images and DNA separately, in this work, we introduce a\nmultimodal approach combining both, using CLIP-style contrastive learning to\nalign images, barcode DNA, and text-based representations of taxonomic labels\nin a unified embedding space. This allows for accurate classification of both\nknown and unknown insect species without task-specific fine-tuning, leveraging\ncontrastive learning for the first time to fuse DNA and image data. Our method\nsurpasses previous single-modality approaches in accuracy by over 8% on\nzero-shot learning tasks, showcasing its effectiveness in biodiversity studies.\n","authors":["ZeMing Gong","Austin T. Wang","Xiaoliang Huo","Joakim Bruslund Haurum","Scott C. Lowe","Graham W. Taylor","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2405.17537v3.pdf","comment":"25 pages with 11 figures"},{"id":"http://arxiv.org/abs/2411.04008v1","updated":"2024-11-06T15:47:18Z","published":"2024-11-06T15:47:18Z","title":"Aligning Characteristic Descriptors with Images for Human-Expert-like\n  Explainability","summary":"  In mission-critical domains such as law enforcement and medical diagnosis,\nthe ability to explain and interpret the outputs of deep learning models is\ncrucial for ensuring user trust and supporting informed decision-making.\nDespite advancements in explainability, existing methods often fall short in\nproviding explanations that mirror the depth and clarity of those given by\nhuman experts. Such expert-level explanations are essential for the dependable\napplication of deep learning models in law enforcement and medical contexts.\nAdditionally, we recognize that most explanations in real-world scenarios are\ncommunicated primarily through natural language. Addressing these needs, we\npropose a novel approach that utilizes characteristic descriptors to explain\nmodel decisions by identifying their presence in images, thereby generating\nexpert-like explanations. Our method incorporates a concept bottleneck layer\nwithin the model architecture, which calculates the similarity between image\nand descriptor encodings to deliver inherent and faithful explanations. Through\nexperiments in face recognition and chest X-ray diagnosis, we demonstrate that\nour approach offers a significant contrast over existing techniques, which are\noften limited to the use of saliency maps. We believe our approach represents a\nsignificant step toward making deep learning systems more accountable,\ntransparent, and trustworthy in the critical domains of face recognition and\nmedical diagnosis.\n","authors":["Bharat Chandra Yalavarthi","Nalini Ratha"],"pdf_url":"https://arxiv.org/pdf/2411.04008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04004v1","updated":"2024-11-06T15:43:51Z","published":"2024-11-06T15:43:51Z","title":"Synomaly Noise and Multi-Stage Diffusion: A Novel Approach for\n  Unsupervised Anomaly Detection in Ultrasound Imaging","summary":"  Ultrasound (US) imaging is widely used in routine clinical practice due to\nits advantages of being radiation-free, cost-effective, and portable. However,\nthe low reproducibility and quality of US images, combined with the scarcity of\nexpert-level annotation, make the training of fully supervised segmentation\nmodels challenging. To address these issues, we propose a novel unsupervised\nanomaly detection framework based on a diffusion model that incorporates a\nsynthetic anomaly (Synomaly) noise function and a multi-stage diffusion\nprocess. Synomaly noise introduces synthetic anomalies into healthy images\nduring training, allowing the model to effectively learn anomaly removal. The\nmulti-stage diffusion process is introduced to progressively denoise images,\npreserving fine details while improving the quality of anomaly-free\nreconstructions. The generated high-fidelity counterfactual healthy images can\nfurther enhance the interpretability of the segmentation models, as well as\nprovide a reliable baseline for evaluating the extent of anomalies and\nsupporting clinical decision-making. Notably, the unsupervised anomaly\ndetection model is trained purely on healthy images, eliminating the need for\nanomalous training samples and pixel-level annotations. We validate the\nproposed approach on carotid US, brain MRI, and liver CT datasets. The\nexperimental results demonstrate that the proposed framework outperforms\nexisting state-of-the-art unsupervised anomaly detection methods, achieving\nperformance comparable to fully supervised segmentation models in the US\ndataset. Additionally, ablation studies underline the importance of\nhyperparameter selection for Synomaly noise and the effectiveness of the\nmulti-stage diffusion process in enhancing model performance.\n","authors":["Yuan Bi","Lucie Huang","Ricarda Clarenbach","Reza Ghotbi","Angelos Karlas","Nassir Navab","Zhongliang Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.04004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03993v1","updated":"2024-11-06T15:34:57Z","published":"2024-11-06T15:34:57Z","title":"Local vs distributed representations: What is the right basis for\n  interpretability?","summary":"  Much of the research on the interpretability of deep neural networks has\nfocused on studying the visual features that maximally activate individual\nneurons. However, recent work has cast doubts on the usefulness of such local\nrepresentations for understanding the behavior of deep neural networks because\nindividual neurons tend to respond to multiple unrelated visual patterns, a\nphenomenon referred to as \"superposition\". A promising alternative to\ndisentangle these complex patterns is learning sparsely distributed vector\nrepresentations from entire network layers, as the resulting basis vectors\nseemingly encode single identifiable visual patterns consistently. Thus, one\nwould expect the resulting code to align better with human perceivable visual\npatterns, but supporting evidence remains, at best, anecdotal. To fill this\ngap, we conducted three large-scale psychophysics experiments collected from a\npool of 560 participants. Our findings provide (i) strong evidence that\nfeatures obtained from sparse distributed representations are easier to\ninterpret by human observers and (ii) that this effect is more pronounced in\nthe deepest layers of a neural network. Complementary analyses also reveal that\n(iii) features derived from sparse distributed representations contribute more\nto the model's decision. Overall, our results highlight that distributed\nrepresentations constitute a superior basis for interpretability, underscoring\na need for the field to move beyond the interpretation of local neural codes in\nfavor of sparsely distributed ones.\n","authors":["Julien Colin","Lore Goetschalckx","Thomas Fel","Victor Boutin","Jay Gopal","Thomas Serre","Nuria Oliver"],"pdf_url":"https://arxiv.org/pdf/2411.03993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03990v1","updated":"2024-11-06T15:30:42Z","published":"2024-11-06T15:30:42Z","title":"ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy","summary":"  Imitation learning, e.g., diffusion policy, has been proven effective in\nvarious robotic manipulation tasks. However, extensive demonstrations are\nrequired for policy robustness and generalization. To reduce the demonstration\nreliance, we leverage spatial symmetry and propose ET-SEED, an efficient\ntrajectory-level SE(3) equivariant diffusion model for generating action\nsequences in complex robot manipulation tasks. Further, previous equivariant\ndiffusion models require the per-step equivariance in the Markov process,\nmaking it difficult to learn policy under such strong constraints. We\ntheoretically extend equivariant Markov kernels and simplify the condition of\nequivariant diffusion process, thereby significantly improving training\nefficiency for trajectory-level SE(3) equivariant diffusion policy in an\nend-to-end manner. We evaluate ET-SEED on representative robotic manipulation\ntasks, involving rigid body, articulated and deformable object. Experiments\ndemonstrate superior data efficiency and manipulation proficiency of our\nproposed method, as well as its ability to generalize to unseen configurations\nwith only a few demonstrations. Website: https://et-seed.github.io/\n","authors":["Chenrui Tie","Yue Chen","Ruihai Wu","Boxuan Dong","Zeyi Li","Chongkai Gao","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2411.03990v1.pdf","comment":"Accept to CoRL 2024 Workshop on X-Embodiment Robot Learning"},{"id":"http://arxiv.org/abs/2411.03982v1","updated":"2024-11-06T15:19:24Z","published":"2024-11-06T15:19:24Z","title":"ReEdit: Multimodal Exemplar-Based Image Editing with Diffusion Models","summary":"  Modern Text-to-Image (T2I) Diffusion models have revolutionized image editing\nby enabling the generation of high-quality photorealistic images. While the de\nfacto method for performing edits with T2I models is through text instructions,\nthis approach non-trivial due to the complex many-to-many mapping between\nnatural language and images. In this work, we address exemplar-based image\nediting -- the task of transferring an edit from an exemplar pair to a content\nimage(s). We propose ReEdit, a modular and efficient end-to-end framework that\ncaptures edits in both text and image modalities while ensuring the fidelity of\nthe edited image. We validate the effectiveness of ReEdit through extensive\ncomparisons with state-of-the-art baselines and sensitivity analyses of key\ndesign choices. Our results demonstrate that ReEdit consistently outperforms\ncontemporary approaches both qualitatively and quantitatively. Additionally,\nReEdit boasts high practical applicability, as it does not require any\ntask-specific optimization and is four times faster than the next best\nbaseline.\n","authors":["Ashutosh Srivastava","Tarun Ram Menta","Abhinav Java","Avadhoot Jadhav","Silky Singh","Surgan Jandial","Balaji Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2411.03982v1.pdf","comment":"First three authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2411.03976v1","updated":"2024-11-06T15:13:31Z","published":"2024-11-06T15:13:31Z","title":"HRDecoder: High-Resolution Decoder Network for Fundus Image Lesion\n  Segmentation","summary":"  High resolution is crucial for precise segmentation in fundus images, yet\nhandling high-resolution inputs incurs considerable GPU memory costs, with\ndiminishing performance gains as overhead increases. To address this issue\nwhile tackling the challenge of segmenting tiny objects, recent studies have\nexplored local-global fusion methods. These methods preserve fine details using\nlocal regions and capture long-range context information from downscaled global\nimages. However, the necessity of multiple forward passes inevitably incurs\nsignificant computational overhead, adversely affecting inference speed. In\nthis paper, we propose HRDecoder, a simple High-Resolution Decoder network for\nfundus lesion segmentation. It integrates a high-resolution representation\nlearning module to capture fine-grained local features and a high-resolution\nfusion module to fuse multi-scale predictions. Our method effectively improves\nthe overall segmentation accuracy of fundus lesions while consuming reasonable\nmemory and computational overhead, and maintaining satisfying inference speed.\nExperimental results on the IDRID and DDR datasets demonstrate the\neffectiveness of our method. Code is available at\nhttps://github.com/CVIU-CSU/HRDecoder.\n","authors":["Ziyuan Ding","Yixiong Liang","Shichao Kan","Qing Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03976v1.pdf","comment":"11 pages, 3 figures, accepted by MICCAI 2024, the revised version"},{"id":"http://arxiv.org/abs/2407.17952v2","updated":"2024-11-06T14:58:17Z","published":"2024-07-25T11:16:37Z","title":"BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular\n  Depth Estimation","summary":"  By training over large-scale datasets, zero-shot monocular depth estimation\n(MDE) methods show robust performance in the wild but often suffer from\ninsufficient detail. Although recent diffusion-based MDE approaches exhibit a\nsuperior ability to extract details, they struggle in geometrically complex\nscenes that challenge their geometry prior, trained on less diverse 3D data. To\nleverage the complementary merits of both worlds, we propose BetterDepth to\nachieve geometrically correct affine-invariant MDE while capturing fine\ndetails. Specifically, BetterDepth is a conditional diffusion-based refiner\nthat takes the prediction from pre-trained MDE models as depth conditioning, in\nwhich the global depth layout is well-captured, and iteratively refines details\nbased on the input image. For the training of such a refiner, we propose global\npre-alignment and local patch masking methods to ensure BetterDepth remains\nfaithful to the depth conditioning while learning to add fine-grained scene\ndetails. With efficient training on small-scale synthetic datasets, BetterDepth\nachieves state-of-the-art zero-shot MDE performance on diverse public datasets\nand on in-the-wild scenes. Moreover, BetterDepth can improve the performance of\nother MDE models in a plug-and-play manner without further re-training.\n","authors":["Xiang Zhang","Bingxin Ke","Hayko Riemenschneider","Nando Metzger","Anton Obukhov","Markus Gross","Konrad Schindler","Christopher Schroers"],"pdf_url":"https://arxiv.org/pdf/2407.17952v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.00738v3","updated":"2024-11-06T14:45:58Z","published":"2024-08-01T17:35:58Z","title":"Virchow2: Scaling Self-Supervised Mixed Magnification Models in\n  Pathology","summary":"  Foundation models are rapidly being developed for computational pathology\napplications. However, it remains an open question which factors are most\nimportant for downstream performance with data scale and diversity, model size,\nand training algorithm all playing a role. In this work, we propose algorithmic\nmodifications, tailored for pathology, and we present the result of scaling\nboth data and model size, surpassing previous studies in both dimensions. We\nintroduce three new models: Virchow2, a 632 million parameter vision\ntransformer, Virchow2G, a 1.9 billion parameter vision transformer, and\nVirchow2G Mini, a 22 million parameter distillation of Virchow2G, each trained\nwith 3.1 million histopathology whole slide images, with diverse tissues,\noriginating institutions, and stains. We achieve state of the art performance\non 12 tile-level tasks, as compared to the top performing competing models. Our\nresults suggest that data diversity and domain-specific methods can outperform\nmodels that only scale in the number of parameters, but, on average,\nperformance benefits from the combination of domain-specific methods, data\nscale, and model scale.\n","authors":["Eric Zimmermann","Eugene Vorontsov","Julian Viret","Adam Casson","Michal Zelechowski","George Shaikovski","Neil Tenenholtz","James Hall","David Klimstra","Razik Yousfi","Thomas Fuchs","Nicolo Fusi","Siqi Liu","Kristen Severson"],"pdf_url":"https://arxiv.org/pdf/2408.00738v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03960v1","updated":"2024-11-06T14:45:41Z","published":"2024-11-06T14:45:41Z","title":"Face Reconstruction from Face Embeddings using Adapter to a Face\n  Foundation Model","summary":"  Face recognition systems extract embedding vectors from face images and use\nthese embeddings to verify or identify individuals. Face reconstruction attack\n(also known as template inversion) refers to reconstructing face images from\nface embeddings and using the reconstructed face image to enter a face\nrecognition system. In this paper, we propose to use a face foundation model to\nreconstruct face images from the embeddings of a blackbox face recognition\nmodel. The foundation model is trained with 42M images to generate face images\nfrom the facial embeddings of a fixed face recognition model. We propose to use\nan adapter to translate target embeddings into the embedding space of the\nfoundation model. The generated images are evaluated on different face\nrecognition models and different datasets, demonstrating the effectiveness of\nour method to translate embeddings of different face recognition models. We\nalso evaluate the transferability of reconstructed face images when attacking\ndifferent face recognition models. Our experimental results show that our\nreconstructed face images outperform previous reconstruction attacks against\nface recognition models.\n","authors":["Hatef Otroshi Shahreza","Anjith George","Sébastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2411.03960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03959v1","updated":"2024-11-06T14:45:16Z","published":"2024-11-06T14:45:16Z","title":"Energy Score-based Pseudo-Label Filtering and Adaptive Loss for\n  Imbalanced Semi-supervised SAR target recognition","summary":"  Automatic target recognition (ATR) is an important use case for synthetic\naperture radar (SAR) image interpretation. Recent years have seen significant\nadvancements in SAR ATR technology based on semi-supervised learning. However,\nexisting semi-supervised SAR ATR algorithms show low recognition accuracy in\nthe case of class imbalance. This work offers a non-balanced semi-supervised\nSAR target recognition approach using dynamic energy scores and adaptive loss.\nFirst, an energy score-based method is developed to dynamically select\nunlabeled samples near to the training distribution as pseudo-labels during\ntraining, assuring pseudo-label reliability in long-tailed distribution\ncircumstances. Secondly, loss functions suitable for class imbalances are\nproposed, including adaptive margin perception loss and adaptive hard triplet\nloss, the former offsets inter-class confusion of classifiers, alleviating the\nimbalance issue inherent in pseudo-label generation. The latter effectively\ntackles the model's preference for the majority class by focusing on complex\ndifficult samples during training. Experimental results on extremely imbalanced\nSAR datasets demonstrate that the proposed method performs well under the dual\nconstraints of scarce labels and data imbalance, effectively overcoming the\nmodel bias caused by data imbalance and achieving high-precision target\nrecognition.\n","authors":["Xinzheng Zhang","Yuqing Luo","Guopeng Li"],"pdf_url":"https://arxiv.org/pdf/2411.03959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07724v2","updated":"2024-11-06T14:29:36Z","published":"2024-04-11T13:16:47Z","title":"Applying Guidance in a Limited Interval Improves Sample and Distribution\n  Quality in Diffusion Models","summary":"  Guidance is a crucial technique for extracting the best performance out of\nimage-generating diffusion models. Traditionally, a constant guidance weight\nhas been applied throughout the sampling chain of an image. We show that\nguidance is clearly harmful toward the beginning of the chain (high noise\nlevels), largely unnecessary toward the end (low noise levels), and only\nbeneficial in the middle. We thus restrict it to a specific range of noise\nlevels, improving both the inference speed and result quality. This limited\nguidance interval improves the record FID in ImageNet-512 significantly, from\n1.81 to 1.40. We show that it is quantitatively and qualitatively beneficial\nacross different sampler parameters, network architectures, and datasets,\nincluding the large-scale setting of Stable Diffusion XL. We thus suggest\nexposing the guidance interval as a hyperparameter in all diffusion models that\nuse guidance.\n","authors":["Tuomas Kynkäänniemi","Miika Aittala","Tero Karras","Samuli Laine","Timo Aila","Jaakko Lehtinen"],"pdf_url":"https://arxiv.org/pdf/2404.07724v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.09786v2","updated":"2024-11-06T14:22:28Z","published":"2024-07-13T06:53:39Z","title":"Self-supervised 3D Point Cloud Completion via Multi-view Adversarial\n  Learning","summary":"  In real-world scenarios, scanned point clouds are often incomplete due to\nocclusion issues. The task of self-supervised point cloud completion involves\nreconstructing missing regions of these incomplete objects without the\nsupervision of complete ground truth. Current self-supervised methods either\nrely on multiple views of partial observations for supervision or overlook the\nintrinsic geometric similarity that can be identified and utilized from the\ngiven partial point clouds. In this paper, we propose MAL-SPC, a framework that\neffectively leverages both object-level and category-specific geometric\nsimilarities to complete missing structures. Our MAL-SPC does not require any\n3D complete supervision and only necessitates a single partial point cloud for\neach object. Specifically, we first introduce a Pattern Retrieval Network to\nretrieve similar position and curvature patterns between the partial input and\nthe predicted shape, then leverage these similarities to densify and refine the\nreconstructed results. Additionally, we render the reconstructed complete shape\ninto multi-view depth maps and design an adversarial learning module to learn\nthe geometry of the target shape from category-specific single-view depth\nimages. To achieve anisotropic rendering, we design a density-aware radius\nestimation algorithm to improve the quality of the rendered images. Our MAL-SPC\nyields the best results compared to current state-of-the-art methods.We will\nmake the source code publicly available at \\url{https://github.com/ltwu6/malspc\n","authors":["Lintai Wu","Xianjing Cheng","Yong Xu","Huanqiang Zeng","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2407.09786v2.pdf","comment":"14 pages,10 figures"},{"id":"http://arxiv.org/abs/2411.03926v1","updated":"2024-11-06T13:57:53Z","published":"2024-11-06T13:57:53Z","title":"Act in Collusion: A Persistent Distributed Multi-Target Backdoor in\n  Federated Learning","summary":"  Federated learning, a novel paradigm designed to protect data privacy, is\nvulnerable to backdoor attacks due to its distributed nature. Current research\noften designs attacks based on a single attacker with a single backdoor,\noverlooking more realistic and complex threats in federated learning. We\npropose a more practical threat model for federated learning: the distributed\nmulti-target backdoor. In this model, multiple attackers control different\nclients, embedding various triggers and targeting different classes,\ncollaboratively implanting backdoors into the global model via central\naggregation. Empirical validation shows that existing methods struggle to\nmaintain the effectiveness of multiple backdoors in the global model. Our key\ninsight is that similar backdoor triggers cause parameter conflicts and\ninjecting new backdoors disrupts gradient directions, significantly weakening\nsome backdoors performance. To solve this, we propose a Distributed\nMulti-Target Backdoor Attack (DMBA), ensuring efficiency and persistence of\nbackdoors from different malicious clients. To avoid parameter conflicts, we\ndesign a multi-channel dispersed frequency trigger strategy to maximize trigger\ndifferences. To mitigate gradient interference, we introduce backdoor replay in\nlocal training to neutralize conflicting gradients. Extensive validation shows\nthat 30 rounds after the attack, Attack Success Rates of three different\nbackdoors from various clients remain above 93%. The code will be made publicly\navailable after the review period.\n","authors":["Tao Liu","Wu Yang","Chen Xu","Jiguang Lv","Huanran Wang","Yuhang Zhang","Shuchun Xu","Dapeng Man"],"pdf_url":"https://arxiv.org/pdf/2411.03926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07001v4","updated":"2024-11-06T13:56:28Z","published":"2024-05-11T12:33:46Z","title":"ChartInsights: Evaluating Multimodal Large Language Models for Low-Level\n  Chart Question Answering","summary":"  Chart question answering (ChartQA) tasks play a critical role in interpreting\nand extracting insights from visualization charts. While recent advancements in\nmultimodal large language models (MLLMs) like GPT-4o have shown promise in\nhigh-level ChartQA tasks, such as chart captioning, their effectiveness in\nlow-level ChartQA tasks (e.g., identifying correlations) remains underexplored.\nIn this paper, we address this gap by evaluating MLLMs on low-level ChartQA\nusing a newly curated dataset, ChartInsights, which consists of 22,347 (chart,\ntask, query, answer) covering 10 data analysis tasks across 7 chart types. We\nsystematically evaluate 19 advanced MLLMs, including 12 open-source and 7\nclosed-source models. The average accuracy rate across these models is 39.8%,\nwith GPT-4o achieving the highest accuracy at 69.17%. To further explore the\nlimitations of MLLMs in low-level ChartQA, we conduct experiments that alter\nvisual elements of charts (e.g., changing color schemes, adding image noise) to\nassess their impact on the task effectiveness. Furthermore, we propose a new\ntextual prompt strategy, Chain-of-Charts, tailored for low-level ChartQA tasks,\nwhich boosts performance by 14.41%, achieving an accuracy of 83.58%. Finally,\nincorporating a visual prompt strategy that directs attention to relevant\nvisual elements further improves accuracy to 84.32%.\n","authors":["Yifan Wu","Lutao Yan","Leixian Shen","Yunhai Wang","Nan Tang","Yuyu Luo"],"pdf_url":"https://arxiv.org/pdf/2405.07001v4.pdf","comment":"EMNLP 2024 Conference Paper"},{"id":"http://arxiv.org/abs/2411.03924v1","updated":"2024-11-06T13:54:26Z","published":"2024-11-06T13:54:26Z","title":"Self-supervised Representation Learning for Cell Event Recognition\n  through Time Arrow Prediction","summary":"  The spatio-temporal nature of live-cell microscopy data poses challenges in\nthe analysis of cell states which is fundamental in bioimaging. Deep-learning\nbased segmentation or tracking methods rely on large amount of high quality\nannotations to work effectively. In this work, we explore an alternative\nsolution: using feature maps obtained from self-supervised representation\nlearning (SSRL) on time arrow prediction (TAP) for the downstream supervised\ntask of cell event recognition. We demonstrate through extensive experiments\nand analysis that this approach can achieve better performance with limited\nannotation compared to models trained from end to end using fully supervised\napproach. Our analysis also provides insight into applications of the SSRL\nusing TAP in live-cell microscopy.\n","authors":["Cangxiong Chen","Vinay P. Namboodiri","Julia E. Sero"],"pdf_url":"https://arxiv.org/pdf/2411.03924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06629v4","updated":"2024-11-06T13:29:57Z","published":"2023-10-10T13:48:18Z","title":"EViT: An Eagle Vision Transformer with Bi-Fovea Self-Attention","summary":"  Owing to advancements in deep learning technology, Vision Transformers (ViTs)\nhave demonstrated impressive performance in various computer vision tasks.\nNonetheless, ViTs still face some challenges, such as high computational\ncomplexity and the absence of desirable inductive biases. To alleviate these\nissues, {the potential advantages of combining eagle vision with ViTs are\nexplored. We summarize a Bi-Fovea Visual Interaction (BFVI) structure inspired\nby the unique physiological and visual characteristics of eagle eyes. A novel\nBi-Fovea Self-Attention (BFSA) mechanism and Bi-Fovea Feedforward Network\n(BFFN) are proposed based on this structural design approach, which can be used\nto mimic the hierarchical and parallel information processing scheme of the\nbiological visual cortex, enabling networks to learn feature representations of\ntargets in a coarse-to-fine manner. Furthermore, a Bionic Eagle Vision (BEV)\nblock is designed as the basic building unit based on the BFSA mechanism and\nBFFN. By stacking BEV blocks, a unified and efficient family of pyramid\nbackbone networks called Eagle Vision Transformers (EViTs) is developed.\nExperimental results show that EViTs exhibit highly competitive performance in\nvarious computer vision tasks, such as image classification, object detection\nand semantic segmentation. Compared with other approaches, EViTs have\nsignificant advantages, especially in terms of performance and computational\nefficiency. Code is available at https://github.com/nkusyl/EViT\n","authors":["Yulong Shi","Mingwei Sun","Yongshuai Wang","Jiahao Ma","Zengqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2310.06629v4.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2411.00393v3","updated":"2024-11-06T13:25:42Z","published":"2024-11-01T06:40:47Z","title":"Advantages of Neural Population Coding for Deep Learning","summary":"  Scalar variables, e.g., the orientation of a shape in an image, are commonly\npredicted using a single output neuron in a neural network. In contrast, the\nmammalian cortex represents variables with a population of neurons. In this\npopulation code, each neuron is most active at its preferred value and shows\npartial activity for other values. Here, we investigate the benefit of using a\npopulation code for the output layer of a neural network. We compare population\ncodes against single-neuron outputs and one-hot vectors. First, we show\ntheoretically and in experiments with synthetic data that population codes\nimprove robustness to input noise in networks of stacked linear layers. Second,\nwe demonstrate the benefit of using population codes to encode ambiguous\noutputs, such as the pose of symmetric objects. Using the T-LESS dataset of\nfeature-less real-world objects, we show that population codes improve the\naccuracy of predicting 3D object orientation from image input.\n","authors":["Heiko Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2411.00393v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03055v2","updated":"2024-11-06T13:24:10Z","published":"2024-11-05T12:42:42Z","title":"ATM: Improving Model Merging by Alternating Tuning and Merging","summary":"  Model merging has recently emerged as a cost-efficient paradigm for\nmulti-task learning. Among current approaches, task arithmetic stands out for\nits simplicity and effectiveness. In this paper, we motivate the effectiveness\nof task vectors by linking them to multi-task gradients. We show that in a\nsingle-epoch scenario, task vectors are mathematically equivalent to the\ngradients obtained via gradient descent in a multi-task setting, and still\napproximate these gradients in subsequent epochs. Furthermore, we show that\ntask vectors perform optimally when equality is maintained, and their\neffectiveness is largely driven by the first epoch's gradient. Building on this\ninsight, we propose viewing model merging as a single step in an iterative\nprocess that Alternates between Tuning and Merging (ATM). This method acts as a\nbridge between model merging and multi-task gradient descent, achieving\nstate-of-the-art results with the same data and computational requirements. We\nextensively evaluate ATM across diverse settings, achieving up to 20% higher\naccuracy in computer vision and NLP tasks, compared to the best baselines.\nFinally, we provide both empirical and theoretical support for its\neffectiveness, demonstrating increased orthogonality between task vectors and\nproving that ATM minimizes an upper bound on the loss obtained by jointly\nfinetuning all tasks.\n","authors":["Luca Zhou","Daniele Solombrino","Donato Crisostomi","Maria Sofia Bucarelli","Fabrizio Silvestri","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2411.03055v2.pdf","comment":"Main paper: 10 Pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2409.08240v3","updated":"2024-11-06T13:03:20Z","published":"2024-09-12T17:39:23Z","title":"IFAdapter: Instance Feature Control for Grounded Text-to-Image\n  Generation","summary":"  While Text-to-Image (T2I) diffusion models excel at generating visually\nappealing images of individual instances, they struggle to accurately position\nand control the features generation of multiple instances. The Layout-to-Image\n(L2I) task was introduced to address the positioning challenges by\nincorporating bounding boxes as spatial control signals, but it still falls\nshort in generating precise instance features. In response, we propose the\nInstance Feature Generation (IFG) task, which aims to ensure both positional\naccuracy and feature fidelity in generated instances. To address the IFG task,\nwe introduce the Instance Feature Adapter (IFAdapter). The IFAdapter enhances\nfeature depiction by incorporating additional appearance tokens and utilizing\nan Instance Semantic Map to align instance-level features with spatial\nlocations. The IFAdapter guides the diffusion process as a plug-and-play\nmodule, making it adaptable to various community models. For evaluation, we\ncontribute an IFG benchmark and develop a verification pipeline to objectively\ncompare models' abilities to generate instances with accurate positioning and\nfeatures. Experimental results demonstrate that IFAdapter outperforms other\nmodels in both quantitative and qualitative evaluations.\n","authors":["Yinwei Wu","Xianpan Zhou","Bing Ma","Xuefeng Su","Kai Ma","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2409.08240v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01853v2","updated":"2024-11-06T12:27:27Z","published":"2024-11-04T07:07:31Z","title":"GVKF: Gaussian Voxel Kernel Functions for Highly Efficient Surface\n  Reconstruction in Open Scenes","summary":"  In this paper we present a novel method for efficient and effective 3D\nsurface reconstruction in open scenes. Existing Neural Radiance Fields (NeRF)\nbased works typically require extensive training and rendering time due to the\nadopted implicit representations. In contrast, 3D Gaussian splatting (3DGS)\nuses an explicit and discrete representation, hence the reconstructed surface\nis built by the huge number of Gaussian primitives, which leads to excessive\nmemory consumption and rough surface details in sparse Gaussian areas. To\naddress these issues, we propose Gaussian Voxel Kernel Functions (GVKF), which\nestablish a continuous scene representation based on discrete 3DGS through\nkernel regression. The GVKF integrates fast 3DGS rasterization and highly\neffective scene implicit representations, achieving high-fidelity open scene\nsurface reconstruction. Experiments on challenging scene datasets demonstrate\nthe efficiency and effectiveness of our proposed GVKF, featuring with high\nreconstruction quality, real-time rendering speed, significant savings in\nstorage and training memory consumption.\n","authors":["Gaochao Song","Chong Cheng","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2411.01853v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03862v1","updated":"2024-11-06T12:14:23Z","published":"2024-11-06T12:14:23Z","title":"ROBIN: Robust and Invisible Watermarks for Diffusion Models with\n  Adversarial Optimization","summary":"  Watermarking generative content serves as a vital tool for authentication,\nownership protection, and mitigation of potential misuse. Existing watermarking\nmethods face the challenge of balancing robustness and concealment. They\nempirically inject a watermark that is both invisible and robust and passively\nachieve concealment by limiting the strength of the watermark, thus reducing\nthe robustness. In this paper, we propose to explicitly introduce a watermark\nhiding process to actively achieve concealment, thus allowing the embedding of\nstronger watermarks. To be specific, we implant a robust watermark in an\nintermediate diffusion state and then guide the model to hide the watermark in\nthe final generated image. We employ an adversarial optimization algorithm to\nproduce the optimal hiding prompt guiding signal for each watermark. The prompt\nembedding is optimized to minimize artifacts in the generated image, while the\nwatermark is optimized to achieve maximum strength. The watermark can be\nverified by reversing the generation process. Experiments on various diffusion\nmodels demonstrate the watermark remains verifiable even under significant\nimage tampering and shows superior invisibility compared to other\nstate-of-the-art robust watermarking methods.\n","authors":["Huayang Huang","Yu Wu","Qian Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03862v1.pdf","comment":"Accept to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03861v1","updated":"2024-11-06T12:14:11Z","published":"2024-11-06T12:14:11Z","title":"FedRISE: Rating Induced Sign Election of Gradients for Byzantine\n  Tolerant Federated Aggregation","summary":"  One of the most common defense strategies against model poisoning in\nfederated learning is to employ a robust aggregator mechanism that makes the\ntraining more resilient. Many of the existing Byzantine robust aggregators\nprovide theoretical guarantees and are empirically effective against certain\ncategories of attacks. However, we observe that certain high-strength attacks\ncan subvert the aggregator and collapse the training. In addition, most\naggregators require identifying tolerant settings to converge. Impact of\nattacks becomes more pronounced when the number of Byzantines is near-majority,\nand becomes harder to evade if the attacker is omniscient with access to data,\nhonest updates and aggregation methods. Motivated by these observations, we\ndevelop a robust aggregator called FedRISE for cross-silo FL that is consistent\nand less susceptible to poisoning updates by an omniscient attacker. The\nproposed method explicitly determines the optimal direction of each gradient\nthrough a sign-voting strategy that uses variance-reduced sparse gradients. We\nargue that vote weighting based on the cosine similarity of raw gradients is\nmisleading, and we introduce a sign-based gradient valuation function that\nignores the gradient magnitude. We compare our method against 8 robust\naggregators under 6 poisoning attacks on 3 datasets and architectures. Our\nresults show that existing robust aggregators collapse for at least some\nattacks under severe settings, while FedRISE demonstrates better robustness\nbecause of a stringent gradient inclusion formulation.\n","authors":["Joseph Geo Benjamin","Mothilal Asokan","Mohammad Yaqub","Karthik Nandakumar"],"pdf_url":"https://arxiv.org/pdf/2411.03861v1.pdf","comment":"This is a work under submission/review process"},{"id":"http://arxiv.org/abs/2408.13800v3","updated":"2024-11-06T12:10:54Z","published":"2024-08-25T10:42:07Z","title":"BCDNet: A Fast Residual Neural Network For Invasive Ductal Carcinoma\n  Detection","summary":"  It is of great significance to diagnose Invasive Ductal Carcinoma (IDC) in\nearly stage, which is the most common subtype of breast cancer. Although the\npowerful models in the Computer-Aided Diagnosis (CAD) systems provide promising\nresults, it is still difficult to integrate them into other medical devices or\nuse them without sufficient computation resource. In this paper, we propose\nBCDNet, which firstly upsamples the input image by the residual block and use\nsmaller convolutional block and a special MLP to learn features. BCDNet is\nproofed to effectively detect IDC in histopathological RGB images with an\naverage accuracy of 91.6% and reduce training consumption effectively compared\nto ResNet 50 and ViT-B-16.\n","authors":["Yujia Lin","Aiwei Lian","Mingyu Liao","Shuangjie Yuan"],"pdf_url":"https://arxiv.org/pdf/2408.13800v3.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.03313v2","updated":"2024-11-06T12:07:08Z","published":"2024-11-05T18:58:15Z","title":"Classification Done Right for Vision-Language Pre-Training","summary":"  We introduce SuperClass, a super simple classification method for\nvision-language pre-training on image-text data. Unlike its contrastive\ncounterpart CLIP who contrast with a text encoder, SuperClass directly utilizes\ntokenized raw text as supervised classification labels, without the need for\nadditional text filtering or selection. Due to the absence of the text encoding\nas contrastive target, SuperClass does not require a text encoder and does not\nneed to maintain a large batch size as CLIP does. SuperClass demonstrated\nsuperior performance on various downstream tasks, including classic computer\nvision benchmarks and vision language downstream tasks. We further explored the\nscaling behavior of SuperClass on model size, training length, or data size,\nand reported encouraging results and comparisons to CLIP.\nhttps://github.com/x-cls/superclass\n","authors":["Zilong Huang","Qinghao Ye","Bingyi Kang","Jiashi Feng","Haoqi Fan"],"pdf_url":"https://arxiv.org/pdf/2411.03313v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2404.05997v2","updated":"2024-11-06T12:06:03Z","published":"2024-04-09T04:04:50Z","title":"Concept-Attention Whitening for Interpretable Skin Lesion Diagnosis","summary":"  The black-box nature of deep learning models has raised concerns about their\ninterpretability for successful deployment in real-world clinical applications.\nTo address the concerns, eXplainable Artificial Intelligence (XAI) aims to\nprovide clear and understandable explanations of the decision-making process.\nIn the medical domain, concepts such as attributes of lesions or abnormalities\nserve as key evidence for deriving diagnostic results. Existing concept-based\nmodels mainly depend on concepts that appear independently and require\nfine-grained concept annotations such as bounding boxes. However, a medical\nimage usually contains multiple concepts, and the fine-grained concept\nannotations are difficult to acquire. In this paper, we aim to interpret\nrepresentations in deep neural networks by aligning the axes of the latent\nspace with known concepts of interest. We propose a novel Concept-Attention\nWhitening (CAW) framework for interpretable skin lesion diagnosis. CAW is\ncomprised of a disease diagnosis branch and a concept alignment branch. In the\nformer branch, we train a convolutional neural network (CNN) with an inserted\nCAW layer to perform skin lesion diagnosis. The CAW layer decorrelates features\nand aligns image features to conceptual meanings via an orthogonal matrix. In\nthe latter branch, the orthogonal matrix is calculated under the guidance of\nthe concept attention mask. We particularly introduce a weakly-supervised\nconcept mask generator that only leverages coarse concept labels for filtering\nlocal regions that are relevant to certain concepts, improving the optimization\nof the orthogonal matrix. Extensive experiments on two public skin lesion\ndiagnosis datasets demonstrated that CAW not only enhanced interpretability but\nalso maintained a state-of-the-art diagnostic performance.\n","authors":["Junlin Hou","Jilan Xu","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2404.05997v2.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2410.11666v3","updated":"2024-11-06T12:00:44Z","published":"2024-10-15T14:53:07Z","title":"Degradation Oriented and Regularized Network for Blind Depth\n  Super-Resolution","summary":"  Recent RGB-guided depth super-resolution methods have achieved impressive\nperformance under the assumption of fixed and known degradation (e.g., bicubic\ndownsampling). However, in real-world scenarios, captured depth data often\nsuffer from unconventional and unknown degradation due to sensor limitations\nand complex imaging environments (e.g., low reflective surfaces, varying\nillumination). Consequently, the performance of these methods significantly\ndeclines when real-world degradation deviate from their assumptions. In this\npaper, we propose the Degradation Oriented and Regularized Network (DORNet), a\nnovel framework designed to adaptively address unknown degradation in\nreal-world scenes through implicit degradation representations. Our approach\nbegins with the development of a self-supervised degradation learning strategy,\nwhich models the degradation representations of low-resolution depth data using\nrouting selection-based degradation regularization. To facilitate effective\nRGB-D fusion, we further introduce a degradation-oriented feature\ntransformation module that selectively propagates RGB content into the depth\ndata based on the learned degradation priors. Extensive experimental results on\nboth real and synthetic datasets demonstrate the superiority of our DORNet in\nhandling unknown degradation, outperforming existing methods. The code is\navailable at https://github.com/yanzq95/DORNet.\n","authors":["Zhengxue Wang","Zhiqiang Yan","Jinshan Pan","Guangwei Gao","Kai Zhang","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2410.11666v3.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.03855v1","updated":"2024-11-06T11:57:55Z","published":"2024-11-06T11:57:55Z","title":"MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba","summary":"  An ecosystem of Transformer-based models has been established by building\nlarge models with extensive data. Parameter-efficient fine-tuning (PEFT) is a\ncrucial technology for deploying these models to downstream tasks with minimal\ncost while achieving effective performance. Recently, Mamba, a State Space\nModel (SSM)-based model, has attracted attention as a potential alternative to\nTransformers. While many large-scale Mamba-based models have been proposed,\nefficiently adapting pre-trained Mamba-based models to downstream tasks remains\nunexplored. In this paper, we conduct an exploratory analysis of PEFT methods\nfor Mamba. We investigate the effectiveness of existing PEFT methods for\nTransformers when applied to Mamba. We also modify these methods to better\nalign with the Mamba architecture. Additionally, we propose new Mamba-specific\nPEFT methods that leverage the distinctive structure of Mamba. Our experiments\nindicate that PEFT performs more effectively for Mamba than Transformers.\nLastly, we demonstrate how to effectively combine multiple PEFT methods and\nprovide a framework that outperforms previous works. To ensure reproducibility,\nwe will release the code after publication.\n","authors":["Masakazu Yoshimura","Teruaki Hayashi","Yota Maeda"],"pdf_url":"https://arxiv.org/pdf/2411.03855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.11124v2","updated":"2024-11-06T11:40:50Z","published":"2024-01-20T05:31:47Z","title":"Cross-Task Affinity Learning for Multitask Dense Scene Predictions","summary":"  Multitask learning (MTL) has become prominent for its ability to predict\nmultiple tasks jointly, achieving better per-task performance with fewer\nparameters than single-task learning. Recently, decoder-focused architectures\nhave significantly improved multitask performance by refining task predictions\nusing features from related tasks. However, most refinement methods struggle to\nefficiently capture both local and long-range dependencies between\ntask-specific representations and cross-task patterns. In this paper, we\nintroduce the Cross-Task Affinity Learning (CTAL) module, a lightweight\nframework that enhances task refinement in multitask networks. CTAL effectively\ncaptures local and long-range cross-task interactions by optimizing task\naffinity matrices for parameter-efficient grouped convolutions without concern\nfor information loss. Our results demonstrate state-of-the-art MTL performance\nfor both CNN and transformer backbones, using significantly fewer parameters\nthan single-task learning. Our code is publicly available at\nhttps://github.com/Armanfard-Lab/EMA-Net.\n","authors":["Dimitrios Sinodinos","Narges Armanfard"],"pdf_url":"https://arxiv.org/pdf/2401.11124v2.pdf","comment":"Accepted for publication at the IEEE Winter Conference on\n  Applications of Computer Vision (WACV) 2025"},{"id":"http://arxiv.org/abs/2411.03835v1","updated":"2024-11-06T11:14:49Z","published":"2024-11-06T11:14:49Z","title":"An Edge Computing-Based Solution for Real-Time Leaf Disease\n  Classification using Thermal Imaging","summary":"  Deep learning (DL) technologies can transform agriculture by improving crop\nhealth monitoring and management, thus improving food safety. In this paper, we\nexplore the potential of edge computing for real-time classification of leaf\ndiseases using thermal imaging. We present a thermal image dataset for plant\ndisease classification and evaluate deep learning models, including\nInceptionV3, MobileNetV1, MobileNetV2, and VGG-16, on resource-constrained\ndevices like the Raspberry Pi 4B. Using pruning and quantization-aware\ntraining, these models achieve inference times up to 1.48x faster on Edge TPU\nMax for VGG16, and up to 2.13x faster with precision reduction on Intel NCS2\nfor MobileNetV1, compared to high-end GPUs like the RTX 3090, while maintaining\nstate-of-the-art accuracy.\n","authors":["Públio Elon Correa da Silva","Jurandy Almeida"],"pdf_url":"https://arxiv.org/pdf/2411.03835v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03831v1","updated":"2024-11-06T11:03:34Z","published":"2024-11-06T11:03:34Z","title":"An Enhancement of Haar Cascade Algorithm Applied to Face Recognition for\n  Gate Pass Security","summary":"  This study is focused on enhancing the Haar Cascade Algorithm to decrease the\nfalse positive and false negative rate in face matching and face detection to\nincrease the accuracy rate even under challenging conditions. The face\nrecognition library was implemented with Haar Cascade Algorithm in which the\n128-dimensional vectors representing the unique features of a face are encoded.\nA subprocess was applied where the grayscale image from Haar Cascade was\nconverted to RGB to improve the face encoding. Logical process and face\nfiltering are also used to decrease non-face detection. The Enhanced Haar\nCascade Algorithm produced a 98.39% accuracy rate (21.39% increase), 63.59%\nprecision rate, 98.30% recall rate, and 72.23% in F1 Score. In comparison, the\nHaar Cascade Algorithm achieved a 46.70% to 77.00% accuracy rate, 44.15%\nprecision rate, 98.61% recall rate, and 47.01% in F1 Score. Both algorithms\nused the Confusion Matrix Test with 301,950 comparisons using the same dataset\nof 550 images. The 98.39% accuracy rate shows a significant decrease in false\npositive and false negative rates in facial recognition. Face matching and face\ndetection are more accurate in images with complex backgrounds, lighting\nvariations, and occlusions, or even those with similar attributes.\n","authors":["Clarence A. Antipona","Romeo R. Magsino","Raymund M. Dioses","Khatalyn E. Mata"],"pdf_url":"https://arxiv.org/pdf/2411.03831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03829v1","updated":"2024-11-06T11:03:02Z","published":"2024-11-06T11:03:02Z","title":"Generalize or Detect? Towards Robust Semantic Segmentation Under\n  Multiple Distribution Shifts","summary":"  In open-world scenarios, where both novel classes and domains may exist, an\nideal segmentation model should detect anomaly classes for safety and\ngeneralize to new domains. However, existing methods often struggle to\ndistinguish between domain-level and semantic-level distribution shifts,\nleading to poor out-of-distribution (OOD) detection or domain generalization\nperformance. In this work, we aim to equip the model to generalize effectively\nto covariate-shift regions while precisely identifying semantic-shift regions.\nTo achieve this, we design a novel generative augmentation method to produce\ncoherent images that incorporate both anomaly (or novel) objects and various\ncovariate shifts at both image and object levels. Furthermore, we introduce a\ntraining strategy that recalibrates uncertainty specifically for semantic\nshifts and enhances the feature extractor to align features associated with\ndomain shifts. We validate the effectiveness of our method across benchmarks\nfeaturing both semantic and domain shifts. Our method achieves state-of-the-art\nperformance across all benchmarks for both OOD detection and domain\ngeneralization. Code is available at\nhttps://github.com/gaozhitong/MultiShiftSeg.\n","authors":["Zhitong Gao","Bingnan Li","Mathieu Salzmann","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2411.03829v1.pdf","comment":"Published in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03823v1","updated":"2024-11-06T10:44:15Z","published":"2024-11-06T10:44:15Z","title":"Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM\n  Data Contamination","summary":"  The rapid progression of multimodal large language models (MLLMs) has\ndemonstrated superior performance on various multimodal benchmarks. However,\nthe issue of data contamination during training creates challenges in\nperformance evaluation and comparison. While numerous methods exist for\ndetecting dataset contamination in large language models (LLMs), they are less\neffective for MLLMs due to their various modalities and multiple training\nphases. In this study, we introduce a multimodal data contamination detection\nframework, MM-Detect, designed for MLLMs. Our experimental results indicate\nthat MM-Detect is sensitive to varying degrees of contamination and can\nhighlight significant performance improvements due to leakage of the training\nset of multimodal benchmarks. Furthermore, We also explore the possibility of\ncontamination originating from the pre-training phase of LLMs used by MLLMs and\nthe fine-tuning phase of MLLMs, offering new insights into the stages at which\ncontamination may be introduced.\n","authors":["Dingjie Song","Sicheng Lai","Shunian Chen","Lichao Sun","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03819v1","updated":"2024-11-06T10:39:00Z","published":"2024-11-06T10:39:00Z","title":"SA3DIP: Segment Any 3D Instance with Potential 3D Priors","summary":"  The proliferation of 2D foundation models has sparked research into adapting\nthem for open-world 3D instance segmentation. Recent methods introduce a\nparadigm that leverages superpoints as geometric primitives and incorporates 2D\nmulti-view masks from Segment Anything model (SAM) as merging guidance,\nachieving outstanding zero-shot instance segmentation results. However, the\nlimited use of 3D priors restricts the segmentation performance. Previous\nmethods calculate the 3D superpoints solely based on estimated normal from\nspatial coordinates, resulting in under-segmentation for instances with similar\ngeometry. Besides, the heavy reliance on SAM and hand-crafted algorithms in 2D\nspace suffers from over-segmentation due to SAM's inherent part-level\nsegmentation tendency. To address these issues, we propose SA3DIP, a novel\nmethod for Segmenting Any 3D Instances via exploiting potential 3D Priors.\nSpecifically, on one hand, we generate complementary 3D primitives based on\nboth geometric and textural priors, which reduces the initial errors that\naccumulate in subsequent procedures. On the other hand, we introduce\nsupplemental constraints from the 3D space by using a 3D detector to guide a\nfurther merging process. Furthermore, we notice a considerable portion of\nlow-quality ground truth annotations in ScanNetV2 benchmark, which affect the\nfair evaluations. Thus, we present ScanNetV2-INS with complete ground truth\nlabels and supplement additional instances for 3D class-agnostic instance\nsegmentation. Experimental evaluations on various 2D-3D datasets demonstrate\nthe effectiveness and robustness of our approach. Our code and proposed\nScanNetV2-INS dataset are available HERE.\n","authors":["Xi Yang","Xu Gu","Xingyilang Yin","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2411.03819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03807v1","updated":"2024-11-06T10:07:46Z","published":"2024-11-06T10:07:46Z","title":"GS2Pose: Tow-stage 6D Object Pose Estimation Guided by Gaussian\n  Splatting","summary":"  This paper proposes a new method for accurate and robust 6D pose estimation\nof novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose\ncan utilize the reconstruction results without requiring a high-quality CAD\nmodel, which means it only requires segmented RGBD images as input.\nSpecifically, GS2Pose employs a two-stage structure consisting of coarse\nestimation followed by refined estimation. In the coarse stage, a lightweight\nU-Net network with a polarization attention mechanism, called Pose-Net, is\ndesigned. By using the 3DGS model for supervised training, Pose-Net can\ngenerate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose\nformulates a pose regression algorithm following the idea of reprojection or\nBundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to\nextend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that\nrefines the coarse pose by comparing the input images with the rendered images.\nGS-Refiner also selectively updates parameters in the 3DGS model to achieve\nenvironmental adaptation, thereby enhancing the algorithm's robustness and\nflexibility to illuminative variation, occlusion, and other challenging\ndisruptive factors. GS2Pose was evaluated through experiments conducted on the\nLineMod dataset, where it was compared with similar algorithms, yielding highly\ncompetitive results. The code for GS2Pose will soon be released on GitHub.\n","authors":["Jilan Mei","Junbo Li","Cai Meng"],"pdf_url":"https://arxiv.org/pdf/2411.03807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17459v2","updated":"2024-11-06T09:50:06Z","published":"2024-09-26T01:34:42Z","title":"TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic\n  Scene","summary":"  Despite advancements in Neural Implicit models for 3D surface reconstruction,\nhandling dynamic environments with arbitrary rigid, non-rigid, or deformable\nentities remains challenging. Many template-based methods are entity-specific,\nfocusing on humans, while generic reconstruction methods adaptable to such\ndynamic scenes often require additional inputs like depth or optical flow or\nrely on pre-trained image features for reasonable outcomes. These methods\ntypically use latent codes to capture frame-by-frame deformations. In contrast,\nsome template-free methods bypass these requirements and adopt traditional LBS\n(Linear Blend Skinning) weights for a detailed representation of deformable\nobject motions, although they involve complex optimizations leading to lengthy\ntraining times. To this end, as a remedy, this paper introduces TFS-NeRF, a\ntemplate-free 3D semantic NeRF for dynamic scenes captured from sparse or\nsingle-view RGB videos, featuring interactions among various entities and more\ntime-efficient than other LBS-based approaches. Our framework uses an\nInvertible Neural Network (INN) for LBS prediction, simplifying the training\nprocess. By disentangling the motions of multiple entities and optimizing\nper-entity skinning weights, our method efficiently generates accurate,\nsemantically separable geometries. Extensive experiments demonstrate that our\napproach produces high-quality reconstructions of both deformable and\nnon-deformable objects in complex interactions, with improved training\nefficiency compared to existing methods.\n","authors":["Sandika Biswas","Qianyi Wu","Biplab Banerjee","Hamid Rezatofighi"],"pdf_url":"https://arxiv.org/pdf/2409.17459v2.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.15306v3","updated":"2024-11-06T09:49:31Z","published":"2024-05-24T07:48:35Z","title":"DeTikZify: Synthesizing Graphics Programs for Scientific Figures and\n  Sketches with TikZ","summary":"  Creating high-quality scientific figures can be time-consuming and\nchallenging, even though sketching ideas on paper is relatively easy.\nFurthermore, recreating existing figures that are not stored in formats\npreserving semantic information is equally complex. To tackle this problem, we\nintroduce DeTikZify, a novel multimodal language model that automatically\nsynthesizes scientific figures as semantics-preserving TikZ graphics programs\nbased on sketches and existing figures. To achieve this, we create three new\ndatasets: DaTikZv2, the largest TikZ dataset to date, containing over 360k\nhuman-created TikZ graphics; SketchFig, a dataset that pairs hand-drawn\nsketches with their corresponding scientific figures; and MetaFig, a collection\nof diverse scientific figures and associated metadata. We train DeTikZify on\nMetaFig and DaTikZv2, along with synthetically generated sketches learned from\nSketchFig. We also introduce an MCTS-based inference algorithm that enables\nDeTikZify to iteratively refine its outputs without the need for additional\ntraining. Through both automatic and human evaluation, we demonstrate that\nDeTikZify outperforms commercial Claude 3 and GPT-4V in synthesizing TikZ\nprograms, with the MCTS algorithm effectively boosting its performance. We make\nour code, models, and datasets publicly available.\n","authors":["Jonas Belouadi","Simone Paolo Ponzetto","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2405.15306v3.pdf","comment":"Accepted at NeurIPS 2024 (spotlight); Project page:\n  https://github.com/potamides/DeTikZify"},{"id":"http://arxiv.org/abs/2411.03795v1","updated":"2024-11-06T09:39:52Z","published":"2024-11-06T09:39:52Z","title":"VQA$^2$:Visual Question Answering for Video Quality Assessment","summary":"  The advent and proliferation of large multi-modal models (LMMs) have\nintroduced a new paradigm to video-related computer vision fields, including\ntraining and inference methods based on visual question answering (VQA). These\nmethods enable models to handle multiple downstream tasks robustly. Video\nQuality Assessment (VQA), a classic field in low-level visual quality\nevaluation, originally focused on quantitative video quality scoring. However,\ndriven by advances in LMMs, it is now evolving towards more comprehensive\nvisual quality understanding tasks. Visual question answering has significantly\nimproved low-level visual evaluation within the image domain recently. However,\nrelated work is almost nonexistent in the video domain, leaving substantial\nroom for improvement. To address this gap, we introduce the VQA2 Instruction\nDataset the first visual question answering instruction dataset entirely\nfocuses on video quality assessment, and based on it, we propose the VQA2\nseries models The VQA2 Instruction Dataset consists of three stages and covers\nvarious video types, containing 157,735 instruction question-answer pairs,\nincluding both manually annotated and synthetic data. We conduct extensive\nexperiments on both video quality scoring and video quality understanding\ntasks. Results demonstrate that the VQA2 series models achieve state-of-the-art\n(SOTA) performance in quality scoring tasks, and their performance in visual\nquality question answering surpasses the renowned GPT-4o. Additionally, our\nfinal model, the VQA2-Assistant, performs well across both scoring and\nquestion-answering tasks, validating its versatility.\n","authors":["Ziheng Jia","Zicheng Zhang","Jiaying Qian","Haoning Wu","Wei Sun","Chunyi Li","Xiaohong Liu","Weisi Lin","Guangtao Zhai","Xiongkuo Min"],"pdf_url":"https://arxiv.org/pdf/2411.03795v1.pdf","comment":"10 pages 3 figures"},{"id":"http://arxiv.org/abs/2411.03794v1","updated":"2024-11-06T09:39:25Z","published":"2024-11-06T09:39:25Z","title":"Harmformer: Harmonic Networks Meet Transformers for Continuous\n  Roto-Translation Equivariance","summary":"  CNNs exhibit inherent equivariance to image translation, leading to efficient\nparameter and data usage, faster learning, and improved robustness. The concept\nof translation equivariant networks has been successfully extended to rotation\ntransformation using group convolution for discrete rotation groups and\nharmonic functions for the continuous rotation group encompassing $360^\\circ$.\nWe explore the compatibility of the SA mechanism with full rotation\nequivariance, in contrast to previous studies that focused on discrete\nrotation. We introduce the Harmformer, a harmonic transformer with a\nconvolutional stem that achieves equivariance for both translation and\ncontinuous rotation. Accompanied by an end-to-end equivariance proof, the\nHarmformer not only outperforms previous equivariant transformers, but also\ndemonstrates inherent stability under any continuous rotation, even without\nseeing rotated samples during training.\n","authors":["Tomáš Karella","Adam Harmanec","Jan Kotera","Jan Blažek","Filip Šroubek"],"pdf_url":"https://arxiv.org/pdf/2411.03794v1.pdf","comment":"Appears in NeurIPS 2024 Workshop on Symmetry and Geometry in Neural\n  Representations"},{"id":"http://arxiv.org/abs/2404.03202v5","updated":"2024-11-06T09:26:23Z","published":"2024-04-04T05:10:26Z","title":"OmniGS: Fast Radiance Field Reconstruction using Omnidirectional\n  Gaussian Splatting","summary":"  Photorealistic reconstruction relying on 3D Gaussian Splatting has shown\npromising potential in various domains. However, the current 3D Gaussian\nSplatting system only supports radiance field reconstruction using undistorted\nperspective images. In this paper, we present OmniGS, a novel omnidirectional\nGaussian splatting system, to take advantage of omnidirectional images for fast\nradiance field reconstruction. Specifically, we conduct a theoretical analysis\nof spherical camera model derivatives in 3D Gaussian Splatting. According to\nthe derivatives, we then implement a new GPU-accelerated omnidirectional\nrasterizer that directly splats 3D Gaussians onto the equirectangular screen\nspace for omnidirectional image rendering. We realize differentiable\noptimization of the omnidirectional radiance field without the requirement of\ncube-map rectification or tangent-plane approximation. Extensive experiments\nconducted in egocentric and roaming scenarios demonstrate that our method\nachieves state-of-the-art reconstruction quality and high rendering speed using\nomnidirectional images. The code will be publicly available.\n","authors":["Longwei Li","Huajian Huang","Sai-Kit Yeung","Hui Cheng"],"pdf_url":"https://arxiv.org/pdf/2404.03202v5.pdf","comment":"8 pages, 6 figures, accepted by WACV 2025, project page:\n  https://liquorleaf.github.io/research/OmniGS/"},{"id":"http://arxiv.org/abs/2411.03223v2","updated":"2024-11-06T09:10:46Z","published":"2024-11-05T16:12:12Z","title":"Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation","summary":"  Earth Observation (EO) data analysis has been significantly revolutionized by\ndeep learning (DL), with applications typically limited to grid-like data\nstructures. Graph Neural Networks (GNNs) emerge as an important innovation,\npropelling DL into the non-Euclidean domain. Naturally, GNNs can effectively\ntackle the challenges posed by diverse modalities, multiple sensors, and the\nheterogeneous nature of EO data. To introduce GNNs in the related domains, our\nreview begins by offering fundamental knowledge on GNNs. Then, we summarize the\ngeneric problems in EO, to which GNNs can offer potential solutions. Following\nthis, we explore a broad spectrum of GNNs' applications to scientific problems\nin Earth systems, covering areas such as weather and climate analysis, disaster\nmanagement, air quality monitoring, agriculture, land cover classification,\nhydrological process modeling, and urban modeling. The rationale behind\nadopting GNNs in these fields is explained, alongside methodologies for\norganizing graphs and designing favorable architectures for various tasks.\nFurthermore, we highlight methodological challenges of implementing GNNs in\nthese domains and possible solutions that could guide future research. While\nacknowledging that GNNs are not a universal solution, we conclude the paper by\ncomparing them with other popular architectures like transformers and analyzing\ntheir potential synergies.\n","authors":["Shan Zhao","Zhaiyu Chen","Zhitong Xiong","Yilei Shi","Sudipan Saha","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.03223v2.pdf","comment":"Accepted for publication in Geoscience and Remote Sensing Magazine\n  (GRSM)"},{"id":"http://arxiv.org/abs/2404.09633v2","updated":"2024-11-06T09:04:35Z","published":"2024-04-15T10:05:36Z","title":"In-Context Translation: Towards Unifying Image Recognition, Processing,\n  and Generation","summary":"  We propose In-Context Translation (ICT), a general learning framework to\nunify visual recognition (e.g., semantic segmentation), low-level image\nprocessing (e.g., denoising), and conditional image generation (e.g.,\nedge-to-image synthesis). Thanks to unification, ICT significantly reduces the\ninherent inductive bias that comes with designing models for specific tasks,\nand it maximizes mutual enhancement across similar tasks. However, the\nunification across a large number of tasks is non-trivial due to various data\nformats and training pipelines. To this end, ICT introduces two designs.\nFirstly, it standardizes input-output data of different tasks into RGB image\npairs, e.g., semantic segmentation data pairs an RGB image with its\nsegmentation mask in the same RGB format. This turns different tasks into a\ngeneral translation task between two RGB images. Secondly, it standardizes the\ntraining of different tasks into a general in-context learning, where\n\"in-context\" means the input comprises an example input-output pair of the\ntarget task and a query image. The learning objective is to generate the\n\"missing\" data paired with the query. The implicit translation process is thus\nbetween the query and the generated image. In experiments, ICT unifies ten\nvision tasks and showcases impressive performance on their respective\nbenchmarks. Notably, ICT performs well across three major categories of\ncomputer vision tasks, while its two competitors (Painter and PromptDiffusion)\nare only effective in at most two of these task categories. In addition,\ncompared to its competitors, ICT trained on only 4 RTX 3090 GPUs is shown to be\nmore efficient and less costly in training.\n","authors":["Han Xue","Qianru Sun","Li Song","Wenjun Zhang","Zhiwu Huang"],"pdf_url":"https://arxiv.org/pdf/2404.09633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03758v1","updated":"2024-11-06T08:33:07Z","published":"2024-11-06T08:33:07Z","title":"Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI\n  Reconstruction","summary":"  Diffusion model-based approaches recently achieved re-markable success in MRI\nreconstruction, but integration into clinical routine remains challenging due\nto its time-consuming convergence. This phenomenon is partic-ularly notable\nwhen directly apply conventional diffusion process to k-space data without\nconsidering the inherent properties of k-space sampling, limiting k-space\nlearning efficiency and image reconstruction quality. To tackle these\nchallenges, we introduce subspace diffusion model with orthogonal\ndecomposition, a method (referred to as Sub-DM) that restrict the diffusion\nprocess via projections onto subspace as the k-space data distribution evolves\ntoward noise. Particularly, the subspace diffusion model circumvents the\ninference challenges posed by the com-plex and high-dimensional characteristics\nof k-space data, so the highly compact subspace ensures that diffusion process\nrequires only a few simple iterations to produce accurate prior information.\nFurthermore, the orthogonal decomposition strategy based on wavelet transform\nhin-ders the information loss during the migration of the vanilla diffusion\nprocess to the subspace. Considering the strate-gy is approximately reversible,\nsuch that the entire pro-cess can be reversed. As a result, it allows the\ndiffusion processes in different spaces to refine models through a mutual\nfeedback mechanism, enabling the learning of ac-curate prior even when dealing\nwith complex k-space data. Comprehensive experiments on different datasets\nclearly demonstrate that the superiority of Sub-DM against state of-the-art\nmethods in terms of reconstruction speed and quality.\n","authors":["Yu Guan","Qinrong Cai","Wei Li","Qiuyun Fan","Dong Liang","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03758v1.pdf","comment":"10 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.13824v3","updated":"2024-11-06T08:29:22Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48% improvement on\nVisualWebBench and a 19.1% boost in element accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03752v1","updated":"2024-11-06T08:27:49Z","published":"2024-11-06T08:27:49Z","title":"Deferred Poisoning: Making the Model More Vulnerable via Hessian\n  Singularization","summary":"  Recent studies have shown that deep learning models are very vulnerable to\npoisoning attacks. Many defense methods have been proposed to address this\nissue. However, traditional poisoning attacks are not as threatening as\ncommonly believed. This is because they often cause differences in how the\nmodel performs on the training set compared to the validation set. Such\ninconsistency can alert defenders that their data has been poisoned, allowing\nthem to take the necessary defensive actions. In this paper, we introduce a\nmore threatening type of poisoning attack called the Deferred Poisoning Attack.\nThis new attack allows the model to function normally during the training and\nvalidation phases but makes it very sensitive to evasion attacks or even\nnatural noise. We achieve this by ensuring the poisoned model's loss function\nhas a similar value as a normally trained model at each input sample but with a\nlarge local curvature. A similar model loss ensures that there is no obvious\ninconsistency between the training and validation accuracy, demonstrating high\nstealthiness. On the other hand, the large curvature implies that a small\nperturbation may cause a significant increase in model loss, leading to\nsubstantial performance degradation, which reflects a worse robustness. We\nfulfill this purpose by making the model have singular Hessian information at\nthe optimal point via our proposed Singularization Regularization term. We have\nconducted both theoretical and empirical analyses of the proposed method and\nvalidated its effectiveness through experiments on image classification tasks.\nFurthermore, we have confirmed the hazards of this form of poisoning attack\nunder more general scenarios using natural noise, offering a new perspective\nfor research in the field of security.\n","authors":["Yuhao He","Jinyu Tian","Xianwei Zheng","Li Dong","Yuanman Li","Leo Yu Zhang","Jiantao Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.03752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17331v2","updated":"2024-11-06T08:22:33Z","published":"2024-07-24T14:54:16Z","title":"Multi-label Cluster Discrimination for Visual Representation Learning","summary":"  Contrastive Language Image Pre-training (CLIP) has recently demonstrated\nsuccess across various tasks due to superior feature representation empowered\nby image-text contrastive learning. However, the instance discrimination method\nused by CLIP can hardly encode the semantic structure of training data. To\nhandle this limitation, cluster discrimination has been proposed through\niterative cluster assignment and classification. Nevertheless, most cluster\ndiscrimination approaches only define a single pseudo-label for each image,\nneglecting multi-label signals in the image. In this paper, we propose a novel\nMulti-Label Cluster Discrimination method named MLCD to enhance representation\nlearning. In the clustering step, we first cluster the large-scale LAION-400M\ndataset into one million centers based on off-the-shelf embedding features.\nConsidering that natural images frequently contain multiple visual objects or\nattributes, we select the multiple closest centers as auxiliary class labels.\nIn the discrimination step, we design a novel multi-label classification loss,\nwhich elegantly separates losses from positive classes and negative classes,\nand alleviates ambiguity on decision boundary. We validate the proposed\nmulti-label cluster discrimination method with experiments on different scales\nof models and pre-training datasets. Experimental results show that our method\nachieves state-of-the-art performance on multiple downstream tasks including\nlinear probe, zero-shot classification, and image-text retrieval. Code and\nmodels have been released at https://github.com/deepglint/unicom .\n","authors":["Xiang An","Kaicheng Yang","Xiangzi Dai","Ziyong Feng","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2407.17331v2.pdf","comment":"Accepted by ECCV2024"},{"id":"http://arxiv.org/abs/2411.03745v1","updated":"2024-11-06T08:22:00Z","published":"2024-11-06T08:22:00Z","title":"Homotopy Continuation Made Easy: Regression-based Online Simulation of\n  Starting Problem-Solution Pairs","summary":"  While automatically generated polynomial elimination templates have sparked\ngreat progress in the field of 3D computer vision, there remain many problems\nfor which the degree of the constraints or the number of unknowns leads to\nintractability. In recent years, homotopy continuation has been introduced as a\nplausible alternative. However, the method currently depends on expensive\nparallel tracking of all possible solutions in the complex domain, or a\nclassification network for starting problem-solution pairs trained over a\nlimited set of real-world examples. Our innovation consists of employing a\nregression network trained in simulation to directly predict a solution from\ninput correspondences, followed by an online simulator that invents a\nconsistent problem-solution pair. Subsequently, homotopy continuation is\napplied to track that single solution back to the original problem. We apply\nthis elegant combination to generalized camera resectioning, and also introduce\na new solution to the challenging generalized relative pose and scale problem.\nAs demonstrated, the proposed method successfully compensates the raw error\ncommitted by the regressor alone, and leads to state-of-the-art efficiency and\nsuccess rates while running on CPU resources, only.\n","authors":["Xinyue Zhang","Zijia Dai","Wanting Xu","Laurent Kneip"],"pdf_url":"https://arxiv.org/pdf/2411.03745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03730v1","updated":"2024-11-06T07:51:19Z","published":"2024-11-06T07:51:19Z","title":"NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document\n  VQA","summary":"  The Privacy Preserving Federated Learning Document VQA (PFL-DocVQA)\ncompetition challenged the community to develop provably private and\ncommunication-efficient solutions in a federated setting for a real-life use\ncase: invoice processing. The competition introduced a dataset of real invoice\ndocuments, along with associated questions and answers requiring information\nextraction and reasoning over the document images. Thereby, it brings together\nresearchers and expertise from the document analysis, privacy, and federated\nlearning communities. Participants fine-tuned a pre-trained, state-of-the-art\nDocument Visual Question Answering model provided by the organizers for this\nnew domain, mimicking a typical federated invoice processing setup. The base\nmodel is a multi-modal generative language model, and sensitive information\ncould be exposed through either the visual or textual input modality.\nParticipants proposed elegant solutions to reduce communication costs while\nmaintaining a minimum utility threshold in track 1 and to protect all\ninformation from each document provider using differential privacy in track 2.\nThe competition served as a new testbed for developing and testing private\nfederated learning methods, simultaneously raising awareness about privacy\nwithin the document image analysis and recognition community. Ultimately, the\ncompetition analysis provides best practices and recommendations for\nsuccessfully running privacy-focused federated learning challenges in the\nfuture.\n","authors":["Marlon Tobaben","Mohamed Ali Souibgui","Rubèn Tito","Khanh Nguyen","Raouf Kerkouche","Kangsoo Jung","Joonas Jälkö","Lei Kang","Andrey Barsky","Vincent Poulain d'Andecy","Aurélie Joseph","Aashiq Muhamed","Kevin Kuo","Virginia Smith","Yusuke Yamasaki","Takumi Fukami","Kenta Niwa","Iifan Tyou","Hiro Ishii","Rio Yokota","Ragul N","Rintu Kutum","Josep Llados","Ernest Valveny","Antti Honkela","Mario Fritz","Dimosthenis Karatzas"],"pdf_url":"https://arxiv.org/pdf/2411.03730v1.pdf","comment":"27 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.03729v1","updated":"2024-11-06T07:48:30Z","published":"2024-11-06T07:48:30Z","title":"Relation Learning and Aggregate-attention for Multi-person Motion\n  Prediction","summary":"  Multi-person motion prediction is an emerging and intricate task with broad\nreal-world applications. Unlike single person motion prediction, it considers\nnot just the skeleton structures or human trajectories but also the\ninteractions between others. Previous methods use various networks to achieve\nimpressive predictions but often overlook that the joints relations within an\nindividual (intra-relation) and interactions among groups (inter-relation) are\ndistinct types of representations. These methods often lack explicit\nrepresentation of inter&intra-relations, and inevitably introduce undesired\ndependencies. To address this issue, we introduce a new collaborative framework\nfor multi-person motion prediction that explicitly modeling these relations:a\nGCN-based network for intra-relations and a novel reasoning network for\ninter-relations.Moreover, we propose a novel plug-and-play aggregation module\ncalled the Interaction Aggregation Module (IAM), which employs an\naggregate-attention mechanism to seamlessly integrate these relations.\nExperiments indicate that the module can also be applied to other dual-path\nmodels. Extensive experiments on the 3DPW, 3DPW-RC, CMU-Mocap, MuPoTS-3D, as\nwell as synthesized datasets Mix1 & Mix2 (9 to 15 persons), demonstrate that\nour method achieves state-of-the-art performance.\n","authors":["Kehua Qu","Rui Ding","Jin Tang"],"pdf_url":"https://arxiv.org/pdf/2411.03729v1.pdf","comment":"Submitted to IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2411.03728v1","updated":"2024-11-06T07:46:34Z","published":"2024-11-06T07:46:34Z","title":"Efficient Fourier Filtering Network with Contrastive Learning for\n  UAV-based Unaligned Bi-modal Salient Object Detection","summary":"  Unmanned aerial vehicle (UAV)-based bi-modal salient object detection (BSOD)\naims to segment salient objects in a scene utilizing complementary cues in\nunaligned RGB and thermal image pairs. However, the high computational expense\nof existing UAV-based BSOD models limits their applicability to real-world UAV\ndevices. To address this problem, we propose an efficient Fourier filter\nnetwork with contrastive learning that achieves both real-time and accurate\nperformance. Specifically, we first design a semantic contrastive alignment\nloss to align the two modalities at the semantic level, which facilitates\nmutual refinement in a parameter-free way. Second, inspired by the fast Fourier\ntransform that obtains global relevance in linear complexity, we propose\nsynchronized alignment fusion, which aligns and fuses bi-modal features in the\nchannel and spatial dimensions by a hierarchical filtering mechanism. Our\nproposed model, AlignSal, reduces the number of parameters by 70.0%, decreases\nthe floating point operations by 49.4%, and increases the inference speed by\n152.5% compared to the cutting-edge BSOD model (i.e., MROS). Extensive\nexperiments on the UAV RGB-T 2400 and three weakly aligned datasets demonstrate\nthat AlignSal achieves both real-time inference speed and better performance\nand generalizability compared to sixteen state-of-the-art BSOD models across\nmost evaluation metrics. In addition, our ablation studies further verify\nAlignSal's potential in boosting the performance of existing aligned BSOD\nmodels on UAV-based unaligned data. The code is available at:\nhttps://github.com/JoshuaLPF/AlignSal.\n","authors":["Pengfei Lyu","Pak-Hei Yeung","Xiufei Cheng","Xiaosheng Yu","Chengdong Wu","Jagath C. Rajapakse"],"pdf_url":"https://arxiv.org/pdf/2411.03728v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.03725v1","updated":"2024-11-06T07:44:04Z","published":"2024-11-06T07:44:04Z","title":"PX2Tooth: Reconstructing the 3D Point Cloud Teeth from a Single\n  Panoramic X-ray","summary":"  Reconstructing the 3D anatomical structures of the oral cavity, which\noriginally reside in the cone-beam CT (CBCT), from a single 2D Panoramic\nX-ray(PX) remains a critical yet challenging task, as it can effectively reduce\nradiation risks and treatment costs during the diagnostic in digital dentistry.\nHowever, current methods are either error-prone or only trained/evaluated on\nsmall-scale datasets (less than 50 cases), resulting in compromised\ntrustworthiness. In this paper, we propose PX2Tooth, a novel approach to\nreconstruct 3D teeth using a single PX image with a two-stage framework. First,\nwe design the PXSegNet to segment the permanent teeth from the PX images,\nproviding clear positional, morphological, and categorical information for each\ntooth. Subsequently, we design a novel tooth generation network (TGNet) that\nlearns to transform random point clouds into 3D teeth. TGNet integrates the\nsegmented patch information and introduces a Prior Fusion Module (PFM) to\nenhance the generation quality, especially in the root apex region. Moreover,\nwe construct a dataset comprising 499 pairs of CBCT and Panoramic X-rays.\nExtensive experiments demonstrate that PX2Tooth can achieve an Intersection\nover Union (IoU) of 0.793, significantly surpassing previous methods,\nunderscoring the great potential of artificial intelligence in digital\ndentistry.\n","authors":["Wen Ma","Huikai Wu","Zikai Xiao","Yang Feng","Jian Wu","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03725v1.pdf","comment":"Ma W, Wu H, Xiao Z, et al. PX2Tooth: Reconstructing the 3D Point\n  Cloud Teeth from a Single Panoramic X-Ray[C]//International Conference on\n  Medical Image Computing and Computer-Assisted Intervention. Cham: Springer\n  Nature Switzerland, 2024: 411-421"},{"id":"http://arxiv.org/abs/2411.03724v1","updated":"2024-11-06T07:43:40Z","published":"2024-11-06T07:43:40Z","title":"Estimation of Psychosocial Work Environment Exposures Through Video\n  Object Detection. Proof of Concept Using CCTV Footage","summary":"  This paper examines the use of computer vision algorithms to estimate aspects\nof the psychosocial work environment using CCTV footage. We present a proof of\nconcept for a methodology that detects and tracks people in video footage and\nestimates interactions between customers and employees by estimating their\nposes and calculating the duration of their encounters. We propose a pipeline\nthat combines existing object detection and tracking algorithms (YOLOv8 and\nDeepSORT) with pose estimation algorithms (BlazePose) to estimate the number of\ncustomers and employees in the footage as well as the duration of their\nencounters. We use a simple rule-based approach to classify the interactions as\npositive, neutral or negative based on three different criteria: distance,\nduration and pose. The proposed methodology is tested on a small dataset of\nCCTV footage. While the data is quite limited in particular with respect to the\nquality of the footage, we have chosen this case as it represents a typical\nsetting where the method could be applied. The results show that the object\ndetection and tracking part of the pipeline has a reasonable performance on the\ndataset with a high degree of recall and reasonable accuracy. At this stage,\nthe pose estimation is still limited to fully detect the type of interactions\ndue to difficulties in tracking employees in the footage. We conclude that the\nmethod is a promising alternative to self-reported measures of the psychosocial\nwork environment and could be used in future studies to obtain external\nobservations of the work environment.\n","authors":["Claus D. Hansen","Thuy Hai Le","David Campos"],"pdf_url":"https://arxiv.org/pdf/2411.03724v1.pdf","comment":"11 pages, 9 figures, presented at IWOAR 9th International Workshop on\n  Sensor-Based Activity Recognition and Artificial Intelligence, September\n  26-27, Potsdam, Germany"},{"id":"http://arxiv.org/abs/2411.03723v1","updated":"2024-11-06T07:40:27Z","published":"2024-11-06T07:40:27Z","title":"Zero-shot Dynamic MRI Reconstruction with Global-to-local Diffusion\n  Model","summary":"  Diffusion models have recently demonstrated considerable advancement in the\ngeneration and reconstruction of magnetic resonance imaging (MRI) data. These\nmodels exhibit great potential in handling unsampled data and reducing noise,\nhighlighting their promise as generative models. However, their application in\ndynamic MRI remains relatively underexplored. This is primarily due to the\nsubstantial amount of fully-sampled data typically required for training, which\nis difficult to obtain in dynamic MRI due to its spatio-temporal complexity and\nhigh acquisition costs. To address this challenge, we propose a dynamic MRI\nreconstruction method based on a time-interleaved acquisition scheme, termed\nthe Glob-al-to-local Diffusion Model. Specifically, fully encoded\nfull-resolution reference data are constructed by merging under-sampled k-space\ndata from adjacent time frames, generating two distinct bulk training datasets\nfor global and local models. The global-to-local diffusion framework\nalternately optimizes global information and local image details, enabling\nzero-shot reconstruction. Extensive experiments demonstrate that the proposed\nmethod performs well in terms of noise reduction and detail preservation,\nachieving reconstruction quality comparable to that of supervised approaches.\n","authors":["Yu Guan","Kunlong Zhang","Qi Qi","Dong Wang","Ziwen Ke","Shaoyu Wang","Dong Liang","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03723v1.pdf","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.03717v1","updated":"2024-11-06T07:30:34Z","published":"2024-11-06T07:30:34Z","title":"These Maps Are Made by Propagation: Adapting Deep Stereo Networks to\n  Road Scenarios with Decisive Disparity Diffusion","summary":"  Stereo matching has emerged as a cost-effective solution for road surface 3D\nreconstruction, garnering significant attention towards improving both\ncomputational efficiency and accuracy. This article introduces decisive\ndisparity diffusion (D3Stereo), marking the first exploration of dense deep\nfeature matching that adapts pre-trained deep convolutional neural networks\n(DCNNs) to previously unseen road scenarios. A pyramid of cost volumes is\ninitially created using various levels of learned representations.\nSubsequently, a novel recursive bilateral filtering algorithm is employed to\naggregate these costs. A key innovation of D3Stereo lies in its alternating\ndecisive disparity diffusion strategy, wherein intra-scale diffusion is\nemployed to complete sparse disparity images, while inter-scale inheritance\nprovides valuable prior information for higher resolutions. Extensive\nexperiments conducted on our created UDTIRI-Stereo and Stereo-Road datasets\nunderscore the effectiveness of D3Stereo strategy in adapting pre-trained DCNNs\nand its superior performance compared to all other explicit programming-based\nalgorithms designed specifically for road surface 3D reconstruction. Additional\nexperiments conducted on the Middlebury dataset with backbone DCNNs pre-trained\non the ImageNet database further validate the versatility of D3Stereo strategy\nin tackling general stereo matching problems.\n","authors":["Chuang-Wei Liu","Yikang Zhang","Qijun Chen","Ioannis Pitas","Rui Fan"],"pdf_url":"https://arxiv.org/pdf/2411.03717v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.03714v1","updated":"2024-11-06T07:28:57Z","published":"2024-11-06T07:28:57Z","title":"Explaining Human Activity Recognition with SHAP: Validating Insights\n  with Perturbation and Quantitative Measures","summary":"  In Human Activity Recognition (HAR), understanding the intricacy of body\nmovements within high-risk applications is essential. This study uses SHapley\nAdditive exPlanations (SHAP) to explain the decision-making process of Graph\nConvolution Networks (GCNs) when classifying activities with skeleton data. We\nemploy SHAP to explain two real-world datasets: one for cerebral palsy (CP)\nclassification and the widely used NTU RGB+D 60 action recognition dataset. To\ntest the explanation, we introduce a novel perturbation approach that modifies\nthe model's edge importance matrix, allowing us to evaluate the impact of\nspecific body key points on prediction outcomes. To assess the fidelity of our\nexplanations, we employ informed perturbation, targeting body key points\nidentified as important by SHAP and comparing them against random perturbation\nas a control condition. This perturbation enables a judgment on whether the\nbody key points are truly influential or non-influential based on the SHAP\nvalues. Results on both datasets show that body key points identified as\nimportant through SHAP have the largest influence on the accuracy, specificity,\nand sensitivity metrics. Our findings highlight that SHAP can provide granular\ninsights into the input feature contribution to the prediction outcome of GCNs\nin HAR tasks. This demonstrates the potential for more interpretable and\ntrustworthy models in high-stakes applications like healthcare or\nrehabilitation.\n","authors":["Felix Tempel","Espen Alexander F. Ihlen","Lars Adde","Inga Strümke"],"pdf_url":"https://arxiv.org/pdf/2411.03714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.05824v2","updated":"2024-11-06T07:23:52Z","published":"2022-09-13T09:00:58Z","title":"CPnP: Consistent Pose Estimator for Perspective-n-Point Problem with\n  Bias Elimination","summary":"  The Perspective-n-Point (PnP) problem has been widely studied in both\ncomputer vision and photogrammetry societies. With the development of feature\nextraction techniques, a large number of feature points might be available in a\nsingle shot. It is promising to devise a consistent estimator, i.e., the\nestimate can converge to the true camera pose as the number of points\nincreases. To this end, we propose a consistent PnP solver, named \\emph{CPnP},\nwith bias elimination. Specifically, linear equations are constructed from the\noriginal projection model via measurement model modification and variable\nelimination, based on which a closed-form least-squares solution is obtained.\nWe then analyze and subtract the asymptotic bias of this solution, resulting in\na consistent estimate. Additionally, Gauss-Newton (GN) iterations are executed\nto refine the consistent solution. Our proposed estimator is efficient in terms\nof computations -- it has $O(n)$ computational complexity. Experimental tests\non both synthetic data and real images show that our proposed estimator is\nsuperior to some well-known ones for images with dense visual features, in\nterms of estimation precision and computing time.\n","authors":["Guangyang Zeng","Shiyu Chen","Biqiang Mu","Guodong Shi","Junfeng Wu"],"pdf_url":"https://arxiv.org/pdf/2209.05824v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03707v1","updated":"2024-11-06T07:11:15Z","published":"2024-11-06T07:11:15Z","title":"Fine-Tuning Vision-Language Model for Automated Engineering Drawing\n  Information Extraction","summary":"  Geometric Dimensioning and Tolerancing (GD&T) plays a critical role in\nmanufacturing by defining acceptable variations in part features to ensure\ncomponent quality and functionality. However, extracting GD&T information from\n2D engineering drawings is a time-consuming and labor-intensive task, often\nrelying on manual efforts or semi-automated tools. To address these challenges,\nthis study proposes an automated and computationally efficient GD&T extraction\nmethod by fine-tuning Florence-2, an open-source vision-language model (VLM).\nThe model is trained on a dataset of 400 drawings with ground truth annotations\nprovided by domain experts. For comparison, two state-of-the-art closed-source\nVLMs, GPT-4o and Claude-3.5-Sonnet, are evaluated on the same dataset. All\nmodels are assessed using precision, recall, F1-score, and hallucination\nmetrics. Due to the computational cost and impracticality of fine-tuning large\nclosed-source VLMs for domain-specific tasks, GPT-4o and Claude-3.5-Sonnet are\nevaluated in a zero-shot setting. In contrast, Florence-2, a smaller model with\n0.23 billion parameters, is optimized through full-parameter fine-tuning across\nthree distinct experiments, each utilizing datasets augmented to different\nlevels. The results show that Florence-2 achieves a 29.95% increase in\nprecision, a 37.75% increase in recall, a 52.40% improvement in F1-score, and a\n43.15% reduction in hallucination rate compared to the best-performing\nclosed-source model. These findings highlight the effectiveness of fine-tuning\nsmaller, open-source VLMs like Florence-2, offering a practical and efficient\nsolution for automated GD&T extraction to support downstream manufacturing\ntasks.\n","authors":["Muhammad Tayyab Khan","Lequn Chen","Ye Han Ng","Wenhe Feng","Nicholas Yew Jin Tan","Seung Ki Moon"],"pdf_url":"https://arxiv.org/pdf/2411.03707v1.pdf","comment":"Paper has been submitted to the 9th International Conference on\n  Innovation in Artificial Intelligence (ICIAI 2025)"},{"id":"http://arxiv.org/abs/2403.20213v3","updated":"2024-11-06T07:09:03Z","published":"2024-03-29T14:50:43Z","title":"VHM: Versatile and Honest Vision Language Model for Remote Sensing Image\n  Analysis","summary":"  This paper develops a Versatile and Honest vision language Model (VHM) for\nremote sensing image analysis. VHM is built on a large-scale remote sensing\nimage-text dataset with rich-content captions (VersaD), and an honest\ninstruction dataset comprising both factual and deceptive questions (HnstD).\nUnlike prevailing remote sensing image-text datasets, in which image captions\nfocus on a few prominent objects and their relationships, VersaD captions\nprovide detailed information about image properties, object attributes, and the\noverall scene. This comprehensive captioning enables VHM to thoroughly\nunderstand remote sensing images and perform diverse remote sensing tasks.\nMoreover, different from existing remote sensing instruction datasets that only\ninclude factual questions, HnstD contains additional deceptive questions\nstemming from the non-existence of objects. This feature prevents VHM from\nproducing affirmative answers to nonsense queries, thereby ensuring its\nhonesty. In our experiments, VHM significantly outperforms various vision\nlanguage models on common tasks of scene classification, visual question\nanswering, and visual grounding. Additionally, VHM achieves competent\nperformance on several unexplored tasks, such as building vectorizing,\nmulti-label classification and honest question answering. We will release the\ncode, data and model weights at https://github.com/opendatalab/VHM .\n","authors":["Chao Pang","Xingxing Weng","Jiang Wu","Jiayu Li","Yi Liu","Jiaxing Sun","Weijia Li","Shuai Wang","Litong Feng","Gui-Song Xia","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2403.20213v3.pdf","comment":"Equal contribution: Chao Pang, Xingxing Weng, Jiang Wu; Corresponding\n  author: Gui-Song Xia, Conghui He"},{"id":"http://arxiv.org/abs/2403.05408v2","updated":"2024-11-06T07:08:58Z","published":"2024-03-08T16:06:54Z","title":"FedFMS: Exploring Federated Foundation Models for Medical Image\n  Segmentation","summary":"  Medical image segmentation is crucial for clinical diagnosis. The\nSegmentation Anything Model (SAM) serves as a powerful foundation model for\nvisual segmentation and can be adapted for medical image segmentation. However,\nmedical imaging data typically contain privacy-sensitive information, making it\nchallenging to train foundation models with centralized storage and sharing. To\ndate, there are few foundation models tailored for medical image deployment\nwithin the federated learning framework, and the segmentation performance, as\nwell as the efficiency of communication and training, remain unexplored. In\nresponse to these issues, we developed Federated Foundation models for Medical\nimage Segmentation (FedFMS), which includes the Federated SAM (FedSAM) and a\ncommunication and training-efficient Federated SAM with Medical SAM Adapter\n(FedMSA). Comprehensive experiments on diverse datasets are conducted to\ninvestigate the performance disparities between centralized training and\nfederated learning across various configurations of FedFMS. The experiments\nrevealed that FedFMS could achieve performance comparable to models trained via\ncentralized training methods while maintaining privacy. Furthermore, FedMSA\ndemonstrated the potential to enhance communication and training efficiency.\nOur model implementation codes are available at\nhttps://github.com/LIU-YUXI/FedFMS.\n","authors":["Yuxi Liu","Guibo Luo","Yuesheng Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.05408v2.pdf","comment":"Accepted by MICCAI'2024"},{"id":"http://arxiv.org/abs/2411.03706v1","updated":"2024-11-06T07:08:41Z","published":"2024-11-06T07:08:41Z","title":"3DGS-CD: 3D Gaussian Splatting-based Change Detection for Physical\n  Object Rearrangement","summary":"  We present 3DGS-CD, the first 3D Gaussian Splatting (3DGS)-based method for\ndetecting physical object rearrangements in 3D scenes. Our approach estimates\n3D object-level changes by comparing two sets of unaligned images taken at\ndifferent times. Leveraging 3DGS's novel view rendering and EfficientSAM's\nzero-shot segmentation capabilities, we detect 2D object-level changes, which\nare then associated and fused across views to estimate 3D changes. Our method\ncan detect changes in cluttered environments using sparse post-change images\nwithin as little as 18s, using as few as a single new image. It does not rely\non depth input, user instructions, object classes, or object models -- An\nobject is recognized simply if it has been re-arranged. Our approach is\nevaluated on both public and self-collected real-world datasets, achieving up\nto 14% higher accuracy and three orders of magnitude faster performance\ncompared to the state-of-the-art radiance-field-based change detection method.\nThis significant performance boost enables a broad range of downstream\napplications, where we highlight three key use cases: object reconstruction,\nrobot workspace reset, and 3DGS model update. Our code and data will be made\navailable at https://github.com/520xyxyzq/3DGS-CD.\n","authors":["Ziqi Lu","Jianbo Ye","John Leonard"],"pdf_url":"https://arxiv.org/pdf/2411.03706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03702v1","updated":"2024-11-06T06:58:17Z","published":"2024-11-06T06:58:17Z","title":"Graph-Based Multi-Modal Sensor Fusion for Autonomous Driving","summary":"  The growing demand for robust scene understanding in mobile robotics and\nautonomous driving has highlighted the importance of integrating multiple\nsensing modalities. By combining data from diverse sensors like cameras and\nLIDARs, fusion techniques can overcome the limitations of individual sensors,\nenabling a more complete and accurate perception of the environment. We\nintroduce a novel approach to multi-modal sensor fusion, focusing on developing\na graph-based state representation that supports critical decision-making\nprocesses in autonomous driving. We present a Sensor-Agnostic Graph-Aware\nKalman Filter [3], the first online state estimation technique designed to fuse\nmulti-modal graphs derived from noisy multi-sensor data. The estimated\ngraph-based state representations serve as a foundation for advanced\napplications like Multi-Object Tracking (MOT), offering a comprehensive\nframework for enhancing the situational awareness and safety of autonomous\nsystems. We validate the effectiveness of our proposed framework through\nextensive experiments conducted on both synthetic and real-world driving\ndatasets (nuScenes). Our results showcase an improvement in MOTA and a\nreduction in estimated position errors (MOTP) and identity switches (IDS) for\ntracked objects using the SAGA-KF. Furthermore, we highlight the capability of\nsuch a framework to develop methods that can leverage heterogeneous information\n(like semantic objects and geometric structures) from various sensing\nmodalities, enabling a more holistic approach to scene understanding and\nenhancing the safety and effectiveness of autonomous systems.\n","authors":["Depanshu Sani","Saket Anand"],"pdf_url":"https://arxiv.org/pdf/2411.03702v1.pdf","comment":"An extended abstract accepted at Young Researchers' Symposium, ICVGIP\n  '24. This extended abstract contains the following: 1. Short summary of our\n  work, SAGA-KF, accepted at ICPR'24. 2. A proposal that was awarded the\n  Qualcomm Innovation Fellowship'24"},{"id":"http://arxiv.org/abs/2411.02188v3","updated":"2024-11-06T06:38:47Z","published":"2024-11-04T15:42:22Z","title":"Digi2Real: Bridging the Realism Gap in Synthetic Data Face Recognition\n  via Foundation Models","summary":"  The accuracy of face recognition systems has improved significantly in the\npast few years, thanks to the large amount of data collected and the\nadvancement in neural network architectures. However, these large-scale\ndatasets are often collected without explicit consent, raising ethical and\nprivacy concerns. To address this, there have been proposals to use synthetic\ndatasets for training face recognition models. Yet, such models still rely on\nreal data to train the generative models and generally exhibit inferior\nperformance compared to those trained on real datasets. One of these datasets,\nDigiFace, uses a graphics pipeline to generate different identities and\ndifferent intra-class variations without using real data in training the\nmodels. However, the performance of this approach is poor on face recognition\nbenchmarks, possibly due to the lack of realism in the images generated from\nthe graphics pipeline. In this work, we introduce a novel framework for realism\ntransfer aimed at enhancing the realism of synthetically generated face images.\nOur method leverages the large-scale face foundation model, and we adapt the\npipeline for realism enhancement. By integrating the controllable aspects of\nthe graphics pipeline with our realism enhancement technique, we generate a\nlarge amount of realistic variations-combining the advantages of both\napproaches. Our empirical evaluations demonstrate that models trained using our\nenhanced dataset significantly improve the performance of face recognition\nsystems over the baseline. The source code and datasets will be made available\npublicly: https://www.idiap.ch/paper/digi2real\n","authors":["Anjith George","Sebastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2411.02188v3.pdf","comment":"The dataset would be available here:\n  https://www.idiap.ch/paper/digi2real"},{"id":"http://arxiv.org/abs/2411.03696v1","updated":"2024-11-06T06:34:27Z","published":"2024-11-06T06:34:27Z","title":"OccLoff: Learning Optimized Feature Fusion for 3D Occupancy Prediction","summary":"  3D semantic occupancy prediction is crucial for finely representing the\nsurrounding environment, which is essential for ensuring the safety in\nautonomous driving. Existing fusion-based occupancy methods typically involve\nperforming a 2D-to-3D view transformation on image features, followed by\ncomputationally intensive 3D operations to fuse these with LiDAR features,\nleading to high computational costs and reduced accuracy. Moreover, current\nresearch on occupancy prediction predominantly focuses on designing specific\nnetwork architectures, often tailored to particular models, with limited\nattention given to the more fundamental aspect of semantic feature learning.\nThis gap hinders the development of more transferable methods that could\nenhance the performance of various occupancy models. To address these\nchallenges, we propose OccLoff, a framework that Learns to Optimize Feature\nFusion for 3D occupancy prediction. Specifically, we introduce a sparse fusion\nencoder with entropy masks that directly fuses 3D and 2D features, improving\nmodel accuracy while reducing computational overhead. Additionally, we propose\na transferable proxy-based loss function and an adaptive hard sample weighting\nalgorithm, which enhance the performance of several state-of-the-art methods.\nExtensive evaluations on the nuScenes and SemanticKITTI benchmarks demonstrate\nthe superiority of our framework, and ablation studies confirm the\neffectiveness of each proposed module.\n","authors":["Ji Zhang","Yiran Ding","Zixin Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03695v1","updated":"2024-11-06T06:33:55Z","published":"2024-11-06T06:33:55Z","title":"AMNCutter: Affinity-Attention-Guided Multi-View Normalized Cutter for\n  Unsupervised Surgical Instrument Segmentation","summary":"  Surgical instrument segmentation (SIS) is pivotal for robotic-assisted\nminimally invasive surgery, assisting surgeons by identifying surgical\ninstruments in endoscopic video frames. Recent unsupervised surgical instrument\nsegmentation (USIS) methods primarily rely on pseudo-labels derived from\nlow-level features such as color and optical flow, but these methods show\nlimited effectiveness and generalizability in complex and unseen endoscopic\nscenarios. In this work, we propose a label-free unsupervised model featuring a\nnovel module named Multi-View Normalized Cutter (m-NCutter). Different from\nprevious USIS works, our model is trained using a graph-cutting loss function\nthat leverages patch affinities for supervision, eliminating the need for\npseudo-labels. The framework adaptively determines which affinities from which\nlevels should be prioritized. Therefore, the low- and high-level features and\ntheir affinities are effectively integrated to train a label-free unsupervised\nmodel, showing superior effectiveness and generalization ability. We conduct\ncomprehensive experiments across multiple SIS datasets to validate our\napproach's state-of-the-art (SOTA) performance, robustness, and exceptional\npotential as a pre-trained model. Our code is released at\nhttps://github.com/MingyuShengSMY/AMNCutter.\n","authors":["Mingyu Sheng","Jianan Fan","Dongnan Liu","Ron Kikinis","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2411.03695v1.pdf","comment":"This paper was accepted by the 2025 IEEE Winter Conference on\n  Applications of Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2411.03688v1","updated":"2024-11-06T06:14:24Z","published":"2024-11-06T06:14:24Z","title":"Where Do We Stand with Implicit Neural Representations? A Technical and\n  Performance Survey","summary":"  Implicit Neural Representations (INRs) have emerged as a paradigm in\nknowledge representation, offering exceptional flexibility and performance\nacross a diverse range of applications. INRs leverage multilayer perceptrons\n(MLPs) to model data as continuous implicit functions, providing critical\nadvantages such as resolution independence, memory efficiency, and\ngeneralisation beyond discretised data structures. Their ability to solve\ncomplex inverse problems makes them particularly effective for tasks including\naudio reconstruction, image representation, 3D object reconstruction, and\nhigh-dimensional data synthesis. This survey provides a comprehensive review of\nstate-of-the-art INR methods, introducing a clear taxonomy that categorises\nthem into four key areas: activation functions, position encoding, combined\nstrategies, and network structure optimisation. We rigorously analyse their\ncritical properties, such as full differentiability, smoothness, compactness,\nand adaptability to varying resolutions while also examining their strengths\nand limitations in addressing locality biases and capturing fine details. Our\nexperimental comparison offers new insights into the trade-offs between\ndifferent approaches, showcasing the capabilities and challenges of the latest\nINR techniques across various tasks. In addition to identifying areas where\ncurrent methods excel, we highlight key limitations and potential avenues for\nimprovement, such as developing more expressive activation functions, enhancing\npositional encoding mechanisms, and improving scalability for complex,\nhigh-dimensional data. This survey serves as a roadmap for researchers,\noffering practical guidance for future exploration in the field of INRs. We aim\nto foster new methodologies by outlining promising research directions for INRs\nand applications.\n","authors":["Amer Essakine","Yanqi Cheng","Chun-Wun Cheng","Lipei Zhang","Zhongying Deng","Lei Zhu","Carola-Bibiane Schönlieb","Angelica I Aviles-Rivero"],"pdf_url":"https://arxiv.org/pdf/2411.03688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04315v4","updated":"2024-11-06T05:35:40Z","published":"2023-11-07T19:41:19Z","title":"A Data Perspective on Enhanced Identity Preservation for Diffusion\n  Personalization","summary":"  Large text-to-image models have revolutionized the ability to generate\nimagery using natural language. However, particularly unique or personal visual\nconcepts, such as pets and furniture, will not be captured by the original\nmodel. This has led to interest in how to personalize a text-to-image model.\nDespite significant progress, this task remains a formidable challenge,\nparticularly in preserving the subject's identity. Most researchers attempt to\naddress this issue by modifying model architectures. These methods are capable\nof keeping the subject structure and color but fail to preserve identity\ndetails. Towards this issue, our approach takes a data-centric perspective. We\nintroduce a novel regularization dataset generation strategy on both the text\nand image level. This strategy enables the model to preserve fine details of\nthe desired subjects, such as text and logos. Our method is\narchitecture-agnostic and can be flexibly applied on various text-to-image\nmodels. We show on established benchmarks that our data-centric approach forms\nthe new state of the art in terms of identity preservation and text alignment.\n","authors":["Xingzhe He","Zhiwen Cao","Nicholas Kolkin","Lantao Yu","Kun Wan","Helge Rhodin","Ratheesh Kalarot"],"pdf_url":"https://arxiv.org/pdf/2311.04315v4.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2410.13147v5","updated":"2024-11-06T05:18:04Z","published":"2024-10-17T02:04:57Z","title":"Utilizing Large Language Models in an iterative paradigm with Domain\n  feedback for Zero-shot Molecule optimization","summary":"  Molecule optimization is a critical task in drug discovery to optimize\ndesired properties of a given molecule through chemical modification. Despite\nLarge Language Models (LLMs) holding the potential to efficiently simulate this\ntask by using natural language to direct the optimization, straightforwardly\nutilizing shows limited performance. In this work, we facilitate utilizing LLMs\nin an iterative paradigm by proposing a simple yet highly effective domain\nfeedback provider, namely $\\text{Re}^3$DF. In detail, $\\text{Re}^3$DF harnesses\nan external toolkit, RDKit, to handle the molecule hallucination, if the\nmodified molecule is chemically invalid. Otherwise, its desired properties are\ncomputed and compared to the original one, establishing reliable domain\nfeedback with correct direction and distance towards the objective, followed by\na retrieved example, to explicitly guide the LLM to refine the modified\nmolecule. We conduct experiments across both single- and multi-property\nobjectives with 2 thresholds, where $\\text{Re}^3$DF shows significant\nimprovements. Particularly, for 20 single-property objectives, $\\text{Re}^3$DF\nenhances Hit ratio by 16.95% and 20.76% under loose and strict thresholds,\nrespectively. For 32 multi-property objectives, $\\text{Re}^3$DF enhances Hit\nratio by 6.04% and 5.25%.\n","authors":["Khiem Le","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2410.13147v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.09774v3","updated":"2024-11-06T05:16:59Z","published":"2024-09-15T15:46:03Z","title":"Generalizing Alignment Paradigm of Text-to-Image Generation with\n  Preferences through $f$-divergence Minimization","summary":"  Direct Preference Optimization (DPO) has recently expanded its successful\napplication from aligning large language models (LLMs) to aligning\ntext-to-image models with human preferences, which has generated considerable\ninterest within the community. However, we have observed that these approaches\nrely solely on minimizing the reverse Kullback-Leibler divergence during\nalignment process between the fine-tuned model and the reference model,\nneglecting the incorporation of other divergence constraints. In this study, we\nfocus on extending reverse Kullback-Leibler divergence in the alignment\nparadigm of text-to-image models to $f$-divergence, which aims to garner better\nalignment performance as well as good generation diversity. We provide the\ngeneralized formula of the alignment paradigm under the $f$-divergence\ncondition and thoroughly analyze the impact of different divergence constraints\non alignment process from the perspective of gradient fields. We conduct\ncomprehensive evaluation on image-text alignment performance, human value\nalignment performance and generation diversity performance under different\ndivergence constraints, and the results indicate that alignment based on\nJensen-Shannon divergence achieves the best trade-off among them. The option of\ndivergence employed for aligning text-to-image models significantly impacts the\ntrade-off between alignment performance (especially human value alignment) and\ngeneration diversity, which highlights the necessity of selecting an\nappropriate divergence for practical applications.\n","authors":["Haoyuan Sun","Bo Xia","Yongzhe Chang","Xueqian Wang"],"pdf_url":"https://arxiv.org/pdf/2409.09774v3.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2411.03672v1","updated":"2024-11-06T05:11:25Z","published":"2024-11-06T05:11:25Z","title":"Towards 3D Semantic Scene Completion for Autonomous Driving: A\n  Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and\n  Mamba Model","summary":"  Semantic scene completion (SSC) is essential for achieving comprehensive\nperception in autonomous driving systems. However, existing SSC methods often\noverlook the high deployment costs in real-world applications. Traditional\narchitectures, such as 3D Convolutional Neural Networks (3D CNNs) and\nself-attention mechanisms, face challenges in efficiently capturing long-range\ndependencies within 3D voxel grids, limiting their effectiveness. To address\nthese issues, we introduce MetaSSC, a novel meta-learning-based framework for\nSSC that leverages deformable convolution, large-kernel attention, and the\nMamba (D-LKA-M) model. Our approach begins with a voxel-based semantic\nsegmentation (SS) pretraining task, aimed at exploring the semantics and\ngeometry of incomplete regions while acquiring transferable meta-knowledge.\nUsing simulated cooperative perception datasets, we supervise the perception\ntraining of a single vehicle using aggregated sensor data from multiple nearby\nconnected autonomous vehicles (CAVs), generating richer and more comprehensive\nlabels. This meta-knowledge is then adapted to the target domain through a\ndual-phase training strategy that does not add extra model parameters, enabling\nefficient deployment. To further enhance the model's capability in capturing\nlong-sequence relationships within 3D voxel grids, we integrate Mamba blocks\nwith deformable convolution and large-kernel attention into the backbone\nnetwork. Extensive experiments demonstrate that MetaSSC achieves\nstate-of-the-art performance, significantly outperforming competing models\nwhile also reducing deployment costs.\n","authors":["Yansong Qu","Zilin Huang","Zihao Sheng","Tiantian Chen","Sikai Chen"],"pdf_url":"https://arxiv.org/pdf/2411.03672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02077v4","updated":"2024-11-06T05:11:24Z","published":"2024-07-02T09:11:17Z","title":"Hierarchical Temporal Context Learning for Camera-based Semantic Scene\n  Completion","summary":"  Camera-based 3D semantic scene completion (SSC) is pivotal for predicting\ncomplicated 3D layouts with limited 2D image observations. The existing\nmainstream solutions generally leverage temporal information by roughly\nstacking history frames to supplement the current frame, such straightforward\ntemporal modeling inevitably diminishes valid clues and increases learning\ndifficulty. To address this problem, we present HTCL, a novel Hierarchical\nTemporal Context Learning paradigm for improving camera-based semantic scene\ncompletion. The primary innovation of this work involves decomposing temporal\ncontext learning into two hierarchical steps: (a) cross-frame affinity\nmeasurement and (b) affinity-based dynamic refinement. Firstly, to separate\ncritical relevant context from redundant information, we introduce the pattern\naffinity with scale-aware isolation and multiple independent learners for\nfine-grained contextual correspondence modeling. Subsequently, to dynamically\ncompensate for incomplete observations, we adaptively refine the feature\nsampling locations based on initially identified locations with high affinity\nand their neighboring relevant regions. Our method ranks $1^{st}$ on the\nSemanticKITTI benchmark and even surpasses LiDAR-based methods in terms of mIoU\non the OpenOccupancy benchmark. Our code is available on\nhttps://github.com/Arlo0o/HTCL.\n","authors":["Bohan Li","Jiajun Deng","Wenyao Zhang","Zhujin Liang","Dalong Du","Xin Jin","Wenjun Zeng"],"pdf_url":"https://arxiv.org/pdf/2407.02077v4.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2411.03670v1","updated":"2024-11-06T05:09:34Z","published":"2024-11-06T05:09:34Z","title":"Touchstone Benchmark: Are We on the Right Way for Evaluating AI\n  Algorithms for Medical Segmentation?","summary":"  How can we test AI performance? This question seems trivial, but it isn't.\nStandard benchmarks often have problems such as in-distribution and small-size\ntest sets, oversimplified metrics, unfair comparisons, and short-term outcome\npressure. As a consequence, good performance on standard benchmarks does not\nguarantee success in real-world scenarios. To address these problems, we\npresent Touchstone, a large-scale collaborative segmentation benchmark of 9\ntypes of abdominal organs. This benchmark is based on 5,195 training CT scans\nfrom 76 hospitals around the world and 5,903 testing CT scans from 11\nadditional hospitals. This diverse test set enhances the statistical\nsignificance of benchmark results and rigorously evaluates AI algorithms across\nvarious out-of-distribution scenarios. We invited 14 inventors of 19 AI\nalgorithms to train their algorithms, while our team, as a third party,\nindependently evaluated these algorithms on three test sets. In addition, we\nalso evaluated pre-existing AI frameworks--which, differing from algorithms,\nare more flexible and can support different algorithms--including MONAI from\nNVIDIA, nnU-Net from DKFZ, and numerous other open-source frameworks. We are\ncommitted to expanding this benchmark to encourage more innovation of AI\nalgorithms for the medical domain.\n","authors":["Pedro R. A. S. Bassi","Wenxuan Li","Yucheng Tang","Fabian Isensee","Zifu Wang","Jieneng Chen","Yu-Cheng Chou","Yannick Kirchhoff","Maximilian Rokuss","Ziyan Huang","Jin Ye","Junjun He","Tassilo Wald","Constantin Ulrich","Michael Baumgartner","Saikat Roy","Klaus H. Maier-Hein","Paul Jaeger","Yiwen Ye","Yutong Xie","Jianpeng Zhang","Ziyang Chen","Yong Xia","Zhaohu Xing","Lei Zhu","Yousef Sadegheih","Afshin Bozorgpour","Pratibha Kumari","Reza Azad","Dorit Merhof","Pengcheng Shi","Ting Ma","Yuxin Du","Fan Bai","Tiejun Huang","Bo Zhao","Haonan Wang","Xiaomeng Li","Hanxue Gu","Haoyu Dong","Jichen Yang","Maciej A. Mazurowski","Saumya Gupta","Linshan Wu","Jiaxin Zhuang","Hao Chen","Holger Roth","Daguang Xu","Matthew B. Blaschko","Sergio Decherchi","Andrea Cavalli","Alan L. Yuille","Zongwei Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.03670v1.pdf","comment":"Accepted to NeurIPS-2024"},{"id":"http://arxiv.org/abs/2409.13941v2","updated":"2024-11-06T05:05:12Z","published":"2024-09-20T23:04:21Z","title":"TalkMosaic: Interactive PhotoMosaic with Multi-modal LLM Q&A\n  Interactions","summary":"  We use images of cars of a wide range of varieties to compose an image of an\nanimal such as a bird or a lion for the theme of environmental protection to\nmaximize the information about cars in a single composed image and to raise the\nawareness about environmental challenges. We present a novel way of image\ninteraction with an artistically-composed photomosaic image, in which a simple\noperation of \"click and display\" is used to demonstrate the interactive switch\nbetween a tile image in a photomosaic image and the corresponding original car\nimage, which will be automatically saved on the Desktop. We build a multimodal\ncustom GPT named TalkMosaic by incorporating car images information and the\nrelated knowledge to ChatGPT. By uploading the original car image to\nTalkMosaic, we can ask questions about the given car image and get the\ncorresponding answers efficiently and effectively such as where to buy the tire\nin the car image that satisfies high environmental standards. We give an\nin-depth analysis on how to speed up the inference of multimodal LLM using\nsparse attention and quantization techniques with presented probabilistic\nFlashAttention (PrFlashAttention) and Staircase Adaptive Quantization (SAQ)\nmethods. The implemented prototype demonstrates the feasibility and\neffectiveness of the presented approach.\n","authors":["Kevin Li","Fulu Li"],"pdf_url":"https://arxiv.org/pdf/2409.13941v2.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.14789v2","updated":"2024-11-06T04:41:48Z","published":"2024-08-27T05:31:30Z","title":"Revisiting Surgical Instrument Segmentation Without Human Intervention:\n  A Graph Partitioning View","summary":"  Surgical instrument segmentation (SIS) on endoscopic images stands as a\nlong-standing and essential task in the context of computer-assisted\ninterventions for boosting minimally invasive surgery. Given the recent surge\nof deep learning methodologies and their data-hungry nature, training a neural\npredictive model based on massive expert-curated annotations has been\ndominating and served as an off-the-shelf approach in the field, which could,\nhowever, impose prohibitive burden to clinicians for preparing fine-grained\npixel-wise labels corresponding to the collected surgical video frames. In this\nwork, we propose an unsupervised method by reframing the video frame\nsegmentation as a graph partitioning problem and regarding image pixels as\ngraph nodes, which is significantly different from the previous efforts. A\nself-supervised pre-trained model is firstly leveraged as a feature extractor\nto capture high-level semantic features. Then, Laplacian matrixs are computed\nfrom the features and are eigendecomposed for graph partitioning. On the \"deep\"\neigenvectors, a surgical video frame is meaningfully segmented into different\nmodules such as tools and tissues, providing distinguishable semantic\ninformation like locations, classes, and relations. The segmentation problem\ncan then be naturally tackled by applying clustering or threshold on the\neigenvectors. Extensive experiments are conducted on various datasets (e.g.,\nEndoVis2017, EndoVis2018, UCL, etc.) for different clinical endpoints. Across\nall the challenging scenarios, our method demonstrates outstanding performance\nand robustness higher than unsupervised state-of-the-art (SOTA) methods. The\ncode is released at https://github.com/MingyuShengSMY/GraphClusteringSIS.git.\n","authors":["Mingyu Sheng","Jianan Fan","Dongnan Liu","Ron Kikinis","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2408.14789v2.pdf","comment":"This paper is accepted by The 32nd ACM International Conference on\n  Multimedia (ACM MM 2024) Workshop on Multimedia Computing for Health and\n  Medicine (MCHM)"},{"id":"http://arxiv.org/abs/2406.15735v3","updated":"2024-11-06T03:53:13Z","published":"2024-06-22T04:56:16Z","title":"Identifying and Solving Conditional Image Leakage in Image-to-Video\n  Diffusion Model","summary":"  Diffusion models have obtained substantial progress in image-to-video\ngeneration. However, in this paper, we find that these models tend to generate\nvideos with less motion than expected. We attribute this to the issue called\nconditional image leakage, where the image-to-video diffusion models (I2V-DMs)\ntend to over-rely on the conditional image at large time steps. We further\naddress this challenge from both inference and training aspects. First, we\npropose to start the generation process from an earlier time step to avoid the\nunreliable large-time steps of I2V-DMs, as well as an initial noise\ndistribution with optimal analytic expressions (Analytic-Init) by minimizing\nthe KL divergence between it and the actual marginal distribution to bridge the\ntraining-inference gap. Second, we design a time-dependent noise distribution\n(TimeNoise) for the conditional image during training, applying higher noise\nlevels at larger time steps to disrupt it and reduce the model's dependency on\nit. We validate these general strategies on various I2V-DMs on our collected\nopen-domain image benchmark and the UCF101 dataset. Extensive results show that\nour methods outperform baselines by producing higher motion scores with lower\nerrors while maintaining image alignment and temporal consistency, thereby\nyielding superior overall performance and enabling more accurate motion\ncontrol. The project page: \\url{https://cond-image-leak.github.io/}.\n","authors":["Min Zhao","Hongzhou Zhu","Chendong Xiang","Kaiwen Zheng","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.15735v3.pdf","comment":"NeurIPS 2024. Project page: https://cond-image-leak.github.io/"},{"id":"http://arxiv.org/abs/2411.01797v2","updated":"2024-11-06T03:45:13Z","published":"2024-11-04T04:45:45Z","title":"AIWR: Aerial Image Water Resource Dataset for Segmentation Analysis","summary":"  Effective water resource management is crucial in agricultural regions like\nnortheastern Thailand, where limited water retention in sandy soils poses\nsignificant challenges. In response to this issue, the Aerial Image Water\nResource (AIWR) dataset was developed, comprising 800 aerial images focused on\nnatural and artificial water bodies in this region. The dataset was created\nusing Bing Maps and follows the standards of the Fundamental Geographic Data\nSet (FGDS). It includes ground truth annotations validated by experts in remote\nsensing, making it an invaluable resource for researchers in geoinformatics,\ncomputer vision, and artificial intelligence. The AIWR dataset presents\nconsiderable challenges, such as segmentation due to variations in the size,\ncolor, shape, and similarity of water bodies, which often resemble other land\nuse categories. The objective of the proposed dataset is to explore advanced\nAI-driven methods for water body segmentation, addressing the unique challenges\nposed by the dataset complexity and limited size. This dataset and related\nresearch contribute to the development of novel algorithms for water\nmanagement, supporting sustainable agricultural practices in regions facing\nsimilar challenges.\n","authors":["Sangdaow Noppitak","Emmanuel Okafor","Olarik Surinta"],"pdf_url":"https://arxiv.org/pdf/2411.01797v2.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.03638v1","updated":"2024-11-06T03:30:46Z","published":"2024-11-06T03:30:46Z","title":"Adaptive Stereo Depth Estimation with Multi-Spectral Images Across All\n  Lighting Conditions","summary":"  Depth estimation under adverse conditions remains a significant challenge.\nRecently, multi-spectral depth estimation, which integrates both visible light\nand thermal images, has shown promise in addressing this issue. However,\nexisting algorithms struggle with precise pixel-level feature matching,\nlimiting their ability to fully exploit geometric constraints across different\nspectra. To address this, we propose a novel framework incorporating stereo\ndepth estimation to enforce accurate geometric constraints. In particular, we\ntreat the visible light and thermal images as a stereo pair and utilize a\nCross-modal Feature Matching (CFM) Module to construct a cost volume for\npixel-level matching. To mitigate the effects of poor lighting on stereo\nmatching, we introduce Degradation Masking, which leverages robust monocular\nthermal depth estimation in degraded regions. Our method achieves\nstate-of-the-art (SOTA) performance on the Multi-Spectral Stereo (MS2) dataset,\nwith qualitative evaluations demonstrating high-quality depth maps under\nvarying lighting conditions.\n","authors":["Zihan Qin","Jialei Xu","Wenbo Zhao","Junjun Jiang","Xianming Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03637v1","updated":"2024-11-06T03:28:06Z","published":"2024-11-06T03:28:06Z","title":"Structure Consistent Gaussian Splatting with Matching Prior for Few-shot\n  Novel View Synthesis","summary":"  Despite the substantial progress of novel view synthesis, existing methods,\neither based on the Neural Radiance Fields (NeRF) or more recently 3D Gaussian\nSplatting (3DGS), suffer significant degradation when the input becomes sparse.\nNumerous efforts have been introduced to alleviate this problem, but they still\nstruggle to synthesize satisfactory results efficiently, especially in the\nlarge scene. In this paper, we propose SCGaussian, a Structure Consistent\nGaussian Splatting method using matching priors to learn 3D consistent scene\nstructure. Considering the high interdependence of Gaussian attributes, we\noptimize the scene structure in two folds: rendering geometry and, more\nimportantly, the position of Gaussian primitives, which is hard to be directly\nconstrained in the vanilla 3DGS due to the non-structure property. To achieve\nthis, we present a hybrid Gaussian representation. Besides the ordinary\nnon-structure Gaussian primitives, our model also consists of ray-based\nGaussian primitives that are bound to matching rays and whose optimization of\ntheir positions is restricted along the ray. Thus, we can utilize the matching\ncorrespondence to directly enforce the position of these Gaussian primitives to\nconverge to the surface points where rays intersect. Extensive experiments on\nforward-facing, surrounding, and complex large scenes show the effectiveness of\nour approach with state-of-the-art performance and high efficiency. Code is\navailable at https://github.com/prstrive/SCGaussian.\n","authors":["Rui Peng","Wangze Xu","Luyang Tang","Liwei Liao","Jianbo Jiao","Ronggang Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03637v1.pdf","comment":"NeurIPS 2024 Accepted"},{"id":"http://arxiv.org/abs/2410.21872v2","updated":"2024-11-06T02:52:47Z","published":"2024-10-29T09:08:57Z","title":"Advancing Efficient Brain Tumor Multi-Class Classification -- New\n  Insights from the Vision Mamba Model in Transfer Learning","summary":"  Early and accurate diagnosis of brain tumors is crucial for improving patient\nsurvival rates. However, the detection and classification of brain tumors are\nchallenging due to their diverse types and complex morphological\ncharacteristics. This study investigates the application of pre-trained models\nfor brain tumor classification, with a particular focus on deploying the Mamba\nmodel. We fine-tuned several mainstream transfer learning models and applied\nthem to the multi-class classification of brain tumors. By comparing these\nmodels to those trained from scratch, we demonstrated the significant\nadvantages of transfer learning, especially in the medical imaging field, where\nannotated data is often limited. Notably, we introduced the Vision Mamba (Vim),\na novel network architecture, and applied it for the first time in brain tumor\nclassification, achieving exceptional classification accuracy. Experimental\nresults indicate that the Vim model achieved 100% classification accuracy on an\nindependent test set, emphasizing its potential for tumor classification tasks.\nThese findings underscore the effectiveness of transfer learning in brain tumor\nclassification and reveal that, compared to existing state-of-the-art models,\nthe Vim model is lightweight, efficient, and highly accurate, offering a new\nperspective for clinical applications. Furthermore, the framework proposed in\nthis study for brain tumor classification, based on transfer learning and the\nVision Mamba model, is broadly applicable to other medical imaging\nclassification problems.\n","authors":["Yinyi Lai","Anbo Cao","Yuan Gao","Jiaqi Shang","Zongyu Li","Jia Guo"],"pdf_url":"https://arxiv.org/pdf/2410.21872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03628v1","updated":"2024-11-06T02:50:30Z","published":"2024-11-06T02:50:30Z","title":"StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video\n  Understanding","summary":"  The rapid development of Multimodal Large Language Models (MLLMs) has\nexpanded their capabilities from image comprehension to video understanding.\nHowever, most of these MLLMs focus primarily on offline video comprehension,\nnecessitating extensive processing of all video frames before any queries can\nbe made. This presents a significant gap compared to the human ability to\nwatch, listen, think, and respond to streaming inputs in real time,\nhighlighting the limitations of current MLLMs. In this paper, we introduce\nStreamingBench, the first comprehensive benchmark designed to evaluate the\nstreaming video understanding capabilities of MLLMs. StreamingBench assesses\nthree core aspects of streaming video understanding: (1) real-time visual\nunderstanding, (2) omni-source understanding, and (3) contextual understanding.\nThe benchmark consists of 18 tasks, featuring 900 videos and 4,500\nhuman-curated QA pairs. Each video features five questions presented at\ndifferent time points to simulate a continuous streaming scenario. We conduct\nexperiments on StreamingBench with 13 open-source and proprietary MLLMs and\nfind that even the most advanced proprietary MLLMs like Gemini 1.5 Pro and\nGPT-4o perform significantly below human-level streaming video understanding\ncapabilities. We hope our work can facilitate further advancements for MLLMs,\nempowering them to approach human-level video comprehension and interaction in\nmore realistic scenarios.\n","authors":["Junming Lin","Zheng Fang","Chi Chen","Zihao Wan","Fuwen Luo","Peng Li","Yang Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2411.03628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03618v1","updated":"2024-11-06T02:23:38Z","published":"2024-11-06T02:23:38Z","title":"Cross Feature Fusion of Fundus Image and Generated Lesion Map for\n  Referable Diabetic Retinopathy Classification","summary":"  Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating\nearly detection and diagnosis. This paper focuses on referable DR\nclassification to enhance the applicability of the proposed method in clinical\npractice. We develop an advanced cross-learning DR classification method\nleveraging transfer learning and cross-attention mechanisms. The proposed\nmethod employs the Swin U-Net architecture to segment lesion maps from DR\nfundus images. The Swin U-Net segmentation model, enriched with DR lesion\ninsights, is transferred to generate a lesion map. Both the fundus image and\nits segmented lesion map are used as complementary inputs for the\nclassification model. A cross-attention mechanism is deployed to improve the\nmodel's ability to capture fine-grained details from the input pairs. Our\nexperiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a\nsuperior accuracy of 94.6%, surpassing current state-of-the-art methods by\n4.4%. To this end, we aim for the proposed method to be seamlessly integrated\ninto clinical workflows, enhancing accuracy and efficiency in identifying\nreferable DR.\n","authors":["Dahyun Mok","Junghyun Bum","Le Duc Tai","Hyunseung Choo"],"pdf_url":"https://arxiv.org/pdf/2411.03618v1.pdf","comment":"ACCV 2024 accepted"},{"id":"http://arxiv.org/abs/2406.16473v2","updated":"2024-11-06T02:17:05Z","published":"2024-06-24T09:25:02Z","title":"D2SP: Dynamic Dual-Stage Purification Framework for Dual Noise\n  Mitigation in Vision-based Affective Recognition","summary":"  The contemporary state-of-the-art of Dynamic Facial Expression Recognition\n(DFER) technology facilitates remarkable progress by deriving emotional\nmappings of facial expressions from video content, underpinned by training on\nvoluminous datasets. Yet, the DFER datasets encompass a substantial volume of\nnoise data. Noise arises from low-quality captures that defy logical labeling,\nand instances that suffer from mislabeling due to annotation bias, engendering\ntwo principal types of uncertainty: the uncertainty regarding data usability\nand the uncertainty concerning label reliability. Addressing the two types of\nuncertainty, we have meticulously crafted a two-stage framework aiming at\n\\textbf{S}eeking \\textbf{C}ertain data \\textbf{I}n extensive \\textbf{U}ncertain\ndata (SCIU). This initiative aims to purge the DFER datasets of these\nuncertainties, thereby ensuring that only clean, verified data is employed in\ntraining processes. To mitigate the issue of low-quality samples, we introduce\nthe Coarse-Grained Pruning (CGP) stage, which assesses sample weights and\nprunes those deemed unusable due to their low weight. For samples with\nincorrect annotations, the Fine-Grained Correction (FGC) stage evaluates\nprediction stability to rectify mislabeled data. Moreover, SCIU is conceived as\na universally compatible, plug-and-play framework, tailored to integrate\nseamlessly with prevailing DFER methodologies. Rigorous experiments across\nprevalent DFER datasets and against numerous benchmark methods substantiates\nSCIU's capacity to markedly elevate performance metrics.\n","authors":["Haoran Wang","Xinji Mai","Zeng Tao","Xuan Tong","Junxiong Lin","Yan Wang","Jiawen Yu","Boyang Wang","Shaoqi Yan","Qing Zhao","Ziheng Zhou","Shuyong Gao","Wenqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16473v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03615v1","updated":"2024-11-06T02:16:34Z","published":"2024-11-06T02:16:34Z","title":"ADMIRE: a locally adaptive single-image, non-uniformity correction and\n  denoising algorithm: application to uncooled IR camera","summary":"  We propose a new way to correct for the non-uniformity (NU) and the noise in\nuncooled infrared-type images. This method works on static images, needs no\nregistration, no camera motion and no model for the non uniformity. The\nproposed method uses an hybrid scheme including an automatic locally-adaptive\ncontrast adjustment and a state-of-the-art image denoising method. It permits\nto correct for a fully non-linear NU and the noise efficiently using only one\nimage. We compared it with total variation on real raw and simulated NU\ninfrared images. The strength of this approach lies in its simplicity, low\ncomputational cost. It needs no test-pattern or calibration and produces no\n\"ghost-artefact\".\n","authors":["Yohann Tendero","Jerome Gilles"],"pdf_url":"https://arxiv.org/pdf/2411.03615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03610v1","updated":"2024-11-06T02:05:44Z","published":"2024-11-06T02:05:44Z","title":"LCP-Fusion: A Neural Implicit SLAM with Enhanced Local Constraints and\n  Computable Prior","summary":"  Recently the dense Simultaneous Localization and Mapping (SLAM) based on\nneural implicit representation has shown impressive progress in hole filling\nand high-fidelity mapping. Nevertheless, existing methods either heavily rely\non known scene bounds or suffer inconsistent reconstruction due to drift in\npotential loop-closure regions, or both, which can be attributed to the\ninflexible representation and lack of local constraints. In this paper, we\npresent LCP-Fusion, a neural implicit SLAM system with enhanced local\nconstraints and computable prior, which takes the sparse voxel octree structure\ncontaining feature grids and SDF priors as hybrid scene representation,\nenabling the scalability and robustness during mapping and tracking. To enhance\nthe local constraints, we propose a novel sliding window selection strategy\nbased on visual overlap to address the loop-closure, and a practical warping\nloss to constrain relative poses. Moreover, we estimate SDF priors as coarse\ninitialization for implicit features, which brings additional explicit\nconstraints and robustness, especially when a light but efficient adaptive\nearly ending is adopted. Experiments demonstrate that our method achieve better\nlocalization accuracy and reconstruction consistency than existing RGB-D\nimplicit SLAM, especially in challenging real scenes (ScanNet) as well as\nself-captured scenes with unknown scene bounds. The code is available at\nhttps://github.com/laliwang/LCP-Fusion.\n","authors":["Jiahui Wang","Yinan Deng","Yi Yang","Yufeng Yue"],"pdf_url":"https://arxiv.org/pdf/2411.03610v1.pdf","comment":"Accepted by 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2411.03576v1","updated":"2024-11-06T00:34:26Z","published":"2024-11-06T00:34:26Z","title":"Hybrid Attention for Robust RGB-T Pedestrian Detection in Real-World\n  Conditions","summary":"  Multispectral pedestrian detection has gained significant attention in recent\nyears, particularly in autonomous driving applications. To address the\nchallenges posed by adversarial illumination conditions, the combination of\nthermal and visible images has demonstrated its advantages. However, existing\nfusion methods rely on the critical assumption that the RGB-Thermal (RGB-T)\nimage pairs are fully overlapping. These assumptions often do not hold in\nreal-world applications, where only partial overlap between images can occur\ndue to sensors configuration. Moreover, sensor failure can cause loss of\ninformation in one modality. In this paper, we propose a novel module called\nthe Hybrid Attention (HA) mechanism as our main contribution to mitigate\nperformance degradation caused by partial overlap and sensor failure, i.e. when\nat least part of the scene is acquired by only one sensor. We propose an\nimproved RGB-T fusion algorithm, robust against partial overlap and sensor\nfailure encountered during inference in real-world applications. We also\nleverage a mobile-friendly backbone to cope with resource constraints in\nembedded systems. We conducted experiments by simulating various partial\noverlap and sensor failure scenarios to evaluate the performance of our\nproposed method. The results demonstrate that our approach outperforms\nstate-of-the-art methods, showcasing its superiority in handling real-world\nchallenges.\n","authors":["Arunkumar Rathinam","Leo Pauly","Abd El Rahman Shabayek","Wassim Rharbaoui","Anis Kacem","Vincent Gaudillière","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2411.03576v1.pdf","comment":"Accepted for publication in IEEE Robotics and Automation Letters,\n  October 2024"},{"id":"http://arxiv.org/abs/2411.03569v1","updated":"2024-11-06T00:17:36Z","published":"2024-11-06T00:17:36Z","title":"Towards Personalized Federated Learning via Comprehensive Knowledge\n  Distillation","summary":"  Federated learning is a distributed machine learning paradigm designed to\nprotect data privacy. However, data heterogeneity across various clients\nresults in catastrophic forgetting, where the model rapidly forgets previous\nknowledge while acquiring new knowledge. To address this challenge,\npersonalized federated learning has emerged to customize a personalized model\nfor each client. However, the inherent limitation of this mechanism is its\nexcessive focus on personalization, potentially hindering the generalization of\nthose models. In this paper, we present a novel personalized federated learning\nmethod that uses global and historical models as teachers and the local model\nas the student to facilitate comprehensive knowledge distillation. The\nhistorical model represents the local model from the last round of client\ntraining, containing historical personalized knowledge, while the global model\nrepresents the aggregated model from the last round of server aggregation,\ncontaining global generalized knowledge. By applying knowledge distillation, we\neffectively transfer global generalized knowledge and historical personalized\nknowledge to the local model, thus mitigating catastrophic forgetting and\nenhancing the general performance of personalized models. Extensive\nexperimental results demonstrate the significant advantages of our method.\n","authors":["Pengju Wang","Bochao Liu","Weijia Guo","Yong Li","Shiming Ge"],"pdf_url":"https://arxiv.org/pdf/2411.03569v1.pdf","comment":"Accepted by IEEE SMC 2024"},{"id":"http://arxiv.org/abs/2411.03568v1","updated":"2024-11-06T00:16:16Z","published":"2024-11-06T00:16:16Z","title":"The American Sign Language Knowledge Graph: Infusing ASL Models with\n  Linguistic Knowledge","summary":"  Language models for American Sign Language (ASL) could make language\ntechnologies substantially more accessible to those who sign. To train models\non tasks such as isolated sign recognition (ISR) and ASL-to-English\ntranslation, datasets provide annotated video examples of ASL signs. To\nfacilitate the generalizability and explainability of these models, we\nintroduce the American Sign Language Knowledge Graph (ASLKG), compiled from\ntwelve sources of expert linguistic knowledge. We use the ASLKG to train\nneuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of\n91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%\nfor classifying the topic of Youtube-ASL videos.\n","authors":["Lee Kezar","Nidhi Munikote","Zian Zeng","Zed Sehyr","Naomi Caselli","Jesse Thomason"],"pdf_url":"https://arxiv.org/pdf/2411.03568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21169v3","updated":"2024-11-06T00:11:08Z","published":"2024-10-28T16:11:35Z","title":"Document Parsing Unveiled: Techniques, Challenges, and Prospects for\n  Structured Information Extraction","summary":"  Document parsing is essential for converting unstructured and semi-structured\ndocuments-such as contracts, academic papers, and invoices-into structured,\nmachine-readable data. Document parsing extract reliable structured data from\nunstructured inputs, providing huge convenience for numerous applications.\nEspecially with recent achievements in Large Language Models, document parsing\nplays an indispensable role in both knowledge base construction and training\ndata generation. This survey presents a comprehensive review of the current\nstate of document parsing, covering key methodologies, from modular pipeline\nsystems to end-to-end models driven by large vision-language models. Core\ncomponents such as layout detection, content extraction (including text,\ntables, and mathematical expressions), and multi-modal data integration are\nexamined in detail. Additionally, this paper discusses the challenges faced by\nmodular document parsing systems and vision-language models in handling complex\nlayouts, integrating multiple modules, and recognizing high-density text. It\nemphasizes the importance of developing larger and more diverse datasets and\noutlines future research directions.\n","authors":["Qintong Zhang","Victor Shea-Jay Huang","Bin Wang","Junyuan Zhang","Zhengren Wang","Hao Liang","Shawn Wang","Matthieu Lin","Conghui He","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.21169v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.12507v3","updated":"2024-11-06T23:44:52Z","published":"2023-04-25T01:12:47Z","title":"Learning Task-Specific Strategies for Accelerated MRI","summary":"  Compressed sensing magnetic resonance imaging (CS-MRI) seeks to recover\nvisual information from subsampled measurements for diagnostic tasks.\nTraditional CS-MRI methods often separately address measurement subsampling,\nimage reconstruction, and task prediction, resulting in a suboptimal end-to-end\nperformance. In this work, we propose TACKLE as a unified co-design framework\nfor jointly optimizing subsampling, reconstruction, and prediction strategies\nfor the performance on downstream tasks. The na\\\"ive approach of simply\nappending a task prediction module and training with a task-specific loss leads\nto suboptimal downstream performance. Instead, we develop a training procedure\nwhere a backbone architecture is first trained for a generic pre-training task\n(image reconstruction in our case), and then fine-tuned for different\ndownstream tasks with a prediction head. Experimental results on multiple\npublic MRI datasets show that TACKLE achieves an improved performance on\nvarious tasks over traditional CS-MRI methods. We also demonstrate that TACKLE\nis robust to distribution shifts by showing that it generalizes to a new\ndataset we experimentally collected using different acquisition setups from the\ntraining data. Without additional fine-tuning, TACKLE leads to both numerical\nand visual improvements compared to existing baselines. We have further\nimplemented a learned 4$\\times$-accelerated sequence on a Siemens 3T MRI Skyra\nscanner. Compared to the fully-sampling scan that takes 335 seconds, our\noptimized sequence only takes 84 seconds, achieving a four-fold time reduction\nas desired, while maintaining high performance.\n","authors":["Zihui Wu","Tianwei Yin","Yu Sun","Robert Frost","Andre van der Kouwe","Adrian V. Dalca","Katherine L. Bouman"],"pdf_url":"https://arxiv.org/pdf/2304.12507v3.pdf","comment":"Our code is available at https://github.com/zihuiwu/TACKLE. More\n  information can be found at http://imaging.cms.caltech.edu/tackle/"},{"id":"http://arxiv.org/abs/2304.04901v2","updated":"2024-11-06T23:32:27Z","published":"2023-04-11T00:17:28Z","title":"Efficiently Collecting Training Dataset for 2D Object Detection by\n  Online Visual Feedback","summary":"  Training deep-learning-based vision systems require the manual annotation of\na significant number of images. Such manual annotation is highly time-consuming\nand labor-intensive. Although previous studies have attempted to eliminate the\neffort required for annotation, the effort required for image collection was\nretained. To address this, we propose a human-in-the-loop dataset collection\nmethod that uses a web application. To counterbalance the workload and\nperformance by encouraging the collection of multi-view object image datasets\nin an enjoyable manner, thereby amplifying motivation, we propose three types\nof online visual feedback features to track the progress of the collection\nstatus. Our experiments thoroughly investigated the impact of each feature on\ncollection performance and quality of operation. The results suggested the\nfeasibility of annotation and object detection.\n","authors":["Takuya Kiyokawa","Naoki Shirakura","Hiroki Katayama","Keita Tomochika","Jun Takamatsu"],"pdf_url":"https://arxiv.org/pdf/2304.04901v2.pdf","comment":"13 pages, 14 figures"},{"id":"http://arxiv.org/abs/2402.03478v2","updated":"2024-11-06T23:02:47Z","published":"2024-02-05T19:39:52Z","title":"Estimating Epistemic and Aleatoric Uncertainty with a Single Model","summary":"  Estimating and disentangling epistemic uncertainty, uncertainty that is\nreducible with more training data, and aleatoric uncertainty, uncertainty that\nis inherent to the task at hand, is critically important when applying machine\nlearning to high-stakes applications such as medical imaging and weather\nforecasting. Conditional diffusion models' breakthrough ability to accurately\nand efficiently sample from the posterior distribution of a dataset now makes\nuncertainty estimation conceptually straightforward: One need only train and\nsample from a large ensemble of diffusion models. Unfortunately, training such\nan ensemble becomes computationally intractable as the complexity of the model\narchitecture grows. In this work we introduce a new approach to ensembling,\nhyper-diffusion models (HyperDM), which allows one to accurately estimate both\nepistemic and aleatoric uncertainty with a single model. Unlike existing\nsingle-model uncertainty methods like Monte-Carlo dropout and Bayesian neural\nnetworks, HyperDM offers prediction accuracy on par with, and in some cases\nsuperior to, multi-model ensembles. Furthermore, our proposed approach scales\nto modern network architectures such as Attention U-Net and yields more\naccurate uncertainty estimates compared to existing methods. We validate our\nmethod on two distinct real-world tasks: x-ray computed tomography\nreconstruction and weather temperature forecasting.\n","authors":["Matthew A. Chan","Maria J. Molina","Christopher A. Metzler"],"pdf_url":"https://arxiv.org/pdf/2402.03478v2.pdf","comment":"19 pages, 11 figures. To be published in Conference on Neural\n  Information Processing Systems (NeurIPS) 2024"},{"id":"http://arxiv.org/abs/2312.02985v2","updated":"2024-11-06T23:02:02Z","published":"2023-11-15T13:28:02Z","title":"FocalPose++: Focal Length and Object Pose Estimation via Render and\n  Compare","summary":"  We introduce FocalPose++, a neural render-and-compare method for jointly\nestimating the camera-object 6D pose and camera focal length given a single RGB\ninput image depicting a known object. The contributions of this work are\nthreefold. First, we derive a focal length update rule that extends an existing\nstate-of-the-art render-and-compare 6D pose estimator to address the joint\nestimation task. Second, we investigate several different loss functions for\njointly estimating the object pose and focal length. We find that a combination\nof direct focal length regression with a reprojection loss disentangling the\ncontribution of translation, rotation, and focal length leads to improved\nresults. Third, we explore the effect of different synthetic training data on\nthe performance of our method. Specifically, we investigate different\ndistributions used for sampling object's 6D pose and camera's focal length when\nrendering the synthetic images, and show that parametric distribution fitted on\nreal training data works the best. We show results on three challenging\nbenchmark datasets that depict known 3D models in uncontrolled settings. We\ndemonstrate that our focal length and 6D pose estimates have lower error than\nthe existing state-of-the-art methods.\n","authors":["Martin Cífka","Georgy Ponimatkin","Yann Labbé","Bryan Russell","Mathieu Aubry","Vladimir Petrik","Josef Sivic"],"pdf_url":"https://arxiv.org/pdf/2312.02985v2.pdf","comment":"25 pages, 22 figures. IEEE TPAMI, 2024. Extended version of the\n  conference paper arXiv:2204.05145"},{"id":"http://arxiv.org/abs/2411.04291v1","updated":"2024-11-06T22:19:32Z","published":"2024-11-06T22:19:32Z","title":"Unfair Alignment: Examining Safety Alignment Across Vision Encoder\n  Layers in Vision-Language Models","summary":"  Vision-language models (VLMs) have improved significantly in multi-modal\ntasks, but their more complex architecture makes their safety alignment more\nchallenging than the alignment of large language models (LLMs). In this paper,\nwe reveal an unfair distribution of safety across the layers of VLM's vision\nencoder, with earlier and middle layers being disproportionately vulnerable to\nmalicious inputs compared to the more robust final layers. This 'cross-layer'\nvulnerability stems from the model's inability to generalize its safety\ntraining from the default architectural settings used during training to unseen\nor out-of-distribution scenarios, leaving certain layers exposed. We conduct a\ncomprehensive analysis by projecting activations from various intermediate\nlayers and demonstrate that these layers are more likely to generate harmful\noutputs when exposed to malicious inputs. Our experiments with LLaVA-1.5 and\nLlama 3.2 show discrepancies in attack success rates and toxicity scores across\nlayers, indicating that current safety alignment strategies focused on a single\ndefault layer are insufficient.\n","authors":["Saketh Bachu","Erfan Shayegani","Trishna Chakraborty","Rohit Lal","Arindam Dutta","Chengyu Song","Yue Dong","Nael Abu-Ghazaleh","Amit K. Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2411.04291v1.pdf","comment":"Preprint, Under Review"},{"id":"http://arxiv.org/abs/2401.03115v2","updated":"2024-11-06T22:09:09Z","published":"2024-01-06T03:03:28Z","title":"Transferable Learned Image Compression-Resistant Adversarial\n  Perturbations","summary":"  Adversarial attacks can readily disrupt the image classification system,\nrevealing the vulnerability of DNN-based recognition tasks. While existing\nadversarial perturbations are primarily applied to uncompressed images or\ncompressed images by the traditional image compression method, i.e., JPEG,\nlimited studies have investigated the robustness of models for image\nclassification in the context of DNN-based image compression. With the rapid\nevolution of advanced image compression, DNN-based learned image compression\nhas emerged as the promising approach for transmitting images in many\nsecurity-critical applications, such as cloud-based face recognition and\nautonomous driving, due to its superior performance over traditional\ncompression. Therefore, there is a pressing need to fully investigate the\nrobustness of a classification system post-processed by learned image\ncompression. To bridge this research gap, we explore the adversarial attack on\na new pipeline that targets image classification models that utilize learned\nimage compressors as pre-processing modules. Furthermore, to enhance the\ntransferability of perturbations across various quality levels and\narchitectures of learned image compression models, we introduce a saliency\nscore-based sampling method to enable the fast generation of transferable\nperturbation. Extensive experiments with popular attack methods demonstrate the\nenhanced transferability of our proposed method when attacking images that have\nbeen post-processed with different learned image compression models.\n","authors":["Yang Sui","Zhuohang Li","Ding Ding","Xiang Pan","Xiaozhong Xu","Shan Liu","Zhenzhong Chen"],"pdf_url":"https://arxiv.org/pdf/2401.03115v2.pdf","comment":"Accepted by BMVC 2024"},{"id":"http://arxiv.org/abs/2410.12692v2","updated":"2024-11-06T21:46:48Z","published":"2024-10-16T15:52:32Z","title":"Machine learning approach to brain tumor detection and classification","summary":"  Brain tumor detection and classification are critical tasks in medical image\nanalysis, particularly in early-stage diagnosis, where accurate and timely\ndetection can significantly improve treatment outcomes. In this study, we apply\nvarious statistical and machine learning models to detect and classify brain\ntumors using brain MRI images. We explore a variety of statistical models\nincluding linear, logistic, and Bayesian regressions, and the machine learning\nmodels including decision tree, random forest, single-layer perceptron,\nmulti-layer perceptron, convolutional neural network (CNN), recurrent neural\nnetwork, and long short-term memory. Our findings show that CNN outperforms\nother models, achieving the best performance. Additionally, we confirm that the\nCNN model can also work for multi-class classification, distinguishing between\nfour categories of brain MRI images such as normal, glioma, meningioma, and\npituitary tumor images. This study demonstrates that machine learning\napproaches are suitable for brain tumor detection and classification,\nfacilitating real-world medical applications in assisting radiologists with\nearly and accurate diagnosis.\n","authors":["Alice Oh","Inyoung Noh","Jian Choo","Jihoo Lee","Justin Park","Kate Hwang","Sanghyeon Kim","Soo Min Oh"],"pdf_url":"https://arxiv.org/pdf/2410.12692v2.pdf","comment":"7 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.04269v1","updated":"2024-11-06T21:22:46Z","published":"2024-11-06T21:22:46Z","title":"Increasing the scalability of graph convolution for FPGA-implemented\n  event-based vision","summary":"  Event cameras are becoming increasingly popular as an alternative to\ntraditional frame-based vision sensors, especially in mobile robotics. Taking\nfull advantage of their high temporal resolution, high dynamic range, low power\nconsumption and sparsity of event data, which only reflects changes in the\nobserved scene, requires both an efficient algorithm and a specialised hardware\nplatform. A recent trend involves using Graph Convolutional Neural Networks\n(GCNNs) implemented on a heterogeneous SoC FPGA. In this paper we focus on\noptimising hardware modules for graph convolution to allow flexible selection\nof the FPGA resource (BlockRAM, DSP and LUT) for their implementation. We\npropose a ''two-step convolution'' approach that utilises additional BRAM\nbuffers in order to reduce up to 94% of LUT usage for multiplications. This\nmethod significantly improves the scalability of GCNNs, enabling the deployment\nof models with more layers, larger graphs sizes and their application for more\ndynamic scenarios.\n","authors":["Piotr Wzorek","Kamil Jeziorek","Tomasz Kryjak","Andrea Pinna"],"pdf_url":"https://arxiv.org/pdf/2411.04269v1.pdf","comment":"Accepted for the PhD forum during FPT 2024 (International Conference\n  on Field Programmable Technology), 10-12 December 2024, Sydney, Australia"},{"id":"http://arxiv.org/abs/2411.04263v1","updated":"2024-11-06T21:16:02Z","published":"2024-11-06T21:16:02Z","title":"Object Recognition in Human Computer Interaction:- A Comparative\n  Analysis","summary":"  Human-computer interaction (HCI) has been a widely researched area for many\nyears, with continuous advancements in technology leading to the development of\nnew techniques that change the way we interact with computers. With the recent\nadvent of powerful computers, we recognize human actions and interact\naccordingly, thus revolutionizing the way we interact with computers. The\npurpose of this paper is to provide a comparative analysis of various\nalgorithms used for recognizing user faces and gestures in the context of\ncomputer vision and HCI. This study aims to explore and evaluate the\nperformance of different algorithms in terms of accuracy, robustness, and\nefficiency. This study aims to provide a comprehensive analysis of algorithms\nfor face and gesture recognition in the context of computer vision and HCI,\nwith the goal of improving the design and development of interactive systems\nthat are more intuitive, efficient, and user-friendly.\n","authors":["Kaushik Ranade","Tanmay Khule","Riddhi More"],"pdf_url":"https://arxiv.org/pdf/2411.04263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04255v1","updated":"2024-11-06T20:55:30Z","published":"2024-11-06T20:55:30Z","title":"Pose-Transformation and Radial Distance Clustering for Unsupervised\n  Person Re-identification","summary":"  Person re-identification (re-ID) aims to tackle the problem of matching\nidentities across non-overlapping cameras. Supervised approaches require\nidentity information that may be difficult to obtain and are inherently biased\ntowards the dataset they are trained on, making them unscalable across domains.\nTo overcome these challenges, we propose an unsupervised approach to the person\nre-ID setup. Having zero knowledge of true labels, our proposed method enhances\nthe discriminating ability of the learned features via a novel two-stage\ntraining strategy. The first stage involves training a deep network on an\nexpertly designed pose-transformed dataset obtained by generating multiple\nperturbations for each original image in the pose space. Next, the network\nlearns to map similar features closer in the feature space using the proposed\ndiscriminative clustering algorithm. We introduce a novel radial distance loss,\nthat attends to the fundamental aspects of feature learning - compact clusters\nwith low intra-cluster and high inter-cluster variation. Extensive experiments\non several large-scale re-ID datasets demonstrate the superiority of our method\ncompared to state-of-the-art approaches.\n","authors":["Siddharth Seth","Akash Sonth","Anirban Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2411.04255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04249v1","updated":"2024-11-06T20:42:13Z","published":"2024-11-06T20:42:13Z","title":"PocoLoco: A Point Cloud Diffusion Model of Human Shape in Loose Clothing","summary":"  Modeling a human avatar that can plausibly deform to articulations is an\nactive area of research. We present PocoLoco -- the first template-free,\npoint-based, pose-conditioned generative model for 3D humans in loose clothing.\nWe motivate our work by noting that most methods require a parametric model of\nthe human body to ground pose-dependent deformations. Consequently, they are\nrestricted to modeling clothing that is topologically similar to the naked body\nand do not extend well to loose clothing. The few methods that attempt to model\nloose clothing typically require either canonicalization or a\nUV-parameterization and need to address the challenging problem of explicitly\nestimating correspondences for the deforming clothes. In this work, we\nformulate avatar clothing deformation as a conditional point-cloud generation\ntask within the denoising diffusion framework. Crucially, our framework\noperates directly on unordered point clouds, eliminating the need for a\nparametric model or a clothing template. This also enables a variety of\npractical applications, such as point-cloud completion and pose-based editing\n-- important features for virtual human animation. As current datasets for\nhuman avatars in loose clothing are far too small for training diffusion\nmodels, we release a dataset of two subjects performing various poses in loose\nclothing with a total of 75K point clouds. By contributing towards tackling the\nchallenging task of effectively modeling loose clothing and expanding the\navailable data for training these models, we aim to set the stage for further\ninnovation in digital humans. The source code is available at\nhttps://github.com/sidsunny/pocoloco .\n","authors":["Siddharth Seth","Rishabh Dabral","Diogo Luvizon","Marc Habermann","Ming-Hsuan Yang","Christian Theobalt","Adam Kortylewski"],"pdf_url":"https://arxiv.org/pdf/2411.04249v1.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2410.22233v2","updated":"2024-11-06T19:52:58Z","published":"2024-10-29T17:01:05Z","title":"ContextIQ: A Multimodal Expert-Based Video Retrieval System for\n  Contextual Advertising","summary":"  Contextual advertising serves ads that are aligned to the content that the\nuser is viewing. The rapid growth of video content on social platforms and\nstreaming services, along with privacy concerns, has increased the need for\ncontextual advertising. Placing the right ad in the right context creates a\nseamless and pleasant ad viewing experience, resulting in higher audience\nengagement and, ultimately, better ad monetization. From a technology\nstandpoint, effective contextual advertising requires a video retrieval system\ncapable of understanding complex video content at a very granular level.\nCurrent text-to-video retrieval models based on joint multimodal training\ndemand large datasets and computational resources, limiting their practicality\nand lacking the key functionalities required for ad ecosystem integration. We\nintroduce ContextIQ, a multimodal expert-based video retrieval system designed\nspecifically for contextual advertising. ContextIQ utilizes modality-specific\nexperts-video, audio, transcript (captions), and metadata such as objects,\nactions, emotion, etc.-to create semantically rich video representations. We\nshow that our system, without joint training, achieves better or comparable\nresults to state-of-the-art models and commercial solutions on multiple\ntext-to-video retrieval benchmarks. Our ablation studies highlight the benefits\nof leveraging multiple modalities for enhanced video retrieval accuracy instead\nof using a vision-language model alone. Furthermore, we show how video\nretrieval systems such as ContextIQ can be used for contextual advertising in\nan ad ecosystem while also addressing concerns related to brand safety and\nfiltering inappropriate content.\n","authors":["Ashutosh Chaubey","Anoubhav Agarwaal","Sartaki Sinha Roy","Aayush Agrawal","Susmita Ghose"],"pdf_url":"https://arxiv.org/pdf/2410.22233v2.pdf","comment":"Accepted at WACV 2025"},{"id":"http://arxiv.org/abs/2411.04224v1","updated":"2024-11-06T19:44:36Z","published":"2024-11-06T19:44:36Z","title":"WiFlexFormer: Efficient WiFi-Based Person-Centric Sensing","summary":"  We propose WiFlexFormer, a highly efficient Transformer-based architecture\ndesigned for WiFi Channel State Information (CSI)-based person-centric sensing.\nWe benchmark WiFlexFormer against state-of-the-art vision and specialized\narchitectures for processing radio frequency data and demonstrate that it\nachieves comparable Human Activity Recognition (HAR) performance while offering\na significantly lower parameter count and faster inference times. With an\ninference time of just 10 ms on an Nvidia Jetson Orin Nano, WiFlexFormer is\noptimized for real-time inference. Additionally, its low parameter count\ncontributes to improved cross-domain generalization, where it often outperforms\nlarger models. Our comprehensive evaluation shows that WiFlexFormer is a\npotential solution for efficient, scalable WiFi-based sensing applications. The\nPyTorch implementation of WiFlexFormer is publicly available at:\nhttps://github.com/StrohmayerJ/WiFlexFormer.\n","authors":["Julian Strohmayer","Matthias Wödlinger","Martin Kampel"],"pdf_url":"https://arxiv.org/pdf/2411.04224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02537v2","updated":"2024-11-06T19:27:10Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v2.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.04168v1","updated":"2024-11-06T18:59:17Z","published":"2024-11-06T18:59:17Z","title":"DiMSUM: Diffusion Mamba -- A Scalable and Unified Spatial-Frequency\n  Method for Image Generation","summary":"  We introduce a novel state-space architecture for diffusion models,\neffectively harnessing spatial and frequency information to enhance the\ninductive bias towards local features in input images for image generation\ntasks. While state-space networks, including Mamba, a revolutionary advancement\nin recurrent neural networks, typically scan input sequences from left to\nright, they face difficulties in designing effective scanning strategies,\nespecially in the processing of image data. Our method demonstrates that\nintegrating wavelet transformation into Mamba enhances the local structure\nawareness of visual inputs and better captures long-range relations of\nfrequencies by disentangling them into wavelet subbands, representing both low-\nand high-frequency components. These wavelet-based outputs are then processed\nand seamlessly fused with the original Mamba outputs through a cross-attention\nfusion layer, combining both spatial and frequency information to optimize the\norder awareness of state-space models which is essential for the details and\noverall quality of image generation. Besides, we introduce a globally-shared\ntransformer to supercharge the performance of Mamba, harnessing its exceptional\npower to capture global relationships. Through extensive experiments on\nstandard benchmarks, our method demonstrates superior results compared to DiT\nand DIFFUSSM, achieving faster training convergence and delivering high-quality\noutputs. The codes and pretrained models are released at\nhttps://github.com/VinAIResearch/DiMSUM.git.\n","authors":["Hao Phung","Quan Dao","Trung Dao","Hoang Phan","Dimitris Metaxas","Anh Tran"],"pdf_url":"https://arxiv.org/pdf/2411.04168v1.pdf","comment":"Accepted to NeurIPS 2024. Project page:\n  https://hao-pt.github.io/dimsum/"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.04051v1","updated":"2024-11-06T16:57:55Z","published":"2024-11-06T16:57:55Z","title":"Reproducible Hybrid Time-Travel Retrieval in Evolving Corpora","summary":"  There are settings in which reproducibility of ranked lists is desirable,\nsuch as when extracting a subset of an evolving document corpus for downstream\nresearch tasks or in domains such as patent retrieval or in medical systematic\nreviews, with high reproducibility expectations. However, as global term\nstatistics change when documents change or are added to a corpus, queries using\ntypical ranked retrieval models are not even reproducible for the parts of the\ndocument corpus that have not changed. Thus, Boolean retrieval frequently\nremains the mechanism of choice in such settings.\n  We present a hybrid retrieval system combining Lucene for fast retrieval with\na column-store-based retrieval system maintaining a versioned and time-stamped\nindex. The latter component allows re-execution of previously posed queries\nresulting in the same ranked list and further allows for time-travel queries\nover evolving collection, as web archives, while maintaining the original\nranking. Thus, retrieval results in evolving document collections are fully\nreproducible even when document collections and thus term statistics change.\n","authors":["Moritz Staudinger","Florina Piroi","Andreas Rauber"],"pdf_url":"https://arxiv.org/pdf/2411.04051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03957v1","updated":"2024-11-06T14:42:39Z","published":"2024-11-06T14:42:39Z","title":"Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in\n  Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) has proven to be an effective method for\nmitigating hallucination issues inherent in large language models (LLMs).\nPrevious approaches typically train retrievers based on semantic similarity,\nlacking optimization for RAG. More recent works have proposed aligning\nretrievers with the preference signals of LLMs. However, these preference\nsignals are often difficult for dense retrievers, which typically have weaker\nlanguage capabilities, to understand and learn effectively. Drawing inspiration\nfrom pedagogical theories like Guided Discovery Learning, we propose a novel\nframework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the\nlanguage capabilities of LLMs to construct examples from a more granular,\ninformation-centric perspective to guide the learning of retrievers.\nSpecifically, our method utilizes LLMs to construct easy-to-understand examples\nfrom samples where the retriever performs poorly, focusing on three learning\nobjectives highly relevant to the RAG scenario: relevance, comprehensiveness,\nand purity. These examples serve as scaffolding to ultimately align the\nretriever with the LLM's preferences. Furthermore, we employ a dual curriculum\nlearning strategy and leverage the reciprocal feedback between LLM and\nretriever to further enhance the performance of the RAG system. A series of\nexperiments demonstrate that our proposed framework enhances the performance of\nRAG systems equipped with different retrievers and is applicable to various\nLLMs.\n","authors":["Yuhang Liu","Xueyu Hu","Shengyu Zhang","Jingyuan Chen","Fan Wu","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2411.03957v1.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.03906v1","updated":"2024-11-06T13:37:28Z","published":"2024-11-06T13:37:28Z","title":"Lexicalization Is All You Need: Examining the Impact of Lexical\n  Knowledge in a Compositional QALD System","summary":"  In this paper, we examine the impact of lexicalization on Question Answering\nover Linked Data (QALD). It is well known that one of the key challenges in\ninterpreting natural language questions with respect to SPARQL lies in bridging\nthe lexical gap, that is mapping the words in the query to the correct\nvocabulary elements. We argue in this paper that lexicalization, that is\nexplicit knowledge about the potential interpretations of a word with respect\nto the given vocabulary, significantly eases the task and increases the\nperformance of QA systems. Towards this goal, we present a compositional QA\nsystem that can leverage explicit lexical knowledge in a compositional manner\nto infer the meaning of a question in terms of a SPARQL query. We show that\nsuch a system, given lexical knowledge, has a performance well beyond current\nQA systems, achieving up to a $35.8\\%$ increase in the micro $F_1$ score\ncompared to the best QA system on QALD-9. This shows the importance and\npotential of including explicit lexical knowledge. In contrast, we show that\nLLMs have limited abilities to exploit lexical knowledge, with only marginal\nimprovements compared to a version without lexical knowledge. This shows that\nLLMs have no ability to compositionally interpret a question on the basis of\nthe meaning of its parts, a key feature of compositional approaches. Taken\ntogether, our work shows new avenues for QALD research, emphasizing the\nimportance of lexicalization and compositionality.\n","authors":["David Maria Schmidt","Mohammad Fazleh Elahi","Philipp Cimiano"],"pdf_url":"https://arxiv.org/pdf/2411.03906v1.pdf","comment":"24th International Conference on Knowledge Engineering and Knowledge\n  Management (EKAW 2024), November 26-28, 2024, Amsterdam, The Netherlands"},{"id":"http://arxiv.org/abs/2411.03881v1","updated":"2024-11-06T12:54:27Z","published":"2024-11-06T12:54:27Z","title":"Data Fusion of Synthetic Query Variants With Generative Large Language\n  Models","summary":"  Considering query variance in information retrieval (IR) experiments is\nbeneficial for retrieval effectiveness. Especially ranking ensembles based on\ndifferent topically related queries retrieve better results than rankings based\non a single query alone. Recently, generative instruction-tuned Large Language\nModels (LLMs) improved on a variety of different tasks in capturing human\nlanguage. To this end, this work explores the feasibility of using synthetic\nquery variants generated by instruction-tuned LLMs in data fusion experiments.\nMore specifically, we introduce a lightweight, unsupervised, and cost-efficient\napproach that exploits principled prompting and data fusion techniques. In our\nexperiments, LLMs produce more effective queries when provided with additional\ncontext information on the topic. Furthermore, our analysis based on four TREC\nnewswire benchmarks shows that data fusion based on synthetic query variants is\nsignificantly better than baselines with single queries and also outperforms\npseudo-relevance feedback methods. We publicly share the code and query\ndatasets with the community as resources for follow-up studies.\n","authors":["Timo Breuer"],"pdf_url":"https://arxiv.org/pdf/2411.03881v1.pdf","comment":"The definitive version of record was published in SIGIR-AP '24"},{"id":"http://arxiv.org/abs/2411.02832v2","updated":"2024-11-06T11:19:42Z","published":"2024-11-05T06:11:17Z","title":"PersianRAG: A Retrieval-Augmented Generation System for Persian Language","summary":"  Retrieval augmented generation (RAG) models, which integrate large-scale\npre-trained generative models with external retrieval mechanisms, have shown\nsignificant success in various natural language processing (NLP) tasks.\nHowever, applying RAG models in Persian language as a low-resource language,\nposes distinct challenges. These challenges primarily involve the\npreprocessing, embedding, retrieval, prompt construction, language modeling,\nand response evaluation of the system. In this paper, we address the challenges\ntowards implementing a real-world RAG system for Persian language called\nPersianRAG. We propose novel solutions to overcome these obstacles and evaluate\nour approach using several Persian benchmark datasets. Our experimental results\ndemonstrate the capability of the PersianRAG framework to enhance question\nanswering task in Persian.\n","authors":["Hossein Hosseini","Mohammad Sobhan Zare","Amir Hossein Mohammadi","Arefeh Kazemi","Zahra Zojaji","Mohammad Ali Nematbakhsh"],"pdf_url":"https://arxiv.org/pdf/2411.02832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03039v2","updated":"2024-11-06T09:28:25Z","published":"2024-11-05T12:22:51Z","title":"Self-Compositional Data Augmentation for Scientific Keyphrase Generation","summary":"  State-of-the-art models for keyphrase generation require large amounts of\ntraining data to achieve good performance. However, obtaining keyphrase-labeled\ndocuments can be challenging and costly. To address this issue, we present a\nself-compositional data augmentation method. More specifically, we measure the\nrelatedness of training documents based on their shared keyphrases, and combine\nsimilar documents to generate synthetic samples. The advantage of our method\nlies in its ability to create additional training samples that keep domain\ncoherence, without relying on external data or resources. Our results on\nmultiple datasets spanning three different domains, demonstrate that our method\nconsistently improves keyphrase generation. A qualitative analysis of the\ngenerated keyphrases for the Computer Science domain confirms this improvement\ntowards their representativity property.\n","authors":["Mael Houbre","Florian Boudin","Beatrice Daille","Akiko Aizawa"],"pdf_url":"https://arxiv.org/pdf/2411.03039v2.pdf","comment":"Accepted to JCDL 2024. This is the author's version of the work. It\n  is posted here for your personal use. Not for redistribution. The definitive\n  version was published in the proceedings of the 2024 ACM/IEEE Joint\n  Conference on Digital Libraries (JCDL 24)\n  https://doi.org/10.1145/3677389.3702504"},{"id":"http://arxiv.org/abs/2411.03701v1","updated":"2024-11-06T06:56:22Z","published":"2024-11-06T06:56:22Z","title":"The Essence of the Essence from the Web:The Metasearch Engine","summary":"  The exponential growth of information source on the web and in turn\ncontinuing technological progress of searching the information by using tools\nlike Search Engines gives rise to many problems for the user to know which tool\nis best for their query and which tool is not. At this time Metasearch Engine\ncomes into play by reducing the user burden by dispatching queries to multiple\nsearch engines in parallel and refining the results of these search engines to\ngive the best out of best by doing superior job on their side. These engines do\nnot own a database of Web pages rather they send search terms to the databases\nmaintained by the search engine companies, get back results from all the search\nengines queried and then compile the results to be presented to the user. In\nthis paper, we describe the working of a typical metasearch engine and then\npresent a comparative study of traditional search engines and metasearch\nengines on the basis of different parameters and show how metasearch engines\nare better than the other search engines.\n","authors":["Rajender Nath","Satinder Bal"],"pdf_url":"https://arxiv.org/pdf/2411.03701v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2401.11505v2","updated":"2024-11-06T04:11:14Z","published":"2024-01-21T14:30:20Z","title":"CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray\n  Report Labeling","summary":"  Free-text radiology reports present a rich data source for various medical\ntasks, but effectively labeling these texts remains challenging. Traditional\nrule-based labeling methods fall short of capturing the nuances of diverse\nfree-text patterns. Moreover, models using expert-annotated data are limited by\ndata scarcity and pre-defined classes, impacting their performance, flexibility\nand scalability. To address these issues, our study offers three main\ncontributions: 1) We demonstrate the potential of GPT as an adept labeler using\ncarefully designed prompts. 2) Utilizing only the data labeled by GPT, we\ntrained a BERT-based labeler, CheX-GPT, which operates faster and more\nefficiently than its GPT counterpart. 3) To benchmark labeler performance, we\nintroduced a publicly available expert-annotated test set, MIMIC-500,\ncomprising 500 cases from the MIMIC validation set. Our findings demonstrate\nthat CheX-GPT not only excels in labeling accuracy over existing models, but\nalso showcases superior efficiency, flexibility, and scalability, supported by\nour introduction of the MIMIC-500 dataset for robust benchmarking. Code and\nmodels are available at https://github.com/Soombit-ai/CheXGPT.\n","authors":["Jawook Gu","Kihyun You","Han-Cheol Cho","Jiho Kim","Eun Kyoung Hong","Byungseok Roh"],"pdf_url":"https://arxiv.org/pdf/2401.11505v2.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.03624v1","updated":"2024-11-06T02:45:16Z","published":"2024-11-06T02:45:16Z","title":"SEGMN: A Structure-Enhanced Graph Matching Network for Graph Similarity\n  Learning","summary":"  Graph similarity computation (GSC) aims to quantify the similarity score\nbetween two graphs. Although recent GSC methods based on graph neural networks\n(GNNs) take advantage of intra-graph structures in message passing, few of them\nfully utilize the structures presented by edges to boost the representation of\ntheir connected nodes. Moreover, previous cross-graph node embedding matching\nlacks the perception of the overall structure of the graph pair, due to the\nfact that the node representations from GNNs are confined to the intra-graph\nstructure, causing the unreasonable similarity score. Intuitively, the\ncross-graph structure represented in the assignment graph is helpful to rectify\nthe inappropriate matching. Therefore, we propose a structure-enhanced graph\nmatching network (SEGMN). Equipped with a dual embedding learning module and a\nstructure perception matching module, SEGMN achieves structure enhancement in\nboth embedding learning and cross-graph matching. The dual embedding learning\nmodule incorporates adjacent edge representation into each node to achieve a\nstructure-enhanced representation. The structure perception matching module\nachieves cross-graph structure enhancement through assignment graph\nconvolution. The similarity score of each cross-graph node pair can be\nrectified by aggregating messages from structurally relevant node pairs.\nExperimental results on benchmark datasets demonstrate that SEGMN outperforms\nthe state-of-the-art GSC methods in the GED regression task, and the structure\nperception matching module is plug-and-play, which can further improve the\nperformance of the baselines by up to 25%.\n","authors":["Wenjun Wang","Jiacheng Lu","Kejia Chen","Zheng Liu","Shilong Sang"],"pdf_url":"https://arxiv.org/pdf/2411.03624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02937v2","updated":"2024-11-06T02:36:02Z","published":"2024-08-06T03:44:06Z","title":"A Real-Time Adaptive Multi-Stream GPU System for Online Approximate\n  Nearest Neighborhood Search","summary":"  In recent years, Approximate Nearest Neighbor Search (ANNS) has played a\npivotal role in modern search and recommendation systems, especially in\nemerging LLM applications like Retrieval-Augmented Generation. There is a\ngrowing exploration into harnessing the parallel computing capabilities of GPUs\nto meet the substantial demands of ANNS. However, existing systems primarily\nfocus on offline scenarios, overlooking the distinct requirements of online\napplications that necessitate real-time insertion of new vectors. This\nlimitation renders such systems inefficient for real-world scenarios. Moreover,\nprevious architectures struggled to effectively support real-time insertion due\nto their reliance on serial execution streams. In this paper, we introduce a\nnovel Real-Time Adaptive Multi-Stream GPU ANNS System (RTAMS-GANNS). Our\narchitecture achieves its objectives through three key advancements: 1) We\ninitially examined the real-time insertion mechanisms in existing GPU ANNS\nsystems and discovered their reliance on repetitive copying and memory\nallocation, which significantly hinders real-time effectiveness on GPUs. As a\nsolution, we introduce a dynamic vector insertion algorithm based on memory\nblocks, which includes in-place rearrangement. 2) To enable real-time vector\ninsertion in parallel, we introduce a multi-stream parallel execution mode,\nwhich differs from existing systems that operate serially within a single\nstream. Our system utilizes a dynamic resource pool, allowing multiple streams\nto execute concurrently without additional execution blocking. 3) Through\nextensive experiments and comparisons, our approach effectively handles varying\nQPS levels across different datasets, reducing latency by up to 40%-80%. The\nproposed system has also been deployed in real-world industrial search and\nrecommendation systems, serving hundreds of millions of users daily, and has\nachieved good results.\n","authors":["Yiping Sun","Yang Shi","Jiaolong Du"],"pdf_url":"https://arxiv.org/pdf/2408.02937v2.pdf","comment":"Accepted by CIKM'24, V2 fixes some typos"},{"id":"http://arxiv.org/abs/2408.09380v3","updated":"2024-11-06T02:26:07Z","published":"2024-08-18T06:41:46Z","title":"ELASTIC: Efficient Linear Attention for Sequential Interest Compression","summary":"  State-of-the-art sequential recommendation models heavily rely on\ntransformer's attention mechanism. However, the quadratic computational and\nmemory complexities of self attention have limited its scalability for modeling\nusers' long range behaviour sequences. To address this problem, we propose\nELASTIC, an Efficient Linear Attention for SequenTial Interest Compression,\nrequiring only linear time complexity and decoupling model capacity from\ncomputational cost. Specifically, ELASTIC introduces a fixed length interest\nexperts with linear dispatcher attention mechanism which compresses the\nlong-term behaviour sequences to a significantly more compact representation\nwhich reduces up to 90% GPU memory usage with x2.7 inference speed up. The\nproposed linear dispatcher attention mechanism significantly reduces the\nquadratic complexity and makes the model feasible for adequately modeling\nextremely long sequences. Moreover, in order to retain the capacity for\nmodeling various user interests, ELASTIC initializes a vast learnable interest\nmemory bank and sparsely retrieves compressed user's interests from the memory\nwith a negligible computational overhead. The proposed interest memory\nretrieval technique significantly expands the cardinality of available interest\nspace while keeping the same computational cost, thereby striking a trade-off\nbetween recommendation accuracy and efficiency. To validate the effectiveness\nof our proposed ELASTIC, we conduct extensive experiments on various public\ndatasets and compare it with several strong sequential recommenders.\nExperimental results demonstrate that ELASTIC consistently outperforms\nbaselines by a significant margin and also highlight the computational\nefficiency of ELASTIC when modeling long sequences. We will make our\nimplementation code publicly available.\n","authors":["Jiaxin Deng","Shiyao Wang","Song Lu","Yinfeng Li","Xinchen Luo","Yuanjun Liu","Peixing Xu","Guorui Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.09380v3.pdf","comment":"We hereby withdraw this paper from arXiv due to incomplete\n  experiments. Upon further review, we have determined that additional\n  experimental work is necessary to fully validate our findings and conclusions"},{"id":"http://arxiv.org/abs/2411.03572v1","updated":"2024-11-06T00:23:55Z","published":"2024-11-06T00:23:55Z","title":"Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge\n  Reasoning and Text Generation","summary":"  This study aims to optimize the existing retrieval-augmented generation model\n(RAG) by introducing a graph structure to improve the performance of the model\nin dealing with complex knowledge reasoning tasks. The traditional RAG model\nhas the problem of insufficient processing efficiency when facing complex graph\nstructure information (such as knowledge graphs, hierarchical relationships,\netc.), which affects the quality and consistency of the generated results. This\nstudy proposes a scheme to process graph structure data by combining graph\nneural network (GNN), so that the model can capture the complex relationship\nbetween entities, thereby improving the knowledge consistency and reasoning\nability of the generated text. The experiment used the Natural Questions (NQ)\ndataset and compared it with multiple existing generation models. The results\nshow that the graph-based RAG model proposed in this paper is superior to the\ntraditional generation model in terms of quality, knowledge consistency, and\nreasoning ability, especially when dealing with tasks that require\nmulti-dimensional reasoning. Through the combination of the enhancement of the\nretrieval module and the graph neural network, the model in this study can\nbetter handle complex knowledge background information and has broad potential\nvalue in multiple practical application scenarios.\n","authors":["Yuxin Dong","Shuo Wang","Hongye Zheng","Jiajing Chen","Zhenhong Zhang","Chihang Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03572v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2407.10964v2","updated":"2024-11-06T18:58:03Z","published":"2024-07-15T17:58:42Z","title":"No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen\n  Representations","summary":"  This paper introduces FUNGI, Features from UNsupervised GradIents, a method\nto enhance the features of transformer encoders by leveraging self-supervised\ngradients. Our method is simple: given any pretrained model, we first compute\ngradients from various self-supervised objectives for each input. These\ngradients are projected to a lower dimension and then concatenated with the\nmodel's output embedding. The resulting features are evaluated on k-nearest\nneighbor classification over 11 datasets from vision, 5 from natural language\nprocessing, and 2 from audio. Across backbones spanning various sizes and\npretraining strategies, FUNGI features provide consistent performance\nimprovements over the embeddings. We also show that using FUNGI features can\nbenefit linear classification, clustering and image retrieval, and that they\nsignificantly improve the retrieval-based in-context scene understanding\nabilities of pretrained models, for example improving upon DINO by +17% for\nsemantic segmentation - without any training.\n","authors":["Walter Simoncini","Spyros Gidaris","Andrei Bursuc","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2407.10964v2.pdf","comment":"NeurIPS 2024. Code available at\n  https://github.com/WalterSimoncini/fungivision"},{"id":"http://arxiv.org/abs/2411.04118v1","updated":"2024-11-06T18:51:02Z","published":"2024-11-06T18:51:02Z","title":"Medical Adaptation of Large Language and Vision-Language Models: Are We\n  Making Progress?","summary":"  Several recent works seek to develop foundation models specifically for\nmedical applications, adapting general-purpose large language models (LLMs) and\nvision-language models (VLMs) via continued pretraining on publicly available\nbiomedical corpora. These works typically claim that such domain-adaptive\npretraining (DAPT) improves performance on downstream medical tasks, such as\nanswering medical licensing exam questions. In this paper, we compare seven\npublic \"medical\" LLMs and two VLMs against their corresponding base models,\narriving at a different conclusion: all medical VLMs and nearly all medical\nLLMs fail to consistently improve over their base models in the zero-/few-shot\nprompting regime for medical question-answering (QA) tasks. For instance,\nacross the tasks and model pairs we consider in the 3-shot setting, medical\nLLMs only outperform their base models in 12.1% of cases, reach a (statistical)\ntie in 49.8% of cases, and are significantly worse than their base models in\nthe remaining 38.2% of cases. Our conclusions are based on (i) comparing each\nmedical model head-to-head, directly against the corresponding base model; (ii)\noptimizing the prompts for each model separately; and (iii) accounting for\nstatistical uncertainty in comparisons. While these basic practices are not\nconsistently adopted in the literature, our ablations show that they\nsubstantially impact conclusions. Our findings suggest that state-of-the-art\ngeneral-domain models may already exhibit strong medical knowledge and\nreasoning capabilities, and offer recommendations to strengthen the conclusions\nof future studies.\n","authors":["Daniel P. Jeong","Saurabh Garg","Zachary C. Lipton","Michael Oberst"],"pdf_url":"https://arxiv.org/pdf/2411.04118v1.pdf","comment":"Accepted to EMNLP 2024 Main Conference as Long Paper (Oral)"},{"id":"http://arxiv.org/abs/2411.04109v1","updated":"2024-11-06T18:36:22Z","published":"2024-11-06T18:36:22Z","title":"Self-Consistency Preference Optimization","summary":"  Self-alignment, whereby models learn to improve themselves without human\nannotation, is a rapidly growing research area. However, existing techniques\noften fail to improve complex reasoning tasks due to the difficulty of\nassigning correct rewards. An orthogonal approach that is known to improve\ncorrectness is self-consistency, a method applied at inference time based on\nmultiple sampling in order to find the most consistent answer. In this work, we\nextend the self-consistency concept to help train models. We thus introduce\nself-consistency preference optimization (ScPO), which iteratively trains\nconsistent answers to be preferred over inconsistent ones on unsupervised new\nproblems. We show ScPO leads to large improvements over conventional reward\nmodel training on reasoning tasks such as GSM8K and MATH, closing the gap with\nsupervised training with gold answers or preferences, and that combining ScPO\nwith standard supervised learning improves results even further. On ZebraLogic,\nScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and\nClaude-3 Haiku.\n","authors":["Archiki Prasad","Weizhe Yuan","Richard Yuanzhe Pang","Jing Xu","Maryam Fazel-Zarandi","Mohit Bansal","Sainbayar Sukhbaatar","Jason Weston","Jane Yu"],"pdf_url":"https://arxiv.org/pdf/2411.04109v1.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.04108v1","updated":"2024-11-06T18:36:21Z","published":"2024-11-06T18:36:21Z","title":"Weighted Sobolev Approximation Rates for Neural Networks on Unbounded\n  Domains","summary":"  In this work, we consider the approximation capabilities of shallow neural\nnetworks in weighted Sobolev spaces for functions in the spectral Barron space.\nThe existing literature already covers several cases, in which the spectral\nBarron space can be approximated well, i.e., without curse of dimensionality,\nby shallow networks and several different classes of activation function. The\nlimitations of the existing results are mostly on the error measures that were\nconsidered, in which the results are restricted to Sobolev spaces over a\nbounded domain. We will here treat two cases that extend upon the existing\nresults. Namely, we treat the case with bounded domain and Muckenhoupt weights\nand the case, where the domain is allowed to be unbounded and the weights are\nrequired to decay. We first present embedding results for the more general\nweighted Fourier-Lebesgue spaces in the weighted Sobolev spaces and then we\nestablish asymptotic approximation rates for shallow neural networks that come\nwithout curse of dimensionality.\n","authors":["Ahmed Abdeljawad","Thomas Dittrich"],"pdf_url":"https://arxiv.org/pdf/2411.04108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01312v2","updated":"2024-11-06T18:35:53Z","published":"2024-11-02T17:13:00Z","title":"From Federated Learning to Quantum Federated Learning for\n  Space-Air-Ground Integrated Networks","summary":"  6G wireless networks are expected to provide seamless and data-based\nconnections that cover space-air-ground and underwater networks. As a core\npartition of future 6G networks, Space-Air-Ground Integrated Networks (SAGIN)\nhave been envisioned to provide countless real-time intelligent applications.\nTo realize this, promoting AI techniques into SAGIN is an inevitable trend. Due\nto the distributed and heterogeneous architecture of SAGIN, federated learning\n(FL) and then quantum FL are emerging AI model training techniques for enabling\nfuture privacy-enhanced and computation-efficient SAGINs. In this work, we\nexplore the vision of using FL/QFL in SAGINs. We present a few representative\napplications enabled by the integration of FL and QFL in SAGINs. A case study\nof QFL over UAV networks is also given, showing the merit of quantum-enabled\ntraining approach over the conventional FL benchmark. Research challenges along\nwith standardization for QFL adoption in future SAGINs are also highlighted.\n","authors":["Vu Khanh Quy","Nguyen Minh Quy","Tran Thi Hoai","Shaba Shaon","Md Raihan Uddin","Tien Nguyen","Dinh C. Nguyen","Aryan Kaushik","Periklis Chatzimisios"],"pdf_url":"https://arxiv.org/pdf/2411.01312v2.pdf","comment":"This work has been accepted by IEEE Conference on Standards for\n  Communications and Networking"},{"id":"http://arxiv.org/abs/2411.04106v1","updated":"2024-11-06T18:35:51Z","published":"2024-11-06T18:35:51Z","title":"A Comparative Study of Deep Reinforcement Learning for Crop Production\n  Management","summary":"  Crop production management is essential for optimizing yield and minimizing a\nfield's environmental impact to crop fields, yet it remains challenging due to\nthe complex and stochastic processes involved. Recently, researchers have\nturned to machine learning to address these complexities. Specifically,\nreinforcement learning (RL), a cutting-edge approach designed to learn optimal\ndecision-making strategies through trial and error in dynamic environments, has\nemerged as a promising tool for developing adaptive crop management policies.\nRL models aim to optimize long-term rewards by continuously interacting with\nthe environment, making them well-suited for tackling the uncertainties and\nvariability inherent in crop management. Studies have shown that RL can\ngenerate crop management policies that compete with, and even outperform,\nexpert-designed policies within simulation-based crop models. In the gym-DSSAT\ncrop model environment, one of the most widely used simulators for crop\nmanagement, proximal policy optimization (PPO) and deep Q-networks (DQN) have\nshown promising results. However, these methods have not yet been\nsystematically evaluated under identical conditions. In this study, we\nevaluated PPO and DQN against static baseline policies across three different\nRL tasks, fertilization, irrigation, and mixed management, provided by the\ngym-DSSAT environment. To ensure a fair comparison, we used consistent default\nparameters, identical reward functions, and the same environment settings. Our\nresults indicate that PPO outperforms DQN in fertilization and irrigation\ntasks, while DQN excels in the mixed management task. This comparative analysis\nprovides critical insights into the strengths and limitations of each approach,\nadvancing the development of more effective RL-based crop management\nstrategies.\n","authors":["Joseph Balderas","Dong Chen","Yanbo Huang","Li Wang","Ren-Cang Li"],"pdf_url":"https://arxiv.org/pdf/2411.04106v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.04105v1","updated":"2024-11-06T18:35:32Z","published":"2024-11-06T18:35:32Z","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic\n  Analysis","summary":"  Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve, but we can train a small\ntransformer to achieve perfect accuracy. Building on our set-up, we then pursue\nan understanding of precisely how a three-layer transformer, trained from\nscratch, solves this problem. We are able to identify certain \"planning\" and\n\"reasoning\" circuits in the network that necessitate cooperation between the\nattention blocks to implement the desired logic. To expand our findings, we\nthen study a larger model, Mistral 7B. Using activation patching, we\ncharacterize internal components that are critical in solving our logic\nproblem. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.\n","authors":["Guan Zhe Hong","Nishanth Dikkala","Enming Luo","Cyrus Rashtchian","Rina Panigrahy"],"pdf_url":"https://arxiv.org/pdf/2411.04105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01313v2","updated":"2024-11-06T18:30:25Z","published":"2024-11-02T17:23:08Z","title":"False Data Injection Attack Detection in Edge-based Smart Metering\n  Networks with Federated Learning","summary":"  Smart metering networks are increasingly susceptible to cyber threats, where\nfalse data injection (FDI) appears as a critical attack. Data-driven-based\nmachine learning (ML) methods have shown immense benefits in detecting FDI\nattacks via data learning and prediction abilities. Literature works have\nmostly focused on centralized learning and deploying FDI attack detection\nmodels at the control center, which requires data collection from local\nutilities like meters and transformers. However, this data sharing may raise\nprivacy concerns due to the potential disclosure of household information like\nenergy usage patterns. This paper proposes a new privacy-preserved FDI attack\ndetection by developing an efficient federated learning (FL) framework in the\nsmart meter network with edge computing. Distributed edge servers located at\nthe network edge run an ML-based FDI attack detection model and share the\ntrained model with the grid operator, aiming to build a strong FDI attack\ndetection model without data sharing. Simulation results demonstrate the\nefficiency of our proposed FL method over the conventional method without\ncollaboration.\n","authors":["Md Raihan Uddin","Ratun Rahman","Dinh C. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.01313v2.pdf","comment":"This work has been accepted by IEEE Consumer Communications &\n  Networking Conference (CCNC)"},{"id":"http://arxiv.org/abs/2403.19863v4","updated":"2024-11-06T18:29:38Z","published":"2024-03-28T22:17:19Z","title":"DeNetDM: Debiasing by Network Depth Modulation","summary":"  Neural networks trained on biased datasets tend to inadvertently learn\nspurious correlations, hindering generalization. We formally prove that (1)\nsamples that exhibit spurious correlations lie on a lower rank manifold\nrelative to the ones that do not; and (2) the depth of a network acts as an\nimplicit regularizer on the rank of the attribute subspace that is encoded in\nits representations. Leveraging these insights, we present DeNetDM, a novel\ndebiasing method that uses network depth modulation as a way of developing\nrobustness to spurious correlations. Using a training paradigm derived from\nProduct of Experts, we create both biased and debiased branches with deep and\nshallow architectures and then distill knowledge to produce the target debiased\nmodel. Our method requires no bias annotations or explicit data augmentation\nwhile performing on par with approaches that require either or both. We\ndemonstrate that DeNetDM outperforms existing debiasing techniques on both\nsynthetic and real-world datasets by 5\\%. The project page is available at\nhttps://vssilpa.github.io/denetdm/.\n","authors":["Silpa Vadakkeeveetil Sreelatha","Adarsh Kappiyath","Abhra Chaudhuri","Anjan Dutta"],"pdf_url":"https://arxiv.org/pdf/2403.19863v4.pdf","comment":"Camera-ready version : NeurIPS 2024, * indicates these authors\n  contributed equally"},{"id":"http://arxiv.org/abs/2411.04098v1","updated":"2024-11-06T18:26:19Z","published":"2024-11-06T18:26:19Z","title":"Interpretable and Efficient Data-driven Discovery and Control of\n  Distributed Systems","summary":"  Effectively controlling systems governed by Partial Differential Equations\n(PDEs) is crucial in several fields of Applied Sciences and Engineering. These\nsystems usually yield significant challenges to conventional control schemes\ndue to their nonlinear dynamics, partial observability, high-dimensionality\nonce discretized, distributed nature, and the requirement for low-latency\nfeedback control. Reinforcement Learning (RL), particularly Deep RL (DRL), has\nrecently emerged as a promising control paradigm for such systems,\ndemonstrating exceptional capabilities in managing high-dimensional, nonlinear\ndynamics. However, DRL faces challenges including sample inefficiency,\nrobustness issues, and an overall lack of interpretability. To address these\nissues, we propose a data-efficient, interpretable, and scalable Dyna-style\nModel-Based RL framework for PDE control, combining the Sparse Identification\nof Nonlinear Dynamics with Control (SINDy-C) algorithm and an autoencoder (AE)\nframework for the sake of dimensionality reduction of PDE states and actions.\nThis novel approach enables fast rollouts, reducing the need for extensive\nenvironment interactions, and provides an interpretable latent space\nrepresentation of the PDE forward dynamics. We validate our method on two PDE\nproblems describing fluid flows - namely, the 1D Burgers equation and 2D\nNavier-Stokes equations - comparing it against a model-free baseline, and\ncarrying out an extensive analysis of the learned dynamics.\n","authors":["Florian Wolf","Nicolò Botteghi","Urban Fasel","Andrea Manzoni"],"pdf_url":"https://arxiv.org/pdf/2411.04098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01632v4","updated":"2024-11-06T18:04:35Z","published":"2024-03-03T22:38:35Z","title":"SynCode: LLM Generation with Grammar Augmentation","summary":"  LLMs are widely used in complex AI applications. These applications\nunderscore the need for LLM outputs to adhere to a specific format, for their\nintegration with other components in the systems. Typically the format rules\ne.g., for data serialization formats such as JSON, YAML, or Code in Programming\nLanguage are expressed as context-free grammar (CFG). Due to the hallucinations\nand unreliability of LLMs, instructing LLMs to adhere to specified syntax\nbecomes an increasingly important challenge.\n  We present SynCode, a novel framework for efficient and general syntactical\ndecoding with LLMs, to address this challenge. SynCode ensures soundness and\ncompleteness with respect to the CFG of a formal language, effectively\nretaining valid tokens while filtering out invalid ones. SynCode uses an\noffline-constructed, efficient lookup table, the DFA mask store, derived from\nthe DFA of the language's grammar for efficient generation. SynCode seamlessly\nintegrates with any language defined by CFG, as evidenced by experiments\nfocusing on generating JSON, Python, and Go outputs. Our experiments evaluating\nthe effectiveness of SynCode for JSON generation demonstrate that SynCode\neliminates all syntax errors and significantly outperforms state-of-the-art\nbaselines. Furthermore, our results underscore how SynCode significantly\nreduces 96.07% of syntax errors in generated Python and Go code, showcasing its\nsubstantial impact on enhancing syntactical precision in LLM generation. Our\ncode is available at https://github.com/uiuc-focal-lab/syncode\n","authors":["Shubham Ugare","Tarun Suresh","Hangoo Kang","Sasa Misailovic","Gagandeep Singh"],"pdf_url":"https://arxiv.org/pdf/2403.01632v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17027v2","updated":"2024-11-06T17:20:42Z","published":"2024-09-25T15:30:24Z","title":"Counterfactual Token Generation in Large Language Models","summary":"  \"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm\nof her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]\nLyra's eyes welled up with tears as she realized the bitter truth - she had\nsacrificed everything for fleeting riches, and lost the love of her crew, her\nfamily, and herself.\" Although this story, generated by a large language model,\nis captivating, one may wonder -- how would the story have unfolded if the\nmodel had chosen \"Captain Maeve\" as the protagonist instead? We cannot know.\nState-of-the-art large language models are stateless -- they maintain no\ninternal memory or state. Given a prompt, they generate a sequence of tokens as\nan output using an autoregressive process. As a consequence, they cannot reason\nabout counterfactual alternatives to tokens they have generated in the past. In\nthis work, our goal is to enhance them with this functionality. To this end, we\ndevelop a causal model of token generation that builds upon the Gumbel-Max\nstructural causal model. Our model allows any large language model to perform\ncounterfactual token generation at almost no cost in comparison with vanilla\ntoken generation, it is embarrassingly simple to implement, and it does not\nrequire any fine-tuning nor prompt engineering. We implement our model on Llama\n3 8B-Instruct and Ministral-8B-Instruct and conduct a qualitative and a\nquantitative analysis of counterfactually generated text. We conclude with a\ndemonstrative application of counterfactual token generation for bias\ndetection, unveiling interesting insights about the model of the world\nconstructed by large language models.\n","authors":["Ivi Chatzi","Nina Corvelo Benz","Eleni Straitouri","Stratis Tsirtsis","Manuel Gomez-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2409.17027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03523v3","updated":"2024-11-06T17:19:39Z","published":"2024-10-04T15:44:23Z","title":"A Probabilistic Perspective on Unlearning and Alignment for Large\n  Language Models","summary":"  Comprehensive evaluation of Large Language Models (LLMs) is an open research\nproblem. Existing evaluations rely on deterministic point estimates generated\nvia greedy decoding. However, we find that deterministic evaluations fail to\ncapture the whole output distribution of a model, yielding inaccurate\nestimations of model capabilities. This is particularly problematic in critical\ncontexts such as unlearning and alignment, where precise model evaluations are\ncrucial. To remedy this, we introduce the first formal probabilistic evaluation\nframework in LLMs. Namely, we derive novel metrics with high-probability\nguarantees concerning the output distribution of a model. Our metrics are\napplication-independent and allow practitioners to make more reliable estimates\nabout model capabilities before deployment. Through a case study focused on\nunlearning, we reveal that deterministic evaluations falsely indicate\nsuccessful unlearning, whereas our probabilistic evaluations demonstrate that\nmost if not all of the supposedly unlearned information remains accessible in\nthese models. Additionally, we propose a novel unlearning loss based on entropy\noptimization and adaptive temperature scaling, which significantly improves\nunlearning in probabilistic settings on recent benchmarks. Our proposed shift\nfrom point estimates to probabilistic evaluations of output distributions\nrepresents an important step toward comprehensive evaluations of LLMs. Code\navailable at https://github.com/yascho/probabilistic-unlearning.\n","authors":["Yan Scholten","Stephan Günnemann","Leo Schwinn"],"pdf_url":"https://arxiv.org/pdf/2410.03523v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03171v2","updated":"2024-11-06T17:19:10Z","published":"2024-11-05T15:19:29Z","title":"Navigating Extremes: Dynamic Sparsity in Large Output Space","summary":"  In recent years, Dynamic Sparse Training (DST) has emerged as an alternative\nto post-training pruning for generating efficient models. In principle, DST\nallows for a more memory efficient training process, as it maintains sparsity\nthroughout the entire training run. However, current DST implementations fail\nto capitalize on this in practice. Because sparse matrix multiplication is much\nless efficient than dense matrix multiplication on GPUs, most implementations\nsimulate sparsity by masking weights. In this paper, we leverage recent\nadvances in semi-structured sparse training to apply DST in the domain of\nclassification with large output spaces, where memory-efficiency is paramount.\nWith a label space of possibly millions of candidates, the classification layer\nalone will consume several gigabytes of memory. Switching from a dense to a\nfixed fan-in sparse layer updated with sparse evolutionary training (SET);\nhowever, severely hampers training convergence, especially at the largest label\nspaces. We find that poor gradient flow from the sparse classifier to the dense\ntext encoder make it difficult to learn good input representations. By\nemploying an intermediate layer or adding an auxiliary training objective, we\nrecover most of the generalisation performance of the dense model. Overall, we\ndemonstrate the applicability and practical benefits of DST in a challenging\ndomain -- characterized by a highly skewed label distribution that differs\nsubstantially from typical DST benchmark datasets -- which enables end-to-end\ntraining with millions of labels on commodity hardware.\n","authors":["Nasib Ullah","Erik Schultheis","Mike Lasby","Yani Ioannou","Rohit Babbar"],"pdf_url":"https://arxiv.org/pdf/2411.03171v2.pdf","comment":"20 pages, 7 figures, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.12057v2","updated":"2024-11-06T17:13:51Z","published":"2024-09-18T15:31:29Z","title":"Cartan moving frames and the data manifolds","summary":"  The purpose of this paper is to employ the language of Cartan moving frames\nto study the geometry of the data manifolds and its Riemannian structure, via\nthe data information metric and its curvature at data points. Using this\nframework and through experiments, explanations on the response of a neural\nnetwork are given by pointing out the output classes that are easily reachable\nfrom a given input. This emphasizes how the proposed mathematical relationship\nbetween the output of the network and the geometry of its inputs can be\nexploited as an explainable artificial intelligence tool.\n","authors":["Eliot Tron","Rita Fioresi","Nicolas Couellan","Stéphane Puechmorel"],"pdf_url":"https://arxiv.org/pdf/2409.12057v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23247v2","updated":"2024-11-06T17:07:53Z","published":"2024-10-30T17:30:35Z","title":"bit2bit: 1-bit quanta video reconstruction via self-supervised photon\n  prediction","summary":"  Quanta image sensors, such as SPAD arrays, are an emerging sensor technology,\nproducing 1-bit arrays representing photon detection events over exposures as\nshort as a few nanoseconds. In practice, raw data are post-processed using\nheavy spatiotemporal binning to create more useful and interpretable images at\nthe cost of degrading spatiotemporal resolution. In this work, we propose\nbit2bit, a new method for reconstructing high-quality image stacks at the\noriginal spatiotemporal resolution from sparse binary quanta image data.\nInspired by recent work on Poisson denoising, we developed an algorithm that\ncreates a dense image sequence from sparse binary photon data by predicting the\nphoton arrival location probability distribution. However, due to the binary\nnature of the data, we show that the assumption of a Poisson distribution is\ninadequate. Instead, we model the process with a Bernoulli lattice process from\nthe truncated Poisson. This leads to the proposal of a novel self-supervised\nsolution based on a masked loss function. We evaluate our method using both\nsimulated and real data. On simulated data from a conventional video, we\nachieve 34.35 mean PSNR with extremely photon-sparse binary input (<0.06\nphotons per pixel per frame). We also present a novel dataset containing a wide\nrange of real SPAD high-speed videos under various challenging imaging\nconditions. The scenes cover strong/weak ambient light, strong motion,\nultra-fast events, etc., which will be made available to the community, on\nwhich we demonstrate the promise of our approach. Both reconstruction quality\nand throughput substantially surpass the state-of-the-art methods (e.g., Quanta\nBurst Photography (QBP)). Our approach significantly enhances the visualization\nand usability of the data, enabling the application of existing analysis\ntechniques.\n","authors":["Yehe Liu","Alexander Krull","Hector Basevi","Ales Leonardis","Michael W. Jenkins"],"pdf_url":"https://arxiv.org/pdf/2410.23247v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04056v1","updated":"2024-11-06T17:05:58Z","published":"2024-11-06T17:05:58Z","title":"Problem Space Transformations for Generalisation in Behavioural Cloning","summary":"  The combination of behavioural cloning and neural networks has driven\nsignificant progress in robotic manipulation. As these algorithms may require a\nlarge number of demonstrations for each task of interest, they remain\nfundamentally inefficient in complex scenarios. This issue is aggravated when\nthe system is treated as a black-box, ignoring its physical properties. This\nwork characterises widespread properties of robotic manipulation, such as pose\nequivariance and locality. We empirically demonstrate that transformations\narising from each of these properties allow neural policies trained with\nbehavioural cloning to better generalise to out-of-distribution problem\ninstances.\n","authors":["Kiran Doshi","Marco Bagatella","Stelian Coros"],"pdf_url":"https://arxiv.org/pdf/2411.04056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04055v1","updated":"2024-11-06T16:59:51Z","published":"2024-11-06T16:59:51Z","title":"Multi-branch Spatio-Temporal Graph Neural Network For Efficient Ice\n  Layer Thickness Prediction","summary":"  Understanding spatio-temporal patterns in polar ice layers is essential for\ntracking changes in ice sheet balance and assessing ice dynamics. While\nconvolutional neural networks are widely used in learning ice layer patterns\nfrom raw echogram images captured by airborne snow radar sensors, noise in the\nechogram images prevents researchers from getting high-quality results.\nInstead, we focus on geometric deep learning using graph neural networks,\naiming to build a spatio-temporal graph neural network that learns from\nthickness information of the top ice layers and predicts for deeper layers. In\nthis paper, we developed a novel multi-branch spatio-temporal graph neural\nnetwork that used the GraphSAGE framework for spatio features learning and a\ntemporal convolution operation to capture temporal changes, enabling different\nbranches of the network to be more specialized and focusing on a single\nlearning task. We found that our proposed multi-branch network can consistently\noutperform the current fused spatio-temporal graph neural network in both\naccuracy and efficiency.\n","authors":["Zesheng Liu","Maryam Rahnemoonfar"],"pdf_url":"https://arxiv.org/pdf/2411.04055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04054v1","updated":"2024-11-06T16:59:11Z","published":"2024-11-06T16:59:11Z","title":"Partial Structure Discovery is Sufficient for No-regret Learning in\n  Causal Bandits","summary":"  Causal knowledge about the relationships among decision variables and a\nreward variable in a bandit setting can accelerate the learning of an optimal\ndecision. Current works often assume the causal graph is known, which may not\nalways be available a priori. Motivated by this challenge, we focus on the\ncausal bandit problem in scenarios where the underlying causal graph is unknown\nand may include latent confounders. While intervention on the parents of the\nreward node is optimal in the absence of latent confounders, this is not\nnecessarily the case in general. Instead, one must consider a set of possibly\noptimal arms/interventions, each being a special subset of the ancestors of the\nreward node, making causal discovery beyond the parents of the reward node\nessential. For regret minimization, we identify that discovering the full\ncausal structure is unnecessary; however, no existing work provides the\nnecessary and sufficient components of the causal graph. We formally\ncharacterize the set of necessary and sufficient latent confounders one needs\nto detect or learn to ensure that all possibly optimal arms are identified\ncorrectly. We also propose a randomized algorithm for learning the causal graph\nwith a limited number of samples, providing a sample complexity guarantee for\nany desired confidence level. In the causal bandit setup, we propose a\ntwo-stage approach. In the first stage, we learn the induced subgraph on\nancestors of the reward, along with a necessary and sufficient subset of latent\nconfounders, to construct the set of possibly optimal arms. The regret incurred\nduring this phase scales polynomially with respect to the number of nodes in\nthe causal graph. The second phase involves the application of a standard\nbandit algorithm, such as the UCB algorithm. We also establish a regret bound\nfor our two-phase approach, which is sublinear in the number of rounds.\n","authors":["Muhammad Qasim Elahi","Mahsa Ghasemi","Murat Kocaoglu"],"pdf_url":"https://arxiv.org/pdf/2411.04054v1.pdf","comment":"To appear in Proceedings of NeurIPS 24"},{"id":"http://arxiv.org/abs/2405.16749v2","updated":"2024-11-06T16:55:39Z","published":"2024-05-27T01:38:30Z","title":"DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion\n  Models","summary":"  Pretrained diffusion models (DMs) have recently been popularly used in\nsolving inverse problems (IPs). The existing methods mostly interleave\niterative steps in the reverse diffusion process and iterative steps to bring\nthe iterates closer to satisfying the measurement constraint. However, such\ninterleaving methods struggle to produce final results that look like natural\nobjects of interest (i.e., manifold feasibility) and fit the measurement (i.e.,\nmeasurement feasibility), especially for nonlinear IPs. Moreover, their\ncapabilities to deal with noisy IPs with unknown types and levels of\nmeasurement noise are unknown. In this paper, we advocate viewing the reverse\nprocess in DMs as a function and propose a novel plug-in method for solving IPs\nusing pretrained DMs, dubbed DMPlug. DMPlug addresses the issues of manifold\nfeasibility and measurement feasibility in a principled manner, and also shows\ngreat potential for being robust to unknown types and levels of noise. Through\nextensive experiments across various IP tasks, including two linear and three\nnonlinear IPs, we demonstrate that DMPlug consistently outperforms\nstate-of-the-art methods, often by large margins especially for nonlinear IPs.\nThe code is available at https://github.com/sun-umn/DMPlug.\n","authors":["Hengkang Wang","Xu Zhang","Taihui Li","Yuxiang Wan","Tiancong Chen","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2405.16749v2.pdf","comment":"Published in NeurIPS 2024\n  (https://openreview.net/forum?id=81IFFsfQUj)"},{"id":"http://arxiv.org/abs/2411.01929v2","updated":"2024-11-06T16:50:44Z","published":"2024-11-04T09:51:10Z","title":"Exploring the Landscape for Generative Sequence Models for Specialized\n  Data Synthesis","summary":"  Artificial Intelligence (AI) research often aims to develop models that can\ngeneralize reliably across complex datasets, yet this remains challenging in\nfields where data is scarce, intricate, or inaccessible. This paper introduces\na novel approach that leverages three generative models of varying complexity\nto synthesize one of the most demanding structured datasets: Malicious Network\nTraffic. Our approach uniquely transforms numerical data into text, re-framing\ndata generation as a language modeling task, which not only enhances data\nregularization but also significantly improves generalization and the quality\nof the synthetic data. Extensive statistical analyses demonstrate that our\nmethod surpasses state-of-the-art generative models in producing high-fidelity\nsynthetic data. Additionally, we conduct a comprehensive study on synthetic\ndata applications, effectiveness, and evaluation strategies, offering valuable\ninsights into its role across various domains. Our code and pre-trained models\nare openly accessible at Github, enabling further exploration and application\nof our methodology. Index Terms: Data synthesis, machine learning, traffic\ngeneration, privacy preserving data, generative models.\n","authors":["Mohammad Zbeeb","Mohammad Ghorayeb","Mariam Salman"],"pdf_url":"https://arxiv.org/pdf/2411.01929v2.pdf","comment":"25 pages, 7 figures, 3 tables, 1 algorithm. code @\n  https://github.com/Moe-Zbeeb/Exploring-the-landscape-for-generative-models-for-specialized-data-generation.git"},{"id":"http://arxiv.org/abs/2402.02989v3","updated":"2024-11-06T16:33:29Z","published":"2024-02-05T13:27:41Z","title":"DexDiffuser: Generating Dexterous Grasps with Diffusion Models","summary":"  We introduce DexDiffuser, a novel dexterous grasping method that generates,\nevaluates, and refines grasps on partial object point clouds. DexDiffuser\nincludes the conditional diffusion-based grasp sampler DexSampler and the\ndexterous grasp evaluator DexEvaluator. DexSampler generates high-quality\ngrasps conditioned on object point clouds by iterative denoising of randomly\nsampled grasps. We also introduce two grasp refinement strategies:\nEvaluator-Guided Diffusion (EGD) and Evaluator-based Sampling Refinement (ESR).\nThe experiment results demonstrate that DexDiffuser consistently outperforms\nthe state-of-the-art multi-finger grasp generation method FFHNet with an, on\naverage, 9.12% and 19.44% higher grasp success rate in simulation and real\nrobot experiments, respectively. Supplementary materials are available at\nhttps://yulihn.github.io/DexDiffuser_page/\n","authors":["Zehang Weng","Haofei Lu","Danica Kragic","Jens Lundell"],"pdf_url":"https://arxiv.org/pdf/2402.02989v3.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2411.04036v1","updated":"2024-11-06T16:33:21Z","published":"2024-11-06T16:33:21Z","title":"Stepping Forward on the Last Mile","summary":"  Continuously adapting pre-trained models to local data on resource\nconstrained edge devices is the $\\emph{last mile}$ for model deployment.\nHowever, as models increase in size and depth, backpropagation requires a large\namount of memory, which becomes prohibitive for edge devices. In addition, most\nexisting low power neural processing engines (e.g., NPUs, DSPs, MCUs, etc.) are\ndesigned as fixed-point inference accelerators, without training capabilities.\nForward gradients, solely based on directional derivatives computed from two\nforward calls, have been recently used for model training, with substantial\nsavings in computation and memory. However, the performance of quantized\ntraining with fixed-point forward gradients remains unclear. In this paper, we\ninvestigate the feasibility of on-device training using fixed-point forward\ngradients, by conducting comprehensive experiments across a variety of deep\nlearning benchmark tasks in both vision and audio domains. We propose a series\nof algorithm enhancements that further reduce the memory footprint, and the\naccuracy gap compared to backpropagation. An empirical study on how training\nwith forward gradients navigates in the loss landscape is further explored. Our\nresults demonstrate that on the last mile of model customization on edge\ndevices, training with fixed-point forward gradients is a feasible and\npractical approach.\n","authors":["Chen Feng","Shaojie Zhuo","Xiaopeng Zhang","Ramchalam Kinattinkara Ramakrishnan","Zhaocong Yuan","Andrew Zou Li"],"pdf_url":"https://arxiv.org/pdf/2411.04036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04034v1","updated":"2024-11-06T16:32:40Z","published":"2024-11-06T16:32:40Z","title":"Non-Stationary Learning of Neural Networks with Automatic Soft Parameter\n  Reset","summary":"  Neural networks are traditionally trained under the assumption that data come\nfrom a stationary distribution. However, settings which violate this assumption\nare becoming more popular; examples include supervised learning under\ndistributional shifts, reinforcement learning, continual learning and\nnon-stationary contextual bandits. In this work we introduce a novel learning\napproach that automatically models and adapts to non-stationarity, via an\nOrnstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift\ntends to draw the parameters towards the initialisation distribution, so the\napproach can be understood as a form of soft parameter reset. We show\nempirically that our approach performs well in non-stationary supervised and\noff-policy reinforcement learning settings.\n","authors":["Alexandre Galashov","Michalis K. Titsias","András György","Clare Lyle","Razvan Pascanu","Yee Whye Teh","Maneesh Sahani"],"pdf_url":"https://arxiv.org/pdf/2411.04034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14916v2","updated":"2024-11-06T16:11:18Z","published":"2024-07-20T16:05:17Z","title":"Improving Context-Aware Preference Modeling for Language Models","summary":"  While finetuning language models from pairwise preferences has proven\nremarkably effective, the underspecified nature of natural language presents\ncritical challenges. Direct preference feedback is uninterpretable, difficult\nto provide where multidimensional criteria may apply, and often inconsistent,\neither because it is based on incomplete instructions or provided by diverse\nprincipals. To address these challenges, we consider the two-step preference\nmodeling procedure that first resolves the under-specification by selecting a\ncontext, and then evaluates preference with respect to the chosen context. We\ndecompose reward modeling error according to these two steps, which suggests\nthat supervising context in addition to context-specific preference may be a\nviable approach to aligning models with diverse human preferences. For this to\nwork, the ability of models to evaluate context-specific preference is\ncritical. To this end, we contribute context-conditioned preference datasets\nand accompanying experiments that investigate the ability of language models to\nevaluate context-specific preference. We use our datasets to (1) show that\nexisting preference models benefit from, but fail to fully consider, added\ncontext, (2) finetune a context-aware reward model with context-specific\nperformance exceeding that of GPT-4 and Llama 3 70B on tested datasets, and (3)\ninvestigate the value of context-aware preference modeling.\n","authors":["Silviu Pitis","Ziang Xiao","Nicolas Le Roux","Alessandro Sordoni"],"pdf_url":"https://arxiv.org/pdf/2407.14916v2.pdf","comment":"NeurIPS 2024. 10 pages (29 with references and appendix)"},{"id":"http://arxiv.org/abs/2410.10875v2","updated":"2024-11-06T15:57:40Z","published":"2024-10-09T03:29:47Z","title":"SHyPar: A Spectral Coarsening Approach to Hypergraph Partitioning","summary":"  State-of-the-art hypergraph partitioners utilize a multilevel paradigm to\nconstruct progressively coarser hypergraphs across multiple layers, guiding cut\nrefinements at each level of the hierarchy. Traditionally, these partitioners\nemploy heuristic methods for coarsening and do not consider the structural\nfeatures of hypergraphs. In this work, we introduce a multilevel spectral\nframework, SHyPar, for partitioning large-scale hypergraphs by leveraging\nhyperedge effective resistances and flow-based community detection techniques.\nInspired by the latest theoretical spectral clustering frameworks, such as\nHyperEF and HyperSF, SHyPar aims to decompose large hypergraphs into multiple\nsubgraphs with few inter-partition hyperedges (cut size). A key component of\nSHyPar is a flow-based local clustering scheme for hypergraph coarsening, which\nincorporates a max-flow-based algorithm to produce clusters with substantially\nimproved conductance. Additionally, SHyPar utilizes an effective\nresistance-based rating function for merging nodes that are strongly connected\n(coupled). Compared with existing state-of-the-art hypergraph partitioning\nmethods, our extensive experimental results on real-world VLSI designs\ndemonstrate that SHyPar can more effectively partition hypergraphs, achieving\nstate-of-the-art solution quality.\n","authors":["Hamed Sajadinia","Ali Aghdaei","Zhuo Feng"],"pdf_url":"https://arxiv.org/pdf/2410.10875v2.pdf","comment":"14 pages, 11 figures, 4 tables"},{"id":"http://arxiv.org/abs/2411.04016v1","updated":"2024-11-06T15:57:20Z","published":"2024-11-06T15:57:20Z","title":"Multi-Scale and Multimodal Species Distribution Modeling","summary":"  Species distribution models (SDMs) aim to predict the distribution of species\nby relating occurrence data with environmental variables. Recent applications\nof deep learning to SDMs have enabled new avenues, specifically the inclusion\nof spatial data (environmental rasters, satellite images) as model predictors,\nallowing the model to consider the spatial context around each species'\nobservations. However, the appropriate spatial extent of the images is not\nstraightforward to determine and may affect the performance of the model, as\nscale is recognized as an important factor in SDMs. We develop a modular\nstructure for SDMs that allows us to test the effect of scale in both single-\nand multi-scale settings. Furthermore, our model enables different scales to be\nconsidered for different modalities, using a late fusion approach. Results on\nthe GeoLifeCLEF 2023 benchmark indicate that considering multimodal data and\nlearning multi-scale representations leads to more accurate models.\n","authors":["Nina van Tiel","Robin Zbinden","Emanuele Dalsasso","Benjamin Kellenberger","Loïc Pellissier","Devis Tuia"],"pdf_url":"https://arxiv.org/pdf/2411.04016v1.pdf","comment":"Published at the CV4Ecology workshop at ECCV 2024\n  (https://cv4e.netlify.app/papers/06.pdf)"},{"id":"http://arxiv.org/abs/2411.04013v1","updated":"2024-11-06T15:50:19Z","published":"2024-11-06T15:50:19Z","title":"$k$NN Attention Demystified: A Theoretical Exploration for Scalable\n  Transformers","summary":"  Despite their power, Transformers face challenges with long sequences due to\nthe quadratic complexity of self-attention. To address this limitation, methods\nlike $k$-Nearest-Neighbor ($k$NN) attention have been introduced [Roy, Saffar,\nVaswani, Grangier, 2021] enabling each token to attend to only its $k$ closest\ntokens. While $k$NN attention has shown empirical success in making\nTransformers more efficient, its exact approximation guarantees have not been\ntheoretically analyzed. In this work, we establish a theoretical framework for\n$k$NN attention, reformulating self-attention as expectations over softmax\ndistributions and leveraging lazy Gumbel sampling [Mussmann, Levy, Ermon, 2017]\nwith $k$NN indices for efficient approximation. Building on this framework, we\nalso propose novel sub-quadratic algorithms that approximate self-attention\ngradients by leveraging efficient sampling techniques, such as Markov\nChain-based estimation. Finally, we demonstrate the practical effectiveness of\nthese algorithms through empirical experiments, showcasing their benefits in\nboth training and inference.\n","authors":["Themistoklis Haris"],"pdf_url":"https://arxiv.org/pdf/2411.04013v1.pdf","comment":"30 pages, 12 figures"},{"id":"http://arxiv.org/abs/2411.04011v1","updated":"2024-11-06T15:49:28Z","published":"2024-11-06T15:49:28Z","title":"Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo\n  Tree Search","summary":"  The growing reliance on renewable energy sources, particularly solar and\nwind, has introduced challenges due to their uncontrollable production. This\ncomplicates maintaining the electrical grid balance, prompting some\ntransmission system operators in Western Europe to implement imbalance tariffs\nthat penalize unsustainable power deviations. These tariffs create an implicit\ndemand response framework to mitigate grid instability. Yet, several challenges\nlimit active participation. In Belgium, for example, imbalance prices are only\ncalculated at the end of each 15-minute settlement period, creating high risk\ndue to price uncertainty. This risk is further amplified by the inherent\nvolatility of imbalance prices, discouraging participation. Although\ntransmission system operators provide minute-based price predictions, the\nsystem imbalance volatility makes accurate price predictions challenging to\nobtain and requires sophisticated techniques. Moreover, publishing price\nestimates can prompt participants to adjust their schedules, potentially\naffecting the system balance and the final price, adding further complexity. To\naddress these challenges, we propose a Monte Carlo Tree Search method that\npublishes accurate imbalance prices while accounting for potential response\nactions. Our approach models the system dynamics using a neural network\nforecaster and a cluster of virtual batteries controlled by reinforcement\nlearning agents. Compared to Belgium's current publication method, our\ntechnique improves price accuracy by 20.4% under ideal conditions and by 12.8%\nin more realistic scenarios. This research addresses an unexplored, yet crucial\nproblem, positioning this paper as a pioneering work in analyzing the potential\nof more advanced imbalance price publishing techniques.\n","authors":["Fabio Pavirani","Jonas Van Gompel","Seyed Soroush Karimi Madahi","Bert Claessens","Chris Develder"],"pdf_url":"https://arxiv.org/pdf/2411.04011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12904v3","updated":"2024-11-06T15:39:05Z","published":"2023-11-21T11:54:21Z","title":"Learning to Compute Gröbner Bases","summary":"  Solving a polynomial system, or computing an associated Gr\\\"obner basis, has\nbeen a fundamental task in computational algebra. However, it is also known for\nits notorious doubly exponential time complexity in the number of variables in\nthe worst case. This paper is the first to address the learning of Gr\\\"obner\nbasis computation with Transformers. The training requires many pairs of a\npolynomial system and the associated Gr\\\"obner basis, raising two novel\nalgebraic problems: random generation of Gr\\\"obner bases and transforming them\ninto non-Gr\\\"obner ones, termed as backward Gr\\\"obner problem. We resolve these\nproblems with 0-dimensional radical ideals, the ideals appearing in various\napplications. Further, we propose a hybrid input embedding to handle\ncoefficient tokens with continuity bias and avoid the growth of the vocabulary\nset. The experiments show that our dataset generation method is a few orders of\nmagnitude faster than a naive approach, overcoming a crucial challenge in\nlearning to compute Gr\\\"obner bases, and Gr\\\"obner computation is learnable in\na particular class.\n","authors":["Hiroshi Kera","Yuki Ishihara","Yuta Kambe","Tristan Vaccon","Kazuhiro Yokoyama"],"pdf_url":"https://arxiv.org/pdf/2311.12904v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02059v2","updated":"2024-11-06T15:38:37Z","published":"2024-11-04T13:03:13Z","title":"TableGPT2: A Large Multimodal Model with Tabular Data Integration","summary":"  The emergence of models like GPTs, Claude, LLaMA, and Qwen has reshaped AI\napplications, presenting vast new opportunities across industries. Yet, the\nintegration of tabular data remains notably underdeveloped, despite its\nfoundational role in numerous real-world domains.\n  This gap is critical for three main reasons. First, database or data\nwarehouse data integration is essential for advanced applications; second, the\nvast and largely untapped resource of tabular data offers immense potential for\nanalysis; and third, the business intelligence domain specifically demands\nadaptable, precise solutions that many current LLMs may struggle to provide.\n  In response, we introduce TableGPT2, a model rigorously pre-trained and\nfine-tuned with over 593.8K tables and 2.36M high-quality query-table-output\ntuples, a scale of table-related data unprecedented in prior research. This\nextensive training enables TableGPT2 to excel in table-centric tasks while\nmaintaining strong general language and coding abilities.\n  One of TableGPT2's key innovations is its novel table encoder, specifically\ndesigned to capture schema-level and cell-level information. This encoder\nstrengthens the model's ability to handle ambiguous queries, missing column\nnames, and irregular tables commonly encountered in real-world applications.\nSimilar to visual language models, this pioneering approach integrates with the\ndecoder to form a robust large multimodal model.\n  We believe the results are compelling: over 23 benchmarking metrics,\nTableGPT2 achieves an average performance improvement of 35.20% in the 7B model\nand 49.32% in the 72B model over prior benchmark-neutral LLMs, with robust\ngeneral-purpose capabilities intact.\n","authors":["Aofeng Su","Aowen Wang","Chao Ye","Chen Zhou","Ga Zhang","Guangcheng Zhu","Haobo Wang","Haokai Xu","Hao Chen","Haoze Li","Haoxuan Lan","Jiaming Tian","Jing Yuan","Junbo Zhao","Junlin Zhou","Kaizhe Shou","Liangyu Zha","Lin Long","Liyao Li","Pengzuo Wu","Qi Zhang","Qingyi Huang","Saisai Yang","Tao Zhang","Wentao Ye","Wufang Zhu","Xiaomeng Hu","Xijun Gu","Xinjie Sun","Xiang Li","Yuhang Yang","Zhiqing Xiao"],"pdf_url":"https://arxiv.org/pdf/2411.02059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03996v1","updated":"2024-11-06T15:38:31Z","published":"2024-11-06T15:38:31Z","title":"Towards Resource-Efficient Federated Learning in Industrial IoT for\n  Multivariate Time Series Analysis","summary":"  Anomaly and missing data constitute a thorny problem in industrial\napplications. In recent years, deep learning enabled anomaly detection has\nemerged as a critical direction, however the improved detection accuracy is\nachieved with the utilization of large neural networks, increasing their\nstorage and computational cost. Moreover, the data collected in edge devices\ncontain user privacy, introducing challenges that can be successfully addressed\nby the privacy-preserving distributed paradigm, known as federated learning\n(FL). This framework allows edge devices to train and exchange models\nincreasing also the communication cost. Thus, to deal with the increased\ncommunication, processing and storage challenges of the FL based deep anomaly\ndetection NN pruning is expected to have significant benefits towards reducing\nthe processing, storage and communication complexity. With this focus, a novel\ncompression-based optimization problem is proposed at the server-side of a FL\nparadigm that fusses the received local models broadcast and performs pruning\ngenerating a more compressed model. Experiments in the context of anomaly\ndetection and missing value imputation demonstrate that the proposed FL\nscenario along with the proposed compressed-based method are able to achieve\nhigh compression rates (more than $99.7\\%$) with negligible performance losses\n(less than $1.18\\%$ ) as compared to the centralized solutions.\n","authors":["Alexandros Gkillas","Aris Lalos"],"pdf_url":"https://arxiv.org/pdf/2411.03996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03990v1","updated":"2024-11-06T15:30:42Z","published":"2024-11-06T15:30:42Z","title":"ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy","summary":"  Imitation learning, e.g., diffusion policy, has been proven effective in\nvarious robotic manipulation tasks. However, extensive demonstrations are\nrequired for policy robustness and generalization. To reduce the demonstration\nreliance, we leverage spatial symmetry and propose ET-SEED, an efficient\ntrajectory-level SE(3) equivariant diffusion model for generating action\nsequences in complex robot manipulation tasks. Further, previous equivariant\ndiffusion models require the per-step equivariance in the Markov process,\nmaking it difficult to learn policy under such strong constraints. We\ntheoretically extend equivariant Markov kernels and simplify the condition of\nequivariant diffusion process, thereby significantly improving training\nefficiency for trajectory-level SE(3) equivariant diffusion policy in an\nend-to-end manner. We evaluate ET-SEED on representative robotic manipulation\ntasks, involving rigid body, articulated and deformable object. Experiments\ndemonstrate superior data efficiency and manipulation proficiency of our\nproposed method, as well as its ability to generalize to unseen configurations\nwith only a few demonstrations. Website: https://et-seed.github.io/\n","authors":["Chenrui Tie","Yue Chen","Ruihai Wu","Boxuan Dong","Zeyi Li","Chongkai Gao","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2411.03990v1.pdf","comment":"Accept to CoRL 2024 Workshop on X-Embodiment Robot Learning"},{"id":"http://arxiv.org/abs/2411.03978v1","updated":"2024-11-06T15:14:27Z","published":"2024-11-06T15:14:27Z","title":"Customized Multiple Clustering via Multi-Modal Subspace Proxy Learning","summary":"  Multiple clustering aims to discover various latent structures of data from\ndifferent aspects. Deep multiple clustering methods have achieved remarkable\nperformance by exploiting complex patterns and relationships in data. However,\nexisting works struggle to flexibly adapt to diverse user-specific needs in\ndata grouping, which may require manual understanding of each clustering. To\naddress these limitations, we introduce Multi-Sub, a novel end-to-end multiple\nclustering approach that incorporates a multi-modal subspace proxy learning\nframework in this work. Utilizing the synergistic capabilities of CLIP and\nGPT-4, Multi-Sub aligns textual prompts expressing user preferences with their\ncorresponding visual representations. This is achieved by automatically\ngenerating proxy words from large language models that act as subspace bases,\nthus allowing for the customized representation of data in terms specific to\nthe user's interests. Our method consistently outperforms existing baselines\nacross a broad set of datasets in visual multiple clustering tasks. Our code is\navailable at https://github.com/Alexander-Yao/Multi-Sub.\n","authors":["Jiawei Yao","Qi Qian","Juhua Hu"],"pdf_url":"https://arxiv.org/pdf/2411.03978v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2310.09657v4","updated":"2024-11-06T15:07:18Z","published":"2023-10-14T20:08:54Z","title":"Topology-guided Hypergraph Transformer Network: Unveiling Structural\n  Insights for Improved Representation","summary":"  Hypergraphs, with their capacity to depict high-order relationships, have\nemerged as a significant extension of traditional graphs. Although Graph Neural\nNetworks (GNNs) have remarkable performance in graph representation learning,\ntheir extension to hypergraphs encounters challenges due to their intricate\nstructures. Furthermore, current hypergraph transformers, a special variant of\nGNN, utilize semantic feature-based self-attention, ignoring topological\nattributes of nodes and hyperedges. To address these challenges, we propose a\nTopology-guided Hypergraph Transformer Network (THTN). In this model, we first\nformulate a hypergraph from a graph while retaining its structural essence to\nlearn higher-order relations within the graph. Then, we design a simple yet\neffective structural and spatial encoding module to incorporate the topological\nand spatial information of the nodes into their representation. Further, we\npresent a structure-aware self-attention mechanism that discovers the important\nnodes and hyperedges from both semantic and structural viewpoints. By\nleveraging these two modules, THTN crafts an improved node representation,\ncapturing both local and global topological expressions. Extensive experiments\nconducted on node classification tasks demonstrate that the performance of the\nproposed model consistently exceeds that of the existing approaches.\n","authors":["Khaled Mohammed Saifuddin","Mehmet Emin Aktas","Esra Akbas"],"pdf_url":"https://arxiv.org/pdf/2310.09657v4.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.13767v2","updated":"2024-11-06T15:02:37Z","published":"2024-08-25T08:24:48Z","title":"Lecture Notes on Linear Neural Networks: A Tale of Optimization and\n  Generalization in Deep Learning","summary":"  These notes are based on a lecture delivered by NC on March 2021, as part of\nan advanced course in Princeton University on the mathematical understanding of\ndeep learning. They present a theory (developed by NC, NR and collaborators) of\nlinear neural networks -- a fundamental model in the study of optimization and\ngeneralization in deep learning. Practical applications born from the presented\ntheory are also discussed. The theory is based on mathematical tools that are\ndynamical in nature. It showcases the potential of such tools to push the\nenvelope of our understanding of optimization and generalization in deep\nlearning. The text assumes familiarity with the basics of statistical learning\ntheory. Exercises (without solutions) are included.\n","authors":["Nadav Cohen","Noam Razin"],"pdf_url":"https://arxiv.org/pdf/2408.13767v2.pdf","comment":"Lecture notes"},{"id":"http://arxiv.org/abs/2411.03965v1","updated":"2024-11-06T15:00:14Z","published":"2024-11-06T15:00:14Z","title":"Bayesian algorithmic perfumery: A Hierarchical Relevance Vector Machine\n  for the Estimation of Personalized Fragrance Preferences based on Three\n  Sensory Layers and Jungian Personality Archetypes","summary":"  This study explores a Bayesian algorithmic approach to personalized fragrance\nrecommendation by integrating hierarchical Relevance Vector Machines (RVM) and\nJungian personality archetypes. The paper proposes a structured model that\nlinks individual scent preferences for top, middle, and base notes to\npersonality traits derived from Jungian archetypes, such as the Hero,\nCaregiver, and Explorer, among others. The algorithm utilizes Bayesian updating\nto dynamically refine predictions as users interact with each fragrance note.\nThis iterative process allows for the personalization of fragrance experiences\nbased on prior data and personality assessments, leading to adaptive and\ninterpretable recommendations. By combining psychological theory with Bayesian\nmachine learning, this approach addresses the complexity of modeling individual\npreferences while capturing user-specific and population-level trends. The\nstudy highlights the potential of hierarchical Bayesian frameworks in creating\ncustomized olfactory experiences, informed by psychological and demographic\nfactors, contributing to advancements in personalized product design and\nmachine learning applications in sensory-based industries.\n","authors":["Rolando Gonzales Martinez"],"pdf_url":"https://arxiv.org/pdf/2411.03965v1.pdf","comment":"15 pages, 0 figures"},{"id":"http://arxiv.org/abs/2411.01521v2","updated":"2024-11-06T14:52:28Z","published":"2024-11-03T10:47:39Z","title":"Diversity Progress for Goal Selection in Discriminability-Motivated RL","summary":"  Non-uniform goal selection has the potential to improve the reinforcement\nlearning (RL) of skills over uniform-random selection. In this paper, we\nintroduce a method for learning a goal-selection policy in\nintrinsically-motivated goal-conditioned RL: \"Diversity Progress\" (DP). The\nlearner forms a curriculum based on observed improvement in discriminability\nover its set of goals. Our proposed method is applicable to the class of\ndiscriminability-motivated agents, where the intrinsic reward is computed as a\nfunction of the agent's certainty of following the true goal being pursued.\nThis reward can motivate the agent to learn a set of diverse skills without\nextrinsic rewards. We demonstrate empirically that a DP-motivated agent can\nlearn a set of distinguishable skills faster than previous approaches, and do\nso without suffering from a collapse of the goal distribution -- a known issue\nwith some prior approaches. We end with plans to take this proof-of-concept\nforward.\n","authors":["Erik M. Lintunen","Nadia M. Ady","Christian Guckelsberger"],"pdf_url":"https://arxiv.org/pdf/2411.01521v2.pdf","comment":"11 pages including appendices, full-track paper at the Intrinsically\n  Motivated Open-ended Learning workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.02101v2","updated":"2024-11-06T14:50:24Z","published":"2024-05-03T13:54:59Z","title":"Discrete Aware Matrix Completion via Convexized $\\ell_0$-Norm\n  Approximation","summary":"  We consider a novel algorithm, for the completion of partially observed\nlow-rank matrices in a structured setting where each entry can be chosen from a\nfinite discrete alphabet set, such as in common recommender systems. The\nproposed low-rank matrix completion (MC) method is an improved variation of\nstate-of-the-art (SotA) discrete aware matrix completion method which we\npreviously proposed, in which discreteness is enforced by an $\\ell_0$-norm\nregularizer, not by replaced with the $\\ell_1$-norm, but instead approximated\nby a continuous and differentiable function normalized via fractional\nprogramming (FP) under a proximal gradient (PG) framework. Simulation results\ndemonstrate the superior performance of the new method compared to the SotA\ntechniques as well as the earlier $\\ell_1$-norm-based discrete-aware matrix\ncompletion approach.\n","authors":["Niclas Führling","Kengo Ando","Giuseppe Thadeu Freitas de Abreu","David González G.","Osvaldo Gonsa"],"pdf_url":"https://arxiv.org/pdf/2405.02101v2.pdf","comment":"Accepted at the IEEE 2024 Asilomar Conference on Signals, Systems,\n  and Computers"},{"id":"http://arxiv.org/abs/2409.16118v3","updated":"2024-11-06T14:34:16Z","published":"2024-09-24T14:25:59Z","title":"TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific\n  Energy-Based Models","summary":"  Data collection is often difficult in critical fields such as medicine,\nphysics, and chemistry. As a result, classification methods usually perform\npoorly with these small datasets, leading to weak predictive performance.\nIncreasing the training set with additional synthetic data, similar to data\naugmentation in images, is commonly believed to improve downstream\nclassification performance. However, current tabular generative methods that\nlearn either the joint distribution $ p(\\mathbf{x}, y) $ or the\nclass-conditional distribution $ p(\\mathbf{x} \\mid y) $ often overfit on small\ndatasets, resulting in poor-quality synthetic data, usually worsening\nclassification performance compared to using real data alone. To solve these\nchallenges, we introduce TabEBM, a novel class-conditional generative method\nusing Energy-Based Models (EBMs). Unlike existing methods that use a shared\nmodel to approximate all class-conditional densities, our key innovation is to\ncreate distinct EBM generative models for each class, each modelling its\nclass-specific data distribution individually. This approach creates robust\nenergy landscapes, even in ambiguous class distributions. Our experiments show\nthat TabEBM generates synthetic data with higher quality and better statistical\nfidelity than existing methods. When used for data augmentation, our synthetic\ndata consistently improves the classification performance across diverse\ndatasets of various sizes, especially small ones. Code is available at\nhttps://github.com/andreimargeloiu/TabEBM.\n","authors":["Andrei Margeloiu","Xiangjian Jiang","Nikola Simidjievski","Mateja Jamnik"],"pdf_url":"https://arxiv.org/pdf/2409.16118v3.pdf","comment":"Accepted by the Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2404.07724v2","updated":"2024-11-06T14:29:36Z","published":"2024-04-11T13:16:47Z","title":"Applying Guidance in a Limited Interval Improves Sample and Distribution\n  Quality in Diffusion Models","summary":"  Guidance is a crucial technique for extracting the best performance out of\nimage-generating diffusion models. Traditionally, a constant guidance weight\nhas been applied throughout the sampling chain of an image. We show that\nguidance is clearly harmful toward the beginning of the chain (high noise\nlevels), largely unnecessary toward the end (low noise levels), and only\nbeneficial in the middle. We thus restrict it to a specific range of noise\nlevels, improving both the inference speed and result quality. This limited\nguidance interval improves the record FID in ImageNet-512 significantly, from\n1.81 to 1.40. We show that it is quantitatively and qualitatively beneficial\nacross different sampler parameters, network architectures, and datasets,\nincluding the large-scale setting of Stable Diffusion XL. We thus suggest\nexposing the guidance interval as a hyperparameter in all diffusion models that\nuse guidance.\n","authors":["Tuomas Kynkäänniemi","Miika Aittala","Tero Karras","Samuli Laine","Timo Aila","Jaakko Lehtinen"],"pdf_url":"https://arxiv.org/pdf/2404.07724v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.14156v3","updated":"2024-11-06T14:29:05Z","published":"2024-03-21T06:10:51Z","title":"Policy Mirror Descent with Lookahead","summary":"  Policy Mirror Descent (PMD) stands as a versatile algorithmic framework\nencompassing several seminal policy gradient algorithms such as natural policy\ngradient, with connections with state-of-the-art reinforcement learning (RL)\nalgorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration\nalgorithm implementing regularized 1-step greedy policy improvement. However,\n1-step greedy policies might not be the best choice and recent remarkable\nempirical successes in RL such as AlphaGo and AlphaZero have demonstrated that\ngreedy approaches with respect to multiple steps outperform their 1-step\ncounterpart. In this work, we propose a new class of PMD algorithms called\n$h$-PMD which incorporates multi-step greedy policy improvement with lookahead\ndepth $h$ to the PMD update rule. To solve discounted infinite horizon Markov\nDecision Processes with discount factor $\\gamma$, we show that $h$-PMD which\ngeneralizes the standard PMD enjoys a faster dimension-free $\\gamma^h$-linear\nconvergence rate, contingent on the computation of multi-step greedy policies.\nWe propose an inexact version of $h$-PMD where lookahead action values are\nestimated. Under a generative model, we establish a sample complexity for\n$h$-PMD which improves over prior work. Finally, we extend our result to linear\nfunction approximation to scale to large state spaces. Under suitable\nassumptions, our sample complexity only involves dependence on the dimension of\nthe feature map space instead of the state space size.\n","authors":["Kimon Protopapas","Anas Barakat"],"pdf_url":"https://arxiv.org/pdf/2403.14156v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03945v1","updated":"2024-11-06T14:25:05Z","published":"2024-11-06T14:25:05Z","title":"Can Custom Models Learn In-Context? An Exploration of Hybrid\n  Architecture Performance on In-Context Learning Tasks","summary":"  In-Context Learning (ICL) is a phenomenon where task learning occurs through\na prompt sequence without the necessity of parameter updates. ICL in\nMulti-Headed Attention (MHA) with absolute positional embedding has been the\nfocus of more study than other sequence model varieties. We examine\nimplications of architectural differences between GPT-2 and LLaMa as well as\nLlaMa and Mamba. We extend work done by Garg et al. (2022) and Park et al.\n(2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the\ninterplay between sequence transformation blocks and regressive performance\nin-context. We note that certain architectural changes cause degraded training\nefficiency/ICL accuracy by converging to suboptimal predictors or converging\nslower. We also find certain hybrids showing optimistic performance\nimprovements, informing potential future ICL-focused architecture\nmodifications. Additionally, we propose the \"ICL regression score\", a scalar\nmetric describing a model's whole performance on a specific task. Compute\nlimitations impose restrictions on our architecture-space, training duration,\nnumber of training runs, function class complexity, and benchmark complexity.\nTo foster reproducible and extensible research, we provide a typed, modular,\nand extensible Python package on which we run all experiments.\n","authors":["Ryan Campbell","Nelson Lojo","Kesava Viswanadha","Christoffer Grondal Tryggestad","Derrick Han Sun","Sriteja Vijapurapu","August Rolfsen","Anant Sahai"],"pdf_url":"https://arxiv.org/pdf/2411.03945v1.pdf","comment":"18 pages, 16 figures"},{"id":"http://arxiv.org/abs/2311.12686v5","updated":"2024-11-06T14:24:33Z","published":"2023-11-21T15:47:06Z","title":"Continuous Management of Machine Learning-Based Application Behavior","summary":"  Modern applications are increasingly driven by Machine Learning (ML) models\nwhose non-deterministic behavior is affecting the entire application life cycle\nfrom design to operation. The pervasive adoption of ML is urgently calling for\napproaches that guarantee a stable non-functional behavior of ML-based\napplications over time and across model changes. To this aim, non-functional\nproperties of ML models, such as privacy, confidentiality, fairness, and\nexplainability, must be monitored, verified, and maintained. Existing\napproaches mostly focus on i) implementing solutions for classifier selection\naccording to the functional behavior of ML models, ii) finding new algorithmic\nsolutions, such as continuous re-training. In this paper, we propose a\nmulti-model approach that aims to guarantee a stable non-functional behavior of\nML-based applications. An architectural and methodological approach is provided\nto compare multiple ML models showing similar non-functional properties and\nselect the model supporting stable non-functional behavior over time according\nto (dynamic and unpredictable) contextual changes. Our approach goes beyond the\nstate of the art by providing a solution that continuously guarantees a stable\nnon-functional behavior of ML-based applications, is ML algorithm-agnostic, and\nis driven by non-functional properties assessed on the ML models themselves. It\nconsists of a two-step process working during application operation, where\nmodel assessment verifies non-functional properties of ML models trained and\nselected at development time, and model substitution guarantees continuous and\nstable support of non-functional properties. We experimentally evaluate our\nsolution in a real-world scenario focusing on non-functional property fairness.\n","authors":["Marco Anisetti","Claudio A. Ardagna","Nicola Bena","Ernesto Damiani","Paolo G. Panero"],"pdf_url":"https://arxiv.org/pdf/2311.12686v5.pdf","comment":"Accepted for publication in IEEE Transactions on Services Computing;\n  DOI: 10.1109/TSC.2024.3486226"},{"id":"http://arxiv.org/abs/2411.03941v1","updated":"2024-11-06T14:18:23Z","published":"2024-11-06T14:18:23Z","title":"Fine-tuning -- a Transfer Learning approach","summary":"  Secondary research use of Electronic Health Records (EHRs) is often hampered\nby the abundance of missing data in this valuable resource. Missingness in EHRs\noccurs naturally as a result of the data recording practices during routine\nclinical care, but handling it is crucial to the precision of medical analysis\nand the decision-making that follows. The literature contains a variety of\nimputation methodologies based on deep neural networks. Those aim to overcome\nthe dynamic, heterogeneous and multivariate missingness patterns of EHRs, which\ncannot be handled by classical and statistical imputation methods. However, all\nexisting deep imputation methods rely on end-to-end pipelines that incorporate\nboth imputation and downstream analyses, e.g. classification. This coupling\nmakes it difficult to assess the quality of imputation and takes away the\nflexibility of re-using the imputer for a different task. Furthermore, most\nend-to-end deep architectures tend to use complex networks to perform the\ndownstream task, in addition to the already sophisticated deep imputation\nnetwork. We, therefore ask if the high performance reported in the literature\nis due to the imputer or the classifier and further ask if an optimised\nstate-of-the-art imputer is used, a simpler classifier can achieve comparable\nperformance. This paper explores the development of a modular, deep\nlearning-based imputation and classification pipeline, specifically built to\nleverage the capabilities of state-of-the-art imputation models for downstream\nclassification tasks. Such a modular approach enables a) objective assessment\nof the quality of the imputer and classifier independently, and b) enables the\nexploration of the performance of simpler classification architectures using an\noptimised imputer.\n","authors":["Joseph Arul Raj","Linglong Qian","Zina Ibrahim"],"pdf_url":"https://arxiv.org/pdf/2411.03941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02964v2","updated":"2024-11-06T14:18:15Z","published":"2024-11-05T10:06:40Z","title":"Speaker Emotion Recognition: Leveraging Self-Supervised Models for\n  Feature Extraction Using Wav2Vec2 and HuBERT","summary":"  Speech is the most natural way of expressing ourselves as humans. Identifying\nemotion from speech is a nontrivial task due to the ambiguous definition of\nemotion itself. Speaker Emotion Recognition (SER) is essential for\nunderstanding human emotional behavior. The SER task is challenging due to the\nvariety of speakers, background noise, complexity of emotions, and speaking\nstyles. It has many applications in education, healthcare, customer service,\nand Human-Computer Interaction (HCI). Previously, conventional machine learning\nmethods such as SVM, HMM, and KNN have been used for the SER task. In recent\nyears, deep learning methods have become popular, with convolutional neural\nnetworks and recurrent neural networks being used for SER tasks. The input of\nthese methods is mostly spectrograms and hand-crafted features. In this work,\nwe study the use of self-supervised transformer-based models, Wav2Vec2 and\nHuBERT, to determine the emotion of speakers from their voice. The models\nautomatically extract features from raw audio signals, which are then used for\nthe classification task. The proposed solution is evaluated on reputable\ndatasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show\nthe effectiveness of the proposed method on different datasets. Moreover, the\nmodel has been used for real-world applications like call center conversations,\nand the results demonstrate that the model accurately predicts emotions.\n","authors":["Pourya Jafarzadeh","Amir Mohammad Rostami","Padideh Choobdar"],"pdf_url":"https://arxiv.org/pdf/2411.02964v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03936v1","updated":"2024-11-06T14:11:46Z","published":"2024-11-06T14:11:46Z","title":"GUIDE-VAE: Advancing Data Generation with User Information and Pattern\n  Dictionaries","summary":"  Generative modelling of multi-user datasets has become prominent in science\nand engineering. Generating a data point for a given user requires employing\nuser information, and conventional generative models, including variational\nautoencoders (VAEs), often ignore that. This paper introduces GUIDE-VAE, a\nnovel conditional generative model that leverages user embeddings to generate\nuser-guided data. By allowing the model to benefit from shared patterns across\nusers, GUIDE-VAE enhances performance in multi-user settings, even under\nsignificant data imbalance. In addition to integrating user information,\nGUIDE-VAE incorporates a pattern dictionary-based covariance composition (PDCC)\nto improve the realism of generated samples by capturing complex feature\ndependencies. While user embeddings drive performance gains, PDCC addresses\ncommon issues such as noise and over-smoothing typically seen in VAEs.\n  The proposed GUIDE-VAE was evaluated on a multi-user smart meter dataset\ncharacterized by substantial data imbalance across users. Quantitative results\nshow that GUIDE-VAE performs effectively in both synthetic data generation and\nmissing record imputation tasks, while qualitative evaluations reveal that\nGUIDE-VAE produces more plausible and less noisy data. These results establish\nGUIDE-VAE as a promising tool for controlled, realistic data generation in\nmulti-user datasets, with potential applications across various domains\nrequiring user-informed modelling.\n","authors":["Kutay Bölat","Simon Tindemans"],"pdf_url":"https://arxiv.org/pdf/2411.03936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03934v1","updated":"2024-11-06T14:11:39Z","published":"2024-11-06T14:11:39Z","title":"Interactions Across Blocks in Post-Training Quantization of Large\n  Language Models","summary":"  Post-training quantization is widely employed to reduce the computational\ndemands of neural networks. Typically, individual substructures, such as layers\nor blocks of layers, are quantized with the objective of minimizing\nquantization errors in their pre-activations by fine-tuning the corresponding\nweights. Deriving this local objective from the global objective of minimizing\ntask loss involves two key simplifications: assuming substructures are mutually\nindependent and ignoring the knowledge of subsequent substructures as well as\nthe task loss. In this work, we assess the effects of these simplifications on\nweight-only quantization of large language models. We introduce two multi-block\nfine-tuning strategies and compare them against the baseline of fine-tuning\nsingle transformer blocks. The first captures correlations of weights across\nblocks by jointly optimizing multiple quantized blocks. The second incorporates\nknowledge of subsequent blocks by minimizing the error in downstream\npre-activations rather than focusing solely on the quantized block. Our\nfindings indicate that the effectiveness of these methods depends on the\nspecific network model, with no impact on some models but demonstrating\nsignificant benefits for others.\n","authors":["Khasmamad Shabanovi","Lukas Wiest","Vladimir Golkov","Daniel Cremers","Thomas Pfeil"],"pdf_url":"https://arxiv.org/pdf/2411.03934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03845v2","updated":"2024-11-06T14:11:05Z","published":"2024-06-06T08:23:22Z","title":"Open Problem: Active Representation Learning","summary":"  In this work, we introduce the concept of Active Representation Learning, a\nnovel class of problems that intertwines exploration and representation\nlearning within partially observable environments. We extend ideas from Active\nSimultaneous Localization and Mapping (active SLAM), and translate them to\nscientific discovery problems, exemplified by adaptive microscopy. We explore\nthe need for a framework that derives exploration skills from representations\nthat are in some sense actionable, aiming to enhance the efficiency and\neffectiveness of data collection and model building in the natural sciences.\n","authors":["Nikola Milosevic","Gesine Müller","Jan Huisken","Nico Scherf"],"pdf_url":"https://arxiv.org/pdf/2406.03845v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05014v2","updated":"2024-11-06T14:09:38Z","published":"2024-06-07T15:24:38Z","title":"Root Cause Analysis of Outliers with Missing Structural Knowledge","summary":"  Recent work conceptualized root cause analysis (RCA) of anomalies via\nquantitative contribution analysis using causal counterfactuals in structural\ncausal models (SCMs).The framework comes with three practical challenges: (1)\nit requires the causal directed acyclic graph (DAG), together with an SCM, (2)\nit is statistically ill-posed since it probes regression models in regions of\nlow probability density, (3) it relies on Shapley values which are\ncomputationally expensive to find.\n  In this paper, we propose simplified, efficient methods of root cause\nanalysis when the task is to identify a unique root cause instead of\nquantitative contribution analysis. Our proposed methods run in linear order of\nSCM nodes and they require only the causal DAG without counterfactuals.\nFurthermore, for those use cases where the causal DAG is unknown, we justify\nthe heuristic of identifying root causes as the variables with the highest\nanomaly score. To this end, we prove that anomalies with small scores are\nunlikely to cause those with large scores and show upper bounds for the\nlikelihood of causal pathways with non-monotonic anomaly scores.\n","authors":["Nastaran Okati","Sergio Hernan Garrido Mejia","William Roy Orchard","Patrick Blöbaum","Dominik Janzing"],"pdf_url":"https://arxiv.org/pdf/2406.05014v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03932v1","updated":"2024-11-06T14:09:11Z","published":"2024-11-06T14:09:11Z","title":"Improved Regret of Linear Ensemble Sampling","summary":"  In this work, we close the fundamental gap of theory and practice by\nproviding an improved regret bound for linear ensemble sampling. We prove that\nwith an ensemble size logarithmic in $T$, linear ensemble sampling can achieve\na frequentist regret bound of $\\tilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$, matching\nstate-of-the-art results for randomized linear bandit algorithms, where $d$ and\n$T$ are the dimension of the parameter and the time horizon respectively. Our\napproach introduces a general regret analysis framework for linear bandit\nalgorithms. Additionally, we reveal a significant relationship between linear\nensemble sampling and Linear Perturbed-History Exploration (LinPHE), showing\nthat LinPHE is a special case of linear ensemble sampling when the ensemble\nsize equals $T$. This insight allows us to derive a new regret bound of\n$\\tilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$ for LinPHE, independent of the number of\narms. Our contributions advance the theoretical foundation of ensemble\nsampling, bringing its regret bounds in line with the best known bounds for\nother randomized exploration algorithms.\n","authors":["Harin Lee","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2411.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03925v1","updated":"2024-11-06T13:57:50Z","published":"2024-11-06T13:57:50Z","title":"Quantum Algorithm for Sparse Online Learning with Truncated Gradient\n  Descent","summary":"  Logistic regression, the Support Vector Machine (SVM), and least squares are\nwell-studied methods in the statistical and computer science community, with\nvarious practical applications. High-dimensional data arriving on a real-time\nbasis makes the design of online learning algorithms that produce sparse\nsolutions essential. The seminal work of\n\\hyperlink{cite.langford2009sparse}{Langford, Li, and Zhang (2009)} developed a\nmethod to obtain sparsity via truncated gradient descent, showing a\nnear-optimal online regret bound. Based on this method, we develop a quantum\nsparse online learning algorithm for logistic regression, the SVM, and least\nsquares. Given efficient quantum access to the inputs, we show that a quadratic\nspeedup in the time complexity with respect to the dimension of the problem is\nachievable, while maintaining a regret of $O(1/\\sqrt{T})$, where $T$ is the\nnumber of iterations.\n","authors":["Debbie Lim","Yixian Qiu","Patrick Rebentrost","Qisheng Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03925v1.pdf","comment":"31 pages, 1 table, 4 algorithms"},{"id":"http://arxiv.org/abs/2411.03919v1","updated":"2024-11-06T13:51:06Z","published":"2024-11-06T13:51:06Z","title":"A Causal Framework for Precision Rehabilitation","summary":"  Precision rehabilitation offers the promise of an evidence-based approach for\noptimizing individual rehabilitation to improve long-term functional outcomes.\nEmerging techniques, including those driven by artificial intelligence, are\nrapidly expanding our ability to quantify the different domains of function\nduring rehabilitation, other encounters with healthcare, and in the community.\nWhile this seems poised to usher rehabilitation into the era of big data and\nshould be a powerful driver of precision rehabilitation, our field lacks a\ncoherent framework to utilize these data and deliver on this promise. We\npropose a framework that builds upon multiple existing pillars to fill this\ngap. Our framework aims to identify the Optimal Dynamic Treatment Regimens\n(ODTR), or the decision-making strategy that takes in the range of available\nmeasurements and biomarkers to identify interventions likely to maximize\nlong-term function. This is achieved by designing and fitting causal models,\nwhich extend the Computational Neurorehabilitation framework using tools from\ncausal inference. These causal models can learn from heterogeneous data from\ndifferent silos, which must include detailed documentation of interventions,\nsuch as using the Rehabilitation Treatment Specification System. The models\nthen serve as digital twins of patient recovery trajectories, which can be used\nto learn the ODTR. Our causal modeling framework also emphasizes quantitatively\nlinking changes across levels of the functioning to ensure that interventions\ncan be precisely selected based on careful measurement of impairments while\nalso being selected to maximize outcomes that are meaningful to patients and\nstakeholders. We believe this approach can provide a unifying framework to\nleverage growing big rehabilitation data and AI-powered measurements to produce\nprecision rehabilitation treatments that can improve clinical outcomes.\n","authors":["R. James Cotton","Bryant A. Seamon","Richard L. Segal","Randal D. Davis","Amrita Sahu","Michelle M. McLeod","Pablo Celnik","Sharon L. Ramey"],"pdf_url":"https://arxiv.org/pdf/2411.03919v1.pdf","comment":"keywords: rehabilitation; precision rehabilitation; causal inference;\n  international classification of functioning; rehabilitation treatment\n  specification system; computational neurorehabilitation"},{"id":"http://arxiv.org/abs/2411.03914v1","updated":"2024-11-06T13:47:04Z","published":"2024-11-06T13:47:04Z","title":"Game-Theoretic Machine Unlearning: Mitigating Extra Privacy Leakage","summary":"  With the extensive use of machine learning technologies, data providers\nencounter increasing privacy risks. Recent legislation, such as GDPR, obligates\norganizations to remove requested data and its influence from a trained model.\nMachine unlearning is an emerging technique designed to enable machine learning\nmodels to erase users' private information. Although several efficient machine\nunlearning schemes have been proposed, these methods still have limitations.\nFirst, removing the contributions of partial data may lead to model performance\ndegradation. Second, discrepancies between the original and generated unlearned\nmodels can be exploited by attackers to obtain target sample's information,\nresulting in additional privacy leakage risks. To address above challenges, we\nproposed a game-theoretic machine unlearning algorithm that simulates the\ncompetitive relationship between unlearning performance and privacy protection.\nThis algorithm comprises unlearning and privacy modules. The unlearning module\npossesses a loss function composed of model distance and classification error,\nwhich is used to derive the optimal strategy. The privacy module aims to make\nit difficult for an attacker to infer membership information from the unlearned\ndata, thereby reducing the privacy leakage risk during the unlearning process.\nAdditionally, the experimental results on real-world datasets demonstrate that\nthis game-theoretic unlearning algorithm's effectiveness and its ability to\ngenerate an unlearned model with a performance similar to that of the retrained\none while mitigating extra privacy leakage risks.\n","authors":["Hengzhu Liu","Tianqing Zhu","Lefeng Zhang","Ping Xiong"],"pdf_url":"https://arxiv.org/pdf/2411.03914v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20180v2","updated":"2024-11-06T13:46:52Z","published":"2024-10-26T13:29:43Z","title":"Copyright-Aware Incentive Scheme for Generative Art Models Using\n  Hierarchical Reinforcement Learning","summary":"  Generative art using Diffusion models has achieved remarkable performance in\nimage generation and text-to-image tasks. However, the increasing demand for\ntraining data in generative art raises significant concerns about copyright\ninfringement, as models can produce images highly similar to copyrighted works.\nExisting solutions attempt to mitigate this by perturbing Diffusion models to\nreduce the likelihood of generating such images, but this often compromises\nmodel performance. Another approach focuses on economically compensating data\nholders for their contributions, yet it fails to address copyright loss\nadequately. Our approach begin with the introduction of a novel copyright\nmetric grounded in copyright law and court precedents on infringement. We then\nemploy the TRAK method to estimate the contribution of data holders. To\naccommodate the continuous data collection process, we divide the training into\nmultiple rounds. Finally, We designed a hierarchical budget allocation method\nbased on reinforcement learning to determine the budget for each round and the\nremuneration of the data holder based on the data holder's contribution and\ncopyright loss in each round. Extensive experiments across three datasets show\nthat our method outperforms all eight benchmarks, demonstrating its\neffectiveness in optimizing budget distribution in a copyright-aware manner. To\nthe best of our knowledge, this is the first technical work that introduces to\nincentive contributors and protect their copyrights by compensating them.\n","authors":["Zhuan Shi","Yifei Song","Xiaoli Tang","Lingjuan Lyu","Boi Faltings"],"pdf_url":"https://arxiv.org/pdf/2410.20180v2.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2407.07655v2","updated":"2024-11-06T13:46:35Z","published":"2024-07-10T13:35:04Z","title":"The Selective G-Bispectrum and its Inversion: Applications to\n  G-Invariant Networks","summary":"  An important problem in signal processing and deep learning is to achieve\n\\textit{invariance} to nuisance factors not relevant for the task. Since many\nof these factors are describable as the action of a group $G$ (e.g. rotations,\ntranslations, scalings), we want methods to be $G$-invariant. The\n$G$-Bispectrum extracts every characteristic of a given signal up to group\naction: for example, the shape of an object in an image, but not its\norientation. Consequently, the $G$-Bispectrum has been incorporated into deep\nneural network architectures as a computational primitive for\n$G$-invariance\\textemdash akin to a pooling mechanism, but with greater\nselectivity and robustness. However, the computational cost of the\n$G$-Bispectrum ($\\mathcal{O}(|G|^2)$, with $|G|$ the size of the group) has\nlimited its widespread adoption. Here, we show that the $G$-Bispectrum\ncomputation contains redundancies that can be reduced into a \\textit{selective\n$G$-Bispectrum} with $\\mathcal{O}(|G|)$ complexity. We prove desirable\nmathematical properties of the selective $G$-Bispectrum and demonstrate how its\nintegration in neural networks enhances accuracy and robustness compared to\ntraditional approaches, while enjoying considerable speeds-up compared to the\nfull $G$-Bispectrum.\n","authors":["Simon Mataigne","Johan Mathe","Sophia Sanborn","Christopher Hillar","Nina Miolane"],"pdf_url":"https://arxiv.org/pdf/2407.07655v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.00393v3","updated":"2024-11-06T13:25:42Z","published":"2024-11-01T06:40:47Z","title":"Advantages of Neural Population Coding for Deep Learning","summary":"  Scalar variables, e.g., the orientation of a shape in an image, are commonly\npredicted using a single output neuron in a neural network. In contrast, the\nmammalian cortex represents variables with a population of neurons. In this\npopulation code, each neuron is most active at its preferred value and shows\npartial activity for other values. Here, we investigate the benefit of using a\npopulation code for the output layer of a neural network. We compare population\ncodes against single-neuron outputs and one-hot vectors. First, we show\ntheoretically and in experiments with synthetic data that population codes\nimprove robustness to input noise in networks of stacked linear layers. Second,\nwe demonstrate the benefit of using population codes to encode ambiguous\noutputs, such as the pose of symmetric objects. Using the T-LESS dataset of\nfeature-less real-world objects, we show that population codes improve the\naccuracy of predicting 3D object orientation from image input.\n","authors":["Heiko Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2411.00393v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04815v3","updated":"2024-11-06T13:24:41Z","published":"2024-06-07T10:35:29Z","title":"Skill-aware Mutual Information Optimisation for Generalisation in\n  Reinforcement Learning","summary":"  Meta-Reinforcement Learning (Meta-RL) agents can struggle to operate across\ntasks with varying environmental features that require different optimal skills\n(i.e., different modes of behaviour). Using context encoders based on\ncontrastive learning to enhance the generalisability of Meta-RL agents is now\nwidely studied but faces challenges such as the requirement for a large sample\nsize, also referred to as the $\\log$-$K$ curse. To improve RL generalisation to\ndifferent tasks, we first introduce Skill-aware Mutual Information (SaMI), an\noptimisation objective that aids in distinguishing context embeddings according\nto skills, thereby equipping RL agents with the ability to identify and execute\ndifferent skills across tasks. We then propose Skill-aware Noise Contrastive\nEstimation (SaNCE), a $K$-sample estimator used to optimise the SaMI objective.\nWe provide a framework for equipping an RL agent with SaNCE in practice and\nconduct experimental validation on modified MuJoCo and Panda-gym benchmarks. We\nempirically find that RL agents that learn by maximising SaMI achieve\nsubstantially improved zero-shot generalisation to unseen tasks. Additionally,\nthe context encoder trained with SaNCE demonstrates greater robustness to a\nreduction in the number of available samples, thus possessing the potential to\novercome the $\\log$-$K$ curse.\n","authors":["Xuehui Yu","Mhairi Dunion","Xin Li","Stefano V. Albrecht"],"pdf_url":"https://arxiv.org/pdf/2406.04815v3.pdf","comment":"The Thirty-eighth Annual Conference on Neural Information Processing\n  Systems (NeurIPS), 2024"},{"id":"http://arxiv.org/abs/2411.03900v1","updated":"2024-11-06T13:24:34Z","published":"2024-11-06T13:24:34Z","title":"Retentive Neural Quantum States: Efficient Ansätze for Ab Initio\n  Quantum Chemistry","summary":"  Neural-network quantum states (NQS) has emerged as a powerful application of\nquantum-inspired deep learning for variational Monte Carlo methods, offering a\ncompetitive alternative to existing techniques for identifying ground states of\nquantum problems. A significant advancement toward improving the practical\nscalability of NQS has been the incorporation of autoregressive models, most\nrecently transformers, as variational ansatze. Transformers learn sequence\ninformation with greater expressiveness than recurrent models, but at the cost\nof increased time complexity with respect to sequence length. We explore the\nuse of the retentive network (RetNet), a recurrent alternative to transformers,\nas an ansatz for solving electronic ground state problems in $\\textit{ab\ninitio}$ quantum chemistry. Unlike transformers, RetNets overcome this time\ncomplexity bottleneck by processing data in parallel during training, and\nrecurrently during inference. We give a simple computational cost estimate of\nthe RetNet and directly compare it with similar estimates for transformers,\nestablishing a clear threshold ratio of problem-to-model size past which the\nRetNet's time complexity outperforms that of the transformer. Though this\nefficiency can comes at the expense of decreased expressiveness relative to the\ntransformer, we overcome this gap through training strategies that leverage the\nautoregressive structure of the model -- namely, variational neural annealing.\nOur findings support the RetNet as a means of improving the time complexity of\nNQS without sacrificing accuracy. We provide further evidence that the ablative\nimprovements of neural annealing extend beyond the RetNet architecture,\nsuggesting it would serve as an effective general training strategy for\nautoregressive NQS.\n","authors":["Oliver Knitter","Dan Zhao","James Stokes","Martin Ganahl","Stefan Leichenauer","Shravan Veerapaneni"],"pdf_url":"https://arxiv.org/pdf/2411.03900v1.pdf","comment":"16 pages, 1 figure, to be submitted for peer-reviewed publication"},{"id":"http://arxiv.org/abs/2411.03055v2","updated":"2024-11-06T13:24:10Z","published":"2024-11-05T12:42:42Z","title":"ATM: Improving Model Merging by Alternating Tuning and Merging","summary":"  Model merging has recently emerged as a cost-efficient paradigm for\nmulti-task learning. Among current approaches, task arithmetic stands out for\nits simplicity and effectiveness. In this paper, we motivate the effectiveness\nof task vectors by linking them to multi-task gradients. We show that in a\nsingle-epoch scenario, task vectors are mathematically equivalent to the\ngradients obtained via gradient descent in a multi-task setting, and still\napproximate these gradients in subsequent epochs. Furthermore, we show that\ntask vectors perform optimally when equality is maintained, and their\neffectiveness is largely driven by the first epoch's gradient. Building on this\ninsight, we propose viewing model merging as a single step in an iterative\nprocess that Alternates between Tuning and Merging (ATM). This method acts as a\nbridge between model merging and multi-task gradient descent, achieving\nstate-of-the-art results with the same data and computational requirements. We\nextensively evaluate ATM across diverse settings, achieving up to 20% higher\naccuracy in computer vision and NLP tasks, compared to the best baselines.\nFinally, we provide both empirical and theoretical support for its\neffectiveness, demonstrating increased orthogonality between task vectors and\nproving that ATM minimizes an upper bound on the loss obtained by jointly\nfinetuning all tasks.\n","authors":["Luca Zhou","Daniele Solombrino","Donato Crisostomi","Maria Sofia Bucarelli","Fabrizio Silvestri","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2411.03055v2.pdf","comment":"Main paper: 10 Pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.03891v1","updated":"2024-11-06T13:09:16Z","published":"2024-11-06T13:09:16Z","title":"Calibrating for the Future:Enhancing Calorimeter Longevity with Deep\n  Learning","summary":"  In the realm of high-energy physics, the longevity of calorimeters is\nparamount. Our research introduces a deep learning strategy to refine the\ncalibration process of calorimeters used in particle physics experiments. We\ndevelop a Wasserstein GAN inspired methodology that adeptly calibrates the\nmisalignment in calorimeter data due to aging or other factors. Leveraging the\nWasserstein distance for loss calculation, this innovative approach requires a\nsignificantly lower number of events and resources to achieve high precision,\nminimizing absolute errors effectively. Our work extends the operational\nlifespan of calorimeters, thereby ensuring the accuracy and reliability of data\nin the long term, and is particularly beneficial for experiments where data\nintegrity is crucial for scientific discovery.\n","authors":["S. Ali","A. S. Ryzhikov","D. A. Derkach","F. D. Ratnikov","V. O. Bocharnikov"],"pdf_url":"https://arxiv.org/pdf/2411.03891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.07077v8","updated":"2024-11-06T13:02:35Z","published":"2021-01-18T13:50:14Z","title":"Yet Another Representation of Binary Decision Trees: A Mathematical\n  Demonstration","summary":"  A decision tree looks like a simple directed acyclic computational graph,\nwhere only the leaf nodes specify the output values and the non-terminals\nspecify their tests or split conditions. From the numerical perspective, we\nexpress decision trees in the language of computational graph. We explicitly\nparameterize the test phase, traversal phase and prediction phase of decision\ntrees based on the bitvectors of non-terminal nodes. As shown, the decision\ntree is a shallow binary network in some sense. Especially, we introduce the\nbitvector matrix to implement the tree traversal in numerical approach, where\nthe core is to convert the logical `AND' operation to arithmetic operations.\nAnd we apply this numerical representation to extend and unify diverse decision\ntrees in concept.\n","authors":["Jinxiong Zhang"],"pdf_url":"https://arxiv.org/pdf/2101.07077v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03884v1","updated":"2024-11-06T13:00:34Z","published":"2024-11-06T13:00:34Z","title":"Polynomial Composition Activations: Unleashing the Dynamics of Large\n  Language Models","summary":"  Transformers have found extensive applications across various domains due to\nthe powerful fitting capabilities. This success can be partially attributed to\ntheir inherent nonlinearity. Thus, in addition to the ReLU function employed in\nthe original transformer architecture, researchers have explored alternative\nmodules such as GeLU and SwishGLU to enhance nonlinearity and thereby augment\nrepresentational capacity. In this paper, we propose a novel category of\npolynomial composition activations (PolyCom), designed to optimize the dynamics\nof transformers. Theoretically, we provide a comprehensive mathematical\nanalysis of PolyCom, highlighting its enhanced expressivity and efficacy\nrelative to other activation functions. Notably, we demonstrate that networks\nincorporating PolyCom achieve the $\\textbf{optimal approximation rate}$,\nindicating that PolyCom networks require minimal parameters to approximate\ngeneral smooth functions in Sobolev spaces. We conduct empirical experiments on\nthe pre-training configurations of large language models (LLMs), including both\ndense and sparse architectures. By substituting conventional activation\nfunctions with PolyCom, we enable LLMs to capture higher-order interactions\nwithin the data, thus improving performance metrics in terms of accuracy and\nconvergence rates. Extensive experimental results demonstrate the effectiveness\nof our method, showing substantial improvements over other activation\nfunctions. Code is available at https://github.com/BryceZhuo/PolyCom.\n","authors":["Zhijian Zhuo","Ya Wang","Yutao Zeng","Xiaoqing Li","Xun Zhou","Jinwen Ma"],"pdf_url":"https://arxiv.org/pdf/2411.03884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03883v1","updated":"2024-11-06T12:57:58Z","published":"2024-11-06T12:57:58Z","title":"MEG: Medical Knowledge-Augmented Large Language Models for Question\n  Answering","summary":"  Question answering is a natural language understanding task that involves\nreasoning over both explicit context and unstated, relevant domain knowledge.\nLarge language models (LLMs), which underpin most contemporary question\nanswering systems, struggle to induce how concepts relate in specialized\ndomains such as medicine. Existing medical LLMs are also costly to train. In\nthis work, we present MEG, a parameter-efficient approach for medical\nknowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate\ngraph embeddings into the LLM, enabling it to leverage external knowledge in a\ncost-effective way. We evaluate our method on four popular medical\nmultiple-choice datasets and show that LLMs greatly benefit from the factual\ngrounding provided by knowledge graph embeddings. MEG attains an average of\n+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized\nmodels like BioMistral. We also show results based on Llama-3. Finally, we show\nthat MEG's performance remains robust to the choice of graph encoder.\n","authors":["Laura Cabello","Carmen Martin-Turrero","Uchenna Akujuobi","Anders Søgaard","Carlos Bobed"],"pdf_url":"https://arxiv.org/pdf/2411.03883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16619v3","updated":"2024-11-06T12:48:36Z","published":"2024-06-24T13:02:36Z","title":"Generalized Dynamic Brain Functional Connectivity Based on Random\n  Convolutions","summary":"  Dynamic functional connectivity (DFC) analysis has been widely applied to\nfunctional magnetic resonance imaging (fMRI) data to reveal time-varying\ndynamic changes of brain states. The sliding window method is by far the most\npopular DFC analysis method due to its simplicity. However, the sliding window\nmethod comes with some assumptions, namely the typically approach uses a single\nwindow which captures dynamics only within a specific frequency range. In this\nstudy, we propose a generalized approach to dynamics via a multi-dimensional\nrandom convolution (RandCon) DFC method that is able to effectively capture\ntime-varying DFC at arbitrary time scales by extracting different local\nfeatures from fMRI time series using a number of multi-dimensional random\nconvolution kernels without the need for learning kernel weights. Compared to a\nstandard sliding window method, multiplication of temporal derivatives (MTD)\nand phase synchrony methods, RandCon with the smallest kernel size (3 time\npoints) showed notable improvements in performance on simulated data,\nparticularly in terms of DFC temporal and spatial estimation in very short\nwindow/kernel size under different noise levels. Results from real fMRI data\nindicated that RandCon was more sensitive to gender differences than competing\nmethods. Furthermore, we show that the sliding window method can be considered\na special case of the proposed multi-dimensional convolution framework. The\nproposed method is simple and efficient significantly broadens the scope of\ndynamic functional connectivity research and offer theoretical and practical\npotential.\n","authors":["Yongjie Duan","Vince D. Calhoun","Zhiying Long"],"pdf_url":"https://arxiv.org/pdf/2406.16619v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03877v1","updated":"2024-11-06T12:48:04Z","published":"2024-11-06T12:48:04Z","title":"EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning","summary":"  Answering reasoning-based complex questions over text and hybrid sources,\nincluding tables, is a challenging task. Recent advances in large language\nmodels (LLMs) have enabled in-context learning (ICL), allowing LLMs to acquire\nproficiency in a specific task using only a few demonstration samples\n(exemplars). A critical challenge in ICL is the selection of optimal exemplars,\nwhich can be either task-specific (static) or test-example-specific (dynamic).\nStatic exemplars provide faster inference times and increased robustness across\na distribution of test examples. In this paper, we propose an algorithm for\nstatic exemplar subset selection for complex reasoning tasks. We introduce\nEXPLORA, a novel exploration method designed to estimate the parameters of the\nscoring function, which evaluates exemplar subsets without incorporating\nconfidence information. EXPLORA significantly reduces the number of LLM calls\nto ~11% of those required by state-of-the-art methods and achieves a\nsubstantial performance improvement of 12.24%. We open-source our code and data\n(https://github.com/kiranpurohit/EXPLORA).\n","authors":["Kiran Purohit","Venktesh V","Raghuram Devalla","Krishna Mohan Yerragorla","Sourangshu Bhattacharya","Avishek Anand"],"pdf_url":"https://arxiv.org/pdf/2411.03877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03876v1","updated":"2024-11-06T12:45:46Z","published":"2024-11-06T12:45:46Z","title":"Large Generative Model-assisted Talking-face Semantic Communication\n  System","summary":"  The rapid development of generative Artificial Intelligence (AI) continually\nunveils the potential of Semantic Communication (SemCom). However, current\ntalking-face SemCom systems still encounter challenges such as low bandwidth\nutilization, semantic ambiguity, and diminished Quality of Experience (QoE).\nThis study introduces a Large Generative Model-assisted Talking-face Semantic\nCommunication (LGM-TSC) System tailored for the talking-face video\ncommunication. Firstly, we introduce a Generative Semantic Extractor (GSE) at\nthe transmitter based on the FunASR model to convert semantically sparse\ntalking-face videos into texts with high information density. Secondly, we\nestablish a private Knowledge Base (KB) based on the Large Language Model (LLM)\nfor semantic disambiguation and correction, complemented by a joint knowledge\nbase-semantic-channel coding scheme. Finally, at the receiver, we propose a\nGenerative Semantic Reconstructor (GSR) that utilizes BERT-VITS2 and SadTalker\nmodels to transform text back into a high-QoE talking-face video matching the\nuser's timbre. Simulation results demonstrate the feasibility and effectiveness\nof the proposed LGM-TSC system.\n","authors":["Feibo Jiang","Siwei Tu","Li Dong","Cunhua Pan","Jiangzhou Wang","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2411.03876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06106v2","updated":"2024-11-06T12:40:53Z","published":"2024-06-10T08:42:48Z","title":"Testably Learning Polynomial Threshold Functions","summary":"  Rubinfeld & Vasilyan recently introduced the framework of testable learning\nas an extension of the classical agnostic model. It relaxes distributional\nassumptions which are difficult to verify by conditions that can be checked\nefficiently by a tester. The tester has to accept whenever the data truly\nsatisfies the original assumptions, and the learner has to succeed whenever the\ntester accepts. We focus on the setting where the tester has to accept standard\nGaussian data. There, it is known that basic concept classes such as halfspaces\ncan be learned testably with the same time complexity as in the\n(distribution-specific) agnostic model. In this work, we ask whether there is a\nprice to pay for testably learning more complex concept classes. In particular,\nwe consider polynomial threshold functions (PTFs), which naturally generalize\nhalfspaces. We show that PTFs of arbitrary constant degree can be testably\nlearned up to excess error $\\varepsilon > 0$ in time\n$n^{\\mathrm{poly}(1/\\varepsilon)}$. This qualitatively matches the best known\nguarantees in the agnostic model. Our results build on a connection between\ntestable learning and fooling. In particular, we show that distributions that\napproximately match at least $\\mathrm{poly}(1/\\varepsilon)$ moments of the\nstandard Gaussian fool constant-degree PTFs (up to error $\\varepsilon$). As a\nsecondary result, we prove that a direct approach to show testable learning\n(without fooling), which was successfully used for halfspaces, cannot work for\nPTFs.\n","authors":["Lucas Slot","Stefan Tiegel","Manuel Wiedmer"],"pdf_url":"https://arxiv.org/pdf/2406.06106v2.pdf","comment":"Accepted to NeurIPS 2024. v2: Minor updates of exposition. 53 pages"},{"id":"http://arxiv.org/abs/2305.17000v8","updated":"2024-11-06T12:27:34Z","published":"2023-05-26T14:59:28Z","title":"DistriBlock: Identifying adversarial audio samples by leveraging\n  characteristics of the output distribution","summary":"  Adversarial attacks can mislead automatic speech recognition (ASR) systems\ninto predicting an arbitrary target text, thus posing a clear security threat.\nTo prevent such attacks, we propose DistriBlock, an efficient detection\nstrategy applicable to any ASR system that predicts a probability distribution\nover output tokens in each time step. We measure a set of characteristics of\nthis distribution: the median, maximum, and minimum over the output\nprobabilities, the entropy of the distribution, as well as the Kullback-Leibler\nand the Jensen-Shannon divergence with respect to the distributions of the\nsubsequent time step. Then, by leveraging the characteristics observed for both\nbenign and adversarial data, we apply binary classifiers, including simple\nthreshold-based classification, ensembles of such classifiers, and neural\nnetworks. Through extensive analysis across different state-of-the-art ASR\nsystems and language data sets, we demonstrate the supreme performance of this\napproach, with a mean area under the receiver operating characteristic curve\nfor distinguishing target adversarial examples against clean and noisy data of\n99% and 97%, respectively. To assess the robustness of our method, we show that\nadaptive adversarial examples that can circumvent DistriBlock are much noisier,\nwhich makes them easier to detect through filtering and creates another avenue\nfor preserving the system's robustness.\n","authors":["Matías Pizarro","Dorothea Kolossa","Asja Fischer"],"pdf_url":"https://arxiv.org/pdf/2305.17000v8.pdf","comment":"Available at: https://proceedings.mlr.press/v244/pizarro24a.html"},{"id":"http://arxiv.org/abs/2411.03865v1","updated":"2024-11-06T12:19:01Z","published":"2024-11-06T12:19:01Z","title":"AdaSociety: An Adaptive Environment with Social Structures for\n  Multi-Agent Decision-Making","summary":"  Traditional interactive environments limit agents' intelligence growth with\nfixed tasks. Recently, single-agent environments address this by generating new\ntasks based on agent actions, enhancing task diversity. We consider the\ndecision-making problem in multi-agent settings, where tasks are further\ninfluenced by social connections, affecting rewards and information access.\nHowever, existing multi-agent environments lack a combination of adaptive\nphysical surroundings and social connections, hindering the learning of\nintelligent behaviors. To address this, we introduce AdaSociety, a customizable\nmulti-agent environment featuring expanding state and action spaces, alongside\nexplicit and alterable social structures. As agents progress, the environment\nadaptively generates new tasks with social structures for agents to undertake.\nIn AdaSociety, we develop three mini-games showcasing distinct social\nstructures and tasks. Initial results demonstrate that specific social\nstructures can promote both individual and collective benefits, though current\nreinforcement learning and LLM-based algorithms show limited effectiveness in\nleveraging social structures to enhance performance. Overall, AdaSociety serves\nas a valuable research platform for exploring intelligence in diverse physical\nand social settings. The code is available at\nhttps://github.com/bigai-ai/AdaSociety.\n","authors":["Yizhe Huang","Xingbo Wang","Hao Liu","Fanqi Kong","Aoyang Qin","Min Tang","Xiaoxi Wang","Song-Chun Zhu","Mingjie Bi","Siyuan Qi","Xue Feng"],"pdf_url":"https://arxiv.org/pdf/2411.03865v1.pdf","comment":"Accepted at NeurIPS D&B 2024"},{"id":"http://arxiv.org/abs/2411.03859v1","updated":"2024-11-06T12:06:43Z","published":"2024-11-06T12:06:43Z","title":"UniTraj: Universal Human Trajectory Modeling from Billion-Scale\n  Worldwide Traces","summary":"  Human trajectory modeling is essential for deciphering movement patterns and\nsupporting advanced applications across various domains. However, existing\nmethods are often tailored to specific tasks and regions, resulting in\nlimitations related to task specificity, regional dependency, and data quality\nsensitivity. Addressing these challenges requires a universal human trajectory\nfoundation model capable of generalizing and scaling across diverse tasks and\ngeographic contexts. To this end, we propose UniTraj, a Universal human\nTrajectory foundation model that is task-adaptive, region-independent, and\nhighly generalizable. To further enhance performance, we construct WorldTrace,\nthe first large-scale, high-quality, globally distributed dataset sourced from\nopen web platforms, encompassing 2.45 million trajectories with billions of\npoints across 70 countries. Through multiple resampling and masking strategies\ndesigned for pre-training, UniTraj effectively overcomes geographic and task\nconstraints, adapting to heterogeneous data quality. Extensive experiments\nacross multiple trajectory analysis tasks and real-world datasets demonstrate\nthat UniTraj consistently outperforms existing approaches in terms of\nscalability and adaptability. These results underscore the potential of UniTraj\nas a versatile, robust solution for a wide range of trajectory analysis\napplications, with WorldTrace serving as an ideal but non-exclusive foundation\nfor training.\n","authors":["Yuanshao Zhu","James Jianqiao Yu","Xiangyu Zhao","Xuetao Wei","Yuxuan Liang"],"pdf_url":"https://arxiv.org/pdf/2411.03859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01813v3","updated":"2024-11-06T12:05:55Z","published":"2024-09-03T11:51:10Z","title":"Reassessing Noise Augmentation Methods in the Context of Adversarial\n  Speech","summary":"  In this study, we investigate if noise-augmented training can concurrently\nimprove adversarial robustness in automatic speech recognition (ASR) systems.\nWe conduct a comparative analysis of the adversarial robustness of four\ndifferent state-of-the-art ASR architectures, where each of the ASR\narchitectures is trained under three different augmentation conditions: one\nsubject to background noise, speed variations, and reverberations, another\nsubject to speed variations only, and a third without any form of data\naugmentation. The results demonstrate that noise augmentation not only improves\nmodel performance on noisy speech but also the model's robustness to\nadversarial attacks.\n","authors":["Karla Pizzi","Matías Pizarro","Asja Fischer"],"pdf_url":"https://arxiv.org/pdf/2409.01813v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03857v1","updated":"2024-11-06T12:00:51Z","published":"2024-11-06T12:00:51Z","title":"Efficient Message Passing Architecture for GCN Training on HBM-based\n  FPGAs with Orthogonal Topology On-Chip Networks","summary":"  Graph Convolutional Networks (GCNs) are state-of-the-art deep learning models\nfor representation learning on graphs. However, the efficient training of GCNs\nis hampered by constraints in memory capacity and bandwidth, compounded by the\nirregular data flow that results in communication bottlenecks. To address these\nchallenges, we propose a message-passing architecture that leverages NUMA-based\nmemory access properties and employs a parallel multicast routing algorithm\nbased on a 4-D hypercube network within the accelerator for efficient message\npassing in graphs. Additionally, we have re-engineered the backpropagation\nalgorithm specific to GCNs within our proposed accelerator. This redesign\nstrategically mitigates the memory demands prevalent during the training phase\nand diminishes the computational overhead associated with the transposition of\nextensive matrices. Compared to the state-of-the-art HP-GNN architecture we\nachieved a performance improvement of $1.03\\times \\sim 1.81\\times$.\n","authors":["Qizhe Wu","Letian Zhao","Yuchen Gui","Huawen Liang Xiaotian Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03857v1.pdf","comment":"This paper has been accepted for 2024 ACM/SIGDA International\n  Symposium on Field Programmable Gate Arrays(FPGA'24) as poster"},{"id":"http://arxiv.org/abs/2411.03855v1","updated":"2024-11-06T11:57:55Z","published":"2024-11-06T11:57:55Z","title":"MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba","summary":"  An ecosystem of Transformer-based models has been established by building\nlarge models with extensive data. Parameter-efficient fine-tuning (PEFT) is a\ncrucial technology for deploying these models to downstream tasks with minimal\ncost while achieving effective performance. Recently, Mamba, a State Space\nModel (SSM)-based model, has attracted attention as a potential alternative to\nTransformers. While many large-scale Mamba-based models have been proposed,\nefficiently adapting pre-trained Mamba-based models to downstream tasks remains\nunexplored. In this paper, we conduct an exploratory analysis of PEFT methods\nfor Mamba. We investigate the effectiveness of existing PEFT methods for\nTransformers when applied to Mamba. We also modify these methods to better\nalign with the Mamba architecture. Additionally, we propose new Mamba-specific\nPEFT methods that leverage the distinctive structure of Mamba. Our experiments\nindicate that PEFT performs more effectively for Mamba than Transformers.\nLastly, we demonstrate how to effectively combine multiple PEFT methods and\nprovide a framework that outperforms previous works. To ensure reproducibility,\nwe will release the code after publication.\n","authors":["Masakazu Yoshimura","Teruaki Hayashi","Yota Maeda"],"pdf_url":"https://arxiv.org/pdf/2411.03855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16103v2","updated":"2024-11-06T11:55:36Z","published":"2024-10-21T15:31:06Z","title":"LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics","summary":"  We introduce LDAdam, a memory-efficient optimizer for training large models,\nthat performs adaptive optimization steps within lower dimensional subspaces,\nwhile consistently exploring the full parameter space during training. This\nstrategy keeps the optimizer's memory footprint to a fraction of the model\nsize. LDAdam relies on a new projection-aware update rule for the optimizer\nstates that allows for transitioning between subspaces, i.e., estimation of the\nstatistics of the projected gradients. To mitigate the errors due to low-rank\nprojection, LDAdam integrates a new generalized error feedback mechanism, which\nexplicitly accounts for both gradient and optimizer state compression. We prove\nthe convergence of LDAdam under standard assumptions, and show that LDAdam\nallows for accurate and efficient fine-tuning and pre-training of language\nmodels.\n","authors":["Thomas Robert","Mher Safaryan","Ionut-Vlad Modoranu","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.16103v2.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2401.11124v2","updated":"2024-11-06T11:40:50Z","published":"2024-01-20T05:31:47Z","title":"Cross-Task Affinity Learning for Multitask Dense Scene Predictions","summary":"  Multitask learning (MTL) has become prominent for its ability to predict\nmultiple tasks jointly, achieving better per-task performance with fewer\nparameters than single-task learning. Recently, decoder-focused architectures\nhave significantly improved multitask performance by refining task predictions\nusing features from related tasks. However, most refinement methods struggle to\nefficiently capture both local and long-range dependencies between\ntask-specific representations and cross-task patterns. In this paper, we\nintroduce the Cross-Task Affinity Learning (CTAL) module, a lightweight\nframework that enhances task refinement in multitask networks. CTAL effectively\ncaptures local and long-range cross-task interactions by optimizing task\naffinity matrices for parameter-efficient grouped convolutions without concern\nfor information loss. Our results demonstrate state-of-the-art MTL performance\nfor both CNN and transformer backbones, using significantly fewer parameters\nthan single-task learning. Our code is publicly available at\nhttps://github.com/Armanfard-Lab/EMA-Net.\n","authors":["Dimitrios Sinodinos","Narges Armanfard"],"pdf_url":"https://arxiv.org/pdf/2401.11124v2.pdf","comment":"Accepted for publication at the IEEE Winter Conference on\n  Applications of Computer Vision (WACV) 2025"},{"id":"http://arxiv.org/abs/2112.07400v3","updated":"2024-11-06T11:32:01Z","published":"2021-12-14T13:50:23Z","title":"Robustifying automatic speech recognition by extracting slowly varying\n  features","summary":"  In the past few years, it has been shown that deep learning systems are\nhighly vulnerable under attacks with adversarial examples. Neural-network-based\nautomatic speech recognition (ASR) systems are no exception. Targeted and\nuntargeted attacks can modify an audio input signal in such a way that humans\nstill recognise the same words, while ASR systems are steered to predict a\ndifferent transcription. In this paper, we propose a defense mechanism against\ntargeted adversarial attacks consisting in removing fast-changing features from\nthe audio signals, either by applying slow feature analysis, a low-pass filter,\nor both, before feeding the input to the ASR system. We perform an empirical\nanalysis of hybrid ASR models trained on data pre-processed in such a way.\nWhile the resulting models perform quite well on benign data, they are\nsignificantly more robust against targeted adversarial attacks: Our final,\nproposed model shows a performance on clean data similar to the baseline model,\nwhile being more than four times more robust.\n","authors":["Matías Pizarro","Dorothea Kolossa","Asja Fischer"],"pdf_url":"https://arxiv.org/pdf/2112.07400v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15645v2","updated":"2024-11-06T11:31:00Z","published":"2024-01-28T12:47:39Z","title":"Ensemble-Based Annealed Importance Sampling","summary":"  Sampling from a multimodal distribution is a fundamental and challenging\nproblem in computational science and statistics. Among various approaches\nproposed for this task, one popular method is Annealed Importance Sampling\n(AIS). In this paper, we propose an ensemble-based version of AIS by combining\nit with population-based Monte Carlo methods to improve its efficiency. By\nkeeping track of an ensemble instead of a single particle along some\ncontinuation path between the starting distribution and the target\ndistribution, we take advantage of the interaction within the ensemble to\nencourage the exploration of undiscovered modes. Specifically, our main idea is\nto utilize either the snooker algorithm or the genetic algorithm used in\nEvolutionary Monte Carlo. We discuss how the proposed algorithm can be\nimplemented and derive a partial differential equation governing the evolution\nof the ensemble under the continuous time and mean-field limit. We also test\nthe efficiency of the proposed algorithm on various continuous and discrete\ndistributions.\n","authors":["Haoxuan Chen","Lexing Ying"],"pdf_url":"https://arxiv.org/pdf/2401.15645v2.pdf","comment":"33 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.03845v1","updated":"2024-11-06T11:29:47Z","published":"2024-11-06T11:29:47Z","title":"Reconsidering the Performance of GAE in Link Prediction","summary":"  Various graph neural networks (GNNs) with advanced training techniques and\nmodel designs have been proposed for link prediction tasks. However, outdated\nbaseline models may lead to an overestimation of the benefits provided by these\nnovel approaches. To address this, we systematically investigate the potential\nof Graph Autoencoders (GAE) by meticulously tuning hyperparameters and\nutilizing the trick of orthogonal embedding and linear propagation. Our\nfindings reveal that a well-optimized GAE can match the performance of more\ncomplex models while offering greater computational efficiency.\n","authors":["Weishuo Ma","Yanbo Wang","Xiyuan Wang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.03845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03840v1","updated":"2024-11-06T11:24:02Z","published":"2024-11-06T11:24:02Z","title":"Flexible task abstractions emerge in linear networks with fast and\n  bounded units","summary":"  Animals survive in dynamic environments changing at arbitrary timescales, but\nsuch data distribution shifts are a challenge to neural networks. To adapt to\nchange, neural systems may change a large number of parameters, which is a slow\nprocess involving forgetting past information. In contrast, animals leverage\ndistribution changes to segment their stream of experience into tasks and\nassociate them with internal task abstracts. Animals can then respond flexibly\nby selecting the appropriate task abstraction. However, how such flexible task\nabstractions may arise in neural systems remains unknown. Here, we analyze a\nlinear gated network where the weights and gates are jointly optimized via\ngradient descent, but with neuron-like constraints on the gates including a\nfaster timescale, nonnegativity, and bounded activity. We observe that the\nweights self-organize into modules specialized for tasks or sub-tasks\nencountered, while the gates layer forms unique representations that switch the\nappropriate weight modules (task abstractions). We analytically reduce the\nlearning dynamics to an effective eigenspace, revealing a virtuous cycle: fast\nadapting gates drive weight specialization by protecting previous knowledge,\nwhile weight specialization in turn increases the update rate of the gating\nlayer. Task switching in the gating layer accelerates as a function of\ncurriculum block size and task training, mirroring key findings in cognitive\nneuroscience. We show that the discovered task abstractions support\ngeneralization through both task and subtask composition, and we extend our\nfindings to a non-linear network switching between two tasks. Overall, our work\noffers a theory of cognitive flexibility in animals as arising from joint\ngradient descent on synaptic and neural gating in a neural network\narchitecture.\n","authors":["Kai Sandbrink","Jan P. Bauer","Alexandra M. Proca","Andrew M. Saxe","Christopher Summerfield","Ali Hummos"],"pdf_url":"https://arxiv.org/pdf/2411.03840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02904v2","updated":"2024-11-06T10:45:04Z","published":"2024-11-05T08:43:54Z","title":"Gradient Descent Finds Over-Parameterized Neural Networks with Sharp\n  Generalization for Nonparametric Regression: A Distribution-Free Analysis","summary":"  We study nonparametric regression by an over-parameterized two-layer neural\nnetwork trained by gradient descent (GD) in this paper. We show that, if the\nneural network is trained by GD with early stopping, then the trained network\nrenders a sharp rate of the nonparametric regression risk of $\\cO(\\eps_n^2)$,\nwhich is the same rate as that for the classical kernel regression trained by\nGD with early stopping, where $\\eps_n$ is the critical population rate of the\nNeural Tangent Kernel (NTK) associated with the network and $n$ is the size of\nthe training data. It is remarked that our result does not require\ndistributional assumptions on the training data, in a strong contrast with many\nexisting results which rely on specific distributions such as the spherical\nuniform data distribution or distributions satisfying certain restrictive\nconditions. The rate $\\cO(\\eps_n^2)$ is known to be minimax optimal for\nspecific cases, such as the case that the NTK has a polynomial eigenvalue decay\nrate which happens under certain distributional assumptions. Our result\nformally fills the gap between training a classical kernel regression model and\ntraining an over-parameterized but finite-width neural network by GD for\nnonparametric regression without distributional assumptions. We also provide\nconfirmative answers to certain open questions or address particular concerns\nin the literature of training over-parameterized neural networks by GD with\nearly stopping for nonparametric regression, including the characterization of\nthe stopping time, the lower bound for the network width, and the constant\nlearning rate used in GD.\n","authors":["Yingzhen Yang","Ping Li"],"pdf_url":"https://arxiv.org/pdf/2411.02904v2.pdf","comment":"This article draws results with revisions from the first author's\n  other work in arXiv:2407.11353"},{"id":"http://arxiv.org/abs/2411.03820v1","updated":"2024-11-06T10:42:04Z","published":"2024-11-06T10:42:04Z","title":"Beyond The Rainbow: High Performance Deep Reinforcement Learning On A\n  Desktop PC","summary":"  Rainbow Deep Q-Network (DQN) demonstrated combining multiple independent\nenhancements could significantly boost a reinforcement learning (RL) agent's\nperformance. In this paper, we present \"Beyond The Rainbow\" (BTR), a novel\nalgorithm that integrates six improvements from across the RL literature to\nRainbow DQN, establishing a new state-of-the-art for RL using a desktop PC,\nwith a human-normalized interquartile mean (IQM) of 7.4 on atari-60. Beyond\nAtari, we demonstrate BTR's capability to handle complex 3D games, successfully\ntraining agents to play Super Mario Galaxy, Mario Kart, and Mortal Kombat with\nminimal algorithmic changes. Designing BTR with computational efficiency in\nmind, agents can be trained using a desktop PC on 200 million Atari frames\nwithin 12 hours. Additionally, we conduct detailed ablation studies of each\ncomponent, analzying the performance and impact using numerous measures.\n","authors":["Tyler Clark","Mark Towers","Christine Evers","Jonathon Hare"],"pdf_url":"https://arxiv.org/pdf/2411.03820v1.pdf","comment":"9 main pages, 26 total. Currently under review at ICLR"},{"id":"http://arxiv.org/abs/2402.13791v2","updated":"2024-11-06T10:35:55Z","published":"2024-02-21T13:19:58Z","title":"Opening the Black-Box: A Systematic Review on Explainable AI in Remote\n  Sensing","summary":"  In recent years, black-box machine learning approaches have become a dominant\nmodeling paradigm for knowledge extraction in remote sensing. Despite the\npotential benefits of uncovering the inner workings of these models with\nexplainable AI, a comprehensive overview summarizing the explainable AI methods\nused and their objectives, findings, and challenges in remote sensing\napplications is still missing. In this paper, we address this gap by performing\na systematic review to identify the key trends in the field and shed light on\nnovel explainable AI approaches and emerging directions that tackle specific\nremote sensing challenges. We also reveal the common patterns of explanation\ninterpretation, discuss the extracted scientific insights, and reflect on the\napproaches used for the evaluation of explainable AI methods. As such, our\nreview provides a complete summary of the state-of-the-art of explainable AI in\nremote sensing. Further, we give a detailed outlook on the challenges and\npromising research directions, representing a basis for novel methodological\ndevelopment and a useful starting point for new researchers in the field.\n","authors":["Adrian Höhl","Ivica Obadic","Miguel Ángel Fernández Torres","Hiba Najjar","Dario Oliveira","Zeynep Akata","Andreas Dengel","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2402.13791v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23893v2","updated":"2024-11-06T10:28:26Z","published":"2024-10-31T12:53:53Z","title":"DiffBatt: A Diffusion Model for Battery Degradation Prediction and\n  Synthesis","summary":"  Battery degradation remains a critical challenge in the pursuit of green\ntechnologies and sustainable energy solutions. Despite significant research\nefforts, predicting battery capacity loss accurately remains a formidable task\ndue to its complex nature, influenced by both aging and cycling behaviors. To\naddress this challenge, we introduce a novel general-purpose model for battery\ndegradation prediction and synthesis, DiffBatt. Leveraging an innovative\ncombination of conditional and unconditional diffusion models with\nclassifier-free guidance and transformer architecture, DiffBatt achieves high\nexpressivity and scalability. DiffBatt operates as a probabilistic model to\ncapture uncertainty in aging behaviors and a generative model to simulate\nbattery degradation. The performance of the model excels in prediction tasks\nwhile also enabling the generation of synthetic degradation curves,\nfacilitating enhanced model training by data augmentation. In the remaining\nuseful life prediction task, DiffBatt provides accurate results with a mean\nRMSE of 196 cycles across all datasets, outperforming all other models and\ndemonstrating superior generalizability. This work represents an important step\ntowards developing foundational models for battery degradation.\n","authors":["Hamidreza Eivazi","André Hebenbrock","Raphael Ginster","Steffen Blömeke","Stefan Wittek","Christoph Herrmann","Thomas S. Spengler","Thomas Turek","Andreas Rausch"],"pdf_url":"https://arxiv.org/pdf/2410.23893v2.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2404.09080v2","updated":"2024-11-06T10:23:59Z","published":"2024-04-13T20:55:15Z","title":"Safe Reinforcement Learning on the Constraint Manifold: Theory and\n  Applications","summary":"  Integrating learning-based techniques, especially reinforcement learning,\ninto robotics is promising for solving complex problems in unstructured\nenvironments. However, most existing approaches are trained in well-tuned\nsimulators and subsequently deployed on real robots without online fine-tuning.\nIn this setting, extensive engineering is required to mitigate the sim-to-real\ngap, which can be challenging for complex systems. Instead, learning with\nreal-world interaction data offers a promising alternative: it not only\neliminates the need for a fine-tuned simulator but also applies to a broader\nrange of tasks where accurate modeling is unfeasible. One major problem for\non-robot reinforcement learning is ensuring safety, as uncontrolled exploration\ncan cause catastrophic damage to the robot or the environment. Indeed, safety\nspecifications, often represented as constraints, can be complex and\nnon-linear, making safety challenging to guarantee in learning systems. In this\npaper, we show how we can impose complex safety constraints on learning-based\nrobotics systems in a principled manner, both from theoretical and practical\npoints of view. Our approach is based on the concept of the Constraint\nManifold, representing the set of safe robot configurations. Exploiting\ndifferential geometry techniques, i.e., the tangent space, we can construct a\nsafe action space, allowing learning agents to sample arbitrary actions while\nensuring safety. We demonstrate the method's effectiveness in a real-world\nRobot Air Hockey task, showing that our method can handle high-dimensional\ntasks with complex constraints. Videos of the real robot experiments are\navailable on the project website (https://puzeliu.github.io/TRO-ATACOM).\n","authors":["Puze Liu","Haitham Bou-Ammar","Jan Peters","Davide Tateo"],"pdf_url":"https://arxiv.org/pdf/2404.09080v2.pdf","comment":"19 pages; sumitted to IEEE Transactions on Robotics"},{"id":"http://arxiv.org/abs/2402.06922v3","updated":"2024-11-06T10:22:27Z","published":"2024-02-10T11:07:24Z","title":"Whispers in the Machine: Confidentiality in LLM-integrated Systems","summary":"  Large Language Models (LLMs) are increasingly augmented with external tools\nand commercial services into LLM-integrated systems. While these interfaces can\nsignificantly enhance the capabilities of the models, they also introduce a new\nattack surface. Manipulated integrations, for example, can exploit the model\nand compromise sensitive data accessed through other interfaces. While previous\nwork primarily focused on attacks targeting a model's alignment or the leakage\nof training data, the security of data that is only available during inference\nhas escaped scrutiny so far. In this work, we demonstrate the vulnerabilities\nassociated with external components and introduce a systematic approach to\nevaluate confidentiality risks in LLM-integrated systems. We identify two\nspecific attack scenarios unique to these systems and formalize these into a\ntool-robustness framework designed to measure a model's ability to protect\nsensitive information. Our findings show that all examined models are highly\nvulnerable to confidentiality attacks, with the risk increasing significantly\nwhen models are used together with external tools.\n","authors":["Jonathan Evertz","Merlin Chlosta","Lea Schönherr","Thorsten Eisenhofer"],"pdf_url":"https://arxiv.org/pdf/2402.06922v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03550v2","updated":"2024-11-06T10:19:32Z","published":"2023-02-07T15:59:08Z","title":"Exponential convergence rates for momentum stochastic gradient descent\n  in the overparametrized setting","summary":"  We prove explicit bounds on the exponential rate of convergence for the\nmomentum stochastic gradient descent scheme (MSGD) for arbitrary, fixed\nhyperparameters (learning rate, friction parameter) and its continuous-in-time\ncounterpart in the context of non-convex optimization. In the small step-size\nregime and in the case of flat minima or large noise intensities, these bounds\nprove faster convergence of MSGD compared to plain stochastic gradient descent\n(SGD). The results are shown for objective functions satisfying a local\nPolyak-Lojasiewicz inequality and under assumptions on the variance of MSGD\nthat are satisfied in overparametrized settings. Moreover, we analyze the\noptimal choice of the friction parameter and show that the MSGD process almost\nsurely converges to a local minimum.\n","authors":["Benjamin Gess","Sebastian Kassing"],"pdf_url":"https://arxiv.org/pdf/2302.03550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03810v1","updated":"2024-11-06T10:14:46Z","published":"2024-11-06T10:14:46Z","title":"Hybrid Transfer Reinforcement Learning: Provable Sample Efficiency from\n  Shifted-Dynamics Data","summary":"  Online Reinforcement learning (RL) typically requires high-stakes online\ninteraction data to learn a policy for a target task. This prompts interest in\nleveraging historical data to improve sample efficiency. The historical data\nmay come from outdated or related source environments with different dynamics.\nIt remains unclear how to effectively use such data in the target task to\nprovably enhance learning and sample efficiency. To address this, we propose a\nhybrid transfer RL (HTRL) setting, where an agent learns in a target\nenvironment while accessing offline data from a source environment with shifted\ndynamics. We show that -- without information on the dynamics shift -- general\nshifted-dynamics data, even with subtle shifts, does not reduce sample\ncomplexity in the target environment. However, with prior information on the\ndegree of the dynamics shift, we design HySRL, a transfer algorithm that\nachieves problem-dependent sample complexity and outperforms pure online RL.\nFinally, our experimental results demonstrate that HySRL surpasses\nstate-of-the-art online RL baseline.\n","authors":["Chengrui Qu","Laixi Shi","Kishan Panaganti","Pengcheng You","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.03810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18038v2","updated":"2024-11-06T10:14:20Z","published":"2024-06-26T03:12:07Z","title":"MT2ST: Adaptive Multi-Task to Single-Task Learning","summary":"  The conventional training approaches often face challenges in balancing the\nbreadth of multi-task learning (MTL) with the depth of single-task learning\n(STL). To address this issue, we introduce the Multi-Task to Single-Task\n(MT2ST) framework, a groundbreaking approach that can combine the\ngeneralizability of MTL with the precision of STL. Our work include two\nstrategies: 'Diminish' and 'Switch'. 'Diminish' Strategy will gradually reduce\nthe influence of auxiliary tasks, while the 'Switch' strategy involves a shift\nfrom multi-tasking to single-tasking at a specific timepoint at the training\nprocess.\n  In this paper, we propose the Multi-Task to Single-Task (MT2ST) framework, a\nnovel approach that significantly enhances the efficiency and accuracy of word\nembedding training while concurrently addressing prevalent issues such as\noverfitting. Our empirical studies demonstrate that MT2ST can reduce training\ntime by 67% when contrasted with single-task learning approaches, and by 13%\ncompared to traditional multi-task learning methods. These findings underscore\nMT2ST's potential to be a powerful tools for word embedding training\nacceleration. The code implementation is can be found at:\nhttps://github.com/NoakLiu/MT2ST-Word-Embeddings-Acceleration.\n","authors":["Dong Liu"],"pdf_url":"https://arxiv.org/pdf/2406.18038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02988v2","updated":"2024-11-06T10:08:30Z","published":"2024-11-05T10:51:01Z","title":"Confidence Calibration of Classifiers with Many Classes","summary":"  For classification models based on neural networks, the maximum predicted\nclass probability is often used as a confidence score. This score rarely\npredicts well the probability of making a correct prediction and requires a\npost-processing calibration step. However, many confidence calibration methods\nfail for problems with many classes. To address this issue, we transform the\nproblem of calibrating a multiclass classifier into calibrating a single\nsurrogate binary classifier. This approach allows for more efficient use of\nstandard calibration methods. We evaluate our approach on numerous neural\nnetworks used for image or text classification and show that it significantly\nenhances existing calibration methods.\n","authors":["Adrien LeCoz","Stéphane Herbin","Faouzi Adjed"],"pdf_url":"https://arxiv.org/pdf/2411.02988v2.pdf","comment":"NeurIPS 2024; code available at\n  https://github.com/allglc/tva-calibration"},{"id":"http://arxiv.org/abs/2411.03802v1","updated":"2024-11-06T09:55:01Z","published":"2024-11-06T09:55:01Z","title":"On the Decomposition of Differential Game","summary":"  To understand the complexity of the dynamic of learning in differential\ngames, we decompose the game into components where the dynamic is well\nunderstood. One of the possible tools is Helmholtz's theorem, which can\ndecompose a vector field into a potential and a harmonic component. This has\nbeen shown to be effective in finite and normal-form games. However, applying\nHelmholtz's theorem by connecting it with the Hodge theorem on $\\mathbb{R}^n$\n(which is the strategy space of differential game) is non-trivial due to the\nnon-compactness of $\\mathbb{R}^n$. Bridging the dynamic-strategic disconnect\nthrough Hodge/Helmoltz's theorem in differential games is then left as an open\nproblem \\cite{letcher2019differentiable}. In this work, we provide two\ndecompositions of differential games to answer this question: the first as an\nexact scalar potential part, a near vector potential part, and a non-strategic\npart; the second as a near scalar potential part, an exact vector potential\npart, and a non-strategic part. We show that scalar potential games coincide\nwith potential games proposed by \\cite{monderer1996potential}, where the\ngradient descent dynamic can successfully find the Nash equilibrium. For the\nvector potential game, we show that the individual gradient field is\ndivergence-free, in which case the gradient descent dynamic may either be\ndivergent or recurrent.\n","authors":["Nanxiang Zhou","Jing Dong","Yutian Li","Baoxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03799v1","updated":"2024-11-06T09:52:45Z","published":"2024-11-06T09:52:45Z","title":"Overcoming label shift in targeted federated learning","summary":"  Federated learning enables multiple actors to collaboratively train models\nwithout sharing private data. This unlocks the potential for scaling machine\nlearning to diverse applications. Existing algorithms for this task are\nwell-justified when clients and the intended target domain share the same\ndistribution of features and labels, but this assumption is often violated in\nreal-world scenarios. One common violation is label shift, where the label\ndistributions differ across clients or between clients and the target domain,\nwhich can significantly degrade model performance. To address this problem, we\npropose FedPALS, a novel model aggregation scheme that adapts to label shifts\nby leveraging knowledge of the target label distribution at the central server.\nOur approach ensures unbiased updates under stochastic gradient descent,\nensuring robust generalization across clients with diverse, label-shifted data.\nExtensive experiments on image classification demonstrate that FedPALS\nconsistently outperforms standard baselines by aligning model aggregation with\nthe target domain. Our findings reveal that conventional federated learning\nmethods suffer severely in cases of extreme client sparsity, highlighting the\ncritical need for target-aware aggregation. FedPALS offers a principled and\npractical solution to mitigate label distribution mismatch, ensuring models\ntrained in federated settings can generalize effectively to label-shifted\ntarget domains.\n","authors":["Edvin Listo Zec","Adam Breitholtz","Fredrik D. Johansson"],"pdf_url":"https://arxiv.org/pdf/2411.03799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03786v1","updated":"2024-11-06T09:23:50Z","published":"2024-11-06T09:23:50Z","title":"The N-Grammys: Accelerating Autoregressive Inference with Learning-Free\n  Batched Speculation","summary":"  Speculative decoding aims to speed up autoregressive generation of a language\nmodel by verifying in parallel the tokens generated by a smaller draft model.In\nthis work, we explore the effectiveness of learning-free, negligible-cost draft\nstrategies, namely $N$-grams obtained from the model weights and the context.\nWhile the predicted next token of the base model is rarely the top prediction\nof these simple strategies, we observe that it is often within their top-$k$\npredictions for small $k$. Based on this, we show that combinations of simple\nstrategies can achieve significant inference speedups over different tasks. The\noverall performance is comparable to more complex methods, yet does not require\nexpensive preprocessing or modification of the base model, and allows for\nseamless `plug-and-play' integration into pipelines.\n","authors":["Lawrence Stewart","Matthew Trager","Sujan Kumar Gonugondla","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2411.03786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20354v3","updated":"2024-11-06T09:20:35Z","published":"2024-10-27T06:53:46Z","title":"FoldMark: Protecting Protein Generative Models with Watermarking","summary":"  Protein structure is key to understanding protein function and is essential\nfor progress in bioengineering, drug discovery, and molecular biology.\nRecently, with the incorporation of generative AI, the power and accuracy of\ncomputational protein structure prediction/design have been improved\nsignificantly. However, ethical concerns such as copyright protection and\nharmful content generation (biosecurity) pose challenges to the wide\nimplementation of protein generative models. Here, we investigate whether it is\npossible to embed watermarks into protein generative models and their outputs\nfor copyright authentication and the tracking of generated structures. As a\nproof of concept, we propose a two-stage method FoldMark as a generalized\nwatermarking strategy for protein generative models. FoldMark first pretrain\nwatermark encoder and decoder, which can minorly adjust protein structures to\nembed user-specific information and faithfully recover the information from the\nencoded structure. In the second step, protein generative models are fine-tuned\nwith watermark Low-Rank Adaptation (LoRA) modules to preserve generation\nquality while learning to generate watermarked structures with high recovery\nrates. Extensive experiments are conducted on open-source protein structure\nprediction models (e.g., ESMFold and MultiFlow) and de novo structure design\nmodels (e.g., FrameDiff and FoldFlow) and we demonstrate that our method is\neffective across all these generative models. Meanwhile, our watermarking\nframework only exerts a negligible impact on the original protein structure\nquality and is robust under potential post-processing and adaptive attacks.\n","authors":["Zaixi Zhang","Ruofan Jin","Kaidi Fu","Le Cong","Marinka Zitnik","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.20354v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03782v1","updated":"2024-11-06T09:18:05Z","published":"2024-11-06T09:18:05Z","title":"Navigating the landscape of multimodal AI in medicine: a scoping review\n  on technical challenges and clinical applications","summary":"  Recent technological advances in healthcare have led to unprecedented growth\nin patient data quantity and diversity. While artificial intelligence (AI)\nmodels have shown promising results in analyzing individual data modalities,\nthere is increasing recognition that models integrating multiple complementary\ndata sources, so-called multimodal AI, could enhance clinical decision-making.\nThis scoping review examines the landscape of deep learning-based multimodal AI\napplications across the medical domain, analyzing 432 papers published between\n2018 and 2024. We provide an extensive overview of multimodal AI development\nacross different medical disciplines, examining various architectural\napproaches, fusion strategies, and common application areas. Our analysis\nreveals that multimodal AI models consistently outperform their unimodal\ncounterparts, with an average improvement of 6.2 percentage points in AUC.\nHowever, several challenges persist, including cross-departmental coordination,\nheterogeneous data characteristics, and incomplete datasets. We critically\nassess the technical and practical challenges in developing multimodal AI\nsystems and discuss potential strategies for their clinical implementation,\nincluding a brief overview of commercially available multimodal AI models for\nclinical decision-making. Additionally, we identify key factors driving\nmultimodal AI development and propose recommendations to accelerate the field's\nmaturation. This review provides researchers and clinicians with a thorough\nunderstanding of the current state, challenges, and future directions of\nmultimodal AI in medicine.\n","authors":["Daan Schouten","Giulia Nicoletti","Bas Dille","Catherine Chia","Pierpaolo Vendittelli","Megan Schuurmans","Geert Litjens","Nadieh Khalili"],"pdf_url":"https://arxiv.org/pdf/2411.03782v1.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2305.14077v3","updated":"2024-11-06T09:13:37Z","published":"2023-05-23T13:56:29Z","title":"Mind the spikes: Benign overfitting of kernels and neural networks in\n  fixed dimension","summary":"  The success of over-parameterized neural networks trained to near-zero\ntraining error has caused great interest in the phenomenon of benign\noverfitting, where estimators are statistically consistent even though they\ninterpolate noisy training data. While benign overfitting in fixed dimension\nhas been established for some learning methods, current literature suggests\nthat for regression with typical kernel methods and wide neural networks,\nbenign overfitting requires a high-dimensional setting where the dimension\ngrows with the sample size. In this paper, we show that the smoothness of the\nestimators, and not the dimension, is the key: benign overfitting is possible\nif and only if the estimator's derivatives are large enough. We generalize\nexisting inconsistency results to non-interpolating models and more kernels to\nshow that benign overfitting with moderate derivatives is impossible in fixed\ndimension. Conversely, we show that rate-optimal benign overfitting is possible\nfor regression with a sequence of spiky-smooth kernels with large derivatives.\nUsing neural tangent kernels, we translate our results to wide neural networks.\nWe prove that while infinite-width networks do not overfit benignly with the\nReLU activation, this can be fixed by adding small high-frequency fluctuations\nto the activation function. Our experiments verify that such neural networks,\nwhile overfitting, can indeed generalize well even on low-dimensional data\nsets.\n","authors":["Moritz Haas","David Holzmüller","Ulrike von Luxburg","Ingo Steinwart"],"pdf_url":"https://arxiv.org/pdf/2305.14077v3.pdf","comment":"Compared to the NeurIPS version (v2), this version strengthens\n  Assumption (K) from d/2<s<=3d/4 to d/2<s<3d/4 and corrects Lemma B.2 by\n  posing additional assumptions. This does not affect any other statements. We\n  provide Python code to reproduce all of our experimental results at\n  https://github.com/moritzhaas/mind-the-spikes"},{"id":"http://arxiv.org/abs/2411.03223v2","updated":"2024-11-06T09:10:46Z","published":"2024-11-05T16:12:12Z","title":"Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation","summary":"  Earth Observation (EO) data analysis has been significantly revolutionized by\ndeep learning (DL), with applications typically limited to grid-like data\nstructures. Graph Neural Networks (GNNs) emerge as an important innovation,\npropelling DL into the non-Euclidean domain. Naturally, GNNs can effectively\ntackle the challenges posed by diverse modalities, multiple sensors, and the\nheterogeneous nature of EO data. To introduce GNNs in the related domains, our\nreview begins by offering fundamental knowledge on GNNs. Then, we summarize the\ngeneric problems in EO, to which GNNs can offer potential solutions. Following\nthis, we explore a broad spectrum of GNNs' applications to scientific problems\nin Earth systems, covering areas such as weather and climate analysis, disaster\nmanagement, air quality monitoring, agriculture, land cover classification,\nhydrological process modeling, and urban modeling. The rationale behind\nadopting GNNs in these fields is explained, alongside methodologies for\norganizing graphs and designing favorable architectures for various tasks.\nFurthermore, we highlight methodological challenges of implementing GNNs in\nthese domains and possible solutions that could guide future research. While\nacknowledging that GNNs are not a universal solution, we conclude the paper by\ncomparing them with other popular architectures like transformers and analyzing\ntheir potential synergies.\n","authors":["Shan Zhao","Zhaiyu Chen","Zhitong Xiong","Yilei Shi","Sudipan Saha","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.03223v2.pdf","comment":"Accepted for publication in Geoscience and Remote Sensing Magazine\n  (GRSM)"},{"id":"http://arxiv.org/abs/2411.03769v1","updated":"2024-11-06T09:05:17Z","published":"2024-11-06T09:05:17Z","title":"No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with\n  Captions in 28 Languages","summary":"  Research in vision and language has made considerable progress thanks to\nbenchmarks such as COCO. COCO captions focused on unambiguous facts in English;\nArtEmis introduced subjective emotions and ArtELingo introduced some\nmultilinguality (Chinese and Arabic). However we believe there should be more\nmultilinguality. Hence, we present ArtELingo-28, a vision-language benchmark\nthat spans $\\textbf{28}$ languages and encompasses approximately\n$\\textbf{200,000}$ annotations ($\\textbf{140}$ annotations per image).\nTraditionally, vision research focused on unambiguous class labels, whereas\nArtELingo-28 emphasizes diversity of opinions over languages and cultures. The\nchallenge is to build machine learning systems that assign emotional captions\nto images. Baseline results will be presented for three novel conditions:\nZero-Shot, Few-Shot and One-vs-All Zero-Shot. We find that cross-lingual\ntransfer is more successful for culturally-related languages. Data and code are\nprovided at www.artelingo.org.\n","authors":["Youssef Mohamed","Runjia Li","Ibrahim Said Ahmad","Kilichbek Haydarov","Philip Torr","Kenneth Ward Church","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2411.03769v1.pdf","comment":"9 pages, Accepted at EMNLP 24, for more details see www.artelingo.org"},{"id":"http://arxiv.org/abs/2411.03768v1","updated":"2024-11-06T09:04:13Z","published":"2024-11-06T09:04:13Z","title":"A Bayesian Approach to Data Point Selection","summary":"  Data point selection (DPS) is becoming a critical topic in deep learning due\nto the ease of acquiring uncurated training data compared to the difficulty of\nobtaining curated or processed data. Existing approaches to DPS are\npredominantly based on a bi-level optimisation (BLO) formulation, which is\ndemanding in terms of memory and computation, and exhibits some theoretical\ndefects regarding minibatches. Thus, we propose a novel Bayesian approach to\nDPS. We view the DPS problem as posterior inference in a novel Bayesian model\nwhere the posterior distributions of the instance-wise weights and the main\nneural network parameters are inferred under a reasonable prior and likelihood\nmodel. We employ stochastic gradient Langevin MCMC sampling to learn the main\nnetwork and instance-wise weights jointly, ensuring convergence even with\nminibatches. Our update equation is comparable to the widely used SGD and much\nmore efficient than existing BLO-based methods. Through controlled experiments\nin both the vision and language domains, we present the proof-of-concept.\nAdditionally, we demonstrate that our method scales effectively to large\nlanguage models and facilitates automated per-task optimization for instruction\nfine-tuning datasets.\n","authors":["Xinnuo Xu","Minyoung Kim","Royson Lee","Brais Martinez","Timothy Hospedales"],"pdf_url":"https://arxiv.org/pdf/2411.03768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04803v2","updated":"2024-11-06T09:00:41Z","published":"2024-10-07T07:27:39Z","title":"Timer-XL: Long-Context Transformers for Unified Time Series Forecasting","summary":"  We present Timer-XL, a generative Transformer for unified time series\nforecasting. To uniformly predict 1D and 2D time series, we generalize next\ntoken prediction, predominantly adopted for causal generation of 1D sequences,\nto multivariate next token prediction. The proposed paradigm uniformly\nformulates various forecasting scenarios as a long-context generation problem.\nWe opt for the generative Transformer, which can capture global-range and\ncausal dependencies while providing contextual flexibility, to implement\nunified forecasting on univariate series characterized by non-stationarity,\nmultivariate time series with complicated dynamics and correlations, and\ncovariate-informed contexts that include both endogenous and exogenous\nvariables. Technically, we propose a universal TimeAttention to facilitate\ngenerative Transformers on time series, which can effectively capture\nfine-grained intra- and inter-series dependencies of flattened time series\ntokens (patches) and is further strengthened by position embeddings in both\ntemporal and variable dimensions. Timer-XL achieves state-of-the-art\nperformance across challenging forecasting benchmarks through a unified\napproach. As a large time series model, it demonstrates notable model\ntransferability by large-scale pre-training, as well as contextual flexibility\nin token lengths, positioning it as a one-for-all forecaster.\n","authors":["Yong Liu","Guo Qin","Xiangdong Huang","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2410.04803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21052v2","updated":"2024-11-06T08:44:03Z","published":"2024-10-28T14:07:41Z","title":"Getting By Goal Misgeneralization With a Little Help From a Mentor","summary":"  While reinforcement learning (RL) agents often perform well during training,\nthey can struggle with distribution shift in real-world deployments. One\nparticularly severe risk of distribution shift is goal misgeneralization, where\nthe agent learns a proxy goal that coincides with the true goal during training\nbut not during deployment. In this paper, we explore whether allowing an agent\nto ask for help from a supervisor in unfamiliar situations can mitigate this\nissue. We focus on agents trained with PPO in the CoinRun environment, a\nsetting known to exhibit goal misgeneralization. We evaluate multiple methods\nfor determining when the agent should request help and find that asking for\nhelp consistently improves performance. However, we also find that methods\nbased on the agent's internal state fail to proactively request help, instead\nwaiting until mistakes have already occurred. Further investigation suggests\nthat the agent's internal state does not represent the coin at all,\nhighlighting the importance of learning nuanced representations, the risks of\nignoring everything not immediately relevant to reward, and the necessity of\ndeveloping ask-for-help strategies tailored to the agent's training algorithm.\n","authors":["Tu Trinh","Mohamad H. Danesh","Nguyen X. Khanh","Benjamin Plaut"],"pdf_url":"https://arxiv.org/pdf/2410.21052v2.pdf","comment":"SATA Workshop @ NeurIPS 2024 (Towards Safe and Trustworthy Agents)"},{"id":"http://arxiv.org/abs/2411.03759v1","updated":"2024-11-06T08:42:53Z","published":"2024-11-06T08:42:53Z","title":"Variational Inference on the Boolean Hypercube with the Quantum Entropy","summary":"  In this paper, we derive variational inference upper-bounds on the\nlog-partition function of pairwise Markov random fields on the Boolean\nhypercube, based on quantum relaxations of the Kullback-Leibler divergence. We\nthen propose an efficient algorithm to compute these bounds based on\nprimal-dual optimization. An improvement of these bounds through the use of\n''hierarchies,'' similar to sum-of-squares (SoS) hierarchies is proposed, and\nwe present a greedy algorithm to select among these relaxations. We carry\nextensive numerical experiments and compare with state-of-the-art methods for\nthis inference problem.\n","authors":["Eliot Beyler","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2411.03759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01220v2","updated":"2024-11-06T08:42:09Z","published":"2024-11-02T11:42:23Z","title":"Enhancing Neural Network Interpretability with Feature-Aligned Sparse\n  Autoencoders","summary":"  Sparse Autoencoders (SAEs) have shown promise in improving the\ninterpretability of neural network activations, but can learn features that are\nnot features of the input, limiting their effectiveness. We propose\n\\textsc{Mutual Feature Regularization} \\textbf{(MFR)}, a regularization\ntechnique for improving feature learning by encouraging SAEs trained in\nparallel to learn similar features. We motivate \\textsc{MFR} by showing that\nfeatures learned by multiple SAEs are more likely to correlate with features of\nthe input. By training on synthetic data with known features of the input, we\nshow that \\textsc{MFR} can help SAEs learn those features, as we can directly\ncompare the features learned by the SAE with the input features for the\nsynthetic data. We then scale \\textsc{MFR} to SAEs that are trained to denoise\nelectroencephalography (EEG) data and SAEs that are trained to reconstruct\nGPT-2 Small activations. We show that \\textsc{MFR} can improve the\nreconstruction loss of SAEs by up to 21.21\\% on GPT-2 Small, and 6.67\\% on EEG\ndata. Our results suggest that the similarity between features learned by\ndifferent SAEs can be leveraged to improve SAE training, thereby enhancing\nperformance and the usefulness of SAEs for model interpretability.\n","authors":["Luke Marks","Alasdair Paren","David Krueger","Fazl Barez"],"pdf_url":"https://arxiv.org/pdf/2411.01220v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07447v3","updated":"2024-11-06T08:38:14Z","published":"2024-03-12T09:37:22Z","title":"Ab-initio variational wave functions for the time-dependent\n  many-electron Schrödinger equation","summary":"  Understanding the real-time evolution of many-electron quantum systems is\nessential for studying dynamical properties in condensed matter, quantum\nchemistry, and complex materials, yet it poses a significant theoretical and\ncomputational challenge. Our work introduces a variational approach for\nfermionic time-dependent wave functions, surpassing mean-field approximations\nby accurately capturing many-body correlations. Therefore, we employ\ntime-dependent Jastrow factors and backflow transformations, which are enhanced\nthrough neural networks parameterizations. To compute the optimal\ntime-dependent parameters, we utilize the time-dependent variational Monte\nCarlo technique and a new method based on Taylor-root expansions of the\npropagator, enhancing the accuracy of our simulations. The approach is\ndemonstrated in three distinct systems. In all cases, we show clear signatures\nof many-body correlations in the dynamics. The results showcase the ability of\nour variational approach to accurately capture the time evolution, providing\ninsight into the quantum dynamics of interacting electronic systems, beyond the\ncapabilities of mean-field.\n","authors":["Jannes Nys","Gabriel Pescia","Alessandro Sinibaldi","Giuseppe Carleo"],"pdf_url":"https://arxiv.org/pdf/2403.07447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03755v1","updated":"2024-11-06T08:30:23Z","published":"2024-11-06T08:30:23Z","title":"Content-Style Learning from Unaligned Domains: Identifiability under\n  Unknown Latent Dimensions","summary":"  Understanding identifiability of latent content and style variables from\nunaligned multi-domain data is essential for tasks such as domain translation\nand data generation. Existing works on content-style identification were often\ndeveloped under somewhat stringent conditions, e.g., that all latent components\nare mutually independent and that the dimensions of the content and style\nvariables are known. We introduce a new analytical framework via cross-domain\n\\textit{latent distribution matching} (LDM), which establishes content-style\nidentifiability under substantially more relaxed conditions. Specifically, we\nshow that restrictive assumptions such as component-wise independence of the\nlatent variables can be removed. Most notably, we prove that prior knowledge of\nthe content and style dimensions is not necessary for ensuring identifiability,\nif sparsity constraints are properly imposed onto the learned latent\nrepresentations. Bypassing the knowledge of the exact latent dimension has been\na longstanding aspiration in unsupervised representation learning -- our\nanalysis is the first to underpin its theoretical and practical viability. On\nthe implementation side, we recast the LDM formulation into a regularized\nmulti-domain GAN loss with coupled latent variables. We show that the\nreformulation is equivalent to LDM under mild conditions -- yet requiring\nconsiderably less computational resource. Experiments corroborate with our\ntheoretical claims.\n","authors":["Sagar Shrestha","Xiao Fu"],"pdf_url":"https://arxiv.org/pdf/2411.03755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03753v1","updated":"2024-11-06T08:29:46Z","published":"2024-11-06T08:29:46Z","title":"Symbolic regression via MDLformer-guided search: from minimizing\n  prediction error to minimizing description length","summary":"  Symbolic regression, a task discovering the formula best fitting the given\ndata, is typically based on the heuristical search. These methods usually\nupdate candidate formulas to obtain new ones with lower prediction errors\niteratively. However, since formulas with similar function shapes may have\ncompletely different symbolic forms, the prediction error does not decrease\nmonotonously as the search approaches the target formula, causing the low\nrecovery rate of existing methods. To solve this problem, we propose a novel\nsearch objective based on the minimum description length, which reflects the\ndistance from the target and decreases monotonically as the search approaches\nthe correct form of the target formula. To estimate the minimum description\nlength of any input data, we design a neural network, MDLformer, which enables\nrobust and scalable estimation through large-scale training. With the\nMDLformer's output as the search objective, we implement a symbolic regression\nmethod, SR4MDL, that can effectively recover the correct mathematical form of\nthe formula. Extensive experiments illustrate its excellent performance in\nrecovering formulas from data. Our method successfully recovers around 50\nformulas across two benchmark datasets comprising 133 problems, outperforming\nstate-of-the-art methods by 43.92%.\n","authors":["Zihan Yu","Jingtao Ding","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2411.03753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03752v1","updated":"2024-11-06T08:27:49Z","published":"2024-11-06T08:27:49Z","title":"Deferred Poisoning: Making the Model More Vulnerable via Hessian\n  Singularization","summary":"  Recent studies have shown that deep learning models are very vulnerable to\npoisoning attacks. Many defense methods have been proposed to address this\nissue. However, traditional poisoning attacks are not as threatening as\ncommonly believed. This is because they often cause differences in how the\nmodel performs on the training set compared to the validation set. Such\ninconsistency can alert defenders that their data has been poisoned, allowing\nthem to take the necessary defensive actions. In this paper, we introduce a\nmore threatening type of poisoning attack called the Deferred Poisoning Attack.\nThis new attack allows the model to function normally during the training and\nvalidation phases but makes it very sensitive to evasion attacks or even\nnatural noise. We achieve this by ensuring the poisoned model's loss function\nhas a similar value as a normally trained model at each input sample but with a\nlarge local curvature. A similar model loss ensures that there is no obvious\ninconsistency between the training and validation accuracy, demonstrating high\nstealthiness. On the other hand, the large curvature implies that a small\nperturbation may cause a significant increase in model loss, leading to\nsubstantial performance degradation, which reflects a worse robustness. We\nfulfill this purpose by making the model have singular Hessian information at\nthe optimal point via our proposed Singularization Regularization term. We have\nconducted both theoretical and empirical analyses of the proposed method and\nvalidated its effectiveness through experiments on image classification tasks.\nFurthermore, we have confirmed the hazards of this form of poisoning attack\nunder more general scenarios using natural noise, offering a new perspective\nfor research in the field of security.\n","authors":["Yuhao He","Jinyu Tian","Xianwei Zheng","Li Dong","Yuanman Li","Leo Yu Zhang","Jiantao Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.03752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03746v1","updated":"2024-11-06T08:22:20Z","published":"2024-11-06T08:22:20Z","title":"Optimal Defenses Against Gradient Reconstruction Attacks","summary":"  Federated Learning (FL) is designed to prevent data leakage through\ncollaborative model training without centralized data storage. However, it\nremains vulnerable to gradient reconstruction attacks that recover original\ntraining data from shared gradients. To optimize the trade-off between data\nleakage and utility loss, we first derive a theoretical lower bound of\nreconstruction error (among all attackers) for the two standard methods: adding\nnoise, and gradient pruning. We then customize these two defenses to be\nparameter- and model-specific and achieve the optimal trade-off between our\nobtained reconstruction lower bound and model utility. Experimental results\nvalidate that our methods outperform Gradient Noise and Gradient Pruning by\nprotecting the training data better while also achieving better utility.\n","authors":["Yuxiao Chen","Gamze Gürsoy","Qi Lei"],"pdf_url":"https://arxiv.org/pdf/2411.03746v1.pdf","comment":"The code for this project is available at\n  https://github.com/cyx78/Optimal_Defenses_Against_Gradient_Reconstruction_Attacks"},{"id":"http://arxiv.org/abs/2411.03744v1","updated":"2024-11-06T08:21:26Z","published":"2024-11-06T08:21:26Z","title":"Graph Neural Networks with Coarse- and Fine-Grained Division for\n  Mitigating Label Sparsity and Noise","summary":"  Graph Neural Networks (GNNs) have gained considerable prominence in\nsemi-supervised learning tasks in processing graph-structured data, primarily\nowing to their message-passing mechanism, which largely relies on the\navailability of clean labels. However, in real-world scenarios, labels on nodes\nof graphs are inevitably noisy and sparsely labeled, significantly degrading\nthe performance of GNNs. Exploring robust GNNs for semi-supervised node\nclassification in the presence of noisy and sparse labels remains a critical\nchallenge. Therefore, we propose a novel \\textbf{G}raph \\textbf{N}eural\n\\textbf{N}etwork with \\textbf{C}oarse- and \\textbf{F}ine-\\textbf{G}rained\n\\textbf{D}ivision for mitigating label sparsity and noise, namely GNN-CFGD. The\nkey idea of GNN-CFGD is reducing the negative impact of noisy labels via\ncoarse- and fine-grained division, along with graph reconstruction.\nSpecifically, we first investigate the effectiveness of linking unlabeled nodes\nto cleanly labeled nodes, demonstrating that this approach is more effective in\ncombating labeling noise than linking to potentially noisy labeled nodes. Based\non this observation, we introduce a Gaussian Mixture Model (GMM) based on the\nmemory effect to perform a coarse-grained division of the given labels into\nclean and noisy labels. Next, we propose a clean labels oriented link that\nconnects unlabeled nodes to cleanly labeled nodes, aimed at mitigating label\nsparsity and promoting supervision propagation. Furthermore, to provide refined\nsupervision for noisy labeled nodes and additional supervision for unlabeled\nnodes, we fine-grain the noisy labeled and unlabeled nodes into two candidate\nsets based on confidence, respectively. Extensive experiments on various\ndatasets demonstrate the superior effectiveness and robustness of GNN-CFGD.\n","authors":["Shuangjie Li","Baoming Zhang","Jianqing Song","Gaoli Ruan","Chongjun Wang","Junyuan Xie"],"pdf_url":"https://arxiv.org/pdf/2411.03744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03742v1","updated":"2024-11-06T08:16:39Z","published":"2024-11-06T08:16:39Z","title":"Adaptive Consensus Gradients Aggregation for Scaled Distributed Training","summary":"  Distributed machine learning has recently become a critical paradigm for\ntraining large models on vast datasets. We examine the stochastic optimization\nproblem for deep learning within synchronous parallel computing environments\nunder communication constraints. While averaging distributed gradients is the\nmost widely used method for gradient estimation, whether this is the optimal\nstrategy remains an open question. In this work, we analyze the distributed\ngradient aggregation process through the lens of subspace optimization. By\nformulating the aggregation problem as an objective-aware subspace optimization\nproblem, we derive an efficient weighting scheme for gradients, guided by\nsubspace coefficients. We further introduce subspace momentum to accelerate\nconvergence while maintaining statistical unbiasedness in the aggregation. Our\nmethod demonstrates improved performance over the ubiquitous gradient averaging\non multiple MLPerf tasks while remaining extremely efficient in both\ncommunicational and computational complexity.\n","authors":["Yoni Choukroun","Shlomi Azoulay","Pavel Kisilev"],"pdf_url":"https://arxiv.org/pdf/2411.03742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03740v1","updated":"2024-11-06T08:13:09Z","published":"2024-11-06T08:13:09Z","title":"Human-in-the-Loop Feature Selection Using Interpretable\n  Kolmogorov-Arnold Network-based Double Deep Q-Network","summary":"  Feature selection is critical for improving the performance and\ninterpretability of machine learning models, particularly in high-dimensional\nspaces where complex feature interactions can reduce accuracy and increase\ncomputational demands. Existing approaches often rely on static feature subsets\nor manual intervention, limiting adaptability and scalability. However,\ndynamic, per-instance feature selection methods and model-specific\ninterpretability in reinforcement learning remain underexplored. This study\nproposes a human-in-the-loop (HITL) feature selection framework integrated into\na Double Deep Q-Network (DDQN) using a Kolmogorov-Arnold Network (KAN). Our\nnovel approach leverages simulated human feedback and stochastic\ndistribution-based sampling, specifically Beta, to iteratively refine feature\nsubsets per data instance, improving flexibility in feature selection. The\nKAN-DDQN achieved notable test accuracies of 93% on MNIST and 83% on\nFashionMNIST, outperforming conventional MLP-DDQN models by up to 9%. The\nKAN-based model provided high interpretability via symbolic representation\nwhile using 4 times fewer neurons in the hidden layer than MLPs did.\nComparatively, the models without feature selection achieved test accuracies of\nonly 58% on MNIST and 64% on FashionMNIST, highlighting significant gains with\nour framework. Pruning and visualization further enhanced model transparency by\nelucidating decision pathways. These findings present a scalable, interpretable\nsolution for feature selection that is suitable for applications requiring\nreal-time, adaptive decision-making with minimal human oversight.\n","authors":["Md Abrar Jahin","M. F. Mridha","Nilanjan Dey"],"pdf_url":"https://arxiv.org/pdf/2411.03740v1.pdf","comment":"Submitted to a journal under IEEE Transactions series"},{"id":"http://arxiv.org/abs/2302.02420v5","updated":"2024-11-06T07:58:39Z","published":"2023-02-05T16:19:01Z","title":"Variational Inference on the Final-Layer Output of Neural Networks","summary":"  Traditional neural networks are simple to train but they typically produce\noverconfident predictions. In contrast, Bayesian neural networks provide good\nuncertainty quantification but optimizing them is time consuming due to the\nlarge parameter space. This paper proposes to combine the advantages of both\napproaches by performing Variational Inference in the Final layer Output space\n(VIFO), because the output space is much smaller than the parameter space. We\nuse neural networks to learn the mean and the variance of the probabilistic\noutput. Using the Bayesian formulation we incorporate collapsed variational\ninference with VIFO which significantly improves the performance in practice.\nOn the other hand, like standard, non-Bayesian models, VIFO enjoys simple\ntraining and one can use Rademacher complexity to provide risk bounds for the\nmodel. Experiments show that VIFO provides a good tradeoff in terms of run time\nand uncertainty quantification, especially for out of distribution data.\n","authors":["Yadi Wei","Roni Khardon"],"pdf_url":"https://arxiv.org/pdf/2302.02420v5.pdf","comment":"Published to TMLR"},{"id":"http://arxiv.org/abs/2411.03731v1","updated":"2024-11-06T07:53:04Z","published":"2024-11-06T07:53:04Z","title":"Reducing Hyperparameter Tuning Costs in ML, Vision and Language Model\n  Training Pipelines via Memoization-Awareness","summary":"  The training or fine-tuning of machine learning, vision, and language models\nis often implemented as a pipeline: a sequence of stages encompassing data\npreparation, model training and evaluation. In this paper, we exploit pipeline\nstructures to reduce the cost of hyperparameter tuning for model\ntraining/fine-tuning, which is particularly valuable for language models given\ntheir high costs in GPU-days. We propose a \"memoization-aware\" Bayesian\nOptimization (BO) algorithm, EEIPU, that works in tandem with a pipeline\ncaching system, allowing it to evaluate significantly more hyperparameter\ncandidates per GPU-day than other tuning algorithms. The result is\nbetter-quality hyperparameters in the same amount of search time, or\nequivalently, reduced search time to reach the same hyperparameter quality. In\nour benchmarks on machine learning (model ensembles), vision (convolutional\narchitecture) and language (T5 architecture) pipelines, we compare EEIPU\nagainst recent BO algorithms: EEIPU produces an average of $103\\%$ more\nhyperparameter candidates (within the same budget), and increases the\nvalidation metric by an average of $108\\%$ more than other algorithms (where\nthe increase is measured starting from the end of warm-up iterations).\n","authors":["Abdelmajid Essofi","Ridwan Salahuddeen","Munachiso Nwadike","Elnura Zhalieva","Kun Zhang","Eric Xing","Willie Neiswanger","Qirong Ho"],"pdf_url":"https://arxiv.org/pdf/2411.03731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03730v1","updated":"2024-11-06T07:51:19Z","published":"2024-11-06T07:51:19Z","title":"NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document\n  VQA","summary":"  The Privacy Preserving Federated Learning Document VQA (PFL-DocVQA)\ncompetition challenged the community to develop provably private and\ncommunication-efficient solutions in a federated setting for a real-life use\ncase: invoice processing. The competition introduced a dataset of real invoice\ndocuments, along with associated questions and answers requiring information\nextraction and reasoning over the document images. Thereby, it brings together\nresearchers and expertise from the document analysis, privacy, and federated\nlearning communities. Participants fine-tuned a pre-trained, state-of-the-art\nDocument Visual Question Answering model provided by the organizers for this\nnew domain, mimicking a typical federated invoice processing setup. The base\nmodel is a multi-modal generative language model, and sensitive information\ncould be exposed through either the visual or textual input modality.\nParticipants proposed elegant solutions to reduce communication costs while\nmaintaining a minimum utility threshold in track 1 and to protect all\ninformation from each document provider using differential privacy in track 2.\nThe competition served as a new testbed for developing and testing private\nfederated learning methods, simultaneously raising awareness about privacy\nwithin the document image analysis and recognition community. Ultimately, the\ncompetition analysis provides best practices and recommendations for\nsuccessfully running privacy-focused federated learning challenges in the\nfuture.\n","authors":["Marlon Tobaben","Mohamed Ali Souibgui","Rubèn Tito","Khanh Nguyen","Raouf Kerkouche","Kangsoo Jung","Joonas Jälkö","Lei Kang","Andrey Barsky","Vincent Poulain d'Andecy","Aurélie Joseph","Aashiq Muhamed","Kevin Kuo","Virginia Smith","Yusuke Yamasaki","Takumi Fukami","Kenta Niwa","Iifan Tyou","Hiro Ishii","Rio Yokota","Ragul N","Rintu Kutum","Josep Llados","Ernest Valveny","Antti Honkela","Mario Fritz","Dimosthenis Karatzas"],"pdf_url":"https://arxiv.org/pdf/2411.03730v1.pdf","comment":"27 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.03726v1","updated":"2024-11-06T07:44:14Z","published":"2024-11-06T07:44:14Z","title":"PropNEAT -- Efficient GPU-Compatible Backpropagation over\n  NeuroEvolutionary Augmenting Topology Networks","summary":"  We introduce PropNEAT, a fast backpropagation implementation of NEAT that\nuses a bidirectional mapping of the genome graph to a layer-based architecture\nthat preserves the NEAT genomes whilst enabling efficient GPU backpropagation.\nWe test PropNEAT on 58 binary classification datasets from the Penn Machine\nLearning Benchmarks database, comparing the performance against logistic\nregression, dense neural networks and random forests, as well as a densely\nretrained variant of the final PropNEAT model. PropNEAT had the second best\noverall performance, behind Random Forest, though the difference between the\nmodels was not statistically significant apart from between Random Forest in\ncomparison with logistic regression and the PropNEAT retrain models. PropNEAT\nwas substantially faster than a naive backpropagation method, and both were\nsubstantially faster and had better performance than the original NEAT\nimplementation. We demonstrate that the per-epoch training time for PropNEAT\nscales linearly with network depth, and is efficient on GPU implementations for\nbackpropagation. This implementation could be extended to support reinforcement\nlearning or convolutional networks, and is able to find sparser and smaller\nnetworks with potential for applications in low-power contexts.\n","authors":["Michael Merry","Patricia Riddle","Jim Warren"],"pdf_url":"https://arxiv.org/pdf/2411.03726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11559v3","updated":"2024-11-06T07:39:22Z","published":"2024-10-15T12:49:24Z","title":"Why Go Full? Elevating Federated Learning Through Partial Network\n  Updates","summary":"  Federated learning is a distributed machine learning paradigm designed to\nprotect user data privacy, which has been successfully implemented across\nvarious scenarios. In traditional federated learning, the entire parameter set\nof local models is updated and averaged in each training round. Although this\nfull network update method maximizes knowledge acquisition and sharing for each\nmodel layer, it prevents the layers of the global model from cooperating\neffectively to complete the tasks of each client, a challenge we refer to as\nlayer mismatch. This mismatch problem recurs after every parameter averaging,\nconsequently slowing down model convergence and degrading overall performance.\nTo address the layer mismatch issue, we introduce the FedPart method, which\nrestricts model updates to either a single layer or a few layers during each\ncommunication round. Furthermore, to maintain the efficiency of knowledge\nacquisition and sharing, we develop several strategies to select trainable\nlayers in each round, including sequential updating and multi-round cycle\ntraining. Through both theoretical analysis and experiments, our findings\ndemonstrate that the FedPart method significantly surpasses conventional full\nnetwork update strategies in terms of convergence speed and accuracy, while\nalso reducing communication and computational overheads.\n","authors":["Haolin Wang","Xuefeng Liu","Jianwei Niu","Wenkai Guo","Shaojie Tang"],"pdf_url":"https://arxiv.org/pdf/2410.11559v3.pdf","comment":"27 pages, 8 figures, accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.08081v3","updated":"2024-11-06T07:31:28Z","published":"2024-10-10T16:25:34Z","title":"Packing Analysis: Packing Is More Appropriate for Large Models or\n  Datasets in Supervised Fine-tuning","summary":"  Packing, initially utilized in the pre-training phase, is an optimization\ntechnique designed to maximize hardware resource efficiency by combining\ndifferent training sequences to fit the model's maximum input length. Although\nit has demonstrated effectiveness during pre-training, there remains a lack of\ncomprehensive analysis for the supervised fine-tuning (SFT) stage on the\nfollowing points: (1) whether packing can effectively enhance training\nefficiency while maintaining performance, (2) the suitable size of the model\nand dataset for fine-tuning with the packing method, and (3) whether packing\nunrelated or related training samples might cause the model to either\nexcessively disregard or over-rely on the context.\n  In this paper, we perform extensive comparisons between SFT methods using\npadding and packing, covering SFT datasets ranging from 69K to 1.2M and models\nfrom 8B to 70B. This provides the first comprehensive analysis of the\nadvantages and limitations of packing versus padding, as well as practical\nconsiderations for implementing packing in various training scenarios. Our\nanalysis covers various benchmarks, including knowledge, reasoning, and coding,\nas well as GPT-based evaluations, time efficiency, and other fine-tuning\nparameters. We also open-source our code for fine-tuning and evaluation and\nprovide checkpoints fine-tuned on datasets of different sizes, aiming to\nadvance future research on packing methods. Code is available at:\nhttps://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-file.\n","authors":["Shuhe Wang","Guoyin Wang","Yizhong Wang","Jiwei Li","Eduard Hovy","Chen Guo"],"pdf_url":"https://arxiv.org/pdf/2410.08081v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18595v2","updated":"2024-11-06T07:28:12Z","published":"2024-02-25T09:35:30Z","title":"EncodingNet: A Novel Encoding-based MAC Design for Efficient Neural\n  Network Acceleration","summary":"  Deep neural networks (DNNs) have achieved great breakthroughs in many fields\nsuch as image classification and natural language processing. However, the\nexecution of DNNs needs to conduct massive numbers of multiply-accumulate (MAC)\noperations on hardware and thus incurs a large power consumption. To address\nthis challenge, we propose a novel digital MAC design based on encoding. In\nthis new design, the multipliers are replaced by simple logic gates to\nrepresent the results with a wide bit representation. The outputs of the new\nmultipliers are added by bit-wise weighted accumulation and the accumulation\nresults are compatible with existing computing platforms accelerating neural\nnetworks. Since the multiplication function is replaced by a simple logic\nrepresentation, the critical paths in the resulting circuits become much\nshorter. Correspondingly, pipelining stages and intermediate registers used to\nstore partial sums in the MAC array can be reduced, leading to a significantly\nsmaller area as well as better power efficiency. The proposed design has been\nsynthesized and verified by ResNet18- Cifar10, ResNet20-Cifar100,\nResNet50-ImageNet, MobileNetV2-Cifar10, MobileNetV2-Cifar100, and\nEfficientNetB0-ImageNet. The experimental results confirmed the reduction of\ncircuit area by up to 48.79% and the reduction of power consumption of\nexecuting DNNs by up to 64.41%, while the accuracy of the neural networks can\nstill be well maintained. The open source code of this work can be found on\nGitHub with link https://github.com/Bo-Liu-TUM/EncodingNet/.\n","authors":["Bo Liu","Grace Li Zhang","Xunzhao Yin","Ulf Schlichtmann","Bing Li"],"pdf_url":"https://arxiv.org/pdf/2402.18595v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03713v1","updated":"2024-11-06T07:27:55Z","published":"2024-11-06T07:27:55Z","title":"Generalized Trusted Multi-view Classification Framework with\n  Hierarchical Opinion Aggregation","summary":"  Recently, multi-view learning has witnessed a considerable interest on the\nresearch of trusted decision-making. Previous methods are mainly inspired from\nan important paper published by Han et al. in 2021, which formulates a Trusted\nMulti-view Classification (TMC) framework that aggregates evidence from\ndifferent views based on Dempster's combination rule. All these methods only\nconsider inter-view aggregation, yet lacking exploitation of intra-view\ninformation. In this paper, we propose a generalized trusted multi-view\nclassification framework with hierarchical opinion aggregation. This\nhierarchical framework includes a two-phase aggregation process: the intra-view\nand inter-view aggregation hierarchies. In the intra aggregation, we assume\nthat each view is comprised of common information shared with other views, as\nwell as its specific information. We then aggregate both the common and\nspecific information. This aggregation phase is useful to eliminate the feature\nnoise inherent to view itself, thereby improving the view quality. In the\ninter-view aggregation, we design an attention mechanism at the evidence level\nto facilitate opinion aggregation from different views. To the best of our\nknowledge, this is one of the pioneering efforts to formulate a hierarchical\naggregation framework in the trusted multi-view learning domain. Extensive\nexperiments show that our model outperforms some state-of-art trust-related\nbaselines.\n","authors":["Long Shi","Chuanqing Tang","Huangyi Deng","Cai Xu","Lei Xing","Badong Chen"],"pdf_url":"https://arxiv.org/pdf/2411.03713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07624v3","updated":"2024-11-06T06:51:56Z","published":"2023-12-12T06:35:56Z","title":"A dynamical clipping approach with task feedback for Proximal Policy\n  Optimization","summary":"  Proximal Policy Optimization (PPO) has been broadly applied to robotics\nlearning, showcasing stable training performance. However, the fixed clipping\nbound setting may limit the performance of PPO. Specifically, there is no\ntheoretical proof that the optimal clipping bound remains consistent throughout\nthe entire training process. Meanwhile, previous researches suggest that a\nfixed clipping bound restricts the policy's ability to explore. Therefore, many\npast studies have aimed to dynamically adjust the PPO clipping bound to enhance\nPPO's performance. However, the objective of these approaches are not directly\naligned with the objective of reinforcement learning (RL) tasks, which is to\nmaximize the cumulative Return. Unlike previous clipping approaches, we propose\na bi-level proximal policy optimization objective that can dynamically adjust\nthe clipping bound to better reflect the preference (maximizing Return) of\nthese RL tasks. Based on this bi-level proximal policy optimization paradigm,\nwe introduce a new algorithm named Preference based Proximal Policy\nOptimization (Pb-PPO). Pb-PPO utilizes a multi-armed bandit approach to\nrefelect RL preference, recommending the clipping bound for PPO that can\nmaximizes the current Return. Therefore, Pb-PPO results in greater stability\nand improved performance compared to PPO with a fixed clipping bound. We test\nPb-PPO on locomotion benchmarks across multiple environments, including\nGym-Mujoco and legged-gym. Additionally, we validate Pb-PPO on customized\nnavigation tasks. Meanwhile, we conducted comparisons with PPO using various\nfixed clipping bounds and various of clipping approaches. The experimental\nresults indicate that Pb-PPO demonstrates superior training performance\ncompared to PPO and its variants. Our codebase has been released at :\nhttps://github.com/stevezhangzA/pb_ppo\n","authors":["Ziqi Zhang","Jingzehua Xu","Zifeng Zhuang","Hongyin Zhang","Jinxin Liu","Donglin wang","Shuai Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.07624v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03687v1","updated":"2024-11-06T06:13:57Z","published":"2024-11-06T06:13:57Z","title":"Beyond Model Adaptation at Test Time: A Survey","summary":"  Machine learning algorithms have achieved remarkable success across various\ndisciplines, use cases and applications, under the prevailing assumption that\ntraining and test samples are drawn from the same distribution. Consequently,\nthese algorithms struggle and become brittle even when samples in the test\ndistribution start to deviate from the ones observed during training. Domain\nadaptation and domain generalization have been studied extensively as\napproaches to address distribution shifts across test and train domains, but\neach has its limitations. Test-time adaptation, a recently emerging learning\nparadigm, combines the benefits of domain adaptation and domain generalization\nby training models only on source data and adapting them to target data during\ntest-time inference. In this survey, we provide a comprehensive and systematic\nreview on test-time adaptation, covering more than 400 recent papers. We\nstructure our review by categorizing existing methods into five distinct\ncategories based on what component of the method is adjusted for test-time\nadaptation: the model, the inference, the normalization, the sample, or the\nprompt, providing detailed analysis of each. We further discuss the various\npreparation and adaptation settings for methods within these categories,\noffering deeper insights into the effective deployment for the evaluation of\ndistribution shifts and their real-world application in understanding images,\nvideo and 3D, as well as modalities beyond vision. We close the survey with an\noutlook on emerging research opportunities for test-time adaptation.\n","authors":["Zehao Xiao","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2411.03687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15750v2","updated":"2024-11-06T06:11:46Z","published":"2024-09-24T05:12:10Z","title":"The Roles of Generative Artificial Intelligence in Internet of Electric\n  Vehicles","summary":"  With the advancements of generative artificial intelligence (GenAI) models,\ntheir capabilities are expanding significantly beyond content generation and\nthe models are increasingly being used across diverse applications.\nParticularly, GenAI shows great potential in addressing challenges in the\nelectric vehicle (EV) ecosystem ranging from charging management to\ncyber-attack prevention. In this paper, we specifically consider Internet of\nelectric vehicles (IoEV) and we categorize GenAI for IoEV into four different\nlayers namely, EV's battery layer, individual EV layer, smart grid layer, and\nsecurity layer. We introduce various GenAI techniques used in each layer of\nIoEV applications. Subsequently, public datasets available for training the\nGenAI models are summarized. Finally, we provide recommendations for future\ndirections. This survey not only categorizes the applications of GenAI in IoEV\nacross different layers but also serves as a valuable resource for researchers\nand practitioners by highlighting the design and implementation challenges\nwithin each layer. Furthermore, it provides a roadmap for future research\ndirections, enabling the development of more robust and efficient IoEV systems\nthrough the integration of advanced GenAI techniques.\n","authors":["Hanwen Zhang","Dusit Niyato","Wei Zhang","Changyuan Zhao","Hongyang Du","Abbas Jamalipour","Sumei Sun","Yiyang Pei"],"pdf_url":"https://arxiv.org/pdf/2409.15750v2.pdf","comment":"25 Pages"},{"id":"http://arxiv.org/abs/2411.03678v1","updated":"2024-11-06T05:57:28Z","published":"2024-11-06T05:57:28Z","title":"Multi-model Ensemble Conformal Prediction in Dynamic Environments","summary":"  Conformal prediction is an uncertainty quantification method that constructs\na prediction set for a previously unseen datum, ensuring the true label is\nincluded with a predetermined coverage probability. Adaptive conformal\nprediction has been developed to address data distribution shifts in dynamic\nenvironments. However, the efficiency of prediction sets varies depending on\nthe learning model used. Employing a single fixed model may not consistently\noffer the best performance in dynamic environments with unknown data\ndistribution shifts. To address this issue, we introduce a novel adaptive\nconformal prediction framework, where the model used for creating prediction\nsets is selected on the fly from multiple candidate models. The proposed\nalgorithm is proven to achieve strongly adaptive regret over all intervals\nwhile maintaining valid coverage. Experiments on real and synthetic datasets\ncorroborate that the proposed approach consistently yields more efficient\nprediction sets while maintaining valid coverage, outperforming alternative\nmethods.\n","authors":["Erfan Hajihashemi","Yanning Shen"],"pdf_url":"https://arxiv.org/pdf/2411.03678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01340v2","updated":"2024-11-06T05:38:51Z","published":"2024-03-31T02:46:27Z","title":"From Similarity to Superiority: Channel Clustering for Time Series\n  Forecasting","summary":"  Time series forecasting has attracted significant attention in recent\ndecades. Previous studies have demonstrated that the Channel-Independent (CI)\nstrategy improves forecasting performance by treating different channels\nindividually, while it leads to poor generalization on unseen instances and\nignores potentially necessary interactions between channels. Conversely, the\nChannel-Dependent (CD) strategy mixes all channels with even irrelevant and\nindiscriminate information, which, however, results in oversmoothing issues and\nlimits forecasting accuracy. There is a lack of channel strategy that\neffectively balances individual channel treatment for improved forecasting\nperformance without overlooking essential interactions between channels.\nMotivated by our observation of a correlation between the time series model's\nperformance boost against channel mixing and the intrinsic similarity on a pair\nof channels, we developed a novel and adaptable Channel Clustering Module\n(CCM). CCM dynamically groups channels characterized by intrinsic similarities\nand leverages cluster information instead of individual channel identities,\ncombining the best of CD and CI worlds. Extensive experiments on real-world\ndatasets demonstrate that CCM can (1) boost the performance of CI and CD models\nby an average margin of 2.4% and 7.2% on long-term and short-term forecasting,\nrespectively; (2) enable zero-shot forecasting with mainstream time series\nforecasting models; (3) uncover intrinsic time series patterns among channels\nand improve interpretability of complex time series models.\n","authors":["Jialin Chen","Jan Eric Lenssen","Aosong Feng","Weihua Hu","Matthias Fey","Leandros Tassiulas","Jure Leskovec","Rex Ying"],"pdf_url":"https://arxiv.org/pdf/2404.01340v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2402.17812v2","updated":"2024-11-06T05:33:16Z","published":"2024-02-27T14:51:11Z","title":"DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping\n  Backward Propagation","summary":"  Large language models (LLMs) have achieved significant success across various\ndomains. However, training these LLMs typically involves substantial memory and\ncomputational costs during both forward and backward propagation. While\nparameter-efficient fine-tuning (PEFT) considerably reduces the training memory\nassociated with parameters, it does not address the significant computational\ncosts and activation memory. In this paper, we propose Dropping Backward\nPropagation (DropBP), a novel approach designed to reduce computational costs\nand activation memory while maintaining accuracy. DropBP randomly drops layers\nduring backward propagation, which is essentially equivalent to training\nshallow submodules generated by undropped layers and residual connections.\nAdditionally, DropBP calculates the sensitivity of each layer to assign an\nappropriate drop rate, thereby stabilizing the training process. DropBP is not\nonly applicable to full fine-tuning but can also be orthogonally integrated\nwith all types of PEFT by dropping layers during backward propagation.\nSpecifically, DropBP can reduce training time by 44% with comparable accuracy\nto the baseline, accelerate convergence to the same perplexity by 1.5x, and\nenable training with a sequence length 6.2x larger on a single NVIDIA-A100 GPU.\nFurthermore, our DropBP enabled a throughput increase of 79% on a NVIDIA A100\nGPU and 117% on an Intel Gaudi2 HPU. The code is available at\nhttps://github.com/WooSunghyeon/dropbp.\n","authors":["Sunghyeon Woo","Baeseong Park","Byeongwook Kim","Minjung Jo","Se Jung Kwon","Dongsuk Jeon","Dongsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2402.17812v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13147v5","updated":"2024-11-06T05:18:04Z","published":"2024-10-17T02:04:57Z","title":"Utilizing Large Language Models in an iterative paradigm with Domain\n  feedback for Zero-shot Molecule optimization","summary":"  Molecule optimization is a critical task in drug discovery to optimize\ndesired properties of a given molecule through chemical modification. Despite\nLarge Language Models (LLMs) holding the potential to efficiently simulate this\ntask by using natural language to direct the optimization, straightforwardly\nutilizing shows limited performance. In this work, we facilitate utilizing LLMs\nin an iterative paradigm by proposing a simple yet highly effective domain\nfeedback provider, namely $\\text{Re}^3$DF. In detail, $\\text{Re}^3$DF harnesses\nan external toolkit, RDKit, to handle the molecule hallucination, if the\nmodified molecule is chemically invalid. Otherwise, its desired properties are\ncomputed and compared to the original one, establishing reliable domain\nfeedback with correct direction and distance towards the objective, followed by\na retrieved example, to explicitly guide the LLM to refine the modified\nmolecule. We conduct experiments across both single- and multi-property\nobjectives with 2 thresholds, where $\\text{Re}^3$DF shows significant\nimprovements. Particularly, for 20 single-property objectives, $\\text{Re}^3$DF\nenhances Hit ratio by 16.95% and 20.76% under loose and strict thresholds,\nrespectively. For 32 multi-property objectives, $\\text{Re}^3$DF enhances Hit\nratio by 6.04% and 5.25%.\n","authors":["Khiem Le","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2410.13147v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03671v1","updated":"2024-11-06T05:10:20Z","published":"2024-11-06T05:10:20Z","title":"Energy-based physics-informed neural network for frictionless contact\n  problems under large deformation","summary":"  Numerical methods for contact mechanics are of great importance in\nengineering applications, enabling the prediction and analysis of complex\nsurface interactions under various conditions. In this work, we propose an\nenergy-based physics-informed neural network (PINNs) framework for solving\nfrictionless contact problems under large deformation. Inspired by microscopic\nLennard-Jones potential, a surface contact energy is used to describe the\ncontact phenomena. To ensure the robustness of the proposed PINN framework,\nrelaxation, gradual loading and output scaling techniques are introduced. In\nthe numerical examples, the well-known Hertz contact benchmark problem is\nconducted, demonstrating the effectiveness and robustness of the proposed PINNs\nframework. Moreover, challenging contact problems with the consideration of\ngeometrical and material nonlinearities are tested. It has been shown that the\nproposed PINNs framework provides a reliable and powerful tool for nonlinear\ncontact mechanics. More importantly, the proposed PINNs framework exhibits\ncompetitive computational efficiency to the commercial FEM software when\ndealing with those complex contact problems. The codes used in this manuscript\nare available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The code\nwill be available after acceptance)\n","authors":["Jinshuai Bai","Zhongya Lin","Yizheng Wang","Jiancong Wen","Yinghua Liu","Timon Rabczuk","YuanTong Gu","Xi-Qiao Feng"],"pdf_url":"https://arxiv.org/pdf/2411.03671v1.pdf","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.13936v2","updated":"2024-11-06T04:53:36Z","published":"2024-06-20T02:08:50Z","title":"Communication-Efficient Adaptive Batch Size Strategies for Distributed\n  Local Gradient Methods","summary":"  Modern deep neural networks often require distributed training with many\nworkers due to their large size. As the number of workers increases,\ncommunication overheads become the main bottleneck in data-parallel minibatch\nstochastic gradient methods with per-iteration gradient synchronization. Local\ngradient methods like Local SGD reduce communication by only synchronizing\nmodel parameters and/or gradients after several local steps. Despite an\nunderstanding of their convergence and the importance of batch sizes for\ntraining efficiency and generalization, optimal batch sizes for local gradient\nmethods are difficult to determine. We introduce adaptive batch size strategies\nfor local gradient methods that increase batch sizes adaptively to reduce\nminibatch gradient variance. We provide convergence guarantees under\nhomogeneous data conditions and support our claims with image classification\nand language modeling experiments, demonstrating the effectiveness of our\nstrategies for both training efficiency and generalization.\n","authors":["Tim Tsz-Kit Lau","Weijian Li","Chenwei Xu","Han Liu","Mladen Kolar"],"pdf_url":"https://arxiv.org/pdf/2406.13936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03663v1","updated":"2024-11-06T04:44:51Z","published":"2024-11-06T04:44:51Z","title":"Can Graph Neural Networks Expose Training Data Properties? An Efficient\n  Risk Assessment Approach","summary":"  Graph neural networks (GNNs) have attracted considerable attention due to\ntheir diverse applications. However, the scarcity and quality limitations of\ngraph data present challenges to their training process in practical settings.\nTo facilitate the development of effective GNNs, companies and researchers\noften seek external collaboration. Yet, directly sharing data raises privacy\nconcerns, motivating data owners to train GNNs on their private graphs and\nshare the trained models. Unfortunately, these models may still inadvertently\ndisclose sensitive properties of their training graphs (e.g., average default\nrate in a transaction network), leading to severe consequences for data owners.\nIn this work, we study graph property inference attack to identify the risk of\nsensitive property information leakage from shared models. Existing approaches\ntypically train numerous shadow models for developing such attack, which is\ncomputationally intensive and impractical. To address this issue, we propose an\nefficient graph property inference attack by leveraging model approximation\ntechniques. Our method only requires training a small set of models on graphs,\nwhile generating a sufficient number of approximated shadow models for attacks.\nTo enhance diversity while reducing errors in the approximated models, we apply\nedit distance to quantify the diversity within a group of approximated models\nand introduce a theoretically guaranteed criterion to evaluate each model's\nerror. Subsequently, we propose a novel selection mechanism to ensure that the\nretained approximated models achieve high diversity and low error. Extensive\nexperiments across six real-world scenarios demonstrate our method's\nsubstantial improvement, with average increases of 2.7% in attack accuracy and\n4.1% in ROC-AUC, while being 6.5$\\times$ faster compared to the best baseline.\n","authors":["Hanyang Yuan","Jiarong Xu","Renhong Huang","Mingli Song","Chunping Wang","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.03663v1.pdf","comment":"In NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.03656v1","updated":"2024-11-06T04:35:39Z","published":"2024-11-06T04:35:39Z","title":"Requirements Engineering for Older Adult Digital Health Software: A\n  Systematic Literature Review","summary":"  Growth of the older adult population has led to an increasing interest in\ntechnology-supported aged care. However, the area has some challenges such as a\nlack of caregivers and limitations in understanding the emotional, social,\nphysical, and mental well-being needs of seniors. Furthermore, there is a gap\nin the understanding between developers and ageing people of their\nrequirements. Digital health can be important in supporting older adults\nwellbeing, emotional requirements, and social needs. Requirements Engineering\n(RE) is a major software engineering field, which can help to identify, elicit\nand prioritize the requirements of stakeholders and ensure that the systems\nmeet standards for performance, reliability, and usability. We carried out a\nsystematic review of the literature on RE for older adult digital health\nsoftware. This was necessary to show the representatives of the current stage\nof understanding the needs of older adults in aged care digital health. Using\nestablished guidelines outlined by the Kitchenham method, the PRISMA and the\nPICO guideline, we developed a protocol, followed by the systematic exploration\nof eight databases. This resulted in 69 primary studies of high relevance,\nwhich were subsequently subjected to data extraction, synthesis, and reporting.\nWe highlight key RE processes in digital health software for ageing people. It\nexplored the utilization of technology for older user well-being and care, and\nthe evaluations of such solutions. The review also identified key limitations\nfound in existing primary studies that inspire future research opportunities.\nThe results indicate that requirement gathering and understanding have a\nsignificant variation between different studies. The differences are in the\nquality, depth, and techniques adopted for requirement gathering and these\ndifferences are largely due to uneven adoption of RE methods.\n","authors":["Yuqing Xiao","John Grundy","Anuradha Madugalla"],"pdf_url":"https://arxiv.org/pdf/2411.03656v1.pdf","comment":"arxiv version of SLR on RE for Older Adult Digital Health Software"},{"id":"http://arxiv.org/abs/2401.09452v2","updated":"2024-11-06T04:25:03Z","published":"2023-12-22T13:09:17Z","title":"Learning with Geometry: Including Riemannian Geometric Features in\n  Coefficient of Pressure Prediction on Aircraft Wings","summary":"  We propose to incorporate Riemannian geometric features from the geometry of\naircraft wing surfaces in the prediction of coefficient of pressure (CP) on the\naircraft wing. Contrary to existing approaches that treat the wing surface as a\nflat object, we represent the wing as a piecewise smooth manifold and calculate\na set of Riemannian geometric features (Riemannian metric, connection, and\ncurvature) over points of the wing. Combining these features in neighborhoods\nof points on the wing with coordinates and flight conditions gives inputs to a\ndeep learning model that predicts CP distributions. Experimental results show\nthat the method with incorporation of Riemannian geometric features, compared\nto state-of-the-art Deep Attention Network (DAN), reduces the predicted mean\nsquare error (MSE) of CP by an average of 15.00% for the DLR-F11 aircraft test\nset.\n","authors":["Liwei Hu","Wenyong Wang","Yu Xiang","Stefan Sommer"],"pdf_url":"https://arxiv.org/pdf/2401.09452v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03651v1","updated":"2024-11-06T04:19:50Z","published":"2024-11-06T04:19:50Z","title":"Policy Aggregation","summary":"  We consider the challenge of AI value alignment with multiple individuals\nthat have different reward functions and optimal policies in an underlying\nMarkov decision process. We formalize this problem as one of policy\naggregation, where the goal is to identify a desirable collective policy. We\nargue that an approach informed by social choice theory is especially suitable.\nOur key insight is that social choice methods can be reinterpreted by\nidentifying ordinal preferences with volumes of subsets of the state-action\noccupancy polytope. Building on this insight, we demonstrate that a variety of\nmethods--including approval voting, Borda count, the proportional veto core,\nand quantile fairness--can be practically applied to policy aggregation.\n","authors":["Parand A. Alamdari","Soroush Ebadian","Ariel D. Procaccia"],"pdf_url":"https://arxiv.org/pdf/2411.03651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10656v3","updated":"2024-11-06T04:04:03Z","published":"2023-06-19T00:42:35Z","title":"Virtual Human Generative Model: Masked Modeling Approach for Learning\n  Human Characteristics","summary":"  Identifying the relationship between healthcare attributes, lifestyles, and\npersonality is vital for understanding and improving physical and mental\nwell-being. Machine learning approaches are promising for modeling their\nrelationships and offering actionable suggestions. In this paper, we propose\nVirtual Human Generative Model (VHGM), a machine learning model for estimating\nhealthcare, lifestyles, and personality attributes. VHGM is a deep generative\nmodel trained with masked modeling to learn the joint distribution of\nattributes conditioned on known ones. Using heterogeneous tabular datasets,\nVHGM learns more than 2,000 attributes efficiently. We numerically evaluate the\nperformance of VHGM and its training techniques and have deployed VHGM as a Web\nservice, enabling various healthcare applications.\n","authors":["Kenta Oono","Nontawat Charoenphakdee","Kotatsu Bito","Zhengyan Gao","Hideyoshi Igata","Masashi Yoshikawa","Yoshiaki Ota","Hiroki Okui","Kei Akita","Shoichiro Yamaguchi","Yohei Sugawara","Shin-ichi Maeda","Kunihiko Miyoshi","Yuki Saito","Koki Tsuda","Hiroshi Maruyama","Kohei Hayashi"],"pdf_url":"https://arxiv.org/pdf/2306.10656v3.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.03641v1","updated":"2024-11-06T03:38:00Z","published":"2024-11-06T03:38:00Z","title":"Constrained Multi-objective Bayesian Optimization through Optimistic\n  Constraints Estimation","summary":"  Multi-objective Bayesian optimization has been widely adopted in scientific\nexperiment design, including drug discovery and hyperparameter optimization. In\npractice, regulatory or safety concerns often impose additional thresholds on\ncertain attributes of the experimental outcomes. Previous work has primarily\nfocused on constrained single-objective optimization tasks or active search\nunder constraints. We propose CMOBO, a sample-efficient constrained\nmulti-objective Bayesian optimization algorithm that balances learning of the\nfeasible region (defined on multiple unknowns) with multi-objective\noptimization within the feasible region in a principled manner. We provide both\ntheoretical justification and empirical evidence, demonstrating the efficacy of\nour approach on various synthetic benchmarks and real-world applications.\n","authors":["Diantong Li","Fengxue Zhang","Chong Liu","Yuxin Chen"],"pdf_url":"https://arxiv.org/pdf/2411.03641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.00675v4","updated":"2024-11-06T03:29:03Z","published":"2021-10-01T23:03:21Z","title":"Contraction Theory for Nonlinear Stability Analysis and Learning-based\n  Control: A Tutorial Overview","summary":"  Contraction theory is an analytical tool to study differential dynamics of a\nnon-autonomous (i.e., time-varying) nonlinear system under a contraction metric\ndefined with a uniformly positive definite matrix, the existence of which\nresults in a necessary and sufficient characterization of incremental\nexponential stability of multiple solution trajectories with respect to each\nother. By using a squared differential length as a Lyapunov-like function, its\nnonlinear stability analysis boils down to finding a suitable contraction\nmetric that satisfies a stability condition expressed as a linear matrix\ninequality, indicating that many parallels can be drawn between well-known\nlinear systems theory and contraction theory for nonlinear systems.\nFurthermore, contraction theory takes advantage of a superior robustness\nproperty of exponential stability used in conjunction with the comparison\nlemma. This yields much-needed safety and stability guarantees for neural\nnetwork-based control and estimation schemes, without resorting to a more\ninvolved method of using uniform asymptotic stability for input-to-state\nstability. Such distinctive features permit systematic construction of a\ncontraction metric via convex optimization, thereby obtaining an explicit\nexponential bound on the distance between a time-varying target trajectory and\nsolution trajectories perturbed externally due to disturbances and learning\nerrors. The objective of this paper is therefore to present a tutorial overview\nof contraction theory and its advantages in nonlinear stability analysis of\ndeterministic and stochastic systems, with an emphasis on deriving formal\nrobustness and stability guarantees for various learning-based and data-driven\nautomatic control methods. In particular, we provide a detailed review of\ntechniques for finding contraction metrics and associated control and\nestimation laws using deep neural networks.\n","authors":["Hiroyasu Tsukamoto","Soon-Jo Chung","Jean-Jacques E. Slotine"],"pdf_url":"https://arxiv.org/pdf/2110.00675v4.pdf","comment":"Annual Reviews in Control, Accepted, Oct. 1st"},{"id":"http://arxiv.org/abs/2404.08254v2","updated":"2024-11-06T03:23:14Z","published":"2024-04-12T06:08:43Z","title":"Balanced Mixed-Type Tabular Data Synthesis with Diffusion Models","summary":"  Diffusion models have emerged as a robust framework for various generative\ntasks, including tabular data synthesis. However, current tabular diffusion\nmodels tend to inherit bias in the training dataset and generate biased\nsynthetic data, which may influence discriminatory actions. In this research,\nwe introduce a novel tabular diffusion model that incorporates sensitive\nguidance to generate fair synthetic data with balanced joint distributions of\nthe target label and sensitive attributes, such as sex and race. The empirical\nresults demonstrate that our method effectively mitigates bias in training data\nwhile maintaining the quality of the generated samples. Furthermore, we provide\nevidence that our approach outperforms existing methods for synthesizing\ntabular data on fairness metrics such as demographic parity ratio and equalized\nodds ratio, achieving improvements of over $10\\%$. Our implementation is\navailable at https://github.com/comp-well-org/fair-tab-diffusion.\n","authors":["Zeyu Yang","Han Yu","Peikun Guo","Khadija Zanna","Xiaoxue Yang","Akane Sano"],"pdf_url":"https://arxiv.org/pdf/2404.08254v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02847v2","updated":"2024-11-06T03:20:03Z","published":"2024-11-05T06:36:48Z","title":"Dissecting the Failure of Invariant Learning on Graphs","summary":"  Enhancing node-level Out-Of-Distribution (OOD) generalization on graphs\nremains a crucial area of research. In this paper, we develop a Structural\nCausal Model (SCM) to theoretically dissect the performance of two prominent\ninvariant learning methods -- Invariant Risk Minimization (IRM) and\nVariance-Risk Extrapolation (VREx) -- in node-level OOD settings. Our analysis\nreveals a critical limitation: due to the lack of class-conditional invariance\nconstraints, these methods may struggle to accurately identify the structure of\nthe predictive invariant ego-graph and consequently rely on spurious features.\nTo address this, we propose Cross-environment Intra-class Alignment (CIA),\nwhich explicitly eliminates spurious features by aligning cross-environment\nrepresentations conditioned on the same class, bypassing the need for explicit\nknowledge of the causal pattern structure. To adapt CIA to node-level OOD\nscenarios where environment labels are hard to obtain, we further propose\nCIA-LRA (Localized Reweighting Alignment) that leverages the distribution of\nneighboring labels to selectively align node representations, effectively\ndistinguishing and preserving invariant features while removing spurious ones,\nall without relying on environment labels. We theoretically prove CIA-LRA's\neffectiveness by deriving an OOD generalization error bound based on\nPAC-Bayesian analysis. Experiments on graph OOD benchmarks validate the\nsuperiority of CIA and CIA-LRA, marking a significant advancement in node-level\nOOD generalization. The codes are available at\nhttps://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs.\n","authors":["Qixun Wang","Yifei Wang","Yisen Wang","Xianghua Ying"],"pdf_url":"https://arxiv.org/pdf/2411.02847v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20119v2","updated":"2024-11-06T02:57:42Z","published":"2024-10-26T08:16:00Z","title":"On Multi-Stage Loss Dynamics in Neural Networks: Mechanisms of Plateau\n  and Descent Stages","summary":"  The multi-stage phenomenon in the training loss curves of neural networks has\nbeen widely observed, reflecting the non-linearity and complexity inherent in\nthe training process. In this work, we investigate the training dynamics of\nneural networks (NNs), with particular emphasis on the small initialization\nregime, identifying three distinct stages observed in the loss curve during\ntraining: the initial plateau stage, the initial descent stage, and the\nsecondary plateau stage. Through rigorous analysis, we reveal the underlying\nchallenges contributing to slow training during the plateau stages. While the\nproof and estimate for the emergence of the initial plateau were established in\nour previous work, the behaviors of the initial descent and secondary plateau\nstages had not been explored before. Here, we provide a more detailed proof for\nthe initial plateau, followed by a comprehensive analysis of the initial\ndescent stage dynamics. Furthermore, we examine the factors facilitating the\nnetwork's ability to overcome the prolonged secondary plateau, supported by\nboth experimental evidence and heuristic reasoning. Finally, to clarify the\nlink between global training trends and local parameter adjustments, we use the\nWasserstein distance to track the fine-scale evolution of weight amplitude\ndistribution.\n","authors":["Zheng-An Chen","Tao Luo","GuiHong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.20119v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02199v2","updated":"2024-11-06T02:51:16Z","published":"2024-11-04T15:54:32Z","title":"Provably Transformers Harness Multi-Concept Word Semantics for Efficient\n  In-Context Learning","summary":"  Transformer-based large language models (LLMs) have displayed remarkable\ncreative prowess and emergence capabilities. Existing empirical studies have\nrevealed a strong connection between these LLMs' impressive emergence abilities\nand their in-context learning (ICL) capacity, allowing them to solve new tasks\nusing only task-specific prompts without further fine-tuning. On the other\nhand, existing empirical and theoretical studies also show that there is a\nlinear regularity of the multi-concept encoded semantic representation behind\ntransformer-based LLMs. However, existing theoretical work fail to build up an\nunderstanding of the connection between this regularity and the innovative\npower of ICL. Additionally, prior work often focuses on simplified, unrealistic\nscenarios involving linear transformers or unrealistic loss functions, and they\nachieve only linear or sub-linear convergence rates. In contrast, this work\nprovides a fine-grained mathematical analysis to show how transformers leverage\nthe multi-concept semantics of words to enable powerful ICL and excellent\nout-of-distribution ICL abilities, offering insights into how transformers\ninnovate solutions for certain unseen tasks encoded with multiple cross-concept\nsemantics. Inspired by empirical studies on the linear latent geometry of LLMs,\nthe analysis is based on a concept-based low-noise sparse coding prompt model.\nLeveraging advanced techniques, this work showcases the exponential 0-1 loss\nconvergence over the highly non-convex training dynamics, which pioneeringly\nincorporates the challenges of softmax self-attention, ReLU-activated MLPs, and\ncross-entropy loss. Empirical simulations corroborate the theoretical findings.\n","authors":["Dake Bu","Wei Huang","Andi Han","Atsushi Nitanda","Taiji Suzuki","Qingfu Zhang","Hau-San Wong"],"pdf_url":"https://arxiv.org/pdf/2411.02199v2.pdf","comment":"Accepted by the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2411.03624v1","updated":"2024-11-06T02:45:16Z","published":"2024-11-06T02:45:16Z","title":"SEGMN: A Structure-Enhanced Graph Matching Network for Graph Similarity\n  Learning","summary":"  Graph similarity computation (GSC) aims to quantify the similarity score\nbetween two graphs. Although recent GSC methods based on graph neural networks\n(GNNs) take advantage of intra-graph structures in message passing, few of them\nfully utilize the structures presented by edges to boost the representation of\ntheir connected nodes. Moreover, previous cross-graph node embedding matching\nlacks the perception of the overall structure of the graph pair, due to the\nfact that the node representations from GNNs are confined to the intra-graph\nstructure, causing the unreasonable similarity score. Intuitively, the\ncross-graph structure represented in the assignment graph is helpful to rectify\nthe inappropriate matching. Therefore, we propose a structure-enhanced graph\nmatching network (SEGMN). Equipped with a dual embedding learning module and a\nstructure perception matching module, SEGMN achieves structure enhancement in\nboth embedding learning and cross-graph matching. The dual embedding learning\nmodule incorporates adjacent edge representation into each node to achieve a\nstructure-enhanced representation. The structure perception matching module\nachieves cross-graph structure enhancement through assignment graph\nconvolution. The similarity score of each cross-graph node pair can be\nrectified by aggregating messages from structurally relevant node pairs.\nExperimental results on benchmark datasets demonstrate that SEGMN outperforms\nthe state-of-the-art GSC methods in the GED regression task, and the structure\nperception matching module is plug-and-play, which can further improve the\nperformance of the baselines by up to 25%.\n","authors":["Wenjun Wang","Jiacheng Lu","Kejia Chen","Zheng Liu","Shilong Sang"],"pdf_url":"https://arxiv.org/pdf/2411.03624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03622v1","updated":"2024-11-06T02:41:26Z","published":"2024-11-06T02:41:26Z","title":"Fully Hyperbolic Rotation for Knowledge Graph Embedding","summary":"  Hyperbolic rotation is commonly used to effectively model knowledge graphs\nand their inherent hierarchies. However, existing hyperbolic rotation models\nrely on logarithmic and exponential mappings for feature transformation. These\nmodels only project data features into hyperbolic space for rotation, limiting\ntheir ability to fully exploit the hyperbolic space. To address this problem,\nwe propose a novel fully hyperbolic model designed for knowledge graph\nembedding. Instead of feature mappings, we define the model directly in\nhyperbolic space with the Lorentz model. Our model considers each relation in\nknowledge graphs as a Lorentz rotation from the head entity to the tail entity.\nWe adopt the Lorentzian version distance as the scoring function for measuring\nthe plausibility of triplets. Extensive results on standard knowledge graph\ncompletion benchmarks demonstrated that our model achieves competitive results\nwith fewer parameters. In addition, our model get the state-of-the-art\nperformance on datasets of CoDEx-s and CoDEx-m, which are more diverse and\nchallenging than before. Our code is available at\nhttps://github.com/llqy123/FHRE.\n","authors":["Qiuyu Liang","Weihua Wang","Feilong Bao","Guanglai Gao"],"pdf_url":"https://arxiv.org/pdf/2411.03622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03620v1","updated":"2024-11-06T02:37:43Z","published":"2024-11-06T02:37:43Z","title":"A Subsampling Based Neural Network for Spatial Data","summary":"  The application of deep neural networks in geospatial data has become a\ntrending research problem in the present day. A significant amount of\nstatistical research has already been introduced, such as generalized least\nsquare optimization by incorporating spatial variance-covariance matrix,\nconsidering basis functions in the input nodes of the neural networks, and so\non. However, for lattice data, there is no available literature about the\nutilization of asymptotic analysis of neural networks in regression for spatial\ndata. This article proposes a consistent localized two-layer deep neural\nnetwork-based regression for spatial data. We have proved the consistency of\nthis deep neural network for bounded and unbounded spatial domains under a\nfixed sampling design of mixed-increasing spatial regions. We have proved that\nits asymptotic convergence rate is faster than that of \\cite{zhan2024neural}'s\nneural network and an improved generalization of \\cite{shen2023asymptotic}'s\nneural network structure. We empirically observe the rate of convergence of\ndiscrepancy measures between the empirical probability distribution of observed\nand predicted data, which will become faster for a less smooth spatial surface.\nWe have applied our asymptotic analysis of deep neural networks to the\nestimation of the monthly average temperature of major cities in the USA from\nits satellite image. This application is an effective showcase of non-linear\nspatial regression. We demonstrate our methodology with simulated lattice data\nin various scenarios.\n","authors":["Debjoy Thakur"],"pdf_url":"https://arxiv.org/pdf/2411.03620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06209v6","updated":"2024-11-06T02:35:30Z","published":"2024-10-08T17:11:24Z","title":"LeanAgent: Lifelong Learning for Formal Theorem Proving","summary":"  Large Language Models (LLMs) have been successful in mathematical reasoning\ntasks such as formal theorem proving when integrated with interactive proof\nassistants like Lean. Existing approaches involve training or fine-tuning an\nLLM on a specific dataset to perform well on particular domains, such as\nundergraduate-level mathematics. These methods struggle with generalizability\nto advanced mathematics. A fundamental limitation is that these approaches\noperate on static domains, failing to capture how mathematicians often work\nacross multiple domains and projects simultaneously or cyclically. We present\nLeanAgent, a novel lifelong learning framework for theorem proving that\ncontinuously generalizes to and improves on ever-expanding mathematical\nknowledge without forgetting previously learned knowledge. LeanAgent introduces\nseveral key innovations, including a curriculum learning strategy that\noptimizes the learning trajectory in terms of mathematical difficulty, a\ndynamic database for efficient management of evolving mathematical knowledge,\nand progressive training to balance stability and plasticity. LeanAgent\nsuccessfully proves 162 theorems previously unproved by humans across 23\ndiverse Lean repositories, many from advanced mathematics. It performs\nsignificantly better than the static LLM baseline, proving challenging theorems\nin domains like abstract algebra and algebraic topology while showcasing a\nclear progression of learning from basic concepts to advanced topics. In\naddition, we analyze LeanAgent's superior performance on key lifelong learning\nmetrics. LeanAgent achieves exceptional scores in stability and backward\ntransfer, where learning new tasks improves performance on previously learned\ntasks. This emphasizes LeanAgent's continuous generalizability and improvement,\nexplaining its superior theorem-proving performance.\n","authors":["Adarsh Kumarappan","Mo Tiwari","Peiyang Song","Robert Joseph George","Chaowei Xiao","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2410.06209v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03611v1","updated":"2024-11-06T02:12:41Z","published":"2024-11-06T02:12:41Z","title":"Designing a Linearized Potential Function in Neural Network Optimization\n  Using Csiszár Type of Tsallis Entropy","summary":"  In recent years, learning for neural networks can be viewed as optimization\nin the space of probability measures. To obtain the exponential convergence to\nthe optimizer, the regularizing term based on Shannon entropy plays an\nimportant role. Even though an entropy function heavily affects convergence\nresults, there is almost no result on its generalization, because of the\nfollowing two technical difficulties: one is the lack of sufficient condition\nfor generalized logarithmic Sobolev inequality, and the other is the\ndistributional dependence of the potential function within the gradient flow\nequation. In this paper, we establish a framework that utilizes a linearized\npotential function via Csisz\\'{a}r type of Tsallis entropy, which is one of the\ngeneralized entropies. We also show that our new framework enable us to derive\nan exponential convergence result.\n","authors":["Keito Akiyama"],"pdf_url":"https://arxiv.org/pdf/2411.03611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01433v2","updated":"2024-11-06T01:49:45Z","published":"2024-11-03T04:25:46Z","title":"HOBBIT: A Mixed Precision Expert Offloading System for Fast MoE\n  Inference","summary":"  The Mixture-of-Experts (MoE) architecture has demonstrated significant\nadvantages in the era of Large Language Models (LLMs), offering enhanced\ncapabilities with reduced inference costs. However, deploying MoE-based LLMs on\nmemoryconstrained edge devices remains challenging due to their substantial\nmemory requirements. While existing expertoffloading methods alleviate the\nmemory requirements, they often incur significant expert-loading costs or\ncompromise model accuracy. We present HOBBIT, a mixed precision expert\noffloading system to enable flexible and efficient MoE inference. Our key\ninsight is that dynamically replacing less critical cache-miss experts with low\nprecision versions can substantially reduce expert-loading latency while\npreserving model accuracy. HOBBIT introduces three innovative techniques that\nmap the natural hierarchy of MoE computation: (1) a token-level dynamic expert\nloading mechanism, (2) a layer-level adaptive expert prefetching technique, and\n(3) a sequence-level multidimensional expert caching policy. These innovations\nfully leverage the benefits of mixedprecision expert inference. By implementing\nHOBBIT on top of the renowned LLM inference framework Llama.cpp, we evaluate\nits performance across different edge devices with representative MoE models.\nThe results demonstrate that HOBBIT achieves up to a 9.93x speedup in decoding\ncompared to state-of-the-art MoE offloading systems.\n","authors":["Peng Tang","Jiacheng Liu","Xiaofeng Hou","Yifei Pu","Jing Wang","Pheng-Ann Heng","Chao Li","Minyi Guo"],"pdf_url":"https://arxiv.org/pdf/2411.01433v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03604v1","updated":"2024-11-06T01:49:13Z","published":"2024-11-06T01:49:13Z","title":"Temporal-Difference Learning Using Distributed Error Signals","summary":"  A computational problem in biological reward-based learning is how credit\nassignment is performed in the nucleus accumbens (NAc). Much research suggests\nthat NAc dopamine encodes temporal-difference (TD) errors for learning value\npredictions. However, dopamine is synchronously distributed in regionally\nhomogeneous concentrations, which does not support explicit credit assignment\n(like used by backpropagation). It is unclear whether distributed errors alone\nare sufficient for synapses to make coordinated updates to learn complex,\nnonlinear reward-based learning tasks. We design a new deep Q-learning\nalgorithm, Artificial Dopamine, to computationally demonstrate that\nsynchronously distributed, per-layer TD errors may be sufficient to learn\nsurprisingly complex RL tasks. We empirically evaluate our algorithm on\nMinAtar, the DeepMind Control Suite, and classic control tasks, and show it\noften achieves comparable performance to deep RL algorithms that use\nbackpropagation.\n","authors":["Jonas Guan","Shon Eduard Verch","Claas Voelcker","Ethan C. Jackson","Nicolas Papernot","William A. Cunningham"],"pdf_url":"https://arxiv.org/pdf/2411.03604v1.pdf","comment":"10 pages, to be published at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03598v1","updated":"2024-11-06T01:34:06Z","published":"2024-11-06T01:34:06Z","title":"Open-Source High-Speed Flight Surrogate Modeling Framework","summary":"  High-speed flight vehicles, which travel much faster than the speed of sound,\nare crucial for national defense and space exploration. However, accurately\npredicting their behavior under numerous, varied flight conditions is a\nchallenge and often prohibitively expensive. The proposed approach involves\ncreating smarter, more efficient machine learning models (also known as\nsurrogate models or meta models) that can fuse data generated from a variety of\nfidelity levels -- to include engineering methods, simulation, wind tunnel, and\nflight test data -- to make more accurate predictions. These models are able to\nmove the bulk of the computation from high performance computing (HPC) to\nsingle user machines (laptop, desktop, etc.). The project builds upon previous\nwork but introduces code improvements and an informed perspective on the\ndirection of the field. The new surrogate modeling framework is now modular\nand, by design, broadly applicable to many modeling problems. The new framework\nalso has a more robust automatic hyperparameter tuning capability and abstracts\naway most of the pre- and post-processing tasks. The Gaussian process\nregression and deep neural network-based models included in the presented\nframework were able to model two datasets with high accuracy (R^2>0.99). The\nprimary conclusion is that the framework is effective and has been delivered to\nthe Air Force for integration into real-world projects. For future work,\nsignificant and immediate investment in continued research is crucial. The\nauthor recommends further testing and refining modeling methods that explicitly\nincorporate physical laws and are robust enough to handle simulation and test\ndata from varying resolutions and sources, including coarse meshes, fine\nmeshes, unstructured meshes, and limited experimental test points.\n","authors":["Tyler E. Korenyi-Both","Nathan J. Falkiewicz","Matthew C. Jones"],"pdf_url":"https://arxiv.org/pdf/2411.03598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03596v1","updated":"2024-11-06T01:20:24Z","published":"2024-11-06T01:20:24Z","title":"Enhancing the Expressivity of Temporal Graph Networks through\n  Source-Target Identification","summary":"  Despite the successful application of Temporal Graph Networks (TGNs) for\ntasks such as dynamic node classification and link prediction, they still\nperform poorly on the task of dynamic node affinity prediction -- where the\ngoal is to predict `how much' two nodes will interact in the future. In fact,\nsimple heuristic approaches such as persistent forecasts and moving averages\nover \\emph{ground-truth labels} significantly and consistently outperform TGNs.\nBuilding on this observation, we find that computing heuristics \\textit{over\nmessages} is an equally competitive approach, outperforming TGN and all current\ntemporal graph (TG) models on dynamic node affinity prediction. In this paper,\nwe prove that no formulation of TGN can represent persistent forecasting or\nmoving averages over messages, and propose to enhance the expressivity of TGNs\nby adding source-target identification to each interaction event message. We\nshow that this modification is required to represent persistent forecasting,\nmoving averages, and the broader class of autoregressive models over messages.\nOur proposed method, TGNv2, significantly outperforms TGN and all current TG\nmodels on all Temporal Graph Benchmark (TGB) dynamic node affinity prediction\ndatasets.\n","authors":["Benedict Aaron Tjandra","Federico Barbero","Michael Bronstein"],"pdf_url":"https://arxiv.org/pdf/2411.03596v1.pdf","comment":"Accepted to NeurIPS Symmetry and Geometry in Neural Representations\n  Workshop 2024"},{"id":"http://arxiv.org/abs/2410.19256v2","updated":"2024-11-06T01:15:13Z","published":"2024-10-25T02:21:01Z","title":"Spatioformer: A Geo-encoded Transformer for Large-Scale Plant Species\n  Richness Prediction","summary":"  Earth observation data have shown promise in predicting species richness of\nvascular plants ($\\alpha$-diversity), but extending this approach to large\nspatial scales is challenging because geographically distant regions may\nexhibit different compositions of plant species ($\\beta$-diversity), resulting\nin a location-dependent relationship between richness and spectral\nmeasurements. In order to handle such geolocation dependency, we propose\nSpatioformer, where a novel geolocation encoder is coupled with the transformer\nmodel to encode geolocation context into remote sensing imagery. The\nSpatioformer model compares favourably to state-of-the-art models in richness\npredictions on a large-scale ground-truth richness dataset (HAVPlot) that\nconsists of 68,170 in-situ richness samples covering diverse landscapes across\nAustralia. The results demonstrate that geolocational information is\nadvantageous in predicting species richness from satellite observations over\nlarge spatial scales. With Spatioformer, plant species richness maps over\nAustralia are compiled from Landsat archive for the years from 2015 to 2023.\nThe richness maps produced in this study reveal the spatiotemporal dynamics of\nplant species richness in Australia, providing supporting evidence to inform\neffective planning and policy development for plant diversity conservation.\nRegions of high richness prediction uncertainties are identified, highlighting\nthe need for future in-situ surveys to be conducted in these areas to enhance\nthe prediction accuracy.\n","authors":["Yiqing Guo","Karel Mokany","Shaun R. Levick","Jinyan Yang","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2410.19256v2.pdf","comment":"Submitted to IEEE Transactions on Geoscience and Remote Sensing"},{"id":"http://arxiv.org/abs/2411.03588v1","updated":"2024-11-06T01:00:17Z","published":"2024-11-06T01:00:17Z","title":"An Experimental Study on Decomposition-Based Deep Ensemble Learning for\n  Traffic Flow Forecasting","summary":"  Traffic flow forecasting is a crucial task in intelligent transport systems.\nDeep learning offers an effective solution, capturing complex patterns in\ntime-series traffic flow data to enable the accurate prediction. However, deep\nlearning models are prone to overfitting the intricate details of flow data,\nleading to poor generalisation. Recent studies suggest that decomposition-based\ndeep ensemble learning methods may address this issue by breaking down a time\nseries into multiple simpler signals, upon which deep learning models are built\nand ensembled to generate the final prediction. However, few studies have\ncompared the performance of decomposition-based ensemble methods with\nnon-decomposition-based ones which directly utilise raw time-series data. This\nwork compares several decomposition-based and non-decomposition-based deep\nensemble learning methods. Experimental results on three traffic datasets\ndemonstrate the superiority of decomposition-based ensemble methods, while also\nrevealing their sensitivity to aggregation strategies and forecasting horizons.\n","authors":["Qiyuan Zhu","A. K. Qin","Hussein Dia","Adriana-Simona Mihaita","Hanna Grzybowska"],"pdf_url":"https://arxiv.org/pdf/2411.03588v1.pdf","comment":"This work has been accepted by the 2024 Australasian Joint Conference\n  on Artificial Intelligence (AJCAI 2024)"},{"id":"http://arxiv.org/abs/2411.03570v1","updated":"2024-11-06T00:19:58Z","published":"2024-11-06T00:19:58Z","title":"Learning Constant-Depth Circuits in Malicious Noise Models","summary":"  The seminal work of Linial, Mansour, and Nisan gave a quasipolynomial-time\nalgorithm for learning constant-depth circuits ($\\mathsf{AC}^0$) with respect\nto the uniform distribution on the hypercube. Extending their algorithm to the\nsetting of malicious noise, where both covariates and labels can be\nadversarially corrupted, has remained open. Here we achieve such a result,\ninspired by recent work on learning with distribution shift. Our running time\nessentially matches their algorithm, which is known to be optimal assuming\nvarious cryptographic primitives.\n  Our proof uses a simple outlier-removal method combined with Braverman's\ntheorem for fooling constant-depth circuits. We attain the best possible\ndependence on the noise rate and succeed in the harshest possible noise model\n(i.e., contamination or so-called \"nasty noise\").\n","authors":["Adam R. Klivans","Konstantinos Stavropoulos","Arsen Vasilyan"],"pdf_url":"https://arxiv.org/pdf/2411.03570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03569v1","updated":"2024-11-06T00:17:36Z","published":"2024-11-06T00:17:36Z","title":"Towards Personalized Federated Learning via Comprehensive Knowledge\n  Distillation","summary":"  Federated learning is a distributed machine learning paradigm designed to\nprotect data privacy. However, data heterogeneity across various clients\nresults in catastrophic forgetting, where the model rapidly forgets previous\nknowledge while acquiring new knowledge. To address this challenge,\npersonalized federated learning has emerged to customize a personalized model\nfor each client. However, the inherent limitation of this mechanism is its\nexcessive focus on personalization, potentially hindering the generalization of\nthose models. In this paper, we present a novel personalized federated learning\nmethod that uses global and historical models as teachers and the local model\nas the student to facilitate comprehensive knowledge distillation. The\nhistorical model represents the local model from the last round of client\ntraining, containing historical personalized knowledge, while the global model\nrepresents the aggregated model from the last round of server aggregation,\ncontaining global generalized knowledge. By applying knowledge distillation, we\neffectively transfer global generalized knowledge and historical personalized\nknowledge to the local model, thus mitigating catastrophic forgetting and\nenhancing the general performance of personalized models. Extensive\nexperimental results demonstrate the significant advantages of our method.\n","authors":["Pengju Wang","Bochao Liu","Weijia Guo","Yong Li","Shiming Ge"],"pdf_url":"https://arxiv.org/pdf/2411.03569v1.pdf","comment":"Accepted by IEEE SMC 2024"},{"id":"http://arxiv.org/abs/2411.04324v1","updated":"2024-11-06T23:54:09Z","published":"2024-11-06T23:54:09Z","title":"Gradient Boosting Trees and Large Language Models for Tabular Data\n  Few-Shot Learning","summary":"  Large Language Models (LLM) have brought numerous of new applications to\nMachine Learning (ML). In the context of tabular data (TD), recent studies show\nthat TabLLM is a very powerful mechanism for few-shot-learning (FSL)\napplications, even if gradient boosting decisions trees (GBDT) have\nhistorically dominated the TD field. In this work we demonstrate that although\nLLMs are a viable alternative, the evidence suggests that baselines used to\ngauge performance can be improved. We replicated public benchmarks and our\nmethodology improves LightGBM by 290%, this is mainly driven by forcing node\nsplitting with few samples, a critical step in FSL with GBDT. Our results show\nan advantage to TabLLM for 8 or fewer shots, but as the number of samples\nincreases GBDT provides competitive performance at a fraction of runtime. For\nother real-life applications with vast number of samples, we found FSL still\nuseful to improve model diversity, and when combined with ExtraTrees it\nprovides strong resilience to overfitting, our proposal was validated in a ML\ncompetition setting ranking first place.\n","authors":["Carlos Huertas"],"pdf_url":"https://arxiv.org/pdf/2411.04324v1.pdf","comment":"FedCSIS 2024 - Data Mining Competition - 1st Place Winner"},{"id":"http://arxiv.org/abs/2411.04323v1","updated":"2024-11-06T23:53:34Z","published":"2024-11-06T23:53:34Z","title":"Efficient Symmetry-Aware Materials Generation via Hierarchical\n  Generative Flow Networks","summary":"  Discovering new solid-state materials requires rapidly exploring the vast\nspace of crystal structures and locating stable regions. Generating stable\nmaterials with desired properties and compositions is extremely difficult as we\nsearch for very small isolated pockets in the exponentially many possibilities,\nconsidering elements from the periodic table and their 3D arrangements in\ncrystal lattices. Materials discovery necessitates both optimized solution\nstructures and diversity in the generated material structures. Existing methods\nstruggle to explore large material spaces and generate diverse samples with\ndesired properties and requirements. We propose the Symmetry-aware Hierarchical\nArchitecture for Flow-based Traversal (SHAFT), a novel generative model\nemploying a hierarchical exploration strategy to efficiently exploit the\nsymmetry of the materials space to generate crystal structures given desired\nproperties. In particular, our model decomposes the exponentially large\nmaterials space into a hierarchy of subspaces consisting of symmetric space\ngroups, lattice parameters, and atoms. We demonstrate that SHAFT significantly\noutperforms state-of-the-art iterative generative methods, such as Generative\nFlow Networks (GFlowNets) and Crystal Diffusion Variational AutoEncoders\n(CDVAE), in crystal structure generation tasks, achieving higher validity,\ndiversity, and stability of generated structures optimized for target\nproperties and requirements.\n","authors":["Tri Minh Nguyen","Sherif Abdulkader Tawfik","Truyen Tran","Sunil Gupta","Santu Rana","Svetha Venkatesh"],"pdf_url":"https://arxiv.org/pdf/2411.04323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04319v1","updated":"2024-11-06T23:47:54Z","published":"2024-11-06T23:47:54Z","title":"Towards Optimizing SQL Generation via LLM Routing","summary":"  Text-to-SQL enables users to interact with databases through natural\nlanguage, simplifying access to structured data. Although highly capable large\nlanguage models (LLMs) achieve strong accuracy for complex queries, they incur\nunnecessary latency and dollar cost for simpler ones. In this paper, we\nintroduce the first LLM routing approach for Text-to-SQL, which dynamically\nselects the most cost-effective LLM capable of generating accurate SQL for each\nquery. We present two routing strategies (score- and classification-based) that\nachieve accuracy comparable to the most capable LLM while reducing costs. We\ndesign the routers for ease of training and efficient inference. In our\nexperiments, we highlight a practical and explainable accuracy-cost trade-off\non the BIRD dataset.\n","authors":["Mohammadhossein Malekpour","Nour Shaheen","Foutse Khomh","Amine Mhedhbi"],"pdf_url":"https://arxiv.org/pdf/2411.04319v1.pdf","comment":"Table Representation Learning Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04316v1","updated":"2024-11-06T23:41:18Z","published":"2024-11-06T23:41:18Z","title":"A Multilingual Sentiment Lexicon for Low-Resource Language Translation\n  using Large Languages Models and Explainable AI","summary":"  South Africa and the Democratic Republic of Congo (DRC) present a complex\nlinguistic landscape with languages such as Zulu, Sepedi, Afrikaans, French,\nEnglish, and Tshiluba (Ciluba), which creates unique challenges for AI-driven\ntranslation and sentiment analysis systems due to a lack of accurately labeled\ndata. This study seeks to address these challenges by developing a multilingual\nlexicon designed for French and Tshiluba, now expanded to include translations\nin English, Afrikaans, Sepedi, and Zulu. The lexicon enhances cultural\nrelevance in sentiment classification by integrating language-specific\nsentiment scores. A comprehensive testing corpus is created to support\ntranslation and sentiment analysis tasks, with machine learning models such as\nRandom Forest, Support Vector Machine (SVM), Decision Trees, and Gaussian Naive\nBayes (GNB) trained to predict sentiment across low resource languages (LRLs).\nAmong them, the Random Forest model performed particularly well, capturing\nsentiment polarity and handling language-specific nuances effectively.\nFurthermore, Bidirectional Encoder Representations from Transformers (BERT), a\nLarge Language Model (LLM), is applied to predict context-based sentiment with\nhigh accuracy, achieving 99% accuracy and 98% precision, outperforming other\nmodels. The BERT predictions were clarified using Explainable AI (XAI),\nimproving transparency and fostering confidence in sentiment classification.\nOverall, findings demonstrate that the proposed lexicon and machine learning\nmodels significantly enhance translation and sentiment analysis for LRLs in\nSouth Africa and the DRC, laying a foundation for future AI models that support\nunderrepresented languages, with applications across education, governance, and\nbusiness in multilingual contexts.\n","authors":["Melusi Malinga","Isaac Lupanda","Mike Wa Nkongolo","Phil van Deventer"],"pdf_url":"https://arxiv.org/pdf/2411.04316v1.pdf","comment":"This work is part of a PhD proposal in Information Technology at the\n  University of Pretoria, supervised by Dr. Mike Wa Nkongolo and co-supervised\n  by Dr. Phil van Deventer, under the Low-Resource Language Processing Lab in\n  the Department of Informatics"},{"id":"http://arxiv.org/abs/2411.04315v1","updated":"2024-11-06T23:39:39Z","published":"2024-11-06T23:39:39Z","title":"Theoretically informed selection of latent activation in autoencoder\n  based recommender systems","summary":"  Autoencoders may lend themselves to the design of more accurate and\ncomputationally efficient recommender systems by distilling sparse\nhigh-dimensional data into dense lower-dimensional latent representations.\nHowever, designing these systems remains challenging due to the lack of\ntheoretical guidance. This work addresses this by identifying three key\nmathematical properties that the encoder in an autoencoder should exhibit to\nimprove recommendation accuracy: (1) dimensionality reduction, (2) preservation\nof similarity ordering in dot product comparisons, and (3) preservation of\nnon-zero vectors. Through theoretical analysis, we demonstrate that common\nactivation functions, such as ReLU and tanh, cannot fulfill these properties\njointly within a generalizable framework. In contrast, sigmoid-like activations\nemerge as suitable choices for latent activations. This theoretically informed\napproach offers a more systematic method for hyperparameter selection,\nenhancing the efficiency of model design.\n","authors":["Aviad Susman"],"pdf_url":"https://arxiv.org/pdf/2411.04315v1.pdf","comment":"2 pages, 1 figure"},{"id":"http://arxiv.org/abs/2402.03478v2","updated":"2024-11-06T23:02:47Z","published":"2024-02-05T19:39:52Z","title":"Estimating Epistemic and Aleatoric Uncertainty with a Single Model","summary":"  Estimating and disentangling epistemic uncertainty, uncertainty that is\nreducible with more training data, and aleatoric uncertainty, uncertainty that\nis inherent to the task at hand, is critically important when applying machine\nlearning to high-stakes applications such as medical imaging and weather\nforecasting. Conditional diffusion models' breakthrough ability to accurately\nand efficiently sample from the posterior distribution of a dataset now makes\nuncertainty estimation conceptually straightforward: One need only train and\nsample from a large ensemble of diffusion models. Unfortunately, training such\nan ensemble becomes computationally intractable as the complexity of the model\narchitecture grows. In this work we introduce a new approach to ensembling,\nhyper-diffusion models (HyperDM), which allows one to accurately estimate both\nepistemic and aleatoric uncertainty with a single model. Unlike existing\nsingle-model uncertainty methods like Monte-Carlo dropout and Bayesian neural\nnetworks, HyperDM offers prediction accuracy on par with, and in some cases\nsuperior to, multi-model ensembles. Furthermore, our proposed approach scales\nto modern network architectures such as Attention U-Net and yields more\naccurate uncertainty estimates compared to existing methods. We validate our\nmethod on two distinct real-world tasks: x-ray computed tomography\nreconstruction and weather temperature forecasting.\n","authors":["Matthew A. Chan","Maria J. Molina","Christopher A. Metzler"],"pdf_url":"https://arxiv.org/pdf/2402.03478v2.pdf","comment":"19 pages, 11 figures. To be published in Conference on Neural\n  Information Processing Systems (NeurIPS) 2024"},{"id":"http://arxiv.org/abs/2405.19279v2","updated":"2024-11-06T22:45:30Z","published":"2024-05-29T17:11:28Z","title":"Understanding and Minimising Outlier Features in Neural Network Training","summary":"  Outlier Features (OFs) are neurons whose activation magnitudes significantly\nexceed the average over a neural network's (NN) width. They are well known to\nemerge during standard transformer training and have the undesirable effect of\nhindering quantisation in afflicted models. Despite their practical importance,\nlittle is known behind why OFs emerge during training, nor how one can minimise\nthem.\n  Our work focuses on the above questions, first identifying several\nquantitative metrics, such as the kurtosis over neuron activation norms, to\nmeasure OFs. With these metrics, we study how architectural and optimisation\nchoices influence OFs, and provide practical insights to minimise OFs during\ntraining. As highlights, we introduce a novel unnormalised transformer block,\nthe Outlier Protected block, and present a previously unknown benefit of\nnon-diagonal preconditioning optimisers, finding both approaches to\nsignificantly reduce OFs and improve quantisation without compromising\nconvergence speed, at scales of up to 7B parameters. Notably, our combination\nof OP block and non-diagonal preconditioner (SOAP) achieves 14.87 int8\nweight-and-activation perplexity (from 14.71 in standard precision), compared\nto 63.4 int8 perplexity (from 16.00) with a default OF-prone combination of\nPre-Norm model and Adam, when quantising OPT-125m models post-training.\nOverall, our findings shed new light on our understanding of, our ability to\nprevent, and the complexity of this important aspect of NN training dynamics.\n","authors":["Bobby He","Lorenzo Noci","Daniele Paliotta","Imanol Schlag","Thomas Hofmann"],"pdf_url":"https://arxiv.org/pdf/2405.19279v2.pdf","comment":"NeurIPS 2024 camera ready"},{"id":"http://arxiv.org/abs/2406.11944v2","updated":"2024-11-06T22:37:30Z","published":"2024-06-17T17:49:00Z","title":"Transcoders Find Interpretable LLM Feature Circuits","summary":"  A key goal in mechanistic interpretability is circuit analysis: finding\nsparse subgraphs of models corresponding to specific behaviors or capabilities.\nHowever, MLP sublayers make fine-grained circuit analysis on transformer-based\nlanguage models difficult. In particular, interpretable features -- such as\nthose found by sparse autoencoders (SAEs) -- are typically linear combinations\nof extremely many neurons, each with its own nonlinearity to account for.\nCircuit analysis in this setting thus either yields intractably large circuits\nor fails to disentangle local and global behavior. To address this we explore\ntranscoders, which seek to faithfully approximate a densely activating MLP\nlayer with a wider, sparsely-activating MLP layer. We introduce a novel method\nfor using transcoders to perform weights-based circuit analysis through MLP\nsublayers. The resulting circuits neatly factorize into input-dependent and\ninput-invariant terms. We then successfully train transcoders on language\nmodels with 120M, 410M, and 1.4B parameters, and find them to perform at least\non par with SAEs in terms of sparsity, faithfulness, and\nhuman-interpretability. Finally, we apply transcoders to reverse-engineer\nunknown circuits in the model, and we obtain novel insights regarding the\n\"greater-than circuit\" in GPT2-small. Our results suggest that transcoders can\nprove effective in decomposing model computations involving MLPs into\ninterpretable circuits. Code is available at\nhttps://github.com/jacobdunefsky/transcoder_circuits/.\n","authors":["Jacob Dunefsky","Philippe Chlenski","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.11944v2.pdf","comment":"29 pages, 6 figures, 4 tables, 2 algorithms. NeurIPS 2024"},{"id":"http://arxiv.org/abs/2310.03722v5","updated":"2024-11-06T22:27:19Z","published":"2023-10-05T17:43:26Z","title":"Anytime-valid t-tests and confidence sequences for Gaussian means with\n  unknown variance","summary":"  In 1976, Lai constructed a nontrivial confidence sequence for the mean $\\mu$\nof a Gaussian distribution with unknown variance $\\sigma^2$. Curiously, he\nemployed both an improper (right Haar) mixture over $\\sigma$ and an improper\n(flat) mixture over $\\mu$. Here, we elaborate carefully on the details of his\nconstruction, which use generalized nonintegrable martingales and an extended\nVille's inequality. While this does yield a sequential t-test, it does not\nyield an \"e-process\" (due to the nonintegrability of his martingale). In this\npaper, we develop two new e-processes and confidence sequences for the same\nsetting: one is a test martingale in a reduced filtration, while the other is\nan e-process in the canonical data filtration. These are respectively obtained\nby swapping Lai's flat mixture for a Gaussian mixture, and swapping the right\nHaar mixture over $\\sigma$ with the maximum likelihood estimate under the null,\nas done in universal inference. We also analyze the width of resulting\nconfidence sequences, which have a curious polynomial dependence on the error\nprobability $\\alpha$ that we prove to be not only unavoidable, but (for\nuniversal inference) even better than the classical fixed-sample t-test.\nNumerical experiments are provided along the way to compare and contrast the\nvarious approaches, including some recent suboptimal ones.\n","authors":["Hongjian Wang","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2310.03722v5.pdf","comment":"Substantive revision in v3 (Apr 23 2024); Final revision in v4 (Nov 6\n  2024) accepted by the journal Sequential Analysis"},{"id":"http://arxiv.org/abs/2411.04295v1","updated":"2024-11-06T22:25:56Z","published":"2024-11-06T22:25:56Z","title":"Fair Exploration and Exploitation","summary":"  In this paper we consider the contextual bandit problem with a finite (or\ninfinite and clustered) context set. We consider the fully adversarial problem\nin which, apart from having bounded losses, there are no assumptions whatsoever\non the generation of the contexts and losses. In our problem we assume that the\ncontext set is partitioned into a set of protected groups. At the start of each\ntrial we are given a probability distribution over the context set and are\nrequired (on that trial) to be fair with respect to that distribution, in that\nif the context (for that trial) was drawn from the distribution then our choice\nof action would be unbiased towards any protected group. We develop an\nalgorithm FexEx for this problem which has remarkable efficiency, having a\nspace and per-trial time complexity at most linear in the dimensionality of the\npolicy space. FexEx can handle non-stationarity, in that its regret can be\nbounded with respect to any sequence of policies satisfying the fairness\nconstraints. For such a sequence the regret bound of FexEx is essentially the\nsame as that of running Exp3.S for each context independently (an approach that\ndoes not satisfy the fairness constraints).\n","authors":["Stephen Pasteris","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2411.04295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03619v2","updated":"2024-11-06T22:25:43Z","published":"2024-06-05T20:38:30Z","title":"Symmetry Discovery Beyond Affine Transformations","summary":"  Symmetry detection can improve various machine learning tasks. In the context\nof continuous symmetry detection, current state of the art experiments are\nlimited to detecting affine transformations. Under the manifold assumption, we\noutline a framework for discovering continuous symmetry in data beyond the\naffine transformation group. We also provide a similar framework for\ndiscovering discrete symmetry. We experimentally compare our method to an\nexisting method known as LieGAN and show that our method is competitive at\ndetecting affine symmetries for large sample sizes and superior than LieGAN for\nsmall sample sizes. We also show our method is able to detect continuous\nsymmetries beyond the affine group and is generally more computationally\nefficient than LieGAN.\n","authors":["Ben Shaw","Abram Magner","Kevin R. Moon"],"pdf_url":"https://arxiv.org/pdf/2406.03619v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12094v3","updated":"2024-11-06T22:21:14Z","published":"2023-02-23T15:28:36Z","title":"Evaluating Explainability in Machine Learning Predictions through\n  Explainer-Agnostic Metrics","summary":"  The rapid integration of artificial intelligence (AI) into various industries\nhas introduced new challenges in governance and regulation, particularly\nregarding the understanding of complex AI systems. A critical demand from\ndecision-makers is the ability to explain the results of machine learning\nmodels, which is essential for fostering trust and ensuring ethical AI\npractices. In this paper, we develop six distinct model-agnostic metrics\ndesigned to quantify the extent to which model predictions can be explained.\nThese metrics measure different aspects of model explainability, ranging from\nlocal importance, global importance, and surrogate predictions, allowing for a\ncomprehensive evaluation of how models generate their outputs. Furthermore, by\ncomputing our metrics, we can rank models in terms of explainability criteria\nsuch as importance concentration and consistency, prediction fluctuation, and\nsurrogate fidelity and stability, offering a valuable tool for selecting models\nbased not only on accuracy but also on transparency. We demonstrate the\npractical utility of these metrics on classification and regression tasks, and\nintegrate these metrics into an existing Python package for public use.\n","authors":["Cristian Munoz","Kleyton da Costa","Bernardo Modenesi","Adriano Koshiyama"],"pdf_url":"https://arxiv.org/pdf/2302.12094v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03987v3","updated":"2024-11-06T22:13:26Z","published":"2024-05-07T03:55:57Z","title":"Navigating Chemical Space with Latent Flows","summary":"  Recent progress of deep generative models in the vision and language domain\nhas stimulated significant interest in more structured data generation such as\nmolecules. However, beyond generating new random molecules, efficient\nexploration and a comprehensive understanding of the vast chemical space are of\ngreat importance to molecular science and applications in drug design and\nmaterials discovery. In this paper, we propose a new framework, ChemFlow, to\ntraverse chemical space through navigating the latent space learned by molecule\ngenerative models through flows. We introduce a dynamical system perspective\nthat formulates the problem as learning a vector field that transports the mass\nof the molecular distribution to the region with desired molecular properties\nor structure diversity. Under this framework, we unify previous approaches on\nmolecule latent space traversal and optimization and propose alternative\ncompeting methods incorporating different physical priors. We validate the\nefficacy of ChemFlow on molecule manipulation and single- and multi-objective\nmolecule optimization tasks under both supervised and unsupervised molecular\ndiscovery settings. Codes and demos are publicly available on GitHub at\nhttps://github.com/garywei944/ChemFlow.\n","authors":["Guanghao Wei","Yining Huang","Chenru Duan","Yue Song","Yuanqi Du"],"pdf_url":"https://arxiv.org/pdf/2405.03987v3.pdf","comment":"Accepted for presentation at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04285v1","updated":"2024-11-06T22:11:20Z","published":"2024-11-06T22:11:20Z","title":"Robust Real-Time Mortality Prediction in the Intensive Care Unit using\n  Temporal Difference Learning","summary":"  The task of predicting long-term patient outcomes using supervised machine\nlearning is a challenging one, in part because of the high variance of each\npatient's trajectory, which can result in the model over-fitting to the\ntraining data. Temporal difference (TD) learning, a common reinforcement\nlearning technique, may reduce variance by generalising learning to the pattern\nof state transitions rather than terminal outcomes. However, in healthcare this\nmethod requires several strong assumptions about patient states, and there\nappears to be limited literature evaluating the performance of TD learning\nagainst traditional supervised learning methods for long-term health outcome\nprediction tasks. In this study, we define a framework for applying TD learning\nto real-time irregularly sampled time series data using a Semi-Markov Reward\nProcess. We evaluate the model framework in predicting intensive care mortality\nand show that TD learning under this framework can result in improved model\nrobustness compared to standard supervised learning methods. and that this\nrobustness is maintained even when validated on external datasets. This\napproach may offer a more reliable method when learning to predict patient\noutcomes using high-variance irregular time series data.\n","authors":["Thomas Frost","Kezhi Li","Steve Harris"],"pdf_url":"https://arxiv.org/pdf/2411.04285v1.pdf","comment":"To be published in the Proceedings of the 4th Machine Learning for\n  Health symposium, Proceedings of Machine Learning Research (PMLR)"},{"id":"http://arxiv.org/abs/2411.04284v1","updated":"2024-11-06T22:10:18Z","published":"2024-11-06T22:10:18Z","title":"Enhancing Security Control Production With Generative AI","summary":"  Security controls are mechanisms or policies designed for cloud based\nservices to reduce risk, protect information, and ensure compliance with\nsecurity regulations. The development of security controls is traditionally a\nlabor-intensive and time-consuming process. This paper explores the use of\nGenerative AI to accelerate the generation of security controls. We\nspecifically focus on generating Gherkin codes which are the domain-specific\nlanguage used to define the behavior of security controls in a structured and\nunderstandable format. By leveraging large language models and in-context\nlearning, we propose a structured framework that reduces the time required for\ndeveloping security controls from 2-3 days to less than one minute. Our\napproach integrates detailed task descriptions, step-by-step instructions, and\nretrieval-augmented generation to enhance the accuracy and efficiency of the\ngenerated Gherkin code. Initial evaluations on AWS cloud services demonstrate\npromising results, indicating that GenAI can effectively streamline the\nsecurity control development process, thus providing a robust and dynamic\nsafeguard for cloud-based infrastructures.\n","authors":["Chen Ling","Mina Ghashami","Vianne Gao","Ali Torkamani","Ruslan Vaulin","Nivedita Mangam","Bhavya Jain","Farhan Diwan","Malini SS","Mingrui Cheng","Shreya Tarur Kumar","Felix Candelario"],"pdf_url":"https://arxiv.org/pdf/2411.04284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15708v2","updated":"2024-11-06T22:07:17Z","published":"2024-06-22T02:07:10Z","title":"Teach Better or Show Smarter? On Instructions and Exemplars in Automatic\n  Prompt Optimization","summary":"  Large language models have demonstrated remarkable capabilities, but their\nperformance is heavily reliant on effective prompt engineering. Automatic\nprompt optimization (APO) methods are designed to automate this and can be\nbroadly categorized into those targeting instructions (instruction\noptimization, IO) vs. those targeting exemplars (exemplar optimization, EO).\nDespite their shared objective, these have evolved rather independently, with\nIO receiving more research attention recently. This paper seeks to bridge this\ngap by comprehensively comparing the performance of representative IO and EO\ntechniques both isolation and combination on a diverse set of challenging\ntasks. Our findings reveal that intelligently reusing model-generated\ninput-output pairs obtained from evaluating prompts on the validation set as\nexemplars, consistently improves performance on top of IO methods but is\ncurrently under-investigated. We also find that despite the recent focus on IO,\nhow we select exemplars can outweigh how we optimize instructions, with EO\nstrategies as simple as random search outperforming state-of-the-art IO methods\nwith seed instructions without any optimization. Moreover, we observe a synergy\nbetween EO and IO, with optimal combinations surpassing the individual\ncontributions. We conclude that studying exemplar optimization both as a\nstandalone method and its optimal combination with instruction optimization\nremain a crucial aspect of APO and deserve greater consideration in future\nresearch, even in the era of highly capable instruction-following models.\n","authors":["Xingchen Wan","Ruoxi Sun","Hootan Nakhost","Sercan O. Arik"],"pdf_url":"https://arxiv.org/pdf/2406.15708v2.pdf","comment":"Expanded version of the NeurIPS 2024 paper"},{"id":"http://arxiv.org/abs/2411.04282v1","updated":"2024-11-06T22:02:30Z","published":"2024-11-06T22:02:30Z","title":"Language Models are Hidden Reasoners: Unlocking Latent Reasoning\n  Capabilities via Self-Rewarding","summary":"  Large language models (LLMs) have shown impressive capabilities, but still\nstruggle with complex reasoning tasks requiring multiple steps. While\nprompt-based methods like Chain-of-Thought (CoT) can improve LLM reasoning at\ninference time, optimizing reasoning capabilities during training remains\nchallenging. We introduce LaTent Reasoning Optimization (LaTRO), a principled\nframework that formulates reasoning as sampling from a latent distribution and\noptimizes it via variational approaches. LaTRO enables LLMs to concurrently\nimprove both their reasoning process and ability to evaluate reasoning quality,\nwithout requiring external feedback or reward models. We validate LaTRO through\nexperiments on GSM8K and ARC-Challenge datasets using multiple model\narchitectures. On GSM8K, LaTRO improves zero-shot accuracy by an average of\n12.5% over base models and 9.6% over supervised fine-tuning across\nPhi-3.5-mini, Mistral-7B, and Llama-3.1-8B. Our findings suggest that\npre-trained LLMs possess latent reasoning capabilities that can be unlocked and\nenhanced through our proposed optimization approach in a self-improvement\nmanner. The code of LaTRO is available at\n\\url{https://github.com/SalesforceAIResearch/LaTRO}.\n","authors":["Haolin Chen","Yihao Feng","Zuxin Liu","Weiran Yao","Akshara Prabhakar","Shelby Heinecke","Ricky Ho","Phil Mui","Silvio Savarese","Caiming Xiong","Huan Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04281v1","updated":"2024-11-06T21:59:19Z","published":"2024-11-06T21:59:19Z","title":"Generating Synthetic Electronic Health Record (EHR) Data: A Review with\n  Benchmarking","summary":"  We conduct a scoping review of existing approaches for synthetic EHR data\ngeneration, and benchmark major methods with proposed open-source software to\noffer recommendations for practitioners. We search three academic databases for\nour scoping review. Methods are benchmarked on open-source EHR datasets,\nMIMIC-III/IV. Seven existing methods covering major categories and two baseline\nmethods are implemented and compared. Evaluation metrics concern data fidelity,\ndownstream utility, privacy protection, and computational cost. 42 studies are\nidentified and classified into five categories. Seven open-source methods\ncovering all categories are selected, trained on MIMIC-III, and evaluated on\nMIMIC-III or MIMIC-IV for transportability considerations. Among them,\nGAN-based methods demonstrate competitive performance in fidelity and utility\non MIMIC-III; rule-based methods excel in privacy protection. Similar findings\nare observed on MIMIC-IV, except that GAN-based methods further outperform the\nbaseline methods in preserving fidelity. A Python package, ``SynthEHRella'', is\nprovided to integrate various choices of approaches and evaluation metrics,\nenabling more streamlined exploration and evaluation of multiple methods. We\nfound that method choice is governed by the relative importance of the\nevaluation metrics in downstream use cases. We provide a decision tree to guide\nthe choice among the benchmarked methods. Based on the decision tree, GAN-based\nmethods excel when distributional shifts exist between the training and testing\npopulations. Otherwise, CorGAN and MedGAN are most suitable for association\nmodeling and predictive modeling, respectively. Future research should\nprioritize enhancing fidelity of the synthetic data while controlling privacy\nexposure, and comprehensive benchmarking of longitudinal or conditional\ngeneration methods.\n","authors":["Xingran Chen","Zhenke Wu","Xu Shi","Hyunghoon Cho","Bhramar Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2411.04281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04280v1","updated":"2024-11-06T21:58:24Z","published":"2024-11-06T21:58:24Z","title":"Bayesian Inference in Recurrent Explicit Duration Switching Linear\n  Dynamical Systems","summary":"  In this paper, we propose a novel model called Recurrent Explicit Duration\nSwitching Linear Dynamical Systems (REDSLDS) that incorporates recurrent\nexplicit duration variables into the rSLDS model. We also propose an inference\nand learning scheme that involves the use of P\\'olya-gamma augmentation. We\ndemonstrate the improved segmentation capabilities of our model on three\nbenchmark datasets, including two quantitative datasets and one qualitative\ndataset.\n","authors":["Mikołaj Słupiński","Piotr Lipiński"],"pdf_url":"https://arxiv.org/pdf/2411.04280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03217v2","updated":"2024-11-06T21:53:44Z","published":"2024-11-05T16:09:28Z","title":"A Personal data Value at Risk Approach","summary":"  What if the main data protection vulnerability is risk management? Data\nProtection merges three disciplines: data protection law, information security,\nand risk management. Nonetheless, very little research has been made on the\nfield of data protection risk management, where subjectivity and superficiality\nare the dominant state of the art. Since the GDPR tells you what to do, but not\nhow to do it, the solution for approaching GDPR compliance is still a gray\nzone, where the trend is using the rule of thumb. Considering that the most\nimportant goal of risk management is to reduce uncertainty in order to take\ninformed decisions, risk management for the protection of the rights and\nfreedoms of the data subjects cannot be disconnected from the impact\nmaterialization that data controllers and processors need to assess. This paper\nproposes a quantitative approach to data protection risk-based compliance from\na data controllers perspective, with the aim of proposing a mindset change,\nwhere data protection impact assessments can be improved by using data\nprotection analytics, quantitative risk analysis, and calibrating expert\nopinions.\n","authors":["Luis Enriquez"],"pdf_url":"https://arxiv.org/pdf/2411.03217v2.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2411.04278v1","updated":"2024-11-06T21:49:20Z","published":"2024-11-06T21:49:20Z","title":"The Recurrent Sticky Hierarchical Dirichlet Process Hidden Markov Model","summary":"  The Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) is a natural\nBayesian nonparametric extension of the classical Hidden Markov Model for\nlearning from (spatio-)temporal data. A sticky HDP-HMM has been proposed to\nstrengthen the self-persistence probability in the HDP-HMM. Then, disentangled\nsticky HDP-HMM has been proposed to disentangle the strength of the\nself-persistence prior and transition prior. However, the sticky HDP-HMM\nassumes that the self-persistence probability is stationary, limiting its\nexpressiveness. Here, we build on previous work on sticky HDP-HMM and\ndisentangled sticky HDP-HMM, developing a more general model: the recurrent\nsticky HDP-HMM (RS-HDP-HMM). We develop a novel Gibbs sampling strategy for\nefficient inference in this model. We show that RS-HDP-HMM outperforms\ndisentangled sticky HDP-HMM, sticky HDP-HMM, and HDP-HMM in both synthetic and\nreal data segmentation.\n","authors":["Mikołaj Słupiński","Piotr Lipiński"],"pdf_url":"https://arxiv.org/pdf/2411.04278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07066v2","updated":"2024-11-06T21:48:57Z","published":"2024-02-10T23:42:05Z","title":"Differentially Private Range Queries with Correlated Input Perturbation","summary":"  This work proposes a class of differentially private mechanisms for linear\nqueries, in particular range queries, that leverages correlated input\nperturbation to simultaneously achieve unbiasedness, consistency, statistical\ntransparency, and control over utility requirements in terms of accuracy\ntargets expressed either in certain query margins or as implied by the\nhierarchical database structure. The proposed Cascade Sampling algorithm\ninstantiates the mechanism exactly and efficiently. Our theoretical and\nempirical analysis demonstrates that we achieve near-optimal utility,\neffectively compete with other methods, and retain all the favorable\nstatistical properties discussed earlier.\n","authors":["Prathamesh Dharangutte","Jie Gao","Ruobin Gong","Guanyang Wang"],"pdf_url":"https://arxiv.org/pdf/2402.07066v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12692v2","updated":"2024-11-06T21:46:48Z","published":"2024-10-16T15:52:32Z","title":"Machine learning approach to brain tumor detection and classification","summary":"  Brain tumor detection and classification are critical tasks in medical image\nanalysis, particularly in early-stage diagnosis, where accurate and timely\ndetection can significantly improve treatment outcomes. In this study, we apply\nvarious statistical and machine learning models to detect and classify brain\ntumors using brain MRI images. We explore a variety of statistical models\nincluding linear, logistic, and Bayesian regressions, and the machine learning\nmodels including decision tree, random forest, single-layer perceptron,\nmulti-layer perceptron, convolutional neural network (CNN), recurrent neural\nnetwork, and long short-term memory. Our findings show that CNN outperforms\nother models, achieving the best performance. Additionally, we confirm that the\nCNN model can also work for multi-class classification, distinguishing between\nfour categories of brain MRI images such as normal, glioma, meningioma, and\npituitary tumor images. This study demonstrates that machine learning\napproaches are suitable for brain tumor detection and classification,\nfacilitating real-world medical applications in assisting radiologists with\nearly and accurate diagnosis.\n","authors":["Alice Oh","Inyoung Noh","Jian Choo","Jihoo Lee","Justin Park","Kate Hwang","Sanghyeon Kim","Soo Min Oh"],"pdf_url":"https://arxiv.org/pdf/2410.12692v2.pdf","comment":"7 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.04276v1","updated":"2024-11-06T21:46:23Z","published":"2024-11-06T21:46:23Z","title":"Labels in Extremes: How Well Calibrated are Extreme Multi-label\n  Classifiers?","summary":"  Extreme multilabel classification (XMLC) problems occur in settings such as\nrelated product recommendation, large-scale document tagging, or ad prediction,\nand are characterized by a label space that can span millions of possible\nlabels. There are two implicit tasks that the classifier performs:\n\\emph{Evaluating} each potential label for its expected worth, and then\n\\emph{selecting} the best candidates. For the latter task, only the relative\norder of scores matters, and this is what is captured by the standard\nevaluation procedure in the XMLC literature. However, in many practical\napplications, it is important to have a good estimate of the actual probability\nof a label being relevant, e.g., to decide whether to pay the fee to be allowed\nto display the corresponding ad. To judge whether an extreme classifier is\nindeed suited to this task, one can look, for example, to whether it returns\n\\emph{calibrated} probabilities, which has hitherto not been done in this\nfield. Therefore, this paper aims to establish the current status quo of\ncalibration in XMLC by providing a systematic evaluation, comprising nine\nmodels from four different model families across seven benchmark datasets. As\nnaive application of Expected Calibration Error (ECE) leads to meaningless\nresults in long-tailed XMC datasets, we instead introduce the notion of\n\\emph{calibration@k} (e.g., ECE@k), which focusses on the top-$k$ probability\nmass, offering a more appropriate measure for evaluating probability\ncalibration in XMLC scenarios. While we find that different models can exhibit\nwidely varying reliability plots, we also show that post-training calibration\nvia a computationally efficient isotonic regression method enhances model\ncalibration without sacrificing prediction accuracy. Thus, the practitioner can\nchoose the model family based on accuracy considerations, and leave calibration\nto isotonic regression.\n","authors":["Nasib Ullah","Erik Schultheis","Jinbin Zhang","Rohit Babbar"],"pdf_url":"https://arxiv.org/pdf/2411.04276v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2304.05872v2","updated":"2024-11-06T21:31:13Z","published":"2023-04-12T14:02:42Z","title":"Learning to Communicate and Collaborate in a Competitive Multi-Agent\n  Setup to Clean the Ocean from Macroplastics","summary":"  Finding a balance between collaboration and competition is crucial for\nartificial agents in many real-world applications. We investigate this using a\nMulti-Agent Reinforcement Learning (MARL) setup on the back of a high-impact\nproblem. The accumulation and yearly growth of plastic in the ocean cause\nirreparable damage to many aspects of oceanic health and the marina system. To\nprevent further damage, we need to find ways to reduce macroplastics from known\nplastic patches in the ocean. Here we propose a Graph Neural Network (GNN)\nbased communication mechanism that increases the agents' observation space. In\nour custom environment, agents control a plastic collecting vessel. The\ncommunication mechanism enables agents to develop a communication protocol\nusing a binary signal. While the goal of the agent collective is to clean up as\nmuch as possible, agents are rewarded for the individual amount of\nmacroplastics collected. Hence agents have to learn to communicate effectively\nwhile maintaining high individual performance. We compare our proposed\ncommunication mechanism with a multi-agent baseline without the ability to\ncommunicate. Results show communication enables collaboration and increases\ncollective performance significantly. This means agents have learned the\nimportance of communication and found a balance between collaboration and\ncompetition.\n","authors":["Philipp Dominic Siedler"],"pdf_url":"https://arxiv.org/pdf/2304.05872v2.pdf","comment":"Tackling Climate Change with Machine Learning Workshop at the 11th\n  International Conference on Learning Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2406.08506v2","updated":"2024-11-06T21:25:19Z","published":"2024-06-01T13:11:11Z","title":"RGFN: Synthesizable Molecular Generation Using GFlowNets","summary":"  Generative models hold great promise for small molecule discovery,\nsignificantly increasing the size of search space compared to traditional in\nsilico screening libraries. However, most existing machine learning methods for\nsmall molecule generation suffer from poor synthesizability of candidate\ncompounds, making experimental validation difficult. In this paper we propose\nReaction-GFlowNet (RGFN), an extension of the GFlowNet framework that operates\ndirectly in the space of chemical reactions, thereby allowing out-of-the-box\nsynthesizability while maintaining comparable quality of generated candidates.\nWe demonstrate that with the proposed set of reactions and building blocks, it\nis possible to obtain a search space of molecules orders of magnitude larger\nthan existing screening libraries coupled with low cost of synthesis. We also\nshow that the approach scales to very large fragment libraries, further\nincreasing the number of potential molecules. We demonstrate the effectiveness\nof the proposed approach across a range of oracle models, including pretrained\nproxy models and GPU-accelerated docking.\n","authors":["Michał Koziarski","Andrei Rekesh","Dmytro Shevchuk","Almer van der Sloot","Piotr Gaiński","Yoshua Bengio","Cheng-Hao Liu","Mike Tyers","Robert A. Batey"],"pdf_url":"https://arxiv.org/pdf/2406.08506v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04266v1","updated":"2024-11-06T21:17:38Z","published":"2024-11-06T21:17:38Z","title":"Generative Discrete Event Process Simulation for Hidden Markov Models to\n  Predict Competitor Time-to-Market","summary":"  We study the challenge of predicting the time at which a competitor product,\nsuch as a novel high-capacity EV battery or a new car model, will be available\nto customers; as new information is obtained, this time-to-market estimate is\nrevised. Our scenario is as follows: We assume that the product is under\ndevelopment at a Firm B, which is a competitor to Firm A; as they are in the\nsame industry, Firm A has a relatively good understanding of the processes and\nsteps required to produce the product. While Firm B tries to keep its\nactivities hidden (think of stealth-mode for start-ups), Firm A is nevertheless\nable to gain periodic insights by observing what type of resources Firm B is\nusing. We show how Firm A can build a model that predicts when Firm B will be\nready to sell its product; the model leverages knowledge of the underlying\nprocesses and required resources to build a Parallel Discrete Simulation\n(PDES)-based process model that it then uses as a generative model to train a\nHidden Markov Model (HMM). We study the question of how many resource\nobservations Firm A requires in order to accurately assess the current state of\ndevelopment at Firm B. In order to gain general insights into the capabilities\nof this approach, we study the effect of different process graph densities,\ndifferent densities of the resource-activity maps, etc., and also scaling\nproperties as we increase the number resource counts. We find that in most\ncases, the HMM achieves a prediction accuracy of 70 to 80 percent after 20\n(daily) observations of a production process that lasts 150 days on average and\nwe characterize the effects of different problem instance densities on this\nprediction accuracy. Our results give insight into the level of market\nknowledge required for accurate and early time-to-market prediction.\n","authors":["Nandakishore Santhi","Stephan Eidenbenz","Brian Key","George Tompkins"],"pdf_url":"https://arxiv.org/pdf/2411.04266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04265v1","updated":"2024-11-06T21:17:14Z","published":"2024-11-06T21:17:14Z","title":"Graph neural networks and non-commuting operators","summary":"  Graph neural networks (GNNs) provide state-of-the-art results in a wide\nvariety of tasks which typically involve predicting features at the vertices of\na graph. They are built from layers of graph convolutions which serve as a\npowerful inductive bias for describing the flow of information among the\nvertices. Often, more than one data modality is available. This work considers\na setting in which several graphs have the same vertex set and a common\nvertex-level learning task. This generalizes standard GNN models to GNNs with\nseveral graph operators that do not commute. We may call this model graph-tuple\nneural networks (GtNN).\n  In this work, we develop the mathematical theory to address the stability and\ntransferability of GtNNs using properties of non-commuting non-expansive\noperators. We develop a limit theory of graphon-tuple neural networks and use\nit to prove a universal transferability theorem that guarantees that all\ngraph-tuple neural networks are transferable on convergent graph-tuple\nsequences. In particular, there is no non-transferable energy under the\nconvergence we consider here. Our theoretical results extend well-known\ntransferability theorems for GNNs to the case of several simultaneous graphs\n(GtNNs) and provide a strict improvement on what is currently known even in the\nGNN case.\n  We illustrate our theoretical results with simple experiments on synthetic\nand real-world data. To this end, we derive a training procedure that provably\nenforces the stability of the resulting model.\n","authors":["Mauricio Velasco","Kaiying O'Hare","Bernardo Rychtenberg","Soledad Villar"],"pdf_url":"https://arxiv.org/pdf/2411.04265v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04263v1","updated":"2024-11-06T21:16:02Z","published":"2024-11-06T21:16:02Z","title":"Object Recognition in Human Computer Interaction:- A Comparative\n  Analysis","summary":"  Human-computer interaction (HCI) has been a widely researched area for many\nyears, with continuous advancements in technology leading to the development of\nnew techniques that change the way we interact with computers. With the recent\nadvent of powerful computers, we recognize human actions and interact\naccordingly, thus revolutionizing the way we interact with computers. The\npurpose of this paper is to provide a comparative analysis of various\nalgorithms used for recognizing user faces and gestures in the context of\ncomputer vision and HCI. This study aims to explore and evaluate the\nperformance of different algorithms in terms of accuracy, robustness, and\nefficiency. This study aims to provide a comprehensive analysis of algorithms\nfor face and gesture recognition in the context of computer vision and HCI,\nwith the goal of improving the design and development of interactive systems\nthat are more intuitive, efficient, and user-friendly.\n","authors":["Kaushik Ranade","Tanmay Khule","Riddhi More"],"pdf_url":"https://arxiv.org/pdf/2411.04263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00599v2","updated":"2024-11-06T21:13:21Z","published":"2024-06-02T03:11:31Z","title":"Robust Fair Clustering with Group Membership Uncertainty Sets","summary":"  We study the canonical fair clustering problem where each cluster is\nconstrained to have close to population-level representation of each group.\nDespite significant attention, the salient issue of having incomplete knowledge\nabout the group membership of each point has been superficially addressed. In\nthis paper, we consider a setting where the assigned group memberships are\nnoisy. We introduce a simple noise model that requires a small number of\nparameters to be given by the decision maker. We then present an algorithm for\nfair clustering with provable \\emph{robustness} guarantees. Our framework\nenables the decision maker to trade off between the robustness and the\nclustering quality. Unlike previous work, our algorithms are backed by\nworst-case theoretical guarantees. Finally, we empirically verify the\nperformance of our algorithm on real world datasets and show its superior\nperformance over existing baselines.\n","authors":["Sharmila Duppala","Juan Luque","John P. Dickerson","Seyed A. Esmaeili"],"pdf_url":"https://arxiv.org/pdf/2406.00599v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02471v2","updated":"2024-11-06T21:10:43Z","published":"2024-11-04T16:51:22Z","title":"Energy-Aware Dynamic Neural Inference","summary":"  The growing demand for intelligent applications beyond the network edge,\ncoupled with the need for sustainable operation, are driving the seamless\nintegration of deep learning (DL) algorithms into energy-limited, and even\nenergy-harvesting end-devices. However, the stochastic nature of ambient energy\nsources often results in insufficient harvesting rates, failing to meet the\nenergy requirements for inference and causing significant performance\ndegradation in energy-agnostic systems. To address this problem, we consider an\non-device adaptive inference system equipped with an energy-harvester and\nfinite-capacity energy storage. We then allow the device to reduce the run-time\nexecution cost on-demand, by either switching between differently-sized neural\nnetworks, referred to as multi-model selection (MMS), or by enabling earlier\npredictions at intermediate layers, called early exiting (EE). The model to be\nemployed, or the exit point is then dynamically chosen based on the energy\nstorage and harvesting process states. We also study the efficacy of\nintegrating the prediction confidence into the decision-making process. We\nderive a principled policy with theoretical guarantees for confidence-aware and\n-agnostic controllers. Moreover, in multi-exit networks, we study the\nadvantages of taking decisions incrementally, exit-by-exit, by designing a\nlightweight reinforcement learning-based controller. Experimental results show\nthat, as the rate of the ambient energy increases, energy- and confidence-aware\ncontrol schemes show approximately 5% improvement in accuracy compared to their\nenergy-aware confidence-agnostic counterparts. Incremental approaches achieve\neven higher accuracy, particularly when the energy storage capacity is limited\nrelative to the energy consumption of the inference model.\n","authors":["Marcello Bullo","Seifallah Jardak","Pietro Carnelli","Deniz Gündüz"],"pdf_url":"https://arxiv.org/pdf/2411.02471v2.pdf","comment":"\\c{opyright}2024 IEEE. This work has been submitted to the IEEE for\n  possible publication"},{"id":"http://arxiv.org/abs/2411.04257v1","updated":"2024-11-06T21:00:45Z","published":"2024-11-06T21:00:45Z","title":"LSHBloom: Memory-efficient, Extreme-scale Document Deduplication","summary":"  Deduplication is a major focus for assembling and curating training datasets\nfor large language models (LLM) -- detecting and eliminating additional\ninstances of the same content -- in large collections of technical documents.\nUnrestrained, duplicates in the training dataset increase training costs and\nlead to undesirable properties such as memorization in trained models or\ncheating on evaluation. Contemporary approaches to document-level deduplication\nare often extremely expensive in both runtime and memory. We propose LSHBloom,\nan extension to MinhashLSH, which replaces the expensive LSHIndex with\nlightweight Bloom filters. LSHBloom demonstrates the same deduplication\nperformance as MinhashLSH with only a marginal increase in false positives (as\nlow as 1e-5 in our experiments); demonstrates competitive runtime (270\\% faster\nthan MinhashLSH on peS2o); and, crucially, uses just 0.6\\% of the disk space\nrequired by MinhashLSH to deduplicate peS2o. We demonstrate that this space\nadvantage scales with increased dataset size -- at the extreme scale of several\nbillion documents, LSHBloom promises a 250\\% speedup and a 54$\\times$ space\nadvantage over traditional MinHashLSH scaling deduplication of text datasets to\nmany billions of documents.\n","authors":["Arham Khan","Robert Underwood","Carlo Siebenschuh","Yadu Babuji","Aswathy Ajith","Kyle Hippe","Ozan Gokdemir","Alexander Brace","Kyle Chard","Ian Foster"],"pdf_url":"https://arxiv.org/pdf/2411.04257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00220v2","updated":"2024-11-06T20:46:10Z","published":"2024-08-01T01:15:52Z","title":"Persistent de Rham-Hodge Laplacians in Eulerian representation for\n  manifold topological learning","summary":"  Recently, topological data analysis has become a trending topic in data\nscience and engineering. However, the key technique of topological data\nanalysis, i.e., persistent homology, is defined on point cloud data, which does\nnot work directly for data on manifolds. Although earlier evolutionary de\nRham-Hodge theory deals with data on manifolds, it is inconvenient for machine\nlearning applications because of the numerical inconsistency caused by\nremeshing the involving manifolds in the Lagrangian representation. In this\nwork, we introduce persistent de Rham-Hodge Laplacian, or persistent Hodge\nLaplacian (PHL) as an abbreviation, for manifold topological learning. Our PHLs\nare constructed in the Eulerian representation via structure-persevering\nCartesian grids, avoiding the numerical inconsistency over the multiscale\nmanifolds. To facilitate the manifold topological learning, we propose a\npersistent Hodge Laplacian learning algorithm for data on manifolds or\nvolumetric data. As a proof-of-principle application of the proposed manifold\ntopological learning model, we consider the prediction of protein-ligand\nbinding affinities with two benchmark datasets. Our numerical experiments\nhighlight the power and promise of the proposed method.\n","authors":["Zhe Su","Yiying Tong","Guo-Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2408.00220v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00190v2","updated":"2024-11-06T20:32:55Z","published":"2024-10-31T20:17:12Z","title":"Monitoring fairness in machine learning models that predict patient\n  mortality in the ICU","summary":"  This work proposes a fairness monitoring approach for machine learning models\nthat predict patient mortality in the ICU. We investigate how well models\nperform for patient groups with different race, sex and medical diagnoses. We\ninvestigate Documentation bias in clinical measurement, showing how fairness\nanalysis provides a more detailed and insightful comparison of model\nperformance than traditional accuracy metrics alone.\n","authors":["Tempest A. van Schaik","Xinggang Liu","Louis Atallah","Omar Badawi"],"pdf_url":"https://arxiv.org/pdf/2411.00190v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2411.04243v1","updated":"2024-11-06T20:12:47Z","published":"2024-11-06T20:12:47Z","title":"ION-C: Integration of Overlapping Networks via Constraints","summary":"  In many causal learning problems, variables of interest are often not all\nmeasured over the same observations, but are instead distributed across\nmultiple datasets with overlapping variables. Tillman et al. (2008) presented\nthe first algorithm for enumerating the minimal equivalence class of\nground-truth DAGs consistent with all input graphs by exploiting local\nindependence relations, called ION. In this paper, this problem is formulated\nas a more computationally efficient answer set programming (ASP) problem, which\nwe call ION-C, and solved with the ASP system clingo. The ION-C algorithm was\nrun on random synthetic graphs with varying sizes, densities, and degrees of\noverlap between subgraphs, with overlap having the largest impact on runtime,\nnumber of solution graphs, and agreement within the output set. To validate\nION-C on real-world data, we ran the algorithm on overlapping graphs learned\nfrom data from two successive iterations of the European Social Survey (ESS),\nusing a procedure for conducting joint independence tests to prevent\ninconsistencies in the input.\n","authors":["Praveen Nair","Payal Bhandari","Mohammadsajad Abavisani","Sergey Plis","David Danks"],"pdf_url":"https://arxiv.org/pdf/2411.04243v1.pdf","comment":"18 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.04242v1","updated":"2024-11-06T20:11:19Z","published":"2024-11-06T20:11:19Z","title":"Multimodal Structure-Aware Quantum Data Processing","summary":"  While large language models (LLMs) have advanced the field of natural\nlanguage processing (NLP), their ``black box'' nature obscures their\ndecision-making processes. To address this, researchers developed structured\napproaches using higher order tensors. These are able to model linguistic\nrelations, but stall when training on classical computers due to their\nexcessive size. Tensors are natural inhabitants of quantum systems and training\non quantum computers provides a solution by translating text to variational\nquantum circuits. In this paper, we develop MultiQ-NLP: a framework for\nstructure-aware data processing with multimodal text+image data. Here,\n``structure'' refers to syntactic and grammatical relationships in language, as\nwell as the hierarchical organization of visual elements in images. We enrich\nthe translation with new types and type homomorphisms and develop novel\narchitectures to represent structure. When tested on a main stream image\nclassification task (SVO Probes), our best model showed a par performance with\nthe state of the art classical models; moreover the best model was fully\nstructured.\n","authors":["Hala Hawashin","Mehrnoosh Sadrzadeh"],"pdf_url":"https://arxiv.org/pdf/2411.04242v1.pdf","comment":"10 Pages, 16 Figures"},{"id":"http://arxiv.org/abs/2411.04228v1","updated":"2024-11-06T19:50:00Z","published":"2024-11-06T19:50:00Z","title":"dsld: A Socially Relevant Tool for Teaching Statistics","summary":"  The growing power of data science can play a crucial role in addressing\nsocial discrimination, necessitating nuanced understanding and effective\nmitigation strategies of potential biases. Data Science Looks At Discrimination\n(dsld) is an R and Python package designed to provide users with a\ncomprehensive toolkit of statistical and graphical methods for assessing\npossible discrimination related to protected groups, such as race, gender, and\nage. Our software offers techniques for discrimination analysis by identifying\nand mitigating confounding variables, along with methods for reducing bias in\npredictive models.\n  In educational settings, dsld offers instructors powerful tools to teach\nimportant statistical principles through motivating real world examples of\ndiscrimination analysis. The inclusion of an 80-page Quarto book further\nsupports users, from statistics educators to legal professionals, in\neffectively applying these analytical tools to real world scenarios.\n","authors":["Taha Abdullah","Arjun Ashok","Brandon Estrada","Norman Matloff","Aditya Mittal"],"pdf_url":"https://arxiv.org/pdf/2411.04228v1.pdf","comment":"To be submitted to the Journal of Statistics and Data Science\n  Education"},{"id":"http://arxiv.org/abs/2411.04225v1","updated":"2024-11-06T19:44:46Z","published":"2024-11-06T19:44:46Z","title":"Approximate Equivariance in Reinforcement Learning","summary":"  Equivariant neural networks have shown great success in reinforcement\nlearning, improving sample efficiency and generalization when there is symmetry\nin the task. However, in many problems, only approximate symmetry is present,\nwhich makes imposing exact symmetry inappropriate. Recently, approximately\nequivariant networks have been proposed for supervised classification and\nmodeling physical systems. In this work, we develop approximately equivariant\nalgorithms in reinforcement learning (RL). We define approximately equivariant\nMDPs and theoretically characterize the effect of approximate equivariance on\nthe optimal Q function. We propose novel RL architectures using relaxed group\nconvolutions and experiment on several continuous control domains and stock\ntrading with real financial data. Our results demonstrate that approximate\nequivariance matches prior work when exact symmetries are present, and\noutperforms them when domains exhibit approximate symmetry. As an added\nbyproduct of these techniques, we observe increased robustness to noise at test\ntime.\n","authors":["Jung Yeon Park","Sujay Bhatt","Sihan Zeng","Lawson L. S. Wong","Alec Koppel","Sumitra Ganesh","Robin Walters"],"pdf_url":"https://arxiv.org/pdf/2411.04225v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.04224v1","updated":"2024-11-06T19:44:36Z","published":"2024-11-06T19:44:36Z","title":"WiFlexFormer: Efficient WiFi-Based Person-Centric Sensing","summary":"  We propose WiFlexFormer, a highly efficient Transformer-based architecture\ndesigned for WiFi Channel State Information (CSI)-based person-centric sensing.\nWe benchmark WiFlexFormer against state-of-the-art vision and specialized\narchitectures for processing radio frequency data and demonstrate that it\nachieves comparable Human Activity Recognition (HAR) performance while offering\na significantly lower parameter count and faster inference times. With an\ninference time of just 10 ms on an Nvidia Jetson Orin Nano, WiFlexFormer is\noptimized for real-time inference. Additionally, its low parameter count\ncontributes to improved cross-domain generalization, where it often outperforms\nlarger models. Our comprehensive evaluation shows that WiFlexFormer is a\npotential solution for efficient, scalable WiFi-based sensing applications. The\nPyTorch implementation of WiFlexFormer is publicly available at:\nhttps://github.com/StrohmayerJ/WiFlexFormer.\n","authors":["Julian Strohmayer","Matthias Wödlinger","Martin Kampel"],"pdf_url":"https://arxiv.org/pdf/2411.04224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18591v2","updated":"2024-11-06T19:40:44Z","published":"2024-02-12T06:56:13Z","title":"Stochastic contextual bandits with graph feedback: from independence\n  number to MAS number","summary":"  We consider contextual bandits with graph feedback, a class of interactive\nlearning problems with richer structures than vanilla contextual bandits, where\ntaking an action reveals the rewards for all neighboring actions in the\nfeedback graph under all contexts. Unlike the multi-armed bandits setting where\na growing literature has painted a near-complete understanding of graph\nfeedback, much remains unexplored in the contextual bandits counterpart. In\nthis paper, we make inroads into this inquiry by establishing a regret lower\nbound $\\Omega(\\sqrt{\\beta_M(G) T})$, where $M$ is the number of contexts, $G$\nis the feedback graph, and $\\beta_M(G)$ is our proposed graph-theoretic\nquantity that characterizes the fundamental learning limit for this class of\nproblems. Interestingly, $\\beta_M(G)$ interpolates between $\\alpha(G)$ (the\nindependence number of the graph) and $\\mathsf{m}(G)$ (the maximum acyclic\nsubgraph (MAS) number of the graph) as the number of contexts $M$ varies. We\nalso provide algorithms that achieve near-optimal regret for important classes\nof context sequences and/or feedback graphs, such as transitively closed graphs\nthat find applications in auctions and inventory control. In particular, with\nmany contexts, our results show that the MAS number essentially characterizes\nthe statistical complexity for contextual bandits, as opposed to the\nindependence number in multi-armed bandits.\n","authors":["Yuxiao Wen","Yanjun Han","Zhengyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2402.18591v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13749v2","updated":"2024-11-06T19:37:01Z","published":"2024-03-20T16:58:28Z","title":"Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph\n  Representational Learning","summary":"  We introduce $r$-loopy Weisfeiler-Leman ($r$-$\\ell{}$WL), a novel hierarchy\nof graph isomorphism tests and a corresponding GNN framework, $r$-$\\ell{}$MPNN,\nthat can count cycles up to length $r + 2$. Most notably, we show that\n$r$-$\\ell{}$WL can count homomorphisms of cactus graphs. This strictly extends\nclassical 1-WL, which can only count homomorphisms of trees and, in fact, is\nincomparable to $k$-WL for any fixed $k$. We empirically validate the\nexpressive and counting power of the proposed $r$-$\\ell{}$MPNN on several\nsynthetic datasets and present state-of-the-art predictive performance on\nvarious real-world datasets. The code is available at\nhttps://github.com/RPaolino/loopy\n","authors":["Raffaele Paolino","Sohir Maskey","Pascal Welke","Gitta Kutyniok"],"pdf_url":"https://arxiv.org/pdf/2403.13749v2.pdf","comment":"NeurIPS 2024 (Oral). The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2411.04219v1","updated":"2024-11-06T19:34:40Z","published":"2024-11-06T19:34:40Z","title":"Equivariant Graph Network Approximations of High-Degree Polynomials for\n  Force Field Prediction","summary":"  Recent advancements in equivariant deep models have shown promise in\naccurately predicting atomic potentials and force fields in molecular dynamics\nsimulations. Using spherical harmonics (SH) and tensor products (TP), these\nequivariant networks gain enhanced physical understanding, like symmetries and\nmany-body interactions. Beyond encoding physical insights, SH and TP are also\ncrucial to represent equivariant polynomial functions. In this work, we analyze\nthe equivariant polynomial functions for the equivariant architecture, and\nintroduce a novel equivariant network, named PACE. The proposed PACE utilizes\nedge booster and the Atomic Cluster Expansion (ACE) technique to approximate a\ngreater number of $SE(3) \\times S_n$ equivariant polynomial functions with\nenhanced degrees. As experimented in commonly used benchmarks, PACE\ndemonstrates state-of-the-art performance in predicting atomic energy and force\nfields, with robust generalization capability across various geometric\ndistributions under molecular dynamics (MD) across different temperature\nconditions. Our code is publicly available as part of the AIRS library\nhttps://github.com/divelab/AIRS/.\n","authors":["Zhao Xu","Haiyang Yu","Montgomery Bohde","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2411.04219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04217v1","updated":"2024-11-06T19:25:06Z","published":"2024-11-06T19:25:06Z","title":"Quantum Diffusion Models for Few-Shot Learning","summary":"  Modern quantum machine learning (QML) methods involve the variational\noptimization of parameterized quantum circuits on training datasets, followed\nby predictions on testing datasets. Most state-of-the-art QML algorithms\ncurrently lack practical advantages due to their limited learning capabilities,\nespecially in few-shot learning tasks. In this work, we propose three new\nframeworks employing quantum diffusion model (QDM) as a solution for the\nfew-shot learning: label-guided generation inference (LGGI); label-guided\ndenoising inference (LGDI); and label-guided noise addition inference (LGNAI).\nExperimental results demonstrate that our proposed algorithms significantly\noutperform existing methods.\n","authors":["Ruhan Wang","Ye Wang","Jing Liu","Toshiaki Koike-Akino"],"pdf_url":"https://arxiv.org/pdf/2411.04217v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.04216v1","updated":"2024-11-06T19:24:34Z","published":"2024-11-06T19:24:34Z","title":"Debiasing Synthetic Data Generated by Deep Generative Models","summary":"  While synthetic data hold great promise for privacy protection, their\nstatistical analysis poses significant challenges that necessitate innovative\nsolutions. The use of deep generative models (DGMs) for synthetic data\ngeneration is known to induce considerable bias and imprecision into synthetic\ndata analyses, compromising their inferential utility as opposed to original\ndata analyses. This bias and uncertainty can be substantial enough to impede\nstatistical convergence rates, even in seemingly straightforward analyses like\nmean calculation. The standard errors of such estimators then exhibit slower\nshrinkage with sample size than the typical 1 over root-$n$ rate. This\ncomplicates fundamental calculations like p-values and confidence intervals,\nwith no straightforward remedy currently available. In response to these\nchallenges, we propose a new strategy that targets synthetic data created by\nDGMs for specific data analyses. Drawing insights from debiased and targeted\nmachine learning, our approach accounts for biases, enhances convergence rates,\nand facilitates the calculation of estimators with easily approximated large\nsample variances. We exemplify our proposal through a simulation study on toy\ndata and two case studies on real-world data, highlighting the importance of\ntailoring DGMs for targeted data analysis. This debiasing strategy contributes\nto advancing the reliability and applicability of synthetic data in statistical\ninference.\n","authors":["Alexander Decruyenaere","Heidelinde Dehaene","Paloma Rabaey","Christiaan Polet","Johan Decruyenaere","Thomas Demeester","Stijn Vansteelandt"],"pdf_url":"https://arxiv.org/pdf/2411.04216v1.pdf","comment":"Accepted for the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024), joint first authors"},{"id":"http://arxiv.org/abs/2411.04209v1","updated":"2024-11-06T19:08:30Z","published":"2024-11-06T19:08:30Z","title":"Machine Learning Mutation-Acyclicity of Quivers","summary":"  Machine learning (ML) has emerged as a powerful tool in mathematical research\nin recent years. This paper applies ML techniques to the study of quivers--a\ntype of directed multigraph with significant relevance in algebra,\ncombinatorics, computer science, and mathematical physics. Specifically, we\nfocus on the challenging problem of determining the mutation-acyclicity of a\nquiver on 4 vertices, a property that is pivotal since mutation-acyclicity is\noften a necessary condition for theorems involving path algebras and cluster\nalgebras. Although this classification is known for quivers with at most 3\nvertices, little is known about quivers on more than 3 vertices. We give a\ncomputer-assisted proof of a theorem to prove that mutation-acyclicity is\ndecidable for quivers on 4 vertices with edge weight at most 2. By leveraging\nneural networks (NNs) and support vector machines (SVMs), we then accurately\nclassify more general 4-vertex quivers as mutation-acyclic or\nnon-mutation-acyclic. Our results demonstrate that ML models can efficiently\ndetect mutation-acyclicity, providing a promising computational approach to\nthis combinatorial problem, from which the trained SVM equation provides a\nstarting point to guide future theoretical development.\n","authors":["Kymani T. K. Armstrong-Williams","Edward Hirst","Blake Jackson","Kyu-Hwan Lee"],"pdf_url":"https://arxiv.org/pdf/2411.04209v1.pdf","comment":"30 pages, 14 figures, 8 tables"},{"id":"http://arxiv.org/abs/2411.04205v1","updated":"2024-11-06T19:06:16Z","published":"2024-11-06T19:06:16Z","title":"Scalable DP-SGD: Shuffling vs. Poisson Subsampling","summary":"  We provide new lower bounds on the privacy guarantee of the multi-epoch\nAdaptive Batch Linear Queries (ABLQ) mechanism with shuffled batch sampling,\ndemonstrating substantial gaps when compared to Poisson subsampling; prior\nanalysis was limited to a single epoch. Since the privacy analysis of\nDifferentially Private Stochastic Gradient Descent (DP-SGD) is obtained by\nanalyzing the ABLQ mechanism, this brings into serious question the common\npractice of implementing shuffling-based DP-SGD, but reporting privacy\nparameters as if Poisson subsampling was used. To understand the impact of this\ngap on the utility of trained machine learning models, we introduce a practical\napproach to implement Poisson subsampling at scale using massively parallel\ncomputation, and efficiently train models with the same. We compare the utility\nof models trained with Poisson-subsampling-based DP-SGD, and the optimistic\nestimates of utility when using shuffling, via our new lower bounds on the\nprivacy guarantee of ABLQ with shuffling.\n","authors":["Lynn Chua","Badih Ghazi","Pritish Kamath","Ravi Kumar","Pasin Manurangsi","Amer Sinha","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.04205v1.pdf","comment":"To appear at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2402.07248v2","updated":"2024-11-06T19:05:34Z","published":"2024-02-11T17:27:26Z","title":"Depth Separations in Neural Networks: Separating the Dimension from the\n  Accuracy","summary":"  We prove an exponential size separation between depth 2 and depth 3 neural\nnetworks (with real inputs), when approximating a $\\mathcal{O}(1)$-Lipschitz\ntarget function to constant accuracy, with respect to a distribution with\nsupport in the unit ball, under the mild assumption that the weights of the\ndepth 2 network are exponentially bounded. This resolves an open problem posed\nin \\citet{safran2019depth}, and proves that the curse of dimensionality\nmanifests itself in depth 2 approximation, even in cases where the target\nfunction can be represented efficiently using a depth 3 network. Previously,\nlower bounds that were used to separate depth 2 from depth 3 networks required\nthat at least one of the Lipschitz constant, target accuracy or (some measure\nof) the size of the domain of approximation scale \\emph{polynomially} with the\ninput dimension, whereas in our result these parameters are fixed to be\n\\emph{constants} independent of the input dimension: our parameters are\nsimultaneously optimal. Our lower bound holds for a wide variety of activation\nfunctions, and is based on a novel application of a worst- to average-case\nrandom self-reducibility argument, allowing us to leverage depth 2 threshold\ncircuits lower bounds in a new domain.\n","authors":["Itay Safran","Daniel Reichman","Paul Valiant"],"pdf_url":"https://arxiv.org/pdf/2402.07248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04204v1","updated":"2024-11-06T19:02:42Z","published":"2024-11-06T19:02:42Z","title":"Online Budgeted Matching with General Bids","summary":"  Online Budgeted Matching (OBM) is a classic problem with important\napplications in online advertising, online service matching, revenue\nmanagement, and beyond. Traditional online algorithms typically assume a small\nbid setting, where the maximum bid-to-budget ratio (\\kappa) is infinitesimally\nsmall. While recent algorithms have tried to address scenarios with non-small\nor general bids, they often rely on the Fractional Last Matching (FLM)\nassumption, which allows for accepting partial bids when the remaining budget\nis insufficient. This assumption, however, does not hold for many applications\nwith indivisible bids. In this paper, we remove the FLM assumption and tackle\nthe open problem of OBM with general bids. We first establish an upper bound of\n1-\\kappa on the competitive ratio for any deterministic online algorithm. We\nthen propose a novel meta algorithm, called MetaAd, which reduces to different\nalgorithms with first known provable competitive ratios parameterized by the\nmaximum bid-to-budget ratio \\kappa \\in [0, 1]. As a by-product, we extend\nMetaAd to the FLM setting and get provable competitive algorithms. Finally, we\napply our competitive analysis to the design learning-augmented algorithms.\n","authors":["Jianyi Yang","Pengfei Li","Adam Wierman","Shaolei Ren"],"pdf_url":"https://arxiv.org/pdf/2411.04204v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04165v1","updated":"2024-11-06T18:36:48Z","published":"2024-11-06T18:36:48Z","title":"Bio-xLSTM: Generative modeling, representation and in-context learning\n  of biological and chemical sequences","summary":"  Language models for biological and chemical sequences enable crucial\napplications such as drug discovery, protein engineering, and precision\nmedicine. Currently, these language models are predominantly based on\nTransformer architectures. While Transformers have yielded impressive results,\ntheir quadratic runtime dependency on the sequence length complicates their use\nfor long genomic sequences and in-context learning on proteins and chemical\nsequences. Recently, the recurrent xLSTM architecture has been shown to perform\nfavorably compared to Transformers and modern state-space model (SSM)\narchitectures in the natural language domain. Similar to SSMs, xLSTMs have a\nlinear runtime dependency on the sequence length and allow for constant-memory\ndecoding at inference time, which makes them prime candidates for modeling\nlong-range dependencies in biological and chemical sequences. In this work, we\ntailor xLSTM towards these domains and propose a suite of architectural\nvariants called Bio-xLSTM. Extensive experiments in three large domains,\ngenomics, proteins, and chemistry, were performed to assess xLSTM's ability to\nmodel biological and chemical sequences. The results show that models based on\nBio-xLSTM a) can serve as proficient generative models for DNA, protein, and\nchemical sequences, b) learn rich representations for those modalities, and c)\ncan perform in-context learning for proteins and small molecules.\n","authors":["Niklas Schmidinger","Lisa Schneckenreiter","Philipp Seidl","Johannes Schimunek","Pieter-Jan Hoedt","Johannes Brandstetter","Andreas Mayr","Sohvi Luukkonen","Sepp Hochreiter","Günter Klambauer"],"pdf_url":"https://arxiv.org/pdf/2411.04165v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2407.14093v2","updated":"2024-11-06T16:45:17Z","published":"2024-07-19T07:57:48Z","title":"Routing Experts: Learning to Route Dynamic Experts in Multi-modal Large\n  Language Models","summary":"  Recently, mixture of experts (MoE) has become a popular paradigm for\nachieving the trade-off between modal capacity and efficiency of multi-modal\nlarge language models (MLLMs). Different from previous efforts, we are\ndedicated to exploring the dynamic expert path in an already exist MLLM and\nshow that a standard MLLM can be also a mixture of experts. To approach this\ntarget, we propose a novel dynamic expert scheme for MLLMs, termed Routing\nExperts (RoE), which can achieve example-dependent optimal path routing without\nobvious structure tweaks. Meanwhile, a new regularization of structure sparsity\nis also introduced to enforce MLLMs to learn more short-cut inference, ensuring\nthe efficiency. In addition, we also realize the first attempt of aligning the\ntraining and inference schemes of MLLMs in terms of network routing. To\nvalidate RoE, we apply it to a set of latest MLLMs, including LLaVA-1.5,\nLLaVA-HR and VILA, and conduct extensive experiments on a bunch of VL\nbenchmarks. The experiment results not only show the great advantages of our\nRoE in improving MLLMs' efficiency, but also yield obvious advantages than\nMoE-LLaVA in both performance and speed, e.g., an average performance gain of\n3.3% on 5 benchmarks while being faster.\n","authors":["Qiong Wu","Zhaoxi Ke","Yiyi Zhou","Gen Luo","Xiaoshuai Sun","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2407.14093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03948v1","updated":"2024-11-06T14:29:49Z","published":"2024-11-06T14:29:49Z","title":"Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of\n  Study in Tabletop Role-Playing Games Soundtracks","summary":"  This paper investigates the capabilities of text-to-audio music generation\nmodels in producing long-form music with prompts that change over time,\nfocusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We\nintroduce Babel Bardo, a system that uses Large Language Models (LLMs) to\ntransform speech transcriptions into music descriptions for controlling a\ntext-to-music model. Four versions of Babel Bardo were compared in two TRPG\ncampaigns: a baseline using direct speech transcriptions, and three LLM-based\nversions with varying approaches to music description generation. Evaluations\nconsidered audio quality, story alignment, and transition smoothness. Results\nindicate that detailed music descriptions improve audio quality while\nmaintaining consistency across consecutive descriptions enhances story\nalignment and transition smoothness.\n","authors":["Felipe Marra","Lucas N. Ferreira"],"pdf_url":"https://arxiv.org/pdf/2411.03948v1.pdf","comment":"Paper accepted at the LAMIR 2024 workshop"},{"id":"http://arxiv.org/abs/2411.03921v1","updated":"2024-11-06T13:52:49Z","published":"2024-11-06T13:52:49Z","title":"Inter-Frame Coding for Dynamic Meshes via Coarse-to-Fine Anchor Mesh\n  Generation","summary":"  In the current Video-based Dynamic Mesh Coding (V-DMC) standard, inter-frame\ncoding is restricted to mesh frames with constant topology. Consequently,\ntemporal redundancy is not fully leveraged, resulting in suboptimal compression\nefficacy. To address this limitation, this paper introduces a novel\ncoarse-to-fine scheme to generate anchor meshes for frames with time-varying\ntopology. Initially, we generate a coarse anchor mesh using an octree-based\nnearest neighbor search. Motion estimation compensates for regions with\nsignificant motion changes during this process. However, the quality of the\ncoarse mesh is low due to its suboptimal vertices. To enhance details, the fine\nanchor mesh is further optimized using the Quadric Error Metrics (QEM)\nalgorithm to calculate more precise anchor points. The inter-frame anchor mesh\ngenerated herein retains the connectivity of the reference base mesh, while\nconcurrently preserving superior quality. Experimental results show that our\nmethod achieves 7.2% ~ 10.3% BD-rate gain compared to the existing V-DMC test\nmodel version 7.\n","authors":["He Huang","Lizhi Hou","Qi Yang","Yiling Xu"],"pdf_url":"https://arxiv.org/pdf/2411.03921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18680v3","updated":"2024-11-06T10:27:05Z","published":"2024-09-27T12:06:53Z","title":"Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large\n  Language Models","summary":"  Various audio-LLMs (ALLMs) have been explored recently for tackling different\naudio tasks simultaneously using a single, unified model. While existing\nevaluations of ALLMs primarily focus on single-audio tasks, real-world\napplications often involve processing multiple audio streams simultaneously. To\nbridge this gap, we propose the first multi-audio evaluation (MAE) benchmark\nthat consists of 20 datasets from 11 multi-audio tasks encompassing both speech\nand sound scenarios. Comprehensive experiments on MAE demonstrate that the\nexisting ALLMs, while being powerful in comprehending primary audio elements in\nindividual audio inputs, struggling to handle multi-audio scenarios. To this\nend, we propose a novel multi-audio-LLM (MALLM) to capture audio context among\nmultiple similar audios using discriminative learning on our proposed synthetic\ndata. The results demonstrate that the proposed MALLM outperforms all baselines\nand achieves high data efficiency using synthetic data without requiring human\nannotations. The proposed MALLM opens the door for ALLMs towards multi-audio\nprocessing era and brings us closer to replicating human auditory capabilities\nin machines.\n","authors":["Yiming Chen","Xianghu Yue","Xiaoxue Gao","Chen Zhang","Luis Fernando D'Haro","Robby T. Tan","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2409.18680v3.pdf","comment":"EMNLP24 Findings. Data available at\n  https://github.com/MatthewCYM/MALLM"},{"id":"http://arxiv.org/abs/2411.03595v1","updated":"2024-11-06T01:14:42Z","published":"2024-11-06T01:14:42Z","title":"Investigating Conceptual Blending of a Diffusion Model for Improving\n  Nonword-to-Image Generation","summary":"  Text-to-image diffusion models sometimes depict blended concepts in the\ngenerated images. One promising use case of this effect would be the\nnonword-to-image generation task which attempts to generate images intuitively\nimaginable from a non-existing word (nonword). To realize nonword-to-image\ngeneration, an existing study focused on associating nonwords with\nsimilar-sounding words. Since each nonword can have multiple similar-sounding\nwords, generating images containing their blended concepts would increase\nintuitiveness, facilitating creative activities and promoting computational\npsycholinguistics. Nevertheless, no existing study has quantitatively evaluated\nthis effect in either diffusion models or the nonword-to-image generation\nparadigm. Therefore, this paper first analyzes the conceptual blending in a\npretrained diffusion model, Stable Diffusion. The analysis reveals that a high\npercentage of generated images depict blended concepts when inputting an\nembedding interpolating between the text embeddings of two text prompts\nreferring to different concepts. Next, this paper explores the best text\nembedding space conversion method of an existing nonword-to-image generation\nframework to ensure both the occurrence of conceptual blending and image\ngeneration quality. We compare the conventional direct prediction approach with\nthe proposed method that combines $k$-nearest neighbor search and linear\nregression. Evaluation reveals that the enhanced accuracy of the embedding\nspace conversion by the proposed method improves the image generation quality,\nwhile the emergence of conceptual blending could be attributed mainly to the\nspecific dimensions of the high-dimensional text embedding space.\n","authors":["Chihaya Matsuhira","Marc A. Kastner","Takahiro Komamizu","Takatsugu Hirayama","Ichiro Ide"],"pdf_url":"https://arxiv.org/pdf/2411.03595v1.pdf","comment":"Paper accepted at ACM MM 2024 (doi: 10.1145/3664647.3681202) with\n  supplementary materials concatenated"},{"id":"http://arxiv.org/abs/2410.21169v3","updated":"2024-11-06T00:11:08Z","published":"2024-10-28T16:11:35Z","title":"Document Parsing Unveiled: Techniques, Challenges, and Prospects for\n  Structured Information Extraction","summary":"  Document parsing is essential for converting unstructured and semi-structured\ndocuments-such as contracts, academic papers, and invoices-into structured,\nmachine-readable data. Document parsing extract reliable structured data from\nunstructured inputs, providing huge convenience for numerous applications.\nEspecially with recent achievements in Large Language Models, document parsing\nplays an indispensable role in both knowledge base construction and training\ndata generation. This survey presents a comprehensive review of the current\nstate of document parsing, covering key methodologies, from modular pipeline\nsystems to end-to-end models driven by large vision-language models. Core\ncomponents such as layout detection, content extraction (including text,\ntables, and mathematical expressions), and multi-modal data integration are\nexamined in detail. Additionally, this paper discusses the challenges faced by\nmodular document parsing systems and vision-language models in handling complex\nlayouts, integrating multiple modules, and recognizing high-density text. It\nemphasizes the importance of developing larger and more diverse datasets and\noutlines future research directions.\n","authors":["Qintong Zhang","Victor Shea-Jay Huang","Bin Wang","Junyuan Zhang","Zhengren Wang","Hao Liang","Shawn Wang","Matthieu Lin","Conghui He","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.21169v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.04901v2","updated":"2024-11-06T23:32:27Z","published":"2023-04-11T00:17:28Z","title":"Efficiently Collecting Training Dataset for 2D Object Detection by\n  Online Visual Feedback","summary":"  Training deep-learning-based vision systems require the manual annotation of\na significant number of images. Such manual annotation is highly time-consuming\nand labor-intensive. Although previous studies have attempted to eliminate the\neffort required for annotation, the effort required for image collection was\nretained. To address this, we propose a human-in-the-loop dataset collection\nmethod that uses a web application. To counterbalance the workload and\nperformance by encouraging the collection of multi-view object image datasets\nin an enjoyable manner, thereby amplifying motivation, we propose three types\nof online visual feedback features to track the progress of the collection\nstatus. Our experiments thoroughly investigated the impact of each feature on\ncollection performance and quality of operation. The results suggested the\nfeasibility of annotation and object detection.\n","authors":["Takuya Kiyokawa","Naoki Shirakura","Hiroki Katayama","Keita Tomochika","Jun Takamatsu"],"pdf_url":"https://arxiv.org/pdf/2304.04901v2.pdf","comment":"13 pages, 14 figures"},{"id":"http://arxiv.org/abs/2401.03115v2","updated":"2024-11-06T22:09:09Z","published":"2024-01-06T03:03:28Z","title":"Transferable Learned Image Compression-Resistant Adversarial\n  Perturbations","summary":"  Adversarial attacks can readily disrupt the image classification system,\nrevealing the vulnerability of DNN-based recognition tasks. While existing\nadversarial perturbations are primarily applied to uncompressed images or\ncompressed images by the traditional image compression method, i.e., JPEG,\nlimited studies have investigated the robustness of models for image\nclassification in the context of DNN-based image compression. With the rapid\nevolution of advanced image compression, DNN-based learned image compression\nhas emerged as the promising approach for transmitting images in many\nsecurity-critical applications, such as cloud-based face recognition and\nautonomous driving, due to its superior performance over traditional\ncompression. Therefore, there is a pressing need to fully investigate the\nrobustness of a classification system post-processed by learned image\ncompression. To bridge this research gap, we explore the adversarial attack on\na new pipeline that targets image classification models that utilize learned\nimage compressors as pre-processing modules. Furthermore, to enhance the\ntransferability of perturbations across various quality levels and\narchitectures of learned image compression models, we introduce a saliency\nscore-based sampling method to enable the fast generation of transferable\nperturbation. Extensive experiments with popular attack methods demonstrate the\nenhanced transferability of our proposed method when attacking images that have\nbeen post-processed with different learned image compression models.\n","authors":["Yang Sui","Zhuohang Li","Ding Ding","Xiang Pan","Xiaozhong Xu","Shan Liu","Zhenzhong Chen"],"pdf_url":"https://arxiv.org/pdf/2401.03115v2.pdf","comment":"Accepted by BMVC 2024"},{"id":"http://arxiv.org/abs/2411.03823v1","updated":"2024-11-06T10:44:15Z","published":"2024-11-06T10:44:15Z","title":"Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM\n  Data Contamination","summary":"  The rapid progression of multimodal large language models (MLLMs) has\ndemonstrated superior performance on various multimodal benchmarks. However,\nthe issue of data contamination during training creates challenges in\nperformance evaluation and comparison. While numerous methods exist for\ndetecting dataset contamination in large language models (LLMs), they are less\neffective for MLLMs due to their various modalities and multiple training\nphases. In this study, we introduce a multimodal data contamination detection\nframework, MM-Detect, designed for MLLMs. Our experimental results indicate\nthat MM-Detect is sensitive to varying degrees of contamination and can\nhighlight significant performance improvements due to leakage of the training\nset of multimodal benchmarks. Furthermore, We also explore the possibility of\ncontamination originating from the pre-training phase of LLMs used by MLLMs and\nthe fine-tuning phase of MLLMs, offering new insights into the stages at which\ncontamination may be introduced.\n","authors":["Dingjie Song","Sicheng Lai","Shunian Chen","Lichao Sun","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03823v1.pdf","comment":null}]},"2024-11-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2408.07832v5","updated":"2024-11-05T23:50:14Z","published":"2024-07-31T14:49:35Z","title":"LADDER: Language Driven Slice Discovery and Error Rectification","summary":"  Error slice discovery associates structured patterns with model errors.\nExisting methods discover error slices by clustering the error-prone samples\nwith similar patterns or assigning discrete attributes to each sample for\npost-hoc analysis. While these methods aim for interpretability and easier\nmitigation through reweighting or rebalancing, they may not capture the full\ncomplexity of error patterns due to incomplete or missing attributes. Contrary\nto the existing approach, this paper utilizes the reasoning capabilities of the\nLarge Language Model (LLM) to analyze complex error patterns and generate\ntestable hypotheses. This paper proposes LADDER: Language Driven slice\nDiscovery and Error Rectification. It first projects the model's representation\ninto a language-aligned feature space (eg CLIP) to preserve semantics in the\noriginal model feature space. This ensures the accurate retrieval of sentences\nthat highlight the model's errors. Next, the LLM utilizes the sentences and\ngenerates hypotheses to discover error slices. Finally, we mitigate the error\nby fine-tuning the classification head by creating a group-balanced dataset\nusing the hypotheses. Our entire method does not require any attribute\nannotation, either explicitly or through external tagging models. We validate\nour method with \\textbf{five} image classification datasets.\n","authors":["Shantanu Ghosh","Rayan Syed","Chenyu Wang","Clare B. Poynton","Shyam Visweswaran","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2408.07832v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12843v3","updated":"2024-11-05T23:15:46Z","published":"2024-07-04T15:10:51Z","title":"NutriBench: A Dataset for Evaluating Large Language Models in\n  Carbohydrate Estimation from Meal Descriptions","summary":"  Accurate nutrition estimation helps people make informed dietary choices and\nis essential in the prevention of serious health complications. We present\nNutriBench, the first publicly available natural language meal description\nnutrition benchmark. NutriBench consists of 11,857 meal descriptions generated\nfrom real-world global dietary intake data. The data is human-verified and\nannotated with macro-nutrient labels, including carbohydrates, proteins, fats,\nand calories. We conduct an extensive evaluation of NutriBench on the task of\ncarbohydrate estimation, testing twelve leading Large Language Models (LLMs),\nincluding GPT-4o, Llama3.1, Qwen2, Gemma2, and OpenBioLLM models, using\nstandard, Chain-of-Thought and Retrieval-Augmented Generation strategies.\nAdditionally, we present a study involving professional nutritionists, finding\nthat LLMs can provide more accurate and faster estimates. Finally, we perform a\nreal-world risk assessment by simulating the effect of carbohydrate predictions\non the blood glucose levels of individuals with diabetes. Our work highlights\nthe opportunities and challenges of using LLMs for nutrition estimation,\ndemonstrating their potential to aid professionals and laypersons and improve\nhealth outcomes. Our benchmark is publicly available at:\nhttps://mehak126.github.io/nutribench.html\n","authors":["Andong Hua","Mehak Preet Dhaliwal","Ryan Burke","Laya Pullela","Yao Qin"],"pdf_url":"https://arxiv.org/pdf/2407.12843v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03550v1","updated":"2024-11-05T23:09:37Z","published":"2024-11-05T23:09:37Z","title":"Learning to Write Rationally: How Information Is Distributed in\n  Non-Native Speakers' Essays","summary":"  People tend to distribute information evenly in language production for\nbetter and clearer communication. In this study, we compared essays written by\nsecond language learners with various native language (L1) backgrounds to\ninvestigate how they distribute information in their non-native language (L2)\nproduction. Analyses of surprisal and constancy of entropy rate indicated that\nwriters with higher L2 proficiency can reduce the expected uncertainty of\nlanguage production while still conveying informative content. However, the\nuniformity of information distribution showed less variability among different\ngroups of L2 speakers, suggesting that this feature may be universal in L2\nessay writing and less affected by L2 writers' variability in L1 background and\nL2 proficiency.\n","authors":["Zixin Tang","Janet G. van Hell"],"pdf_url":"https://arxiv.org/pdf/2411.03550v1.pdf","comment":"To appear in main of Conference on Empirical Methods in Natural\n  Language Processing; EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.03542v1","updated":"2024-11-05T22:45:10Z","published":"2024-11-05T22:45:10Z","title":"Exploring the Benefits of Domain-Pretraining of Generative Large\n  Language Models for Chemistry","summary":"  A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and\nmore) are driving forward novel development of multipurpose AI for a variety of\ntasks, particularly natural language processing (NLP) tasks. These models\ndemonstrate strong performance on a range of tasks; however, there has been\nevidence of brittleness when applied to more niche or narrow domains where\nhallucinations or fluent but incorrect responses reduce performance. Given the\ncomplex nature of scientific domains, it is prudent to investigate the\ntrade-offs of leveraging off-the-shelf versus more targeted foundation models\nfor scientific domains. In this work, we examine the benefits of in-domain\npre-training for a given scientific domain, chemistry, and compare these to\nopen-source, off-the-shelf models with zero-shot and few-shot prompting. Our\nresults show that not only do in-domain base models perform reasonably well on\nin-domain tasks in a zero-shot setting but that further adaptation using\ninstruction fine-tuning yields impressive performance on chemistry-specific\ntasks such as named entity recognition and molecular formula generation.\n","authors":["Anurag Acharya","Shivam Sharma","Robin Cosbey","Megha Subramanian","Scott Howland","Maria Glenski"],"pdf_url":"https://arxiv.org/pdf/2411.03542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03538v1","updated":"2024-11-05T22:37:43Z","published":"2024-11-05T22:37:43Z","title":"Long Context RAG Performance of Large Language Models","summary":"  Retrieval Augmented Generation (RAG) has emerged as a crucial technique for\nenhancing the accuracy of Large Language Models (LLMs) by incorporating\nexternal information. With the advent of LLMs that support increasingly longer\ncontext lengths, there is a growing interest in understanding how these models\nperform in RAG scenarios. Can these new long context models improve RAG\nperformance? This paper presents a comprehensive study of the impact of\nincreased context length on RAG performance across 20 popular open source and\ncommercial LLMs. We ran RAG workflows while varying the total context length\nfrom 2,000 to 128,000 tokens (and 2 million tokens when possible) on three\ndomain-specific datasets, and report key insights on the benefits and\nlimitations of long context in RAG applications. Our findings reveal that while\nretrieving more documents can improve performance, only a handful of the most\nrecent state of the art LLMs can maintain consistent accuracy at long context\nabove 64k tokens. We also identify distinct failure modes in long context\nscenarios, suggesting areas for future research.\n","authors":["Quinn Leng","Jacob Portes","Sam Havens","Matei Zaharia","Michael Carbin"],"pdf_url":"https://arxiv.org/pdf/2411.03538v1.pdf","comment":"2024 NeurIPS workshop on Adaptive Foundation Models: Evolving AI for\n  Personalized and Efficient Learning"},{"id":"http://arxiv.org/abs/2406.16450v2","updated":"2024-11-05T22:34:29Z","published":"2024-06-24T08:43:21Z","title":"Building on Efficient Foundations: Effectively Training LLMs with\n  Structured Feedforward Layers","summary":"  State-of-the-art results in large language models (LLMs) often rely on scale,\nwhich becomes computationally expensive. This has sparked a research agenda to\nreduce these models' parameter counts and computational costs without\nsignificantly impacting their performance. Our study focuses on\ntransformer-based LLMs, specifically targeting the computationally intensive\nfeedforward networks (FFNs), which are less studied than attention blocks. We\nconsider three structured linear parameterizations of the FFN using efficient\nlow-rank and block-diagonal matrices. In contrast to many previous works that\nexamined these approximations, our study i) explores these structures from a\ntraining-from-scratch perspective, ii) scales up to 1.3B parameters, and iii)\nis conducted within recent Transformer-based LLMs rather than convolutional\narchitectures. We demonstrate that these structures can lead to actual\ncomputational gains in various scenarios, including online decoding when using\na pre-merge technique. Additionally, we propose a novel training regime, called\n\\textit{self-guided training}, aimed at improving the poor training dynamics\nthat these approximations exhibit when used from initialization. Interestingly,\nthe scaling performance of structured matrices is explored, revealing steeper\ncurves in scaling training FLOPs, along with a favorable scaling trend in the\novertraining regime. Specifically, we show that wide and structured networks\ncan utilize training FLOPs more efficiently, with fewer parameters and lower\nloss than dense models at their optimal trade-off. Our code is available at\n\\url{https://github.com/CLAIRE-Labo/StructuredFFN/tree/main}.\n","authors":["Xiuying Wei","Skander Moalla","Razvan Pascanu","Caglar Gulcehre"],"pdf_url":"https://arxiv.org/pdf/2406.16450v2.pdf","comment":"Accepted by NeurIPS2024"},{"id":"http://arxiv.org/abs/2411.03524v1","updated":"2024-11-05T22:01:27Z","published":"2024-11-05T22:01:27Z","title":"Mitigating Metric Bias in Minimum Bayes Risk Decoding","summary":"  While Minimum Bayes Risk (MBR) decoding using metrics such as COMET or\nMetricX has outperformed traditional decoding methods such as greedy or beam\nsearch, it introduces a challenge we refer to as metric bias. As MBR decoding\naims to produce translations that score highly according to a specific utility\nmetric, this very process makes it impossible to use the same metric for both\ndecoding and evaluation, as improvements might simply be due to reward hacking\nrather than reflecting real quality improvements. In this work we find that\ncompared to human ratings, neural metrics not only overestimate the quality of\nMBR decoding when the same metric is used as the utility metric, but they also\noverestimate the quality of MBR/QE decoding with other neural utility metrics\nas well. We also show that the metric bias issue can be mitigated by using an\nensemble of utility metrics during MBR decoding: human evaluations show that\nMBR decoding using an ensemble of utility metrics outperforms a single utility\nmetric.\n","authors":["Geza Kovacs","Daniel Deutsch","Markus Freitag"],"pdf_url":"https://arxiv.org/pdf/2411.03524v1.pdf","comment":"To appear at WMT2024"},{"id":"http://arxiv.org/abs/2411.03513v1","updated":"2024-11-05T21:19:49Z","published":"2024-11-05T21:19:49Z","title":"Change Is the Only Constant: Dynamic LLM Slicing based on Layer\n  Redundancy","summary":"  This paper introduces a novel model compression approach through dynamic\nlayer-specific pruning in Large Language Models (LLMs), enhancing the\ntraditional methodology established by SliceGPT. By transitioning from constant\nto dynamic slicing, our method leverages the newly proposed Layer Redundancy\n(LR) score, which assesses how much change each layer changes its input by\nmeasuring the cosine similarity of the input to the output of the layer. We use\nthis score to prune parts of individual layers based on redundancy in such a\nway that the average pruned percentage for all layers is a fixed value. We\nconducted extensive experiments using models like Llama3-8B and Mistral-7B on\nmultiple datasets, evaluating different slicing bases and percentages to\ndetermine optimal configurations that balance efficiency and performance. Our\nfindings show that our dynamic slicing approach not only maintains but, in many\ncases, enhances model performance compared to the baseline established by\nconstant slicing methods. For instance, in several settings, we see performance\nimprovements of up to 5% over the SliceGPT baseline. Additionally, a perplexity\ndecrease by as much as 7% was observed across multiple benchmarks, validating\nthe effectiveness of our method. The code, model weights, and datasets are\nopen-sourced at https://github.com/RazvanDu/DynamicSlicing.\n","authors":["Razvan-Gabriel Dumitru","Paul-Ioan Clotan","Vikas Yadav","Darius Peteleaza","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2411.03513v1.pdf","comment":"Accepted at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2403.00143v2","updated":"2024-11-05T21:04:23Z","published":"2024-02-29T21:49:31Z","title":"Tree-Averaging Algorithms for Ensemble-Based Unsupervised Discontinuous\n  Constituency Parsing","summary":"  We address unsupervised discontinuous constituency parsing, where we observe\na high variance in the performance of the only previous model in the\nliterature. We propose to build an ensemble of different runs of the existing\ndiscontinuous parser by averaging the predicted trees, to stabilize and boost\nperformance. To begin with, we provide comprehensive computational complexity\nanalysis (in terms of P and NP-complete) for tree averaging under different\nsetups of binarity and continuity. We then develop an efficient exact algorithm\nto tackle the task, which runs in a reasonable time for all samples in our\nexperiments. Results on three datasets show our method outperforms all\nbaselines in all metrics; we also provide in-depth analyses of our approach.\n","authors":["Behzad Shayegh","Yuqiao Wen","Lili Mou"],"pdf_url":"https://arxiv.org/pdf/2403.00143v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03497v1","updated":"2024-11-05T20:20:15Z","published":"2024-11-05T20:20:15Z","title":"Uncertainty Quantification for Clinical Outcome Predictions with (Large)\n  Language Models","summary":"  To facilitate healthcare delivery, language models (LMs) have significant\npotential for clinical prediction tasks using electronic health records (EHRs).\nHowever, in these high-stakes applications, unreliable decisions can result in\nhigh costs due to compromised patient safety and ethical concerns, thus\nincreasing the need for good uncertainty modeling of automated clinical\npredictions. To address this, we consider the uncertainty quantification of LMs\nfor EHR tasks in white- and black-box settings. We first quantify uncertainty\nin white-box models, where we can access model parameters and output logits. We\nshow that an effective reduction of model uncertainty can be achieved by using\nthe proposed multi-tasking and ensemble methods in EHRs. Continuing with this\nidea, we extend our approach to black-box settings, including popular\nproprietary LMs such as GPT-4. We validate our framework using longitudinal\nclinical data from more than 6,000 patients in ten clinical prediction tasks.\nResults show that ensembling methods and multi-task prediction prompts reduce\nuncertainty across different scenarios. These findings increase the\ntransparency of the model in white-box and black-box settings, thus advancing\nreliable AI healthcare.\n","authors":["Zizhang Chen","Peizhao Li","Xiaomeng Dong","Pengyu Hong"],"pdf_url":"https://arxiv.org/pdf/2411.03497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03495v1","updated":"2024-11-05T20:18:53Z","published":"2024-11-05T20:18:53Z","title":"Automatic Generation of Question Hints for Mathematics Problems using\n  Large Language Models in Educational Technology","summary":"  The automatic generation of hints by Large Language Models (LLMs) within\nIntelligent Tutoring Systems (ITSs) has shown potential to enhance student\nlearning. However, generating pedagogically sound hints that address student\nmisconceptions and adhere to specific educational objectives remains\nchallenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as\nteachers to generate effective hints for students simulated through LLMs\n(GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math\nexercises designed for human high-school students, and designed using cognitive\nscience principles. We present here the study of several dimensions: 1)\nidentifying error patterns made by simulated students on secondary-level math\nexercises; 2) developing various prompts for GPT-4o as a teacher and evaluating\ntheir effectiveness in generating hints that enable simulated students to\nself-correct; and 3) testing the best-performing prompts, based on their\nability to produce relevant hints and facilitate error correction, with\nLlama-3-8B-Instruct as the teacher, allowing for a performance comparison with\nGPT-4o. The results show that model errors increase with higher temperature\nsettings. Notably, when hints are generated by GPT-4o, the most effective\nprompts include prompts tailored to specific errors as well as prompts\nproviding general hints based on common mathematical errors. Interestingly,\nLlama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.\nAlso the problem-solving and response revision capabilities of the LLMs as\nstudents, particularly GPT-3.5-turbo, improved significantly after receiving\nhints, especially at lower temperature settings. However, models like\nMistral-7B-Instruct demonstrated a decline in performance as the temperature\nincreased.\n","authors":["Junior Cedric Tonga","Benjamin Clement","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2411.03495v1.pdf","comment":"Accepted at NeurIPS 2024 Workshop on Large Foundation Models for\n  Educational Assessment (FM-Assess)"},{"id":"http://arxiv.org/abs/2411.03493v1","updated":"2024-11-05T20:18:28Z","published":"2024-11-05T20:18:28Z","title":"LASER: Attention with Exponential Transformation","summary":"  Transformers have had tremendous impact for several sequence related tasks,\nlargely due to their ability to retrieve from any part of the sequence via\nsoftmax based dot-product attention. This mechanism plays a crucial role in\nTransformer's performance. We analyze the gradients backpropagated through the\nsoftmax operation in the attention mechanism and observe that these gradients\ncan often be small. This poor gradient signal backpropagation can lead to\ninefficient learning of parameters preceeding the attention operations. To this\nend, we introduce a new attention mechanism called LASER, which we analytically\nshow to admit a larger gradient signal. We show that LASER Attention can be\nimplemented by making small modifications to existing attention\nimplementations. We conduct experiments on autoregressive large language models\n(LLMs) with upto 2.2 billion parameters where we show upto 3.38% and an average\nof ~1% improvement over standard attention on downstream evaluations. Using\nLASER gives the following relative improvements in generalization performance\nacross a variety of tasks (vision, text and speech): 4.67% accuracy in Vision\nTransformer (ViT) on Imagenet, 2.25% error rate in Conformer on the Librispeech\nspeech-to-text and 0.93% fraction of incorrect predictions in BERT with 2.2\nbillion parameters.\n","authors":["Sai Surya Duvvuri","Inderjit S. Dhillon"],"pdf_url":"https://arxiv.org/pdf/2411.03493v1.pdf","comment":"15 pages, under review in ICLR 2025"},{"id":"http://arxiv.org/abs/2411.03486v1","updated":"2024-11-05T20:10:25Z","published":"2024-11-05T20:10:25Z","title":"LLM Generated Distribution-Based Prediction of US Electoral Results,\n  Part I","summary":"  This paper introduces distribution-based prediction, a novel approach to\nusing Large Language Models (LLMs) as predictive tools by interpreting output\ntoken probabilities as distributions representing the models' learned\nrepresentation of the world. This distribution-based nature offers an\nalternative perspective for analyzing algorithmic fidelity, complementing the\napproach used in silicon sampling. We demonstrate the use of distribution-based\nprediction in the context of recent United States presidential election,\nshowing that this method can be used to determine task specific bias, prompt\nnoise, and algorithmic fidelity. This approach has significant implications for\nassessing the reliability and increasing transparency of LLM-based predictions\nacross various domains.\n","authors":["Caleb Bradshaw","Caelen Miller","Sean Warnick"],"pdf_url":"https://arxiv.org/pdf/2411.03486v1.pdf","comment":"17 pages, 10 Figures, Pre-print"},{"id":"http://arxiv.org/abs/2411.03471v1","updated":"2024-11-05T19:52:58Z","published":"2024-11-05T19:52:58Z","title":"MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs","summary":"  Large Language Models (LLMs) have been applied to various hardware design\ntasks, including Verilog code generation, EDA tool scripting, and RTL bug\nfixing. Despite this extensive exploration, LLMs are yet to be used for the\ntask of post-synthesis metric reasoning and estimation of HDL designs. In this\npaper, we assess the ability of LLMs to reason about post-synthesis metrics of\nVerilog designs. We introduce MetRex, a large-scale dataset comprising 25,868\nVerilog HDL designs and their corresponding post-synthesis metrics, namely\narea, delay, and static power. MetRex incorporates a Chain of Thought (CoT)\ntemplate to enhance LLMs' reasoning about these metrics. Extensive experiments\nshow that Supervised Fine-Tuning (SFT) boosts the LLM's reasoning capabilities\non average by 37.0\\%, 25.3\\%, and 25.7\\% on the area, delay, and static power,\nrespectively. While SFT improves performance on our benchmark, it remains far\nfrom achieving optimal results, especially on complex problems. Comparing to\nstate-of-the-art regression models, our approach delivers accurate\npost-synthesis predictions for 17.4\\% more designs (within a 5\\% error margin),\nin addition to offering a 1.7x speedup by eliminating the need for\npre-processing. This work lays the groundwork for advancing LLM-based Verilog\ncode metric reasoning.\n","authors":["Manar Abdelatty","Jingxiao Ma","Sherief Reda"],"pdf_url":"https://arxiv.org/pdf/2411.03471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20424v3","updated":"2024-11-05T19:46:38Z","published":"2024-10-27T12:44:25Z","title":"AutoKaggle: A Multi-Agent Framework for Autonomous Data Science\n  Competitions","summary":"  Data science tasks involving tabular data present complex challenges that\nrequire sophisticated problem-solving approaches. We propose AutoKaggle, a\npowerful and user-centric framework that assists data scientists in completing\ndaily data pipelines through a collaborative multi-agent system. AutoKaggle\nimplements an iterative development process that combines code execution,\ndebugging, and comprehensive unit testing to ensure code correctness and logic\nconsistency. The framework offers highly customizable workflows, allowing users\nto intervene at each phase, thus integrating automated intelligence with human\nexpertise. Our universal data science toolkit, comprising validated functions\nfor data cleaning, feature engineering, and modeling, forms the foundation of\nthis solution, enhancing productivity by streamlining common tasks. We selected\n8 Kaggle competitions to simulate data processing workflows in real-world\napplication scenarios. Evaluation results demonstrate that AutoKaggle achieves\na validation submission rate of 0.85 and a comprehensive score of 0.82 in\ntypical data science pipelines, fully proving its effectiveness and\npracticality in handling complex data science tasks.\n","authors":["Ziming Li","Qianbo Zang","David Ma","Jiawei Guo","Tuney Zheng","Minghao Liu","Xinyao Niu","Yue Wang","Jian Yang","Jiaheng Liu","Wanjun Zhong","Wangchunshu Zhou","Wenhao Huang","Ge Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.20424v3.pdf","comment":"44 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.03445v1","updated":"2024-11-05T19:00:34Z","published":"2024-11-05T19:00:34Z","title":"Solving Trojan Detection Competitions with Linear Weight Classification","summary":"  Neural networks can conceal malicious Trojan backdoors that allow a trigger\nto covertly change the model behavior. Detecting signs of these backdoors,\nparticularly without access to any triggered data, is the subject of ongoing\nresearch and open challenges. In one common formulation of the problem, we are\ngiven a set of clean and poisoned models and need to predict whether a given\ntest model is clean or poisoned. In this paper, we introduce a detector that\nworks remarkably well across many of the existing datasets and domains. It is\nobtained by training a binary classifier on a large number of models' weights\nafter performing a few different pre-processing steps including feature\nselection and standardization, reference model weights subtraction, and model\nalignment prior to detection. We evaluate this algorithm on a diverse set of\nTrojan detection benchmarks and domains and examine the cases where the\napproach is most and least effective.\n","authors":["Todd Huster","Peter Lin","Razvan Stefanescu","Emmanuel Ekwedike","Ritu Chadha"],"pdf_url":"https://arxiv.org/pdf/2411.03445v1.pdf","comment":"9 pages, 4 Figures"},{"id":"http://arxiv.org/abs/2411.03314v1","updated":"2024-11-05T18:59:51Z","published":"2024-11-05T18:59:51Z","title":"MME-Finance: A Multimodal Finance Benchmark for Expert-level\n  Understanding and Reasoning","summary":"  In recent years, multimodal benchmarks for general domains have guided the\nrapid development of multimodal models on general tasks. However, the financial\nfield has its peculiarities. It features unique graphical images (e.g.,\ncandlestick charts, technical indicator charts) and possesses a wealth of\nspecialized financial knowledge (e.g., futures, turnover rate). Therefore,\nbenchmarks from general fields often fail to measure the performance of\nmultimodal models in the financial domain, and thus cannot effectively guide\nthe rapid development of large financial models. To promote the development of\nlarge financial multimodal models, we propose MME-Finance, an bilingual\nopen-ended and practical usage-oriented Visual Question Answering (VQA)\nbenchmark. The characteristics of our benchmark are finance and expertise,\nwhich include constructing charts that reflect the actual usage needs of users\n(e.g., computer screenshots and mobile photography), creating questions\naccording to the preferences in financial domain inquiries, and annotating\nquestions by experts with 10+ years of experience in the financial industry.\nAdditionally, we have developed a custom-designed financial evaluation system\nin which visual information is first introduced in the multi-modal evaluation\nprocess. Extensive experimental evaluations of 19 mainstream MLLMs are\nconducted to test their perception, reasoning, and cognition capabilities. The\nresults indicate that models performing well on general benchmarks cannot do\nwell on MME-Finance; for instance, the top-performing open-source and\nclosed-source models obtain 65.69 (Qwen2VL-72B) and 63.18 (GPT-4o),\nrespectively. Their performance is particularly poor in categories most\nrelevant to finance, such as candlestick charts and technical indicator charts.\nIn addition, we propose a Chinese version, which helps compare performance of\nMLLMs under a Chinese context.\n","authors":["Ziliang Gan","Yu Lu","Dong Zhang","Haohan Li","Che Liu","Jian Liu","Ji Liu","Haipang Wu","Chaoyou Fu","Zenglin Xu","Rongjunchen Zhang","Yong Dai"],"pdf_url":"https://arxiv.org/pdf/2411.03314v1.pdf","comment":"Project Page: https://hithink-research.github.io/MME-Finance/"},{"id":"http://arxiv.org/abs/2411.03417v1","updated":"2024-11-05T18:58:00Z","published":"2024-11-05T18:58:00Z","title":"Usefulness of LLMs as an Author Checklist Assistant for Scientific\n  Papers: NeurIPS'24 Experiment","summary":"  Large language models (LLMs) represent a promising, but controversial, tool\nin aiding scientific peer review. This study evaluates the usefulness of LLMs\nin a conference setting as a tool for vetting paper submissions against\nsubmission standards. We conduct an experiment at the 2024 Neural Information\nProcessing Systems (NeurIPS) conference, where 234 papers were voluntarily\nsubmitted to an \"LLM-based Checklist Assistant.\" This assistant validates\nwhether papers adhere to the author checklist used by NeurIPS, which includes\nquestions to ensure compliance with research and manuscript preparation\nstandards. Evaluation of the assistant by NeurIPS paper authors suggests that\nthe LLM-based assistant was generally helpful in verifying checklist\ncompletion. In post-usage surveys, over 70% of authors found the assistant\nuseful, and 70% indicate that they would revise their papers or checklist\nresponses based on its feedback. While causal attribution to the assistant is\nnot definitive, qualitative evidence suggests that the LLM contributed to\nimproving some submissions. Survey responses and analysis of re-submissions\nindicate that authors made substantive revisions to their submissions in\nresponse to specific feedback from the LLM. The experiment also highlights\ncommon issues with LLMs: inaccuracy (20/52) and excessive strictness (14/52)\nwere the most frequent issues flagged by authors. We also conduct experiments\nto understand potential gaming of the system, which reveal that the assistant\ncould be manipulated to enhance scores through fabricated justifications,\nhighlighting potential vulnerabilities of automated review tools.\n","authors":["Alexander Goldberg","Ihsan Ullah","Thanh Gia Hieu Khuong","Benedictus Kent Rachmat","Zhen Xu","Isabelle Guyon","Nihar B. Shah"],"pdf_url":"https://arxiv.org/pdf/2411.03417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01720v2","updated":"2024-11-05T18:45:22Z","published":"2024-01-26T18:37:21Z","title":"Deep Learning Based Amharic Chatbot for FAQs in Universities","summary":"  University students often spend a considerable amount of time seeking answers\nto common questions from administrators or teachers. This can become tedious\nfor both parties, leading to a need for a solution. In response, this paper\nproposes a chatbot model that utilizes natural language processing and deep\nlearning techniques to answer frequently asked questions (FAQs) in the Amharic\nlanguage. Chatbots are computer programs that simulate human conversation\nthrough the use of artificial intelligence (AI), acting as a virtual assistant\nto handle questions and other tasks. The proposed chatbot program employs\ntokenization, normalization, stop word removal, and stemming to analyze and\ncategorize Amharic input sentences. Three machine learning model algorithms\nwere used to classify tokens and retrieve appropriate responses: Support Vector\nMachine (SVM), Multinomial Na\\\"ive Bayes, and deep neural networks implemented\nthrough TensorFlow, Keras, and NLTK. The deep learning model achieved the best\nresults with 91.55% accuracy and a validation loss of 0.3548 using an Adam\noptimizer and SoftMax activation function. The chatbot model was integrated\nwith Facebook Messenger and deployed on a Heroku server for 24-hour\naccessibility. The experimental results demonstrate that the chatbot framework\nachieved its objectives and effectively addressed challenges such as Amharic\nFidel variation, morphological variation, and lexical gaps. Future research\ncould explore the integration of Amharic WordNet to narrow the lexical gap and\nsupport more complex questions.\n","authors":["Goitom Ybrah Hailu","Hadush Hailu","Shishay Welay"],"pdf_url":"https://arxiv.org/pdf/2402.01720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14319v2","updated":"2024-11-05T18:43:57Z","published":"2024-06-20T13:52:30Z","title":"LiveMind: Low-latency Large Language Models with Simultaneous Inference","summary":"  In this paper, we introduce LiveMind, a novel low-latency inference framework\nfor large language model (LLM) inference which enables LLMs to perform\ninferences with incomplete user input. By reallocating computational processes\nto the input phase, a substantial reduction in latency is achieved, thereby\nsignificantly enhancing the interactive experience for users of LLMs. The\nframework adeptly manages the visibility of the streaming input to the model,\nallowing it to infer from incomplete user input or await additional content.\nCompared with traditional inference methods on complete user input, our\napproach demonstrates an average reduction in response latency of 84.0% on the\nMMLU dataset and 71.6% on the MMLU-Pro dataset, while maintaining comparable\naccuracy. Additionally, our framework facilitates collaborative inference and\noutput across different models. By employing an large LLM for inference and a\nsmall LLM for output, we achieve an average 37% reduction in response latency,\nalongside a 4.30% improvement in accuracy on the MMLU-Pro dataset compared with\nthe baseline. The proposed LiveMind framework advances the field of human-AI\ninteraction by enabling more responsive and efficient communication between\nusers and AI systems.\n","authors":["Chuangtao Chen","Grace Li Zhang","Xunzhao Yin","Cheng Zhuo","Ulf Schlichtmann","Bing Li"],"pdf_url":"https://arxiv.org/pdf/2406.14319v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00593v2","updated":"2024-11-05T18:35:39Z","published":"2024-11-01T13:53:14Z","title":"Adapting Language Models via Token Translation","summary":"  Modern large language models use a fixed tokenizer to effectively compress\ntext drawn from a source domain. However, applying the same tokenizer to a new\ntarget domain often leads to inferior compression, more costly inference, and\nreduced semantic alignment. To address this deficiency, we introduce Sparse\nSinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the\ntarget domain and learns to translate between target and source tokens,\nenabling more effective reuse of the pre-trained next-source-token predictor.\nIn our experiments with finetuned English language models, S2T2 improves both\nthe perplexity and the compression of out-of-domain protein sequences,\noutperforming direct finetuning with either the source or target tokenizer. In\naddition, we find that token translations learned for smaller, less expensive\nmodels can be directly transferred to larger, more powerful models to reap the\nbenefits of S2T2 at lower cost.\n","authors":["Zhili Feng","Tanya Marwah","Nicolo Fusi","David Alvarez-Melis","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2411.00593v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03397v1","updated":"2024-11-05T18:31:06Z","published":"2024-11-05T18:31:06Z","title":"SAUCE: Synchronous and Asynchronous User-Customizable Environment for\n  Multi-Agent LLM Interaction","summary":"  Many human interactions, such as political debates, are carried out in group\nsettings, where there are arbitrarily many participants, each with different\nviews and agendas. To explore such complex social settings, we present SAUCE: a\ncustomizable Python platform, allowing researchers to plug-and-play various\nLLMs participating in discussions on any topic chosen by the user. Our platform\ntakes care of instantiating the models, scheduling their responses, managing\nthe discussion history, and producing a comprehensive output log, all\ncustomizable through configuration files, requiring little to no coding skills.\nA novel feature of SAUCE is our asynchronous communication feature, where\nmodels decide when to speak in addition to what to say, thus modeling an\nimportant facet of human communication. We show SAUCE's attractiveness in two\ninitial experiments, and invite the community to use it in simulating various\ngroup simulations.\n","authors":["Shlomo Neuberger","Niv Eckhaus","Uri Berger","Amir Taubenfeld","Gabriel Stanovsky","Ariel Goldstein"],"pdf_url":"https://arxiv.org/pdf/2411.03397v1.pdf","comment":"https://github.com/Deep-Cognition-Lab/SAUCE"},{"id":"http://arxiv.org/abs/2411.03395v1","updated":"2024-11-05T18:30:13Z","published":"2024-11-05T18:30:13Z","title":"Exploring Large Language Models for Specialist-level Oncology Care","summary":"  Large language models (LLMs) have shown remarkable progress in encoding\nclinical knowledge and responding to complex medical queries with appropriate\nclinical reasoning. However, their applicability in subspecialist or complex\nmedical settings remains underexplored. In this work, we probe the performance\nof AMIE, a research conversational diagnostic AI system, in the subspecialist\ndomain of breast oncology care without specific fine-tuning to this challenging\ndomain. To perform this evaluation, we curated a set of 50 synthetic breast\ncancer vignettes representing a range of treatment-naive and\ntreatment-refractory cases and mirroring the key information available to a\nmultidisciplinary tumor board for decision-making (openly released with this\nwork). We developed a detailed clinical rubric for evaluating management plans,\nincluding axes such as the quality of case summarization, safety of the\nproposed care plan, and recommendations for chemotherapy, radiotherapy, surgery\nand hormonal therapy. To improve performance, we enhanced AMIE with the\ninference-time ability to perform web search retrieval to gather relevant and\nup-to-date clinical knowledge and refine its responses with a multi-stage\nself-critique pipeline. We compare response quality of AMIE with internal\nmedicine trainees, oncology fellows, and general oncology attendings under both\nautomated and specialist clinician evaluations. In our evaluations, AMIE\noutperformed trainees and fellows demonstrating the potential of the system in\nthis challenging and important domain. We further demonstrate through\nqualitative examples, how systems such as AMIE might facilitate conversational\ninteractions to assist clinicians in their decision making. However, AMIE's\nperformance was overall inferior to attending oncologists suggesting that\nfurther research is needed prior to consideration of prospective uses.\n","authors":["Anil Palepu","Vikram Dhillon","Polly Niravath","Wei-Hung Weng","Preethi Prasad","Khaled Saab","Ryutaro Tanno","Yong Cheng","Hanh Mai","Ethan Burns","Zainub Ajmal","Kavita Kulkarni","Philip Mansfield","Dale Webster","Joelle Barral","Juraj Gottweis","Mike Schaekermann","S. Sara Mahdavi","Vivek Natarajan","Alan Karthikesalingam","Tao Tu"],"pdf_url":"https://arxiv.org/pdf/2411.03395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03307v1","updated":"2024-11-05T18:01:12Z","published":"2024-11-05T18:01:12Z","title":"LLMs for Domain Generation Algorithm Detection","summary":"  This work analyzes the use of large language models (LLMs) for detecting\ndomain generation algorithms (DGAs). We perform a detailed evaluation of two\nimportant techniques: In-Context Learning (ICL) and Supervised Fine-Tuning\n(SFT), showing how they can improve detection. SFT increases performance by\nusing domain-specific data, whereas ICL helps the detection model to quickly\nadapt to new threats without requiring much retraining. We use Meta's Llama3 8B\nmodel, on a custom dataset with 68 malware families and normal domains,\ncovering several hard-to-detect schemes, including recent word-based DGAs.\nResults proved that LLM-based methods can achieve competitive results in DGA\ndetection. In particular, the SFT-based LLM DGA detector outperforms\nstate-of-the-art models using attention layers, achieving 94% accuracy with a\n4% false positive rate (FPR) and excelling at detecting word-based DGA domains.\n","authors":["Reynier Leyva La O","Carlos A. Catania","Tatiana Parlanti"],"pdf_url":"https://arxiv.org/pdf/2411.03307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03300v1","updated":"2024-11-05T17:53:25Z","published":"2024-11-05T17:53:25Z","title":"VERITAS: A Unified Approach to Reliability Evaluation","summary":"  Large language models (LLMs) often fail to synthesize information from their\ncontext to generate an accurate response. This renders them unreliable in\nknowledge intensive settings where reliability of the output is key. A critical\ncomponent for reliable LLMs is the integration of a robust fact-checking system\nthat can detect hallucinations across various formats. While several\nopen-access fact-checking models are available, their functionality is often\nlimited to specific tasks, such as grounded question-answering or entailment\nverification, and they perform less effectively in conversational settings. On\nthe other hand, closed-access models like GPT-4 and Claude offer greater\nflexibility across different contexts, including grounded dialogue\nverification, but are hindered by high costs and latency. In this work, we\nintroduce VERITAS, a family of hallucination detection models designed to\noperate flexibly across diverse contexts while minimizing latency and costs.\nVERITAS achieves state-of-the-art results considering average performance on\nall major hallucination detection benchmarks, with $10\\%$ increase in average\nperformance when compared to similar-sized models and get close to the\nperformance of GPT4 turbo with LLM-as-a-judge setting.\n","authors":["Rajkumar Ramamurthy","Meghana Arakkal Rajeev","Oliver Molenschot","James Zou","Nazneen Rajani"],"pdf_url":"https://arxiv.org/pdf/2411.03300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03284v1","updated":"2024-11-05T17:33:39Z","published":"2024-11-05T17:33:39Z","title":"SMoA: Improving Multi-agent Large Language Models with Sparse\n  Mixture-of-Agents","summary":"  While multi-agent systems have been shown to significantly enhance the\nperformance of Large Language Models (LLMs) across various tasks and\napplications, the dense interaction between scaling agents potentially hampers\ntheir efficiency and diversity. To address these challenges, we draw\ninspiration from the sparse mixture-of-agents (SMoE) and propose a sparse\nmixture-of-agents (SMoA) framework to improve the efficiency and diversity of\nmulti-agent LLMs. Unlike completely connected structures, SMoA introduces novel\nResponse Selection and Early Stopping mechanisms to sparsify information flows\namong individual LLM agents, striking a balance between performance and\nefficiency. Additionally, inspired by the expert diversity principle in SMoE\nframeworks for workload balance between experts, we assign distinct role\ndescriptions to each LLM agent, fostering diverse and divergent thinking.\nExtensive experiments on reasoning, alignment, and fairness benchmarks\ndemonstrate that SMoA achieves performance comparable to traditional\nmixture-of-agents approaches but with significantly lower computational costs.\nFurther analysis reveals that SMoA is more stable, has a greater capacity to\nscale, and offers considerable potential through hyper-parameter optimization.\nCode and data will be available at: https://github.com/David-Li0406/SMoA.\n","authors":["Dawei Li","Zhen Tan","Peijia Qian","Yifan Li","Kumar Satvik Chaudhary","Lijie Hu","Jiayi Shen"],"pdf_url":"https://arxiv.org/pdf/2411.03284v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.14550v2","updated":"2024-11-05T16:51:40Z","published":"2024-06-20T17:57:51Z","title":"GraphReader: Building Graph-based Agent to Enhance Long-Context\n  Abilities of Large Language Models","summary":"  Long-context capabilities are essential for large language models (LLMs) to\ntackle complex and long-input tasks. Despite numerous efforts made to optimize\nLLMs for long contexts, challenges persist in robustly processing long inputs.\nIn this paper, we introduce GraphReader, a graph-based agent system designed to\nhandle long texts by structuring them into a graph and employing an agent to\nexplore this graph autonomously. Upon receiving a question, the agent first\nundertakes a step-by-step analysis and devises a rational plan. It then invokes\na set of predefined functions to read node content and neighbors, facilitating\na coarse-to-fine exploration of the graph. Throughout the exploration, the\nagent continuously records new insights and reflects on current circumstances\nto optimize the process until it has gathered sufficient information to\ngenerate an answer. Experimental results on the LV-Eval dataset reveal that\nGraphReader, using a 4k context window, consistently outperforms GPT-4-128k\nacross context lengths from 16k to 256k by a large margin. Additionally, our\napproach demonstrates superior performance on four challenging single-hop and\nmulti-hop benchmarks.\n","authors":["Shilong Li","Yancheng He","Hangyu Guo","Xingyuan Bu","Ge Bai","Jie Liu","Jiaheng Liu","Xingwei Qu","Yangguang Li","Wanli Ouyang","Wenbo Su","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.14550v2.pdf","comment":"[EMNLP 2024] The first four authors contributed equally, 29 pages"},{"id":"http://arxiv.org/abs/2406.06484v4","updated":"2024-11-05T16:48:53Z","published":"2024-06-10T17:24:42Z","title":"Parallelizing Linear Transformers with the Delta Rule over Sequence\n  Length","summary":"  Transformers with linear attention (i.e., linear transformers) and\nstate-space models have recently been suggested as a viable linear-time\nalternative to transformers with softmax attention. However, these models still\nunderperform transformers especially on tasks that require in-context\nretrieval. While more expressive variants of linear transformers which replace\nthe additive update in linear transformers with the delta rule (DeltaNet) have\nbeen found to be more effective at associative recall, existing algorithms for\ntraining such models do not parallelize over sequence length and are thus\ninefficient to train on modern hardware. This work describes a\nhardware-efficient algorithm for training linear transformers with the delta\nrule, which exploits a memory-efficient representation for computing products\nof Householder matrices. This algorithm allows us to scale up DeltaNet to\nstandard language modeling settings. We train a 1.3B model for 100B tokens and\nfind that it outperforms recent linear-time baselines such as Mamba and GLA in\nterms of perplexity and zero-shot performance on downstream tasks. We also\nexperiment with two hybrid models which combine DeltaNet layers with (1)\nsliding-window attention layers every other layer or (2) two global attention\nlayers, and find that these hybrids outperform strong transformer baselines.\n","authors":["Songlin Yang","Bailin Wang","Yu Zhang","Yikang Shen","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2406.06484v4.pdf","comment":"NeurIPS 2024 camera ready"},{"id":"http://arxiv.org/abs/2411.03250v1","updated":"2024-11-05T16:47:53Z","published":"2024-11-05T16:47:53Z","title":"DiffLM: Controllable Synthetic Data Generation via Diffusion Language\n  Models","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced their knowledge and generative capabilities, leading to a surge of\ninterest in leveraging LLMs for high-quality data synthesis. However, synthetic\ndata generation via prompting LLMs remains challenging due to LLMs' limited\nunderstanding of target data distributions and the complexity of prompt\nengineering, especially for structured formatted data. To address these issues,\nwe introduce DiffLM, a controllable data synthesis framework based on\nvariational autoencoder (VAE), which further (1) leverages diffusion models to\nreserve more information of original distribution and format structure in the\nlearned latent distribution and (2) decouples the learning of target\ndistribution knowledge from the LLM's generative objectives via a plug-and-play\nlatent feature injection module. As we observed significant discrepancies\nbetween the VAE's latent representations and the real data distribution, the\nlatent diffusion module is introduced into our framework to learn a fully\nexpressive latent distribution. Evaluations on seven real-world datasets with\nstructured formatted data (i.e., Tabular, Code and Tool data) demonstrate that\nDiffLM generates high-quality data, with performance on downstream tasks\nsurpassing that of real data by 2-7 percent in certain cases. The data and code\nwill be publicly available upon completion of internal review.\n","authors":["Ying Zhou","Xinyao Wang","Yulei Niu","Yaojie Shen","Lexin Tang","Fan Chen","Ben He","Le Sun","Longyin Wen"],"pdf_url":"https://arxiv.org/pdf/2411.03250v1.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2406.11811v2","updated":"2024-11-05T16:47:43Z","published":"2024-06-17T17:52:54Z","title":"RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen\n  Reference Content","summary":"  Large Language Models (LLMs) are trained on vast amounts of data, most of\nwhich is automatically scraped from the internet. This data includes\nencyclopedic documents that harbor a vast amount of general knowledge (e.g.,\nWikipedia) but also potentially overlap with benchmark datasets used for\nevaluating LLMs. Consequently, evaluating models on test splits that might have\nleaked into the training set is prone to misleading conclusions. To foster\nsound evaluation of language models, we introduce a new test dataset named\nRepLiQA, suited for question-answering and topic retrieval tasks. RepLiQA is a\ncollection of five splits of test sets, four of which have not been released to\nthe internet or exposed to LLM APIs prior to this publication. Each sample in\nRepLiQA comprises (1) a reference document crafted by a human annotator and\ndepicting an imaginary scenario (e.g., a news article) absent from the\ninternet; (2) a question about the document's topic; (3) a ground-truth answer\nderived directly from the information in the document; and (4) the paragraph\nextracted from the reference document containing the answer. As such, accurate\nanswers can only be generated if a model can find relevant content within the\nprovided document. We run a large-scale benchmark comprising several\nstate-of-the-art LLMs to uncover differences in performance across models of\nvarious types and sizes in a context-conditional language modeling setting.\nReleased splits of RepLiQA can be found here:\nhttps://huggingface.co/datasets/ServiceNow/repliqa.\n","authors":["Joao Monteiro","Pierre-Andre Noel","Etienne Marcotte","Sai Rajeswar","Valentina Zantedeschi","David Vazquez","Nicolas Chapados","Christopher Pal","Perouz Taslakian"],"pdf_url":"https://arxiv.org/pdf/2406.11811v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14762v3","updated":"2024-11-05T16:40:21Z","published":"2024-02-22T18:21:59Z","title":"MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language\n  Models in Multi-Turn Dialogues","summary":"  The advent of Large Language Models (LLMs) has drastically enhanced dialogue\nsystems. However, comprehensively evaluating the dialogue abilities of LLMs\nremains a challenge. Previous benchmarks have primarily focused on single-turn\ndialogues or provided coarse-grained and incomplete assessments of multi-turn\ndialogues, overlooking the complexity and fine-grained nuances of real-life\ndialogues. To address this issue, we introduce MT-Bench-101, specifically\ndesigned to evaluate the fine-grained abilities of LLMs in multi-turn\ndialogues. By conducting a detailed analysis of real multi-turn dialogue data,\nwe construct a three-tier hierarchical ability taxonomy comprising 4208 turns\nacross 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21\npopular LLMs based on MT-Bench-101, conducting comprehensive analyses from both\nability and task perspectives and observing differing trends in LLMs\nperformance across dialogue turns within various tasks. Further analysis\nindicates that neither utilizing common alignment techniques nor chat-specific\ndesigns has led to obvious enhancements in the multi-turn abilities of LLMs.\nExtensive case studies suggest that our designed tasks accurately assess the\ncorresponding multi-turn abilities. The data and code are available at\n\\url{https://github.com/mtbench101/mt-bench-101}.\n","authors":["Ge Bai","Jie Liu","Xingyuan Bu","Yancheng He","Jiaheng Liu","Zhanhui Zhou","Zhuoran Lin","Wenbo Su","Tiezheng Ge","Bo Zheng","Wanli Ouyang"],"pdf_url":"https://arxiv.org/pdf/2402.14762v3.pdf","comment":"[ACL 2024] The first three authors contribute equally, 34 pages, repo\n  at https://github.com/mtbench101/mt-bench-101"},{"id":"http://arxiv.org/abs/2311.17898v3","updated":"2024-11-05T16:31:24Z","published":"2023-11-29T18:51:46Z","title":"Contextual Knowledge Pursuit for Faithful Visual Synthesis","summary":"  Modern text-to-vision generative models often hallucinate when the prompt\ndescribing the scene to be generated is underspecified. In large language\nmodels (LLMs), a prevalent strategy to reduce hallucinations is to retrieve\nfactual knowledge from an external database. While such retrieval augmentation\nstrategies have great potential to enhance text-to-vision generators, existing\nstatic top-K retrieval methods explore the knowledge pool once, missing the\nbroader context necessary for high-quality generation. Furthermore, LLMs\ninternally possess rich world knowledge learned during large-scale training\n(parametric knowledge) that could mitigate the need for external data\nretrieval. This paper proposes Contextual Knowledge Pursuit (CKPT), a framework\nthat leverages the complementary strengths of external and parametric knowledge\nto help generators produce reliable visual content. Instead of the one-time\nretrieval of facts from an external database to improve a given prompt, CKPT\nuses (1) an LLM to decide whether to seek external knowledge or to self-elicit\ndescriptions from LLM parametric knowledge, (2) a knowledge pursuit process to\ncontextually seek and sequentially gather most relevant facts, (3) a knowledge\naggregator for prompt enhancement with the gathered fact context, and (4) a\nfiltered fine-tuning objective to improve visual synthesis with richer prompts.\nWe evaluate CKPT across multiple text-driven generative tasks (image, 3D\nrendering, and video) on datasets of rare objects and daily scenarios. Our\nresults show that CKPT is capable of generating faithful and semantically rich\ncontent across diverse visual domains, offering a promising data source for\nzero-shot synthesis and filtered fine-tuning of text-to-vision generative\nmodels.\n","authors":["Jinqi Luo","Kwan Ho Ryan Chan","Dimitris Dimos","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2311.17898v3.pdf","comment":"Accepted in ECCV 2024 SDCV Workshop. GitHub repository at\n  https://github.com/peterljq/Contextual-Knowledge-Pursuit"},{"id":"http://arxiv.org/abs/2407.11019v2","updated":"2024-11-05T16:21:55Z","published":"2024-06-28T17:31:47Z","title":"Efficacy of Various Large Language Models in Generating Smart Contracts","summary":"  This study analyzes the application of code-generating Large Language Models\nin the creation of immutable Solidity smart contracts on the Ethereum\nBlockchain. Other works have previously analyzed Artificial Intelligence code\ngeneration abilities. This paper aims to expand this to a larger scope to\ninclude programs where security and efficiency are of utmost priority such as\nsmart contracts. The hypothesis leading into the study was that LLMs in general\nwould have difficulty in rigorously implementing security details in the code,\nwhich was shown through our results, but surprisingly generally succeeded in\nmany common types of contracts. We also discovered a novel way of generating\nsmart contracts through new prompting strategies.\n","authors":["Siddhartha Chatterjee","Bina Ramamurthy"],"pdf_url":"https://arxiv.org/pdf/2407.11019v2.pdf","comment":"18 pages, accepted for presentation at 8th annual Future of\n  Information and Communication Conference"},{"id":"http://arxiv.org/abs/2401.06477v4","updated":"2024-11-05T16:02:21Z","published":"2024-01-12T09:56:57Z","title":"Kun: Answer Polishment for Chinese Self-Alignment with Instruction\n  Back-Translation","summary":"  In this paper, we introduce Kun, a novel approach for creating high-quality\ninstruction-tuning datasets for large language models (LLMs) without relying on\nmanual annotations. Adapting a self-training algorithm based on instruction\nback-translation and answer polishment, Kun leverages unlabelled data from\ndiverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial\ndataset of over a million Chinese instructional data points. This approach\nsignificantly deviates from traditional methods by using a self-curation\nprocess to refine and select the most effective instruction-output pairs. Our\nexperiments with the 6B-parameter Yi model across various benchmarks\ndemonstrate Kun's robustness and scalability. Our method's core contributions\nlie in its algorithmic advancement, which enhances data retention and clarity,\nand its innovative data generation approach that substantially reduces the\nreliance on costly and time-consuming manual annotations. This methodology\npresents a scalable and efficient solution for improving the\ninstruction-following capabilities of LLMs, with significant implications for\ntheir application across diverse fields. The code and dataset can be found at\nhttps://github.com/Zheng0428/COIG-Kun\n","authors":["Tianyu Zheng","Shuyue Guo","Xingwei Qu","Jiawei Guo","Xinrun Du","Qi Jia","Chenghua Lin","Wenhao Huang","Jie Fu","Ge Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.06477v4.pdf","comment":"12 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.04331v2","updated":"2024-11-05T15:43:18Z","published":"2024-06-06T17:59:10Z","title":"PaCE: Parsimonious Concept Engineering for Large Language Models","summary":"  Large Language Models (LLMs) are being used for a wide variety of tasks.\nWhile they are capable of generating human-like responses, they can also\nproduce undesirable output including potentially harmful information, racist or\nsexist language, and hallucinations. Alignment methods are designed to reduce\nsuch undesirable outputs via techniques such as fine-tuning, prompt\nengineering, and representation engineering. However, existing methods face\nseveral challenges: some require costly fine-tuning for every alignment task;\nsome do not adequately remove undesirable concepts, failing alignment; some\nremove benign concepts, lowering the linguistic capabilities of LLMs. To\naddress these issues, we propose Parsimonious Concept Engineering (PaCE), a\nnovel activation engineering framework for alignment. First, to sufficiently\nmodel the concepts, we construct a large-scale concept dictionary in the\nactivation space, in which each atom corresponds to a semantic concept. Given\nany alignment task, we instruct a concept partitioner to efficiently annotate\nthe concepts as benign or undesirable. Then, at inference time, we decompose\nthe LLM activations along the concept dictionary via sparse coding, to\naccurately represent the activations as linear combinations of benign and\nundesirable components. By removing the latter ones from the activations, we\nreorient the behavior of the LLM towards the alignment goal. We conduct\nexperiments on tasks such as response detoxification, faithfulness enhancement,\nand sentiment revising, and show that PaCE achieves state-of-the-art alignment\nperformance while maintaining linguistic capabilities.\n","authors":["Jinqi Luo","Tianjiao Ding","Kwan Ho Ryan Chan","Darshan Thaker","Aditya Chattopadhyay","Chris Callison-Burch","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2406.04331v2.pdf","comment":"Accepted in NeurIPS 2024. GitHub repository at\n  https://github.com/peterljq/Parsimonious-Concept-Engineering"},{"id":"http://arxiv.org/abs/2411.01076v2","updated":"2024-11-05T15:03:45Z","published":"2024-11-01T23:14:30Z","title":"Privacy Risks of Speculative Decoding in Large Language Models","summary":"  Speculative decoding in large language models (LLMs) accelerates token\ngeneration by speculatively predicting multiple tokens cheaply and verifying\nthem in parallel, and has been widely deployed. In this paper, we provide the\nfirst study demonstrating the privacy risks of speculative decoding. We observe\nthat input-dependent patterns of correct and incorrect predictions can be\nleaked out to an adversary monitoring token generation times and packet sizes,\nleading to privacy breaches. By observing the pattern of correctly and\nincorrectly speculated tokens, we show that a malicious adversary can\nfingerprint queries and learn private user inputs with more than $90\\%$\naccuracy across three different speculative decoding techniques - REST (almost\n$100\\%$ accuracy), LADE (up to $92\\%$ accuracy), and BiLD (up to $95\\%$\naccuracy). We show that an adversary can also leak out confidential\nintellectual property used to design these techniques, such as data from\ndata-stores used for prediction (in REST) at a rate of more than $25$ tokens\nper second, or even hyper-parameters used for prediction (in LADE). We also\ndiscuss mitigation strategies, such as aggregating tokens across multiple\niterations and padding packets with additional bytes, to avoid such privacy or\nconfidentiality breaches.\n","authors":["Jiankun Wei","Abdulrahman Abdulrazzag","Tianchen Zhang","Adel Muursepp","Gururaj Saileshwar"],"pdf_url":"https://arxiv.org/pdf/2411.01076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21333v2","updated":"2024-11-05T13:47:25Z","published":"2024-10-27T18:30:41Z","title":"Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on\n  Tasks where Thinking Makes Humans Worse","summary":"  Chain-of-thought (CoT) prompting has become a widely used strategy for\nworking with large language and multimodal models. While CoT has been shown to\nimprove performance across many tasks, determining the settings in which it is\neffective remains an ongoing effort. In particular, it is still an open\nquestion in what settings CoT systematically reduces model performance. In this\npaper, we seek to identify the characteristics of tasks where CoT reduces\nperformance by drawing inspiration from cognitive psychology, looking at cases\nwhere (i) verbal thinking or deliberation hurts performance in humans, and (ii)\nthe constraints governing human performance generalize to language models.\nThree such cases are implicit statistical learning, visual recognition, and\nclassifying with patterns containing exceptions. In extensive experiments\nacross all three settings, we find that a diverse collection of\nstate-of-the-art models exhibit significant drop-offs in performance (e.g., up\nto 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using\ninference-time reasoning compared to zero-shot counterparts. We also identify\nthree tasks that satisfy condition (i) but not (ii), and find that while verbal\nthinking reduces human performance in these tasks, CoT retains or increases\nmodel performance. Overall, our results show that while there is not an exact\nparallel between the cognitive processes of models and those of humans,\nconsidering cases where thinking has negative consequences for human\nperformance can help us identify settings where it negatively impacts models.\nBy connecting the literature on human deliberation with evaluations of CoT, we\noffer a new tool that can be used in understanding the impact of prompt choices\nand inference-time reasoning.\n","authors":["Ryan Liu","Jiayi Geng","Addison J. Wu","Ilia Sucholutsky","Tania Lombrozo","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2410.21333v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23074v2","updated":"2024-11-05T13:26:07Z","published":"2024-10-30T14:46:43Z","title":"Multi-Programming Language Sandbox for LLMs","summary":"  We introduce MPLSandbox, an out-of-the-box multi-programming language sandbox\ndesigned to provide unified and comprehensive feedback from compiler and\nanalysis tools for Large Language Models (LLMs). It can automatically identify\nthe programming language of the code, compiling and executing it within an\nisolated sub-sandbox to ensure safety and stability. In addition, MPLSandbox\nalso integrates both traditional and LLM-based code analysis tools, providing a\ncomprehensive analysis of generated code. MPLSandbox can be effortlessly\nintegrated into the training and deployment of LLMs to improve the quality and\ncorrectness of their generated code. It also helps researchers streamline their\nworkflows for various LLM-based code-related tasks, reducing the development\ncost. To validate the effectiveness of MPLSandbox, we integrate it into\ntraining and deployment approaches, and also employ it to optimize workflows\nfor a wide range of real-world code-related tasks. Our goal is to enhance\nresearcher productivity on LLM-based code-related tasks by simplifying and\nautomating workflows through delegation to MPLSandbox.\n","authors":["Shihan Dou","Jiazheng Zhang","Jianxiang Zang","Yunbo Tao","Weikang Zhou","Haoxiang Jia","Shichun Liu","Yuming Yang","Zhiheng Xi","Shenxi Wu","Shaoqing Zhang","Muling Wu","Changze Lv","Limao Xiong","Wenyu Zhan","Lin Zhang","Rongxiang Weng","Jingang Wang","Xunliang Cai","Yueming Wu","Ming Wen","Rui Zheng","Tao Ji","Yixin Cao","Tao Gui","Xipeng Qiu","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2410.23074v2.pdf","comment":"25 pages, 14 figures"},{"id":"http://arxiv.org/abs/2312.11517v4","updated":"2024-11-05T13:21:08Z","published":"2023-12-12T19:34:23Z","title":"A Natural Language Processing-Based Classification and Mode-Based\n  Ranking of Musculoskeletal Disorder Risk Factors","summary":"  This research delves into Musculoskeletal Disorder (MSD) risk factors, using\na blend of Natural Language Processing (NLP) and mode-based ranking. The aim is\nto refine understanding, classification, and prioritization for focused\nprevention and treatment. Eight NLP models are evaluated, combining pre-trained\ntransformers, cosine similarity, and distance metrics to categorize factors\ninto personal, biomechanical, workplace, psychological, and organizational\nclasses. BERT with cosine similarity achieves 28% accuracy; sentence\ntransformer with Euclidean, Bray-Curtis, and Minkowski distances scores 100%.\nWith 10-fold cross-validation, statistical tests ensure robust results. Survey\ndata and mode-based ranking determine severity hierarchy, aligning with the\nliterature. \"Working posture\" is the most severe, highlighting posture's role.\nSurvey insights emphasize \"Job insecurity,\" \"Effort reward imbalance,\" and\n\"Poor employee facility\" as significant contributors. Rankings offer actionable\ninsights for MSD prevention. The study suggests targeted interventions,\nworkplace improvements, and future research directions. This integrated NLP and\nranking approach enhances MSD comprehension and informs occupational health\nstrategies.\n","authors":["Md Abrar Jahin","Subrata Talapatra"],"pdf_url":"https://arxiv.org/pdf/2312.11517v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10229v2","updated":"2024-11-05T13:18:31Z","published":"2024-04-16T02:19:28Z","title":"Generative Text Steganography with Large Language Model","summary":"  Recent advances in large language models (LLMs) have blurred the boundary of\nhigh-quality text generation between humans and machines, which is favorable\nfor generative text steganography. While, current advanced steganographic\nmapping is not suitable for LLMs since most users are restricted to accessing\nonly the black-box API or user interface of the LLMs, thereby lacking access to\nthe training vocabulary and its sampling probabilities. In this paper, we\nexplore a black-box generative text steganographic method based on the user\ninterfaces of large language models, which is called LLM-Stega. The main goal\nof LLM-Stega is that the secure covert communication between Alice (sender) and\nBob (receiver) is conducted by using the user interfaces of LLMs. Specifically,\nWe first construct a keyword set and design a new encrypted steganographic\nmapping to embed secret messages. Furthermore, to guarantee accurate extraction\nof secret messages and rich semantics of generated stego texts, an optimization\nmechanism based on reject sampling is proposed. Comprehensive experiments\ndemonstrate that the proposed LLM-Stega outperforms current state-of-the-art\nmethods.\n","authors":["Jiaxuan Wu","Zhengxian Wu","Yiming Xue","Juan Wen","Wanli Peng"],"pdf_url":"https://arxiv.org/pdf/2404.10229v2.pdf","comment":"9 pages, 4 figures, accepted at ACM Multimedia 2024"},{"id":"http://arxiv.org/abs/2406.13618v2","updated":"2024-11-05T13:17:56Z","published":"2024-06-19T15:14:55Z","title":"In-Context Former: Lightning-fast Compressing Context for Large Language\n  Model","summary":"  With the rising popularity of Transformer-based large language models (LLMs),\nreducing their high inference costs has become a significant research focus.\nOne effective approach is to compress the long input contexts. Existing methods\ntypically leverage the self-attention mechanism of the LLM itself for context\ncompression. While these methods have achieved notable results, the compression\nprocess still involves quadratic time complexity, which limits their\napplicability. To mitigate this limitation, we propose the In-Context Former\n(IC-Former). Unlike previous methods, IC-Former does not depend on the target\nLLMs. Instead, it leverages the cross-attention mechanism and a small number of\nlearnable digest tokens to directly condense information from the contextual\nword embeddings. This approach significantly reduces inference time, which\nachieves linear growth in time complexity within the compression range.\nExperimental results indicate that our method requires only 1/32 of the\nfloating-point operations of the baseline during compression and improves\nprocessing speed by 68 to 112 times while achieving over 90% of the baseline\nperformance on evaluation metrics. Overall, our model effectively reduces\ncompression costs and makes real-time compression scenarios feasible.\n","authors":["Xiangfeng Wang","Zaiyi Chen","Zheyong Xie","Tong Xu","Yongyi He","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2406.13618v2.pdf","comment":"Accepted by EMNLP2024(Findings)"},{"id":"http://arxiv.org/abs/2411.03042v1","updated":"2024-11-05T12:26:25Z","published":"2024-11-05T12:26:25Z","title":"Predictor-Corrector Enhanced Transformers with Exponential Moving\n  Average Coefficient Learning","summary":"  Residual networks, as discrete approximations of Ordinary Differential\nEquations (ODEs), have inspired significant advancements in neural network\ndesign, including multistep methods, high-order methods, and multi-particle\ndynamical systems. The precision of the solution to ODEs significantly affects\nparameter optimization, thereby impacting model performance. In this work, we\npresent a series of advanced explorations of Transformer architecture design to\nminimize the error compared to the true ``solution.'' First, we introduce a\npredictor-corrector learning framework to minimize truncation errors, which\nconsists of a high-order predictor and a multistep corrector. Second, we\npropose an exponential moving average-based coefficient learning method to\nstrengthen our higher-order predictor. Extensive experiments on large-scale\nmachine translation, abstractive summarization, language modeling, and natural\nlanguage understanding benchmarks demonstrate the superiority of our approach.\nOn the WMT'14 English-German and English-French tasks, our model achieved BLEU\nscores of 30.95 and 44.27, respectively. Furthermore, on the OPUS multilingual\nmachine translation task, our model surpasses a robust 3.8B DeepNet by an\naverage of 2.9 SacreBLEU, using only 1/3 parameters. Notably, it also beats\nLLama models by 5.7 accuracy points on the LM Harness Evaluation.\n","authors":["Bei Li","Tong Zheng","Rui Wang","Jiahao Liu","Qingyan Guo","Junliang Guo","Xu Tan","Tong Xiao","Jingbo Zhu","Jingang Wang","Xunliang Cai"],"pdf_url":"https://arxiv.org/pdf/2411.03042v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.19839v2","updated":"2024-11-05T12:10:51Z","published":"2024-09-30T00:41:51Z","title":"ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities","summary":"  Forecasts of future events are essential inputs into informed\ndecision-making. Machine learning (ML) systems have the potential to deliver\nforecasts at scale, but there is no framework for evaluating the accuracy of ML\nsystems on a standardized set of forecasting questions. To address this gap, we\nintroduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML\nsystems on an automatically generated and regularly updated set of 1,000\nforecasting questions. To avoid any possibility of data leakage, ForecastBench\nis comprised solely of questions about future events that have no known answer\nat the time of submission. We quantify the capabilities of current ML systems\nby collecting forecasts from expert (human) forecasters, the general public,\nand LLMs on a random subset of questions from the benchmark ($N=200$). While\nLLMs have achieved super-human performance on many benchmarks, they perform\nless well here: expert forecasters outperform the top-performing LLM (p-value\n$=0.01$). We display system and human scores in a public leaderboard at\nwww.forecastbench.org.\n","authors":["Ezra Karger","Houtan Bastani","Chen Yueh-Han","Zachary Jacobs","Danny Halawi","Fred Zhang","Philip E. Tetlock"],"pdf_url":"https://arxiv.org/pdf/2409.19839v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18481v2","updated":"2024-11-05T11:40:07Z","published":"2024-10-24T07:10:18Z","title":"Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence\n  Embeddings for Automatic Dialog Flow Extraction","summary":"  Efficiently deriving structured workflows from unannotated dialogs remains an\nunderexplored and formidable challenge in computational linguistics. Automating\nthis process could significantly accelerate the manual design of workflows in\nnew domains and enable the grounding of large language models in\ndomain-specific flowcharts, enhancing transparency and controllability. In this\npaper, we introduce Dialog2Flow (D2F) embeddings, which differ from\nconventional sentence embeddings by mapping utterances to a latent space where\nthey are grouped according to their communicative and informative functions\n(i.e., the actions they represent). D2F allows for modeling dialogs as\ncontinuous trajectories in a latent space with distinct action-related regions.\nBy clustering D2F embeddings, the latent space is quantized, and dialogs can be\nconverted into sequences of region/action IDs, facilitating the extraction of\nthe underlying workflow. To pre-train D2F, we build a comprehensive dataset by\nunifying twenty task-oriented dialog datasets with normalized per-turn action\nannotations. We also introduce a novel soft contrastive loss that leverages the\nsemantic information of these actions to guide the representation learning\nprocess, showing superior performance compared to standard supervised\ncontrastive loss. Evaluation against various sentence embeddings, including\ndialog-specific ones, demonstrates that D2F yields superior qualitative and\nquantitative results across diverse domains.\n","authors":["Sergio Burdisso","Srikanth Madikeri","Petr Motlicek"],"pdf_url":"https://arxiv.org/pdf/2410.18481v2.pdf","comment":"Accepted to EMNLP 2024 main conference"},{"id":"http://arxiv.org/abs/2406.15570v2","updated":"2024-11-05T11:40:05Z","published":"2024-06-21T18:07:46Z","title":"DEM: Distribution Edited Model for Training with Mixed Data\n  Distributions","summary":"  Training with mixed data distributions is a common and important part of\ncreating multi-task and instruction-following models. The diversity of the data\ndistributions and cost of joint training makes the optimization procedure\nextremely challenging. Data mixing methods partially address this problem,\nalbeit having a sub-optimal performance across data sources and require\nmultiple expensive training runs. In this paper, we propose a simple and\nefficient alternative for better optimization of the data sources by combining\nmodels individually trained on each data source with the base model using basic\nelement-wise vector operations. The resulting model, namely Distribution Edited\nModel (DEM), is 11x cheaper than standard data mixing and outperforms strong\nbaselines on a variety of benchmarks, yielding upto 6.2% improvement on MMLU,\n11.5% on BBH, 16.1% on DROP, 6% on MathQA, and 9.3% on HELM with models of size\n3B to 13B. Notably, DEM does not require full re-training when modifying a\nsingle data-source, thus making it very flexible and scalable for training with\ndiverse data sources.\n","authors":["Dhananjay Ram","Aditya Rawal","Momchil Hardalov","Nikolaos Pappas","Sheng Zha"],"pdf_url":"https://arxiv.org/pdf/2406.15570v2.pdf","comment":"Accepted to EMNLP 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2410.08565v3","updated":"2024-11-05T11:29:59Z","published":"2024-10-11T06:44:31Z","title":"Ocean-omni: To Understand the World with Omni-modality","summary":"  The salient multimodal capabilities and interactive experience of GPT-4o\nhighlight its critical role in practical applications, yet it lacks a\nhigh-performing open-source counterpart. In this paper, we introduce\nOcean-omni, the first open-source 7B Multimodal Large Language Model (MLLM)\nadept at concurrently processing and analyzing modalities of image, video,\naudio, and text, while delivering an advanced multimodal interactive experience\nand strong performance. We propose an effective multimodal training schema\nstarting with 7B model and proceeding through two stages of multimodal\nalignment and multitask fine-tuning across audio, image, video, and text modal.\nThis approach equips the language model with the ability to handle visual and\naudio data effectively. Demonstrating strong performance across various\nomni-modal and multimodal benchmarks, we aim for this contribution to serve as\na competitive baseline for the open-source community in advancing multimodal\nunderstanding and real-time interaction.\n","authors":["Yadong Li","Haoze Sun","Mingan Lin","Tianpeng Li","Guosheng Dong","Tao Zhang","Bowen Ding","Wei Song","Zhenglin Cheng","Yuqi Huo","Song Chen","Xu Li","Da Pan","Shusen Zhang","Xin Wu","Zheng Liang","Jun Liu","Tao Zhang","Keer Lu","Yaqi Zhao","Yanjun Shen","Fan Yang","Kaicheng Yu","Tao Lin","Jianhua Xu","Zenan Zhou","Weipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.08565v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03012v1","updated":"2024-11-05T11:25:12Z","published":"2024-11-05T11:25:12Z","title":"Leveraging Large Language Models in Code Question Answering: Baselines\n  and Issues","summary":"  Question answering over source code provides software engineers and project\nmanagers with helpful information about the implemented features of a software\nproduct. This paper presents a work devoted to using large language models for\nquestion answering over source code in Python. The proposed method for\nimplementing a source code question answering system involves fine-tuning a\nlarge language model on a unified dataset of questions and answers for Python\ncode. To achieve the highest quality answers, we tested various models trained\non datasets preprocessed in different ways: a dataset without grammar\ncorrection, a dataset with grammar correction, and a dataset augmented with the\ngenerated summaries. The model answers were also analyzed for errors manually.\nWe report BLEU-4, BERTScore F1, BLEURT, and Exact Match metric values, along\nwith the conclusions from the manual error analysis. The obtained experimental\nresults highlight the current problems of the research area, such as poor\nquality of the public genuine question-answering datasets. In addition, the\nfindings include the positive effect of the grammar correction of the training\ndata on the testing metric values. The addressed findings and issues could be\nimportant for other researchers who attempt to improve the quality of source\ncode question answering solutions. The training and evaluation code is publicly\navailable at https://github.com/IU-AES-AI4Code/CodeQuestionAnswering.\n","authors":["Georgy Andryushchenko","Vladimir Ivanov","Vladimir Makharev","Elizaveta Tukhtina","Aidar Valeev"],"pdf_url":"https://arxiv.org/pdf/2411.03012v1.pdf","comment":"15 pages, 3 figures, Accepted to NLP (CCIS) @ AIST'24"},{"id":"http://arxiv.org/abs/2408.07888v2","updated":"2024-11-05T11:07:19Z","published":"2024-08-15T02:22:48Z","title":"Evaluating Fine-Tuning Efficiency of Human-Inspired Learning Strategies\n  in Medical Question Answering","summary":"  Fine-tuning Large Language Models (LLMs) incurs considerable training costs,\ndriving the need for data-efficient training with optimised data ordering.\nHuman-inspired strategies offer a solution by organising data based on human\nlearning practices. This study evaluates the fine-tuning efficiency of five\nhuman-inspired strategies across four language models, three datasets, and both\nhuman- and LLM-labelled data in the context of medical question answering.\nThese strategies achieve the best accuracy gain of 1.81% and an average gain of\n1.02% across datasets, with interleaved strategies delivering the best average\nresults. However, the best strategy varies across model-dataset combinations,\nlimiting the generalisability of the effects of any single strategy.\nAdditionally, LLM-defined question difficulty outperforms human-defined labels\nin curriculum-based learning, showing the potential of model-generated data as\na cost-effective alternative for optimising fine-tuning.\n","authors":["Yushi Yang","Andrew M. Bean","Robert McCraith","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2408.07888v2.pdf","comment":"NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning:\n  Principles and Scalability (FITML)"},{"id":"http://arxiv.org/abs/2411.02989v1","updated":"2024-11-05T10:52:20Z","published":"2024-11-05T10:52:20Z","title":"Growing a Tail: Increasing Output Diversity in Large Language Models","summary":"  How diverse are the outputs of large language models when diversity is\ndesired? We examine the diversity of responses of various models to questions\nwith multiple possible answers, comparing them with human responses. Our\nfindings suggest that models' outputs are highly concentrated, reflecting a\nnarrow, mainstream 'worldview', in comparison to humans, whose responses\nexhibit a much longer-tail. We examine three ways to increase models' output\ndiversity: 1) increasing generation randomness via temperature sampling; 2)\nprompting models to answer from diverse perspectives; 3) aggregating outputs\nfrom several models. A combination of these measures significantly increases\nmodels' output diversity, reaching that of humans. We discuss implications of\nthese findings for AI policy that wishes to preserve cultural diversity, an\nessential building block of a democratic social fabric.\n","authors":["Michal Shur-Ofry","Bar Horowitz-Amsalem","Adir Rahamim","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2411.02989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04691v4","updated":"2024-11-05T10:32:36Z","published":"2024-08-08T13:10:51Z","title":"Synthetic SQL Column Descriptions and Their Impact on Text-to-SQL\n  Performance","summary":"  Relational databases often suffer from uninformative descriptors of table\ncontents, such as ambiguous columns and hard-to-interpret values, impacting\nboth human users and text-to-SQL models. In this paper, we explore the use of\nlarge language models (LLMs) to automatically generate detailed natural\nlanguage descriptions for SQL database columns, aiming to improve text-to-SQL\nperformance and automate metadata creation. We create a dataset of gold column\ndescriptions based on the BIRD-Bench benchmark, manually refining its column\ndescriptions and creating a taxonomy for categorizing column difficulty. We\nthen evaluate several different LLMs in generating column descriptions across\nthe columns and different difficulties in the dataset, finding that models\nunsurprisingly struggle with columns that exhibit inherent ambiguity,\nhighlighting the need for manual expert input. We also find that incorporating\nsuch generated column descriptions consistently enhances text-to-SQL model\nperformance, particularly for larger models like GPT-4o, Qwen2 72B and Mixtral\n22Bx8. Notably, Qwen2-generated descriptions, containing by annotators deemed\nsuperfluous information, outperform manually curated gold descriptions,\nsuggesting that models benefit from more detailed metadata than humans expect.\nFuture work will investigate the specific features of these high-performing\ndescriptions and explore other types of metadata, such as numerical reasoning\nand synonyms, to further improve text-to-SQL systems. The dataset, annotations\nand code will all be made available.\n","authors":["Niklas Wretblad","Oskar Holmström","Erik Larsson","Axel Wiksäter","Oscar Söderlund","Hjalmar Öhman","Ture Pontén","Martin Forsberg","Martin Sörme","Fredrik Heintz"],"pdf_url":"https://arxiv.org/pdf/2408.04691v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12034v2","updated":"2024-11-05T10:24:42Z","published":"2024-06-30T22:18:49Z","title":"Understanding Transformers via N-gram Statistics","summary":"  Transformer based large-language models (LLMs) display extreme proficiency\nwith language yet a precise understanding of how they work remains elusive. One\nway of demystifying transformer predictions would be to describe how they\ndepend on their context in terms of simple template functions. This paper takes\na first step in this direction by considering families of functions (i.e.\nrules) formed out of simple N-gram based statistics of the training data. By\nstudying how well these rulesets approximate transformer predictions, we obtain\na variety of novel discoveries: a simple method to detect overfitting during\ntraining without using a holdout set, a quantitative measure of how\ntransformers progress from learning simple to more complex statistical rules\nover the course of training, a model-variance criterion governing when\ntransformer predictions tend to be described by N-gram rules, and insights into\nhow well transformers can be approximated by N-gram rulesets in the limit where\nthese rulesets become increasingly complex. In this latter direction, we find\nthat for 79% and 68% of LLM next-token distributions on TinyStories and\nWikipedia, respectively, their top-1 predictions agree with those provided by\nour N-gram rulesets.\n","authors":["Timothy Nguyen"],"pdf_url":"https://arxiv.org/pdf/2407.12034v2.pdf","comment":"NeurIPS 2024. Datasets and N-gram statistics open-sourced:\n  https://github.com/google-deepmind/transformer_ngrams"},{"id":"http://arxiv.org/abs/2411.02973v1","updated":"2024-11-05T10:18:53Z","published":"2024-11-05T10:18:53Z","title":"[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for\n  Diabetic Retinopathy using Chatbots and Generative AI","summary":"  We present an outline of the first large language model (LLM) based chatbot\napplication in the context of patient-reported outcome measures (PROMs) for\ndiabetic retinopathy. By utilizing the capabilities of current LLMs, we enable\npatients to provide feedback about their quality of life and treatment progress\nvia an interactive application. The proposed framework offers significant\nadvantages over the current approach, which encompasses only qualitative\ncollection of survey data or a static survey with limited answer options. Using\nthe PROBot LLM-PROM application, patients will be asked tailored questions\nabout their individual challenges, and can give more detailed feedback on the\nprogress of their treatment. Based on this input, we will use machine learning\nto infer conventional PROM scores, which can be used by clinicians to evaluate\nthe treatment status. The goal of the application is to improve adherence to\nthe healthcare system and treatments, and thus ultimately reduce cases of\nsubsequent vision impairment. The approach needs to be further validated using\na survey and a clinical study.\n","authors":["Maren Pielka","Tobias Schneider","Jan Terheyden","Rafet Sifa"],"pdf_url":"https://arxiv.org/pdf/2411.02973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02948v1","updated":"2024-11-05T09:44:53Z","published":"2024-11-05T09:44:53Z","title":"Grounding Natural Language to SQL Translation with Data-Based\n  Self-Explanations","summary":"  Natural Language Interfaces for Databases empower non-technical users to\ninteract with data using natural language (NL). Advanced approaches, utilizing\neither neural sequence-to-sequence or more recent sophisticated large-scale\nlanguage models, typically implement NL to SQL (NL2SQL) translation in an\nend-to-end fashion. However, like humans, these end-to-end translation models\nmay not always generate the best SQL output on their first try. In this paper,\nwe propose CycleSQL, an iterative framework designed for end-to-end translation\nmodels to autonomously generate the best output through self-evaluation. The\nmain idea of CycleSQL is to introduce data-grounded NL explanations of query\nresults as self-provided feedback, and use the feedback to validate the\ncorrectness of the translation iteratively, hence improving the overall\ntranslation accuracy. Extensive experiments, including quantitative and\nqualitative evaluations, are conducted to study CycleSQL by applying it to\nseven existing translation models on five widely used benchmarks. The results\nshow that 1) the feedback loop introduced in CycleSQL can consistently improve\nthe performance of existing models, and in particular, by applying CycleSQL to\nRESDSQL, obtains a translation accuracy of 82.0% (+2.6%) on the validation set,\nand 81.6% (+3.2%) on the test set of Spider benchmark; 2) the generated NL\nexplanations can also provide insightful information for users, aiding in the\ncomprehension of translation results and consequently enhancing the\ninterpretability of NL2SQL translation.\n","authors":["Yuankai Fan","Tonghui Ren","Can Huang","Zhenying He","X. Sean Wang"],"pdf_url":"https://arxiv.org/pdf/2411.02948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02943v1","updated":"2024-11-05T09:37:23Z","published":"2024-11-05T09:37:23Z","title":"Capturing research literature attitude towards Sustainable Development\n  Goals: an LLM-based topic modeling approach","summary":"  The world is facing a multitude of challenges that hinder the development of\nhuman civilization and the well-being of humanity on the planet. The\nSustainable Development Goals (SDGs) were formulated by the United Nations in\n2015 to address these global challenges by 2030. Natural language processing\ntechniques can help uncover discussions on SDGs within research literature. We\npropose a completely automated pipeline to 1) fetch content from the Scopus\ndatabase and prepare datasets dedicated to five groups of SDGs; 2) perform\ntopic modeling, a statistical technique used to identify topics in large\ncollections of textual data; and 3) enable topic exploration through\nkeywords-based search and topic frequency time series extraction. For topic\nmodeling, we leverage the stack of BERTopic scaled up to be applied on large\ncorpora of textual documents (we find hundreds of topics on hundreds of\nthousands of documents), introducing i) a novel LLM-based embeddings\ncomputation for representing scientific abstracts in the continuous space and\nii) a hyperparameter optimizer to efficiently find the best configuration for\nany new big datasets. We additionally produce the visualization of results on\ninteractive dashboards reporting topics' temporal evolution. Results are made\ninspectable and explorable, contributing to the interpretability of the topic\nmodeling process. Our proposed LLM-based topic modeling pipeline for big-text\ndatasets allows users to capture insights on the evolution of the attitude\ntoward SDGs within scientific abstracts in the 2006-2023 time span. All the\nresults are reproducible by using our system; the workflow can be generalized\nto be applied at any point in time to any big corpus of textual documents.\n","authors":["Francesco Invernici","Francesca Curati","Jelena Jakimov","Amirhossein Samavi","Anna Bernasconi"],"pdf_url":"https://arxiv.org/pdf/2411.02943v1.pdf","comment":"27 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.02939v1","updated":"2024-11-05T09:32:26Z","published":"2024-11-05T09:32:26Z","title":"A Post-Training Enhanced Optimization Approach for Small Language Models","summary":"  This paper delves into the continuous post-training optimization methods for\nsmall language models, and proposes a continuous post-training alignment data\nconstruction method for small language models. The core of this method is based\non the data guidance of large models, optimizing the diversity and accuracy of\nalignment data. In addition, to verify the effectiveness of the methods in this\npaper, we used Qwen2-0.5B-Instruct model as the baseline model for small\nlanguage models, using the alignment dataset constructed by our proposed\nmethod, we trained and compared several groups of experiments, including SFT\n(Supervised Fine Tuning) post-training experiment and KTO (Kahneman Tversky\noptimization) post-training experiment, as well as SFT-KTO two-stage\npost-training experiment and model weight fusion experiment. Finally, we\nevaluated and analyzed the performance of post-training models, and confirmed\nthat the continuous post-training optimization method proposed by us can\nsignificantly improve the performance of small language models.\n","authors":["Keke Zhai"],"pdf_url":"https://arxiv.org/pdf/2411.02939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02930v1","updated":"2024-11-05T09:22:08Z","published":"2024-11-05T09:22:08Z","title":"Textual Aesthetics in Large Language Models","summary":"  Image aesthetics is a crucial metric in the field of image generation.\nHowever, textual aesthetics has not been sufficiently explored. With the\nwidespread application of large language models (LLMs), previous work has\nprimarily focused on the correctness of content and the helpfulness of\nresponses. Nonetheless, providing responses with textual aesthetics is also an\nimportant factor for LLMs, which can offer a cleaner layout and ensure greater\nconsistency and coherence in content. In this work, we introduce a pipeline for\naesthetics polishing and help construct a textual aesthetics dataset named\nTexAes. We propose a textual aesthetics-powered fine-tuning method based on\ndirect preference optimization, termed TAPO, which leverages textual aesthetics\nwithout compromising content correctness. Additionally, we develop two\nevaluation methods for textual aesthetics based on text and image analysis,\nrespectively. Our experiments demonstrate that using textual aesthetics data\nand employing the TAPO fine-tuning method not only improves aesthetic scores\nbut also enhances performance on general evaluation datasets such as\nAlpacalEval and Anera-hard.\n","authors":["Lingjie Jiang","Shaohan Huang","Xun Wu","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2411.02930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13517v2","updated":"2024-11-05T09:08:28Z","published":"2024-10-17T13:06:02Z","title":"Bias in the Mirror: Are LLMs opinions robust to their own adversarial\n  attacks ?","summary":"  Large language models (LLMs) inherit biases from their training data and\nalignment processes, influencing their responses in subtle ways. While many\nstudies have examined these biases, little work has explored their robustness\nduring interactions. In this paper, we introduce a novel approach where two\ninstances of an LLM engage in self-debate, arguing opposing viewpoints to\npersuade a neutral version of the model. Through this, we evaluate how firmly\nbiases hold and whether models are susceptible to reinforcing misinformation or\nshifting to harmful viewpoints. Our experiments span multiple LLMs of varying\nsizes, origins, and languages, providing deeper insights into bias persistence\nand flexibility across linguistic and cultural contexts.\n","authors":["Virgile Rennard","Christos Xypolopoulos","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2410.13517v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02839v3","updated":"2024-11-05T09:07:22Z","published":"2024-03-05T10:20:52Z","title":"An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned\n  Judge Model is not a General Substitute for GPT-4","summary":"  Recently, there has been a growing trend of utilizing Large Language Model\n(LLM) to evaluate the quality of other LLMs. Many studies have employed\nproprietary close-sourced models, especially GPT-4, as the evaluator.\nAlternatively, other works have fine-tuned judge models based on open-source\nLLMs as the evaluator. While the fine-tuned judge models are claimed to achieve\ncomparable evaluation capability with GPT-4, in this work, we conduct an\nempirical study of judge models. Our findings indicate that although the\nfine-tuned judge models achieve high performance on in-domain test sets, even\nsurpassing GPT-4, they underperform GPT-4 across several dimensions, including\ngeneralizability, fairness, aspect-specific evaluation, and scalability. We\nalso reveal that the fine-tuned judge model inherently operates as a\ntask-specific classifier, consequently imposing the limitations. Finally, we\nintroduce a integrated method, leveraging GPT-4 to compensate for the\nlimitations and improve the fine-tuned judges. Experiment results show our\nmethod achieves accuracy on par with GPT-4 with only 50% of the API expense.\n","authors":["Hui Huang","Yingqi Qu","Xingyuan Bu","Hongli Zhou","Jing Liu","Muyun Yang","Bing Xu","Tiejun Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.02839v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11445v2","updated":"2024-11-05T08:46:01Z","published":"2024-09-17T03:39:45Z","title":"Jailbreaking Large Language Models with Symbolic Mathematics","summary":"  Recent advancements in AI safety have led to increased efforts in training\nand red-teaming large language models (LLMs) to mitigate unsafe content\ngeneration. However, these safety mechanisms may not be comprehensive, leaving\npotential vulnerabilities unexplored. This paper introduces MathPrompt, a novel\njailbreaking technique that exploits LLMs' advanced capabilities in symbolic\nmathematics to bypass their safety mechanisms. By encoding harmful natural\nlanguage prompts into mathematical problems, we demonstrate a critical\nvulnerability in current AI safety measures. Our experiments across 13\nstate-of-the-art LLMs reveal an average attack success rate of 73.6\\%,\nhighlighting the inability of existing safety training mechanisms to generalize\nto mathematically encoded inputs. Analysis of embedding vectors shows a\nsubstantial semantic shift between original and encoded prompts, helping\nexplain the attack's success. This work emphasizes the importance of a holistic\napproach to AI safety, calling for expanded red-teaming efforts to develop\nrobust safeguards across all potential input types and their associated risks.\n","authors":["Emet Bethany","Mazal Bethany","Juan Arturo Nolazco Flores","Sumit Kumar Jha","Peyman Najafirad"],"pdf_url":"https://arxiv.org/pdf/2409.11445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02116v2","updated":"2024-11-05T08:35:14Z","published":"2024-11-04T14:29:28Z","title":"Advancements and limitations of LLMs in replicating human color-word\n  associations","summary":"  Color-word associations play a fundamental role in human cognition and design\napplications. Large Language Models (LLMs) have become widely available and\ndemonstrated intelligent behaviors in various benchmarks with natural\nconversation skills. However, their ability to replicate human color-word\nassociations remains understudied. We compared multiple generations of LLMs\n(from GPT-3 to GPT-4o) against human color-word associations using data\ncollected from over 10,000 Japanese participants, involving 17 colors and words\nfrom eight categories in Japanese. Our findings reveal a clear progression in\nLLM performance across generations, with GPT-4o achieving the highest accuracy\nin predicting the best voted word for each color and category. However, the\nhighest median performance was approximately 50% even for GPT-4o with visual\ninputs (chance level is 10%), and the performance levels varied significantly\nacross word categories and colors, indicating a failure to fully replicate\nhuman color-word associations. On the other hand, color discrimination ability\nestimated from our color-word association data showed that LLMs demonstrated\nhigh correlation with human color discrimination patterns, similarly to\nprevious studies. Our study highlights both the advancements in LLM\ncapabilities and their persistent limitations, suggesting differences in\nsemantic memory structures between humans and LLMs in representing color-word\nassociations.\n","authors":["Makoto Fukushima","Shusuke Eshita","Hiroshige Fukuhara"],"pdf_url":"https://arxiv.org/pdf/2411.02116v2.pdf","comment":"20 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2411.02902v1","updated":"2024-11-05T08:35:08Z","published":"2024-11-05T08:35:08Z","title":"Membership Inference Attacks against Large Vision-Language Models","summary":"  Large vision-language models (VLLMs) exhibit promising capabilities for\nprocessing multi-modal tasks across various application scenarios. However,\ntheir emergence also raises significant data security concerns, given the\npotential inclusion of sensitive information, such as private photos and\nmedical records, in their training datasets. Detecting inappropriately used\ndata in VLLMs remains a critical and unresolved issue, mainly due to the lack\nof standardized datasets and suitable methodologies. In this study, we\nintroduce the first membership inference attack (MIA) benchmark tailored for\nvarious VLLMs to facilitate training data detection. Then, we propose a novel\nMIA pipeline specifically designed for token-level image detection. Lastly, we\npresent a new metric called MaxR\\'enyi-K%, which is based on the confidence of\nthe model output and applies to both text and image data. We believe that our\nwork can deepen the understanding and methodology of MIAs in the context of\nVLLMs. Our code and datasets are available at\nhttps://github.com/LIONS-EPFL/VL-MIA.\n","authors":["Zhan Li","Yongtao Wu","Yihang Chen","Francesco Tonin","Elias Abad Rocamora","Volkan Cevher"],"pdf_url":"https://arxiv.org/pdf/2411.02902v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.14722v6","updated":"2024-11-05T08:22:00Z","published":"2024-05-23T15:51:24Z","title":"DAPE: Data-Adaptive Positional Encoding for Length Extrapolation","summary":"  Positional encoding plays a crucial role in transformers, significantly\nimpacting model performance and length generalization. Prior research has\nintroduced absolute positional encoding (APE) and relative positional encoding\n(RPE) to distinguish token positions in given sequences. However, both APE and\nRPE remain fixed after model training regardless of input data, limiting their\nadaptability and flexibility. Hence, we expect that the desired positional\nencoding should be data-adaptive and can be dynamically adjusted with the given\nattention. In this paper, we propose a Data-Adaptive Positional Encoding (DAPE)\nmethod, which dynamically and semantically adjusts based on input context and\nlearned fixed priors. Experimental validation on real-world datasets (Arxiv,\nBooks3, and CHE) demonstrates that DAPE enhances model performances in terms of\ntrained length and length generalization, where the improvements are\nstatistically significant. The model visualization suggests that our model can\nkeep both local and anti-local information. Finally, we successfully train the\nmodel on sequence length 128 and achieve better performance at evaluation\nsequence length 8192, compared with other static positional encoding methods,\nrevealing the benefit of the adaptive positional encoding method.\n","authors":["Chuanyang Zheng","Yihang Gao","Han Shi","Minbin Huang","Jingyao Li","Jing Xiong","Xiaozhe Ren","Michael Ng","Xin Jiang","Zhenguo Li","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2405.14722v6.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02887v1","updated":"2024-11-05T07:59:22Z","published":"2024-11-05T07:59:22Z","title":"The Translation of Circumlocution in Arabic Short Stories into English","summary":"  This study investigates the translation of circumlocution from Arabic to\nEnglish in a corpus of short stories by renowned Arabic authors. By analyzing\nthe source and target texts, the study aims to identify and categorize\ncircumlocution instances in Arabic and their corresponding renditions in\nEnglish. The study employs Nida's (1964) translation theory as a framework to\nassess the appropriateness of the translation strategies employed. It examines\nthe extent to which translators successfully rendered Arabic circumlocution\ninto English, identifying potential challenges and limitations in the\ntranslation process. The findings reveal significant similarities between\nArabic circumlocution categories and English metadiscourse categories,\nparticularly in terms of textual and interpersonal functions. However, the\nstudy also highlights instances where translators encountered difficulties in\naccurately conveying the nuances of circumlocution, often resorting to\nstrategies like addition, subtraction, and alteration.\n","authors":["Dalal Waadallah Shehab"],"pdf_url":"https://arxiv.org/pdf/2411.02887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02886v1","updated":"2024-11-05T07:56:24Z","published":"2024-11-05T07:56:24Z","title":"TokenSelect: Efficient Long-Context Inference and Length Extrapolation\n  for LLMs via Dynamic Token-Level KV Cache Selection","summary":"  With the development of large language models (LLMs), the ability to handle\nlonger contexts has become a key capability for Web applications such as\ncross-document understanding and LLM-powered search systems. However, this\nprogress faces two major challenges: performance degradation due to sequence\nlengths out-of-distribution, and excessively long inference times caused by the\nquadratic computational complexity of attention. These issues hinder the\napplication of LLMs in long-context scenarios. In this paper, we propose\nDynamic Token-Level KV Cache Selection (TokenSelect), a model-agnostic,\ntraining-free method for efficient and accurate long-context inference.\nTokenSelect builds upon the observation of non-contiguous attention sparsity,\nusing Query-Key dot products to measure per-head KV Cache criticality at\ntoken-level. By per-head soft voting mechanism, TokenSelect selectively\ninvolves a small number of critical KV cache tokens in the attention\ncalculation without sacrificing accuracy. To further accelerate TokenSelect, we\ndesigned the Selection Cache based on observations of consecutive Query\nsimilarity and implemented efficient dot product kernel, significantly reducing\nthe overhead of token selection. A comprehensive evaluation of TokenSelect\ndemonstrates up to 23.84x speedup in attention computation and up to 2.28x\nacceleration in end-to-end latency, while providing superior performance\ncompared to state-of-the-art long-context inference methods.\n","authors":["Wei Wu","Zhuoshi Pan","Chao Wang","Liyi Chen","Yunchu Bai","Kun Fu","Zheng Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2411.02886v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02864v1","updated":"2024-11-05T07:12:36Z","published":"2024-11-05T07:12:36Z","title":"Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document\n  Relation Extraction with Graph-of-Thoughts Reasoning","summary":"  Large language models (LLMs) pre-trained on massive corpora have demonstrated\nimpressive few-shot learning capability on many NLP tasks. Recasting an NLP\ntask into a text-to-text generation task is a common practice so that\ngenerative LLMs can be prompted to resolve it. However, performing\ndocument-level relation extraction (DocRE) tasks with generative LLM models is\nstill challenging due to the structured output format of DocRE, which\ncomplicates the conversion to plain text. Limited information available in\nfew-shot samples and prompt instructions induce further difficulties and\nchallenges in relation extraction for mentioned entities in a document. In this\npaper, we represent the structured output as a graph-style triplet rather than\nnatural language expressions and leverage generative LLMs for the DocRE task.\nOur approach, the Graph-DPEP framework is grounded in the reasoning behind\ntriplet explanation thoughts presented in natural language. In this framework,\nwe first introduce a ``decomposed-plug\" method for performing the generation\nfrom LLMs over prompts with type-space decomposition to alleviate the burden of\ndistinguishing all relation types. Second, we employ a verifier for calibrating\nthe generation and identifying overlooked query entity pairs. Third, we develop\n\"ensemble-play\", reapplying generation on the entire type list by leveraging\nthe reasoning thoughts embedded in a sub-graph associated with the missing\nquery pair to address the missingness issue. Through extensive comparisons with\nexisting prompt techniques and alternative Language Models (LLMs), our\nframework demonstrates superior performance on publicly available benchmarks in\nexperiments.\n","authors":["Tao Zhang","Ning Yan","Masood Mortazavi","Hoang H. Nguyen","Zhongfen Deng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2411.02864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02851v1","updated":"2024-11-05T06:49:14Z","published":"2024-11-05T06:49:14Z","title":"Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual\n  Visual Answer Localization","summary":"  The goal of Multilingual Visual Answer Localization (MVAL) is to locate a\nvideo segment that answers a given multilingual question. Existing methods\neither focus solely on visual modality or integrate visual and subtitle\nmodalities. However, these methods neglect the audio modality in videos,\nconsequently leading to incomplete input information and poor performance in\nthe MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span\nLocalization (AVTSL) method that incorporates audio modality to augment both\nvisual and textual representations for the MVAL task. Specifically, we\nintegrate features from three modalities and develop three predictors, each\ntailored to the unique contributions of the fused modalities: an audio-visual\npredictor, a visual predictor, and a textual predictor. Each predictor\ngenerates predictions based on its respective modality. To maintain consistency\nacross the predicted results, we introduce an Audio-Visual-Textual Consistency\nmodule. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing\neach modality's predictor to dynamically learn from the others. This\ncollaborative learning ensures that the model generates consistent and\ncomprehensive answers. Extensive experiments show that our proposed method\noutperforms several state-of-the-art (SOTA) methods, which demonstrates the\neffectiveness of the audio modality.\n","authors":["Zhibin Wen","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.02851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12629v4","updated":"2024-11-05T06:34:40Z","published":"2024-06-18T13:55:13Z","title":"SeTAR: Out-of-Distribution Detection with Selective Low-Rank\n  Approximation","summary":"  Out-of-distribution (OOD) detection is crucial for the safe deployment of\nneural networks. Existing CLIP-based approaches perform OOD detection by\ndevising novel scoring functions or sophisticated fine-tuning methods. In this\nwork, we propose SeTAR, a novel, training-free OOD detection method that\nleverages selective low-rank approximation of weight matrices in\nvision-language and vision-only models. SeTAR enhances OOD detection via\npost-hoc modification of the model's weight matrices using a simple greedy\nsearch algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning\nextension optimizing model performance for OOD detection tasks. Extensive\nevaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior\nperformance, reducing the relatively false positive rate by up to 18.95% and\n36.80% compared to zero-shot and fine-tuning baselines. Ablation studies\nfurther validate SeTAR's effectiveness, robustness, and generalizability across\ndifferent model backbones. Our work offers a scalable, efficient solution for\nOOD detection, setting a new state-of-the-art in this area.\n","authors":["Yixia Li","Boya Xiong","Guanhua Chen","Yun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.12629v4.pdf","comment":"Accepted by NeurIPS 2024. Project page is live at\n  https://SeTAR-OOD.github.io. Code are available at\n  https://github.com/X1AOX1A/SeTAR"},{"id":"http://arxiv.org/abs/2402.05785v5","updated":"2024-11-05T06:32:38Z","published":"2024-02-08T16:23:29Z","title":"Limits of Transformer Language Models on Learning to Compose Algorithms","summary":"  We analyze the capabilities of Transformer language models in learning\ncompositional discrete tasks. To this end, we evaluate training LLaMA models\nand prompting GPT-4 and Gemini on four tasks demanding to learn a composition\nof several discrete sub-tasks. In particular, we measure how well these models\ncan reuse primitives observable in the sub-tasks to learn the composition task.\nOur results indicate that compositional learning in state-of-the-art\nTransformer language models is highly sample inefficient: LLaMA requires more\ndata samples than relearning all sub-tasks from scratch to learn the\ncompositional task; in-context prompting with few samples is unreliable and\nfails at executing the sub-tasks or correcting the errors in multi-round code\ngeneration. Further, by leveraging complexity theory, we support these findings\nwith a theoretical analysis focused on the sample inefficiency of gradient\ndescent in memorizing feedforward models. We open source our code at\nhttps://github.com/IBM/limitations-lm-algorithmic-compositional-learning.\n","authors":["Jonathan Thomm","Giacomo Camposampiero","Aleksandar Terzic","Michael Hersche","Bernhard Schölkopf","Abbas Rahimi"],"pdf_url":"https://arxiv.org/pdf/2402.05785v5.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02830v1","updated":"2024-11-05T06:02:41Z","published":"2024-11-05T06:02:41Z","title":"Mixtures of In-Context Learners","summary":"  In-context learning (ICL) adapts LLMs by providing demonstrations without\nfine-tuning the model parameters; however, it does not differentiate between\ndemonstrations and quadratically increases the complexity of Transformer LLMs,\nexhausting the memory. As a solution, we propose Mixtures of In-Context\nLearners (MoICL), a novel approach to treat subsets of demonstrations as\nexperts and learn a weighting function to merge their output distributions\nbased on a training set. In our experiments, we show performance improvements\non 5 out of 7 classification datasets compared to a set of strong baselines (up\nto +13\\% compared to ICL and LENS). Moreover, we enhance the Pareto frontier of\nICL by reducing the inference time needed to achieve the same performance with\nfewer demonstrations. Finally, MoICL is more robust to out-of-domain (up to\n+11\\%), imbalanced (up to +49\\%), or noisy demonstrations (up to +38\\%) or can\nfilter these out from datasets. Overall, MoICL is a more expressive approach to\nlearning from demonstrations without exhausting the context window or memory.\n","authors":["Giwon Hong","Emile van Krieken","Edoardo Ponti","Nikolay Malkin","Pasquale Minervini"],"pdf_url":"https://arxiv.org/pdf/2411.02830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14419v2","updated":"2024-11-05T05:43:30Z","published":"2024-04-14T07:06:12Z","title":"Evaluation and Improvement of Fault Detection for Large Language Models","summary":"  Large language models (LLMs) have recently achieved significant success\nacross various application domains, garnering substantial attention from\ndifferent communities. Unfortunately, even for the best LLM, many\n\\textit{faults} still exist that LLM cannot properly predict. Such faults will\nharm the usability of LLMs in general and could introduce safety issues in\nreliability-critical systems such as autonomous driving systems. How to quickly\nreveal these faults in real-world datasets that LLM could face is important,\nbut challenging. The major reason is that the ground truth is necessary but the\ndata labeling process is heavy considering the time and human effort. To handle\nthis problem, in the conventional deep learning testing field, test selection\nmethods have been proposed for efficiently evaluating deep learning models by\nprioritizing faults. However, despite their importance, the usefulness of these\nmethods on LLMs is unclear, and lack of exploration. In this paper, we conduct\nthe first empirical study to investigate the effectiveness of existing fault\ndetection methods for LLMs. Experimental results on four different\ntasks~(including both code tasks and natural language processing tasks) and\nfour LLMs~(e.g., LLaMA3 and GPT4) demonstrated that simple methods such as\nMargin perform well on LLMs but there is still a big room for improvement.\nBased on the study, we further propose \\textbf{MuCS}, a prompt\n\\textbf{Mu}tation-based prediction \\textbf{C}onfidence \\textbf{S}moothing\nframework to boost the fault detection capability of existing methods.\nConcretely, multiple prompt mutation techniques have been proposed to help\ncollect more diverse outputs for confidence smoothing. The results show that\nour proposed framework significantly enhances existing methods with the\nimprovement of test relative coverage by up to 70.53\\%.\n","authors":["Qiang Hu","Jin Wen","Maxime Cordy","Yuheng Huang","Wei Ma","Xiaofei Xie","Lei Ma"],"pdf_url":"https://arxiv.org/pdf/2404.14419v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02820v1","updated":"2024-11-05T05:41:41Z","published":"2024-11-05T05:41:41Z","title":"DroidSpeak: Enhancing Cross-LLM Communication","summary":"  In multi-agent systems utilizing Large Language Models (LLMs), communication\nbetween agents traditionally relies on natural language. This communication\noften includes the full context of the query so far, which can introduce\nsignificant prefill-phase latency, especially with long contexts.\n  We introduce DroidSpeak, a novel framework to target this cross-LLM\ncommunication by leveraging the reuse of intermediate data, such as input\nembeddings (E-cache) and key-value caches (KV-cache). We efficiently bypass the\nneed to reprocess entire contexts for fine-tuned versions of the same\nfoundational model. This approach allows faster context integration while\nmaintaining the quality of task performance. Experimental evaluations\ndemonstrate DroidSpeak's ability to significantly accelerate inter-agent\ncommunication, achieving up to a 2.78x speedup in prefill latency with\nnegligible loss in accuracy. Our findings underscore the potential to create\nmore efficient and scalable multi-agent systems.\n","authors":["Yuhan Liu","Esha Choukse","Shan Lu","Junchen Jiang","Madan Musuvathi"],"pdf_url":"https://arxiv.org/pdf/2411.02820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10884v2","updated":"2024-11-05T05:13:13Z","published":"2024-02-16T18:42:08Z","title":"Multi-modal Preference Alignment Remedies Degradation of Visual\n  Instruction Tuning on Language Models","summary":"  Multi-modal large language models (MLLMs) are expected to support multi-turn\nqueries of interchanging image and text modalities in production. However, the\ncurrent MLLMs trained with visual-question-answering (VQA) datasets could\nsuffer from degradation, as VQA datasets lack the diversity and complexity of\nthe original text instruction datasets with which the underlying language model\nwas trained. To address this degradation, we first collect a lightweight,\n5k-sample VQA preference dataset where answers were annotated by Gemini for\nfive quality metrics in a granular fashion and investigate standard Supervised\nFine-tuning, rejection sampling, Direct Preference Optimization (DPO) and\nSteerLM algorithms. Our findings indicate that with DPO, we can surpass the\ninstruction-following capabilities of the language model, achieving a 6.73\nscore on MT-Bench, compared to Vicuna's 6.57 and LLaVA's 5.99. This enhancement\nin textual instruction-following capability correlates with boosted visual\ninstruction performance (+4.9\\% on MM-Vet, +6\\% on LLaVA-Bench), with minimal\nalignment tax on visual knowledge benchmarks compared to the previous RLHF\napproach. In conclusion, we propose a distillation-based multi-modal alignment\nmodel with fine-grained annotations on a small dataset that restores and boosts\nMLLM's language capability after visual instruction tuning.\n","authors":["Shengzhi Li","Rongyu Lin","Shichao Pei"],"pdf_url":"https://arxiv.org/pdf/2402.10884v2.pdf","comment":"Project code, model and data: https://github.com/findalexli/mllm-dpo"},{"id":"http://arxiv.org/abs/2410.11772v2","updated":"2024-11-05T05:13:00Z","published":"2024-10-15T16:53:26Z","title":"Layer-wise Importance Matters: Less Memory for Better Performance in\n  Parameter-efficient Fine-tuning of Large Language Models","summary":"  Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant\npopularity for adapting pre-trained Large Language Models (LLMs) to downstream\ntasks, primarily due to their potential to significantly reduce memory and\ncomputational overheads. However, a common limitation in most PEFT approaches\nis their application of a uniform architectural design across all layers. This\nuniformity involves identical trainable modules and ignores the varying\nimportance of each layer, leading to sub-optimal fine-tuning results. To\novercome the above limitation and obtain better performance, we develop a novel\napproach, Importance-aware Sparse Tuning (IST), to fully utilize the inherent\nsparsity and select the most important subset of full layers with effective\nlayer-wise importance scoring. The proposed IST is a versatile and\nplug-and-play technique compatible with various PEFT methods that operate on a\nper-layer basis. By leveraging the estimated importance scores, IST dynamically\nupdates these selected layers in PEFT modules, leading to reduced memory\ndemands. We further provide theoretical proof of convergence and empirical\nevidence of superior performance to demonstrate the advantages of IST over\nuniform updating strategies. Extensive experiments on a range of LLMs, PEFTs,\nand downstream tasks substantiate the effectiveness of our proposed method,\nshowcasing IST's capacity to enhance existing layer-based PEFT methods. Our\ncode is available at https://github.com/Kaiseem/IST.\n","authors":["Kai Yao","Penglei Gao","Lichun Li","Yuan Zhao","Xiaofeng Wang","Wei Wang","Jianke Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.11772v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2405.17977v2","updated":"2024-11-05T04:37:22Z","published":"2024-05-28T09:06:18Z","title":"Aligning to Thousands of Preferences via System Message Generalization","summary":"  Although humans inherently have diverse values, current large language model\n(LLM) alignment methods often assume that aligning LLMs with the general\npublic's preferences is optimal. A major challenge in adopting a more\nindividualized approach to LLM alignment is its lack of scalability, as it\ninvolves repeatedly acquiring preference data and training new reward models\nand LLMs for each individual's preferences. To address these challenges, we\npropose a new paradigm where users specify what they value most within the\nsystem message, steering the LLM's generation behavior to better align with the\nuser's intentions. However, a naive application of such an approach is\nnon-trivial since LLMs are typically trained on a uniform system message (e.g.,\n\"You are a helpful assistant\") which limits their ability to generalize to\ndiverse, unseen system messages. To improve this generalization, we create the\nMultifaceted Collection, a preference dataset with 192k combinations of values\nbeyond generic helpfulness and harmlessness, spanning 65k user instructions.\nUsing this dataset, we train a 7B LLM called Janus and test it on 921 prompts\nfrom 5 benchmarks (AlpacaEval 2.0, FLASK, Koala, MT-Bench, and Self-Instruct)\nby adding various unseen system messages that reflect user preferences. Janus\nachieves tie+win rate of 75.2%, 72.4%, and 66.4% against Mistral 7B Instruct\nv0.2, GPT-3.5 Turbo, and GPT-4, respectively. Unexpectedly, on three benchmarks\nfocused on response helpfulness (AlpacaEval 2.0, MT-Bench, Arena Hard Auto\nv0.1), Janus also outperforms LLaMA 3 8B Instruct by a +4.0%, +0.1%, +3.0%\nmargin, underscoring that training with a vast array of system messages could\nalso enhance alignment to the general public's preference as well. Our code,\ndataset, benchmark, and models are available at\nhttps://github.com/kaistAI/Janus.\n","authors":["Seongyun Lee","Sue Hyun Park","Seungone Kim","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2405.17977v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.01030v2","updated":"2024-11-05T04:35:33Z","published":"2024-11-01T21:01:13Z","title":"Birdie: Advancing State Space Models with Reward-Driven Objectives and\n  Curricula","summary":"  Efficient state space models (SSMs), such as linear recurrent neural networks\nand linear attention variants, offer computational advantages over Transformers\nbut struggle with tasks requiring long-range in-context retrieval-like text\ncopying, associative recall, and question answering over long contexts.\nPrevious efforts to address these challenges have focused on architectural\nmodifications, often reintroducing computational inefficiencies. In this paper,\nwe propose a novel training procedure, Birdie, that significantly enhances the\nin-context retrieval capabilities of SSMs without altering their architecture.\nOur approach combines bidirectional input processing with dynamic mixtures of\nspecialized pre-training objectives, optimized via reinforcement learning. We\nintroduce a new bidirectional SSM architecture that seamlessly transitions from\nbidirectional context processing to causal generation. Experimental evaluations\ndemonstrate that Birdie markedly improves performance on retrieval-intensive\ntasks such as multi-number phone book lookup, long paragraph\nquestion-answering, and infilling. This narrows the performance gap with\nTransformers, while retaining computational efficiency. Our findings highlight\nthe importance of training procedures in leveraging the fixed-state capacity of\nSSMs, offering a new direction to advance their capabilities. All code and\npre-trained models are available at https://www.github.com/samblouir/birdie,\nwith support for JAX and PyTorch.\n","authors":["Sam Blouir","Jimmy T. H. Smith","Antonios Anastasopoulos","Amarda Shehu"],"pdf_url":"https://arxiv.org/pdf/2411.01030v2.pdf","comment":"Accepted to EMNLP 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2408.15543v2","updated":"2024-11-05T04:13:55Z","published":"2024-08-28T05:36:25Z","title":"An Investigation of Warning Erroneous Chat Translations in Cross-lingual\n  Communication","summary":"  Machine translation models are still inappropriate for translating chats,\ndespite the popularity of translation software and plug-in applications. The\ncomplexity of dialogues poses significant challenges and can hinder\ncrosslingual communication. Instead of pursuing a flawless translation system,\na more practical approach would be to issue warning messages about potential\nmistranslations to reduce confusion. However, it is still unclear how\nindividuals perceive these warning messages and whether they benefit the crowd.\nThis paper tackles to investigate this question and demonstrates the warning\nmessages' contribution to making chat translation systems effective.\n","authors":["Yunmeng Li","Jun Suzuki","Makoto Morishita","Kaori Abe","Kentaro Inui"],"pdf_url":"https://arxiv.org/pdf/2408.15543v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.03561v1","updated":"2024-11-05T23:53:19Z","published":"2024-11-05T23:53:19Z","title":"Estimating Ego-Body Pose from Doubly Sparse Egocentric Video Data","summary":"  We study the problem of estimating the body movements of a camera wearer from\negocentric videos. Current methods for ego-body pose estimation rely on\ntemporally dense sensor data, such as IMU measurements from spatially sparse\nbody parts like the head and hands. However, we propose that even temporally\nsparse observations, such as hand poses captured intermittently from egocentric\nvideos during natural or periodic hand movements, can effectively constrain\noverall body motion. Naively applying diffusion models to generate full-body\npose from head pose and sparse hand pose leads to suboptimal results. To\novercome this, we develop a two-stage approach that decomposes the problem into\ntemporal completion and spatial completion. First, our method employs masked\nautoencoders to impute hand trajectories by leveraging the spatiotemporal\ncorrelations between the head pose sequence and intermittent hand poses,\nproviding uncertainty estimates. Subsequently, we employ conditional diffusion\nmodels to generate plausible full-body motions based on these temporally dense\ntrajectories of the head and hands, guided by the uncertainty estimates from\nthe imputation. The effectiveness of our method was rigorously tested and\nvalidated through comprehensive experiments conducted on various HMD setup with\nAMASS and Ego-Exo4D datasets.\n","authors":["Seunggeun Chi","Pin-Hao Huang","Enna Sachdeva","Hengbo Ma","Karthik Ramani","Kwonjoon Lee"],"pdf_url":"https://arxiv.org/pdf/2411.03561v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.07832v5","updated":"2024-11-05T23:50:14Z","published":"2024-07-31T14:49:35Z","title":"LADDER: Language Driven Slice Discovery and Error Rectification","summary":"  Error slice discovery associates structured patterns with model errors.\nExisting methods discover error slices by clustering the error-prone samples\nwith similar patterns or assigning discrete attributes to each sample for\npost-hoc analysis. While these methods aim for interpretability and easier\nmitigation through reweighting or rebalancing, they may not capture the full\ncomplexity of error patterns due to incomplete or missing attributes. Contrary\nto the existing approach, this paper utilizes the reasoning capabilities of the\nLarge Language Model (LLM) to analyze complex error patterns and generate\ntestable hypotheses. This paper proposes LADDER: Language Driven slice\nDiscovery and Error Rectification. It first projects the model's representation\ninto a language-aligned feature space (eg CLIP) to preserve semantics in the\noriginal model feature space. This ensures the accurate retrieval of sentences\nthat highlight the model's errors. Next, the LLM utilizes the sentences and\ngenerates hypotheses to discover error slices. Finally, we mitigate the error\nby fine-tuning the classification head by creating a group-balanced dataset\nusing the hypotheses. Our entire method does not require any attribute\nannotation, either explicitly or through external tagging models. We validate\nour method with \\textbf{five} image classification datasets.\n","authors":["Shantanu Ghosh","Rayan Syed","Chenyu Wang","Clare B. Poynton","Shyam Visweswaran","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2408.07832v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03555v1","updated":"2024-11-05T23:28:57Z","published":"2024-11-05T23:28:57Z","title":"Object and Contact Point Tracking in Demonstrations Using 3D Gaussian\n  Splatting","summary":"  This paper introduces a method to enhance Interactive Imitation Learning\n(IIL) by extracting touch interaction points and tracking object movement from\nvideo demonstrations. The approach extends current IIL systems by providing\nrobots with detailed knowledge of both where and how to interact with objects,\nparticularly complex articulated ones like doors and drawers. By leveraging\ncutting-edge techniques such as 3D Gaussian Splatting and FoundationPose for\ntracking, this method allows robots to better understand and manipulate objects\nin dynamic environments. The research lays the foundation for more effective\ntask learning and execution in autonomous robotic systems.\n","authors":["Michael Büttner","Jonathan Francis","Helge Rhodin","Andrew Melnik"],"pdf_url":"https://arxiv.org/pdf/2411.03555v1.pdf","comment":"CoRL 2024, Workshop on Lifelong Learning for Home Robots, Munich,\n  Germany"},{"id":"http://arxiv.org/abs/2411.03554v1","updated":"2024-11-05T23:26:10Z","published":"2024-11-05T23:26:10Z","title":"Benchmarking Vision Language Model Unlearning via Fictitious Facial\n  Identity Dataset","summary":"  Machine unlearning has emerged as an effective strategy for forgetting\nspecific information in the training data. However, with the increasing\nintegration of visual data, privacy concerns in Vision Language Models (VLMs)\nremain underexplored. To address this, we introduce Facial Identity Unlearning\nBenchmark (FIUBench), a novel VLM unlearning benchmark designed to robustly\nevaluate the effectiveness of unlearning algorithms under the Right to be\nForgotten setting. Specifically, we formulate the VLM unlearning task via\nconstructing the Fictitious Facial Identity VQA dataset and apply a two-stage\nevaluation pipeline that is designed to precisely control the sources of\ninformation and their exposure levels. In terms of evaluation, since VLM\nsupports various forms of ways to ask questions with the same semantic meaning,\nwe also provide robust evaluation metrics including membership inference\nattacks and carefully designed adversarial privacy attacks to evaluate the\nperformance of algorithms. Through the evaluation of four baseline VLM\nunlearning algorithms within FIUBench, we find that all methods remain limited\nin their unlearning performance, with significant trade-offs between model\nutility and forget quality. Furthermore, our findings also highlight the\nimportance of privacy attacks for robust evaluations. We hope FIUBench will\ndrive progress in developing more effective VLM unlearning algorithms.\n","authors":["Yingzi Ma","Jiongxiao Wang","Fei Wang","Siyuan Ma","Jiazhao Li","Xiujun Li","Furong Huang","Lichao Sun","Bo Li","Yejin Choi","Muhao Chen","Chaowei Xiao"],"pdf_url":"https://arxiv.org/pdf/2411.03554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03551v1","updated":"2024-11-05T23:11:26Z","published":"2024-11-05T23:11:26Z","title":"Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via\n  Controllable Image Generation","summary":"  Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.\n","authors":["Zhiling Yue","Yingying Fang","Liutao Yang","Nikhil Baid","Simon Walsh","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.03551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03531v1","updated":"2024-11-05T22:14:35Z","published":"2024-11-05T22:14:35Z","title":"Personalized Video Summarization by Multimodal Video Understanding","summary":"  Video summarization techniques have been proven to improve the overall user\nexperience when it comes to accessing and comprehending video content. If the\nuser's preference is known, video summarization can identify significant\ninformation or relevant content from an input video, aiding them in obtaining\nthe necessary information or determining their interest in watching the\noriginal video. Adapting video summarization to various types of video and user\npreferences requires significant training data and expensive human labeling. To\nfacilitate such research, we proposed a new benchmark for video summarization\nthat captures various user preferences. Also, we present a pipeline called\nVideo Summarization with Language (VSL) for user-preferred video summarization\nthat is based on pre-trained visual language models (VLMs) to avoid the need to\ntrain a video summarization system on a large training dataset. The pipeline\ntakes both video and closed captioning as input and performs semantic analysis\nat the scene level by converting video frames into text. Subsequently, the\nuser's genre preference was used as the basis for selecting the pertinent\ntextual scenes. The experimental results demonstrate that our proposed pipeline\noutperforms current state-of-the-art unsupervised video summarization models.\nWe show that our method is more adaptable across different datasets compared to\nsupervised query-based video summarization models. In the end, the runtime\nanalysis demonstrates that our pipeline is more suitable for practical use when\nscaling up the number of user preferences and videos.\n","authors":["Brian Chen","Xiangyuan Zhao","Yingnan Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.03531v1.pdf","comment":"In Proceedings of CIKM 2024 Applied Research Track"},{"id":"http://arxiv.org/abs/2312.05269v3","updated":"2024-11-05T22:08:14Z","published":"2023-12-07T19:19:25Z","title":"LifelongMemory: Leveraging LLMs for Answering Queries in Long-form\n  Egocentric Videos","summary":"  In this paper we introduce LifelongMemory, a new framework for accessing\nlong-form egocentric videographic memory through natural language question\nanswering and retrieval. LifelongMemory generates concise video activity\ndescriptions of the camera wearer and leverages the zero-shot capabilities of\npretrained large language models to perform reasoning over long-form video\ncontext. Furthermore, LifelongMemory uses a confidence and explanation module\nto produce confident, high-quality, and interpretable answers. Our approach\nachieves state-of-the-art performance on the EgoSchema benchmark for question\nanswering and is highly competitive on the natural language query (NLQ)\nchallenge of Ego4D. Code is available at\nhttps://github.com/agentic-learning-ai-lab/lifelong-memory.\n","authors":["Ying Wang","Yanlai Yang","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2312.05269v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.08798v2","updated":"2024-11-05T21:10:54Z","published":"2023-09-15T22:45:02Z","title":"D3: Data Diversity Design for Systematic Generalization in Visual\n  Question Answering","summary":"  Systematic generalization is a crucial aspect of intelligence, which refers\nto the ability to generalize to novel tasks by combining known subtasks and\nconcepts. One critical factor that has been shown to influence systematic\ngeneralization is the diversity of training data. However, diversity can be\ndefined in various ways, as data have many factors of variation. A more\ngranular understanding of how different aspects of data diversity affect\nsystematic generalization is lacking. We present new evidence in the problem of\nVisual Question Answering (VQA) that reveals that the diversity of simple tasks\n(i.e. tasks formed by a few subtasks and concepts) plays a key role in\nachieving systematic generalization. This implies that it may not be essential\nto gather a large and varied number of complex tasks, which could be costly to\nobtain. We demonstrate that this result is independent of the similarity\nbetween the training and testing data and applies to well-known families of\nneural network architectures for VQA (i.e. monolithic architectures and neural\nmodule networks). Additionally, we observe that neural module networks leverage\nall forms of data diversity we evaluated, while monolithic architectures\nrequire more extensive amounts of data to do so. These findings provide a first\nstep towards understanding the interactions between data diversity design,\nneural network architectures, and systematic generalization capabilities.\n","authors":["Amir Rahimi","Vanessa D'Amario","Moyuru Yamada","Kentaro Takemoto","Tomotake Sasaki","Xavier Boix"],"pdf_url":"https://arxiv.org/pdf/2309.08798v2.pdf","comment":"TMLR (https://openreview.net/forum?id=ZAin13msOp)"},{"id":"http://arxiv.org/abs/2411.03511v1","updated":"2024-11-05T21:08:19Z","published":"2024-11-05T21:08:19Z","title":"Beyond Complete Shapes: A quantitative Evaluation of 3D Shape Matching\n  Algorithms","summary":"  Finding correspondences between 3D shapes is an important and long-standing\nproblem in computer vision, graphics and beyond. While approaches based on\nmachine learning dominate modern 3D shape matching, almost all existing\n(learning-based) methods require that at least one of the involved shapes is\ncomplete. In contrast, the most challenging and arguably most practically\nrelevant setting of matching partially observed shapes, is currently\nunderexplored. One important factor is that existing datasets contain only a\nsmall number of shapes (typically below 100), which are unable to serve\ndata-hungry machine learning approaches, particularly in the unsupervised\nregime. In addition, the type of partiality present in existing datasets is\noften artificial and far from realistic. To address these limitations and to\nencourage research on these relevant settings, we provide a generic and\nflexible framework for the procedural generation of challenging partial shape\nmatching scenarios. Our framework allows for a virtually infinite generation of\npartial shape matching instances from a finite set of shapes with complete\ngeometry. Further, we manually create cross-dataset correspondences between\nseven existing (complete geometry) shape matching datasets, leading to a total\nof 2543 shapes. Based on this, we propose several challenging partial benchmark\nsettings, for which we evaluate respective state-of-the-art methods as\nbaselines.\n","authors":["Viktoria Ehm","Nafie El Amrani","Yizheng Xie","Lennart Bastian","Maolin Gao","Weikang Wang","Lu Sang","Dongliang Cao","Zorah Lähner","Daniel Cremers","Florian Bernard"],"pdf_url":"https://arxiv.org/pdf/2411.03511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04090v2","updated":"2024-11-05T20:51:06Z","published":"2024-06-06T14:01:28Z","title":"Interpretable Lightweight Transformer via Unrolling of Learned Graph\n  Smoothness Priors","summary":"  We build interpretable and lightweight transformer-like neural networks by\nunrolling iterative optimization algorithms that minimize graph smoothness\npriors -- the quadratic graph Laplacian regularizer (GLR) and the $\\ell_1$-norm\ngraph total variation (GTV) -- subject to an interpolation constraint. The\ncrucial insight is that a normalized signal-dependent graph learning module\namounts to a variant of the basic self-attention mechanism in conventional\ntransformers. Unlike \"black-box\" transformers that require learning of large\nkey, query and value matrices to compute scaled dot products as affinities and\nsubsequent output embeddings, resulting in huge parameter sets, our unrolled\nnetworks employ shallow CNNs to learn low-dimensional features per node to\nestablish pairwise Mahalanobis distances and construct sparse similarity\ngraphs. At each layer, given a learned graph, the target interpolated signal is\nsimply a low-pass filtered output derived from the minimization of an assumed\ngraph smoothness prior, leading to a dramatic reduction in parameter count.\nExperiments for two image interpolation applications verify the restoration\nperformance, parameter efficiency and robustness to covariate shift of our\ngraph-based unrolled networks compared to conventional transformers.\n","authors":["Tam Thuc Do","Parham Eftekhar","Seyed Alireza Hosseini","Gene Cheung","Philip Chou"],"pdf_url":"https://arxiv.org/pdf/2406.04090v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03505v1","updated":"2024-11-05T20:42:23Z","published":"2024-11-05T20:42:23Z","title":"SynthSet: Generative Diffusion Model for Semantic Segmentation in\n  Precision Agriculture","summary":"  This paper introduces a methodology for generating synthetic annotated data\nto address data scarcity in semantic segmentation tasks within the precision\nagriculture domain. Utilizing Denoising Diffusion Probabilistic Models (DDPMs)\nand Generative Adversarial Networks (GANs), we propose a dual diffusion model\narchitecture for synthesizing realistic annotated agricultural data, without\nany human intervention. We employ super-resolution to enhance the phenotypic\ncharacteristics of the synthesized images and their coherence with the\ncorresponding generated masks. We showcase the utility of the proposed method\nfor wheat head segmentation. The high quality of synthesized data underscores\nthe effectiveness of the proposed methodology in generating image-mask pairs.\nFurthermore, models trained on our generated data exhibit promising performance\nwhen tested on an external, diverse dataset of real wheat fields. The results\nshow the efficacy of the proposed methodology for addressing data scarcity for\nsemantic segmentation tasks. Moreover, the proposed approach can be readily\nadapted for various segmentation tasks in precision agriculture and beyond.\n","authors":["Andrew Heschl","Mauricio Murillo","Keyhan Najafian","Farhad Maleki"],"pdf_url":"https://arxiv.org/pdf/2411.03505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03491v1","updated":"2024-11-05T20:16:15Z","published":"2024-11-05T20:16:15Z","title":"An Application-Agnostic Automatic Target Recognition System Using Vision\n  Language Models","summary":"  We present a novel Automatic Target Recognition (ATR) system using\nopen-vocabulary object detection and classification models. A primary advantage\nof this approach is that target classes can be defined just before runtime by a\nnon-technical end user, using either a few natural language text descriptions\nof the target, or a few image exemplars, or both. Nuances in the desired\ntargets can be expressed in natural language, which is useful for unique\ntargets with little or no training data. We also implemented a novel\ncombination of several techniques to improve performance, such as leveraging\nthe additional information in the sequence of overlapping frames to perform\ntubelet identification (i.e., sequential bounding box matching), bounding box\nre-scoring, and tubelet linking. Additionally, we developed a technique to\nvisualize the aggregate output of many overlapping frames as a mosaic of the\narea scanned during the aerial surveillance or reconnaissance, and a kernel\ndensity estimate (or heatmap) of the detected targets. We initially applied\nthis ATR system to the use case of detecting and clearing unexploded ordinance\non airfield runways and we are currently extending our research to other\nreal-world applications.\n","authors":["Anthony Palladino","Dana Gajewski","Abigail Aronica","Patryk Deptula","Alexander Hamme","Seiyoung C. Lee","Jeff Muri","Todd Nelling","Michael A. Riley","Brian Wong","Margaret Duff"],"pdf_url":"https://arxiv.org/pdf/2411.03491v1.pdf","comment":"Accepted to the Thirty-Seventh Annual Conference on Innovative\n  Applications of Artificial Intelligence (IAAI-25)"},{"id":"http://arxiv.org/abs/2411.03480v1","updated":"2024-11-05T20:06:50Z","published":"2024-11-05T20:06:50Z","title":"Rainfall regression from C-band Synthetic Aperture Radar using\n  Multi-Task Generative Adversarial Networks","summary":"  This paper introduces a data-driven approach to estimate precipitation rates\nfrom Synthetic Aperture Radar (SAR) at a spatial resolution of 200 meters per\npixel. It addresses previous challenges related to the collocation of SAR and\nweather radar data, specifically the misalignment in collocations and the\nscarcity of rainfall examples under strong wind. To tackle these challenges,\nthe paper proposes a multi-objective formulation, introducing patch-level\ncomponents and an adversarial component. It exploits the full NEXRAD archive to\nlook for potential co-locations with Sentinel-1 data. With additional\nenhancements to the training procedure and the incorporation of additional\ninputs, the resulting model demonstrates improved accuracy in rainfall\nestimates and the ability to extend its performance to scenarios up to 15 m/s.\n","authors":["Aurélien Colin","Romain Husson"],"pdf_url":"https://arxiv.org/pdf/2411.03480v1.pdf","comment":"36 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.03475v1","updated":"2024-11-05T19:59:40Z","published":"2024-11-05T19:59:40Z","title":"Self Supervised Networks for Learning Latent Space Representations of\n  Human Body Scans and Motions","summary":"  This paper introduces self-supervised neural network models to tackle several\nfundamental problems in the field of 3D human body analysis and processing.\nFirst, we propose VariShaPE (Varifold Shape Parameter Estimator), a novel\narchitecture for the retrieval of latent space representations of body shapes\nand poses. This network offers a fast and robust method to estimate the\nembedding of arbitrary unregistered meshes into the latent space. Second, we\ncomplement the estimation of latent codes with MoGeN (Motion Geometry Network)\na framework that learns the geometry on the latent space itself. This is\nachieved by lifting the body pose parameter space into a higher dimensional\nEuclidean space in which body motion mini-sequences from a training set of 4D\ndata can be approximated by simple linear interpolation. Using the SMPL latent\nspace representation we illustrate how the combination of these network models,\nonce trained, can be used to perform a variety of tasks with very limited\ncomputational cost. This includes operations such as motion interpolation,\nextrapolation and transfer as well as random shape and pose generation.\n","authors":["Emmanuel Hartman","Nicolas Charon","Martin Bauer"],"pdf_url":"https://arxiv.org/pdf/2411.03475v1.pdf","comment":"23 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2401.08426v4","updated":"2024-11-05T19:57:19Z","published":"2024-01-16T15:11:29Z","title":"GD doesn't make the cut: Three ways that non-differentiability affects\n  neural network training","summary":"  This paper investigates the distinctions between gradient methods applied to\nnon-differentiable functions (NGDMs) and classical gradient descents (GDs)\ndesigned for differentiable functions. First, we demonstrate significant\ndifferences in the convergence properties of NGDMs compared to GDs, challenging\nthe applicability of the extensive neural network convergence literature based\non $L-smoothness$ to non-smooth neural networks. Next, we demonstrate the\nparadoxical nature of NGDM solutions for $L_{1}$-regularized problems, showing\nthat increasing the regularization penalty leads to an increase in the $L_{1}$\nnorm of optimal solutions in NGDMs. Consequently, we show that widely adopted\n$L_{1}$ penalization-based techniques for network pruning do not yield expected\nresults. Additionally, we dispel the common belief that optimization algorithms\nlike Adam and RMSProp perform similarly in non-differentiable contexts.\nFinally, we explore the Edge of Stability phenomenon, indicating its\ninapplicability even to Lipschitz continuous convex differentiable functions,\nleaving its relevance to non-convex non-differentiable neural networks\ninconclusive. Our analysis exposes misguided interpretations of NGDMs in widely\nreferenced papers and texts due to an overreliance on strong smoothness\nassumptions, emphasizing the necessity for a nuanced understanding of\nfoundational assumptions in the analysis of these systems.\n","authors":["Siddharth Krishna Kumar"],"pdf_url":"https://arxiv.org/pdf/2401.08426v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07079v2","updated":"2024-11-05T19:44:03Z","published":"2024-08-07T14:04:50Z","title":"Anatomical Foundation Models for Brain MRIs","summary":"  Deep Learning (DL) in neuroimaging has become increasingly relevant for\ndetecting neurological conditions and neurodegenerative disorders. One of the\nmost predominant biomarkers in neuroimaging is represented by brain age, which\nhas been shown to be a good indicator for different conditions, such as\nAlzheimer's Disease. Using brain age for pretraining DL models in transfer\nlearning settings has also recently shown promising results, especially when\ndealing with data scarcity of different conditions. On the other hand,\nanatomical information of brain MRIs (e.g. cortical thickness) can provide\nimportant information for learning good representations that can be transferred\nto many downstream tasks. In this work, we propose AnatCL, an anatomical\nfoundation model for brain MRIs that i.) leverages anatomical information with\na weakly contrastive learning approach and ii.) achieves state-of-the-art\nperformances in many different downstream tasks. To validate our approach we\nconsider 12 different downstream tasks for diagnosis classification, and\nprediction of 10 different clinical assessment scores. Pretrained models can be\nfound at https://github.com/EIDOSLAB/AnatCL.\n","authors":["Carlo Alberto Barbano","Matteo Brunello","Benoit Dufumier","Marco Grangetto"],"pdf_url":"https://arxiv.org/pdf/2408.07079v2.pdf","comment":"12 pages; added source url"},{"id":"http://arxiv.org/abs/2411.03464v1","updated":"2024-11-05T19:35:10Z","published":"2024-11-05T19:35:10Z","title":"TopoTxR: A topology-guided deep convolutional network for breast\n  parenchyma learning on DCE-MRIs","summary":"  Characterization of breast parenchyma in dynamic contrast-enhanced magnetic\nresonance imaging (DCE-MRI) is a challenging task owing to the complexity of\nunderlying tissue structures. Existing quantitative approaches, like radiomics\nand deep learning models, lack explicit quantification of intricate and subtle\nparenchymal structures, including fibroglandular tissue. To address this, we\npropose a novel topological approach that explicitly extracts multi-scale\ntopological structures to better approximate breast parenchymal structures, and\nthen incorporates these structures into a deep-learning-based prediction model\nvia an attention mechanism. Our topology-informed deep learning model,\n\\emph{TopoTxR}, leverages topology to provide enhanced insights into tissues\ncritical for disease pathophysiology and treatment response. We empirically\nvalidate \\emph{TopoTxR} using the VICTRE phantom breast dataset, showing that\nthe topological structures extracted by our model effectively approximate the\nbreast parenchymal structures. We further demonstrate \\emph{TopoTxR}'s efficacy\nin predicting response to neoadjuvant chemotherapy. Our qualitative and\nquantitative analyses suggest differential topological behavior of breast\ntissue in treatment-na\\\"ive imaging, in patients who respond favorably to\ntherapy as achieving pathological complete response (pCR) versus those who do\nnot. In a comparative analysis with several baselines on the publicly available\nI-SPY 1 dataset (N=161, including 47 patients with pCR and 114 without) and the\nRutgers proprietary dataset (N=120, with 69 patients achieving pCR and 51 not),\n\\emph{TopoTxR} demonstrates a notable improvement, achieving a 2.6\\% increase\nin accuracy and a 4.6\\% enhancement in AUC compared to the state-of-the-art\nmethod.\n","authors":["Fan Wang","Zhilin Zou","Nicole Sakla","Luke Partyka","Nil Rawal","Gagandeep Singh","Wei Zhao","Haibin Ling","Chuan Huang","Prateek Prasanna","Chao Chen"],"pdf_url":"https://arxiv.org/pdf/2411.03464v1.pdf","comment":"22 pages, 8 figures, 8 tables, accepted by Medical Image Analysis (\n  https://www.sciencedirect.com/science/article/abs/pii/S1361841524002986 )"},{"id":"http://arxiv.org/abs/2411.03456v1","updated":"2024-11-05T19:17:38Z","published":"2024-11-05T19:17:38Z","title":"BOston Neonatal Brain Injury Data for Hypoxic Ischemic Encephalopathy\n  (BONBID-HIE): II. 2-year Neurocognitive Outcome and NICU Outcome","summary":"  Hypoxic Ischemic Encephalopathy (HIE) affects approximately 1-5/1000 newborns\nglobally and leads to adverse neurocognitive outcomes in 30% to 50% of cases by\ntwo years of age. Despite therapeutic advances with Therapeutic Hypothermia\n(TH), prognosis remains challenging, highlighting the need for improved\nbiomarkers. This paper introduces the second release of the Boston Neonatal\nBrain Injury Dataset for Hypoxic-Ischemic Encephalopathy (BONBID-HIE), an\nopen-source, comprehensive MRI and clinical dataset featuring 237 patients,\nincluding NICU outcomes and 2-year neurocognitive outcomes from Massachusetts\nGeneral Hospital and Boston Children's Hospital.\n","authors":["Rina Bao","Yangming Ou"],"pdf_url":"https://arxiv.org/pdf/2411.03456v1.pdf","comment":"Data description for BONBID-HIE 2024 Challenge on MICCAI 2024"},{"id":"http://arxiv.org/abs/2411.02229v2","updated":"2024-11-05T19:06:16Z","published":"2024-11-04T16:21:00Z","title":"FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage\n  Training","summary":"  The field of novel view synthesis from images has seen rapid advancements\nwith the introduction of Neural Radiance Fields (NeRF) and more recently with\n3D Gaussian Splatting. Gaussian Splatting became widely adopted due to its\nefficiency and ability to render novel views accurately. While Gaussian\nSplatting performs well when a sufficient amount of training images are\navailable, its unstructured explicit representation tends to overfit in\nscenarios with sparse input images, resulting in poor rendering performance. To\naddress this, we present a 3D Gaussian-based novel view synthesis method using\nsparse input images that can accurately render the scene from the viewpoints\nnot covered by the training images. We propose a multi-stage training scheme\nwith matching-based consistency constraints imposed on the novel views without\nrelying on pre-trained depth estimation or diffusion models. This is achieved\nby using the matches of the available training images to supervise the\ngeneration of the novel views sampled between the training frames with color,\ngeometry, and semantic losses. In addition, we introduce a locality preserving\nregularization for 3D Gaussians which removes rendering artifacts by preserving\nthe local color structure of the scene. Evaluation on synthetic and real-world\ndatasets demonstrates competitive or superior performance of our method in\nfew-shot novel view synthesis compared to existing state-of-the-art methods.\n","authors":["Ruihong Yin","Vladimir Yugay","Yue Li","Sezer Karaoglu","Theo Gevers"],"pdf_url":"https://arxiv.org/pdf/2411.02229v2.pdf","comment":"Accepted by NeurIPS2024"},{"id":"http://arxiv.org/abs/2411.03445v1","updated":"2024-11-05T19:00:34Z","published":"2024-11-05T19:00:34Z","title":"Solving Trojan Detection Competitions with Linear Weight Classification","summary":"  Neural networks can conceal malicious Trojan backdoors that allow a trigger\nto covertly change the model behavior. Detecting signs of these backdoors,\nparticularly without access to any triggered data, is the subject of ongoing\nresearch and open challenges. In one common formulation of the problem, we are\ngiven a set of clean and poisoned models and need to predict whether a given\ntest model is clean or poisoned. In this paper, we introduce a detector that\nworks remarkably well across many of the existing datasets and domains. It is\nobtained by training a binary classifier on a large number of models' weights\nafter performing a few different pre-processing steps including feature\nselection and standardization, reference model weights subtraction, and model\nalignment prior to detection. We evaluate this algorithm on a diverse set of\nTrojan detection benchmarks and domains and examine the cases where the\napproach is most and least effective.\n","authors":["Todd Huster","Peter Lin","Razvan Stefanescu","Emmanuel Ekwedike","Ritu Chadha"],"pdf_url":"https://arxiv.org/pdf/2411.03445v1.pdf","comment":"9 pages, 4 Figures"},{"id":"http://arxiv.org/abs/2411.03314v1","updated":"2024-11-05T18:59:51Z","published":"2024-11-05T18:59:51Z","title":"MME-Finance: A Multimodal Finance Benchmark for Expert-level\n  Understanding and Reasoning","summary":"  In recent years, multimodal benchmarks for general domains have guided the\nrapid development of multimodal models on general tasks. However, the financial\nfield has its peculiarities. It features unique graphical images (e.g.,\ncandlestick charts, technical indicator charts) and possesses a wealth of\nspecialized financial knowledge (e.g., futures, turnover rate). Therefore,\nbenchmarks from general fields often fail to measure the performance of\nmultimodal models in the financial domain, and thus cannot effectively guide\nthe rapid development of large financial models. To promote the development of\nlarge financial multimodal models, we propose MME-Finance, an bilingual\nopen-ended and practical usage-oriented Visual Question Answering (VQA)\nbenchmark. The characteristics of our benchmark are finance and expertise,\nwhich include constructing charts that reflect the actual usage needs of users\n(e.g., computer screenshots and mobile photography), creating questions\naccording to the preferences in financial domain inquiries, and annotating\nquestions by experts with 10+ years of experience in the financial industry.\nAdditionally, we have developed a custom-designed financial evaluation system\nin which visual information is first introduced in the multi-modal evaluation\nprocess. Extensive experimental evaluations of 19 mainstream MLLMs are\nconducted to test their perception, reasoning, and cognition capabilities. The\nresults indicate that models performing well on general benchmarks cannot do\nwell on MME-Finance; for instance, the top-performing open-source and\nclosed-source models obtain 65.69 (Qwen2VL-72B) and 63.18 (GPT-4o),\nrespectively. Their performance is particularly poor in categories most\nrelevant to finance, such as candlestick charts and technical indicator charts.\nIn addition, we propose a Chinese version, which helps compare performance of\nMLLMs under a Chinese context.\n","authors":["Ziliang Gan","Yu Lu","Dong Zhang","Haohan Li","Che Liu","Jian Liu","Ji Liu","Haipang Wu","Chaoyou Fu","Zenglin Xu","Rongjunchen Zhang","Yong Dai"],"pdf_url":"https://arxiv.org/pdf/2411.03314v1.pdf","comment":"Project Page: https://hithink-research.github.io/MME-Finance/"},{"id":"http://arxiv.org/abs/2411.03312v1","updated":"2024-11-05T18:54:21Z","published":"2024-11-05T18:54:21Z","title":"Inference Optimal VLMs Need Only One Visual Token but Larger Models","summary":"  Vision Language Models (VLMs) have demonstrated strong capabilities across\nvarious visual understanding and reasoning tasks. However, their real-world\ndeployment is often constrained by high latency during inference due to\nsubstantial compute required to process the large number of input tokens\n(predominantly from the image) by the LLM. To reduce inference costs, one can\neither downsize the LLM or reduce the number of input image-tokens, the latter\nof which has been the focus of many recent works around token compression.\nHowever, it is unclear what the optimal trade-off is, as both the factors\ndirectly affect the VLM performance. We first characterize this optimal\ntrade-off between the number of visual tokens and LLM parameters by\nestablishing scaling laws that capture variations in performance with these two\nfactors. Our results reveal a surprising trend: for visual reasoning tasks, the\ninference-optimal behavior in VLMs, i.e., minimum downstream error at any given\nfixed inference compute, is achieved when using the largest LLM that fits\nwithin the inference budget while minimizing visual token count - often to a\nsingle token. While the token reduction literature has mainly focused on\nmaintaining base model performance by modestly reducing the token count (e.g.,\n$5-10\\times$), our results indicate that the compute-optimal inference regime\nrequires operating under even higher token compression ratios. Based on these\ninsights, we take some initial steps towards building approaches tailored for\nhigh token compression settings. Code is available at\nhttps://github.com/locuslab/llava-token-compression.\n","authors":["Kevin Y. Li","Sachin Goyal","Joao D. Semedo","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2411.03312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05438v2","updated":"2024-11-05T18:44:55Z","published":"2024-10-07T19:04:24Z","title":"DAAL: Density-Aware Adaptive Line Margin Loss for Multi-Modal Deep\n  Metric Learning","summary":"  Multi-modal deep metric learning is crucial for effectively capturing diverse\nrepresentations in tasks such as face verification, fine-grained object\nrecognition, and product search. Traditional approaches to metric learning,\nwhether based on distance or margin metrics, primarily emphasize class\nseparation, often overlooking the intra-class distribution essential for\nmulti-modal feature learning. In this context, we propose a novel loss function\ncalled Density-Aware Adaptive Margin Loss(DAAL), which preserves the density\ndistribution of embeddings while encouraging the formation of adaptive\nsub-clusters within each class. By employing an adaptive line strategy, DAAL\nnot only enhances intra-class variance but also ensures robust inter-class\nseparation, facilitating effective multi-modal representation. Comprehensive\nexperiments on benchmark fine-grained datasets demonstrate the superior\nperformance of DAAL, underscoring its potential in advancing retrieval\napplications and multi-modal deep metric learning.\n","authors":["Hadush Hailu Gebrerufael","Anil Kumar Tiwari","Gaurav Neupane","Goitom Ybrah Hailu"],"pdf_url":"https://arxiv.org/pdf/2410.05438v2.pdf","comment":"13 pages, 4 fugues, 2 tables"},{"id":"http://arxiv.org/abs/2411.03405v1","updated":"2024-11-05T18:39:25Z","published":"2024-11-05T18:39:25Z","title":"Fine-Grained Spatial and Verbal Losses for 3D Visual Grounding","summary":"  3D visual grounding consists of identifying the instance in a 3D scene which\nis referred by an accompanying language description. While several\narchitectures have been proposed within the commonly employed\ngrounding-by-selection framework, the utilized losses are comparatively\nunder-explored. In particular, most methods rely on a basic supervised\ncross-entropy loss on the predicted distribution over candidate instances,\nwhich fails to model both spatial relations between instances and the internal\nfine-grained word-level structure of the verbal referral. Sparse attempts to\nadditionally supervise verbal embeddings globally by learning the class of the\nreferred instance from the description or employing verbo-visual contrast to\nbetter separate instance embeddings do not fundamentally lift the\naforementioned limitations. Responding to these shortcomings, we introduce two\nnovel losses for 3D visual grounding: a visual-level offset loss on regressed\nvector offsets from each instance to the ground-truth referred instance and a\nlanguage-related span loss on predictions for the word-level span of the\nreferred instance in the description. In addition, we equip the verbo-visual\nfusion module of our new 3D visual grounding architecture AsphaltNet with a\ntop-down bidirectional attentive fusion block, which enables the supervisory\nsignals from our two losses to propagate to the respective converse branches of\nthe network and thus aid the latter to learn context-aware instance embeddings\nand grounding-aware verbal embeddings. AsphaltNet proposes novel auxiliary\nlosses to aid 3D visual grounding with competitive results compared to the\nstate-of-the-art on the ReferIt3D benchmark.\n","authors":["Sombit Dey","Ozan Unal","Christos Sakaridis","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2411.03405v1.pdf","comment":"Accepted at WACV 2025"},{"id":"http://arxiv.org/abs/2411.03403v1","updated":"2024-11-05T18:38:42Z","published":"2024-11-05T18:38:42Z","title":"Enhancing Maritime Situational Awareness through End-to-End Onboard Raw\n  Data Analysis","summary":"  Satellite-based onboard data processing is crucial for time-sensitive\napplications requiring timely and efficient rapid response. Advances in edge\nartificial intelligence are shifting computational power from ground-based\ncenters to on-orbit platforms, transforming the\n\"sensing-communication-decision-feedback\" cycle and reducing latency from\nacquisition to delivery. The current research presents a framework addressing\nthe strict bandwidth, energy, and latency constraints of small satellites,\nfocusing on maritime monitoring. The study contributes three main innovations.\nFirstly, it investigates the application of deep learning techniques for direct\nship detection and classification from raw satellite imagery. By simplifying\nthe onboard processing chain, our approach facilitates direct analyses without\nrequiring computationally intensive steps such as calibration and\northo-rectification. Secondly, to address the scarcity of raw satellite data,\nwe introduce two novel datasets, VDS2Raw and VDV2Raw, which are derived from\nraw data from Sentinel-2 and Vegetation and Environment Monitoring New Micro\nSatellite (VENuS) missions, respectively, and enriched with Automatic\nIdentification System (AIS) records. Thirdly, we characterize the tasks'\noptimal single and multiple spectral band combinations through statistical and\nfeature-based analyses validated on both datasets. In sum, we demonstrate the\nfeasibility of the proposed method through a proof-of-concept on CubeSat-like\nhardware, confirming the models' potential for operational satellite-based\nmaritime monitoring.\n","authors":["Roberto Del Prete","Manuel Salvoldi","Domenico Barretta","Nicolas Longépé","Gabriele Meoni","Arnon Karnieli","Maria Daniela Graziano","Alfredo Renga"],"pdf_url":"https://arxiv.org/pdf/2411.03403v1.pdf","comment":"38 pages"},{"id":"http://arxiv.org/abs/2407.15668v2","updated":"2024-11-05T18:38:08Z","published":"2024-07-22T14:29:36Z","title":"SLVideo: A Sign Language Video Moment Retrieval Framework","summary":"  SLVideo is a video moment retrieval system for Sign Language videos that\nincorporates facial expressions, addressing this gap in existing technology.\nThe system extracts embedding representations for the hand and face signs from\nvideo frames to capture the signs in their entirety, enabling users to search\nfor a specific sign language video segment with text queries. A collection of\neight hours of annotated Portuguese Sign Language videos is used as the\ndataset, and a CLIP model is used to generate the embeddings. The initial\nresults are promising in a zero-shot setting. In addition, SLVideo incorporates\na thesaurus that enables users to search for similar signs to those retrieved,\nusing the video segment embeddings, and also supports the edition and creation\nof video sign language annotations. Project web page:\nhttps://novasearch.github.io/SLVideo/\n","authors":["Gonçalo Vinagre Martins","João Magalhães","Afonso Quinaz","Carla Viegas","Sofia Cavaco"],"pdf_url":"https://arxiv.org/pdf/2407.15668v2.pdf","comment":"4 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2405.17705v3","updated":"2024-11-05T18:02:53Z","published":"2024-05-27T23:38:10Z","title":"DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam\n  Videos","summary":"  We present DC-Gaussian, a new method for generating novel views from\nin-vehicle dash cam videos. While neural rendering techniques have made\nsignificant strides in driving scenarios, existing methods are primarily\ndesigned for videos collected by autonomous vehicles. However, these videos are\nlimited in both quantity and diversity compared to dash cam videos, which are\nmore widely used across various types of vehicles and capture a broader range\nof scenarios. Dash cam videos often suffer from severe obstructions such as\nreflections and occlusions on the windshields, which significantly impede the\napplication of neural rendering techniques. To address this challenge, we\ndevelop DC-Gaussian based on the recent real-time neural rendering technique 3D\nGaussian Splatting (3DGS). Our approach includes an adaptive image\ndecomposition module to model reflections and occlusions in a unified manner.\nAdditionally, we introduce illumination-aware obstruction modeling to manage\nreflections and occlusions under varying lighting conditions. Lastly, we employ\na geometry-guided Gaussian enhancement strategy to improve rendering details by\nincorporating additional geometry priors. Experiments on self-captured and\npublic dash cam videos show that our method not only achieves state-of-the-art\nperformance in novel view synthesis, but also accurately reconstructing\ncaptured scenes getting rid of obstructions. See the project page for code,\ndata: https://linhanwang.github.io/dcgaussian/.\n","authors":["Linhan Wang","Kai Cheng","Shuo Lei","Shengkun Wang","Wei Yin","Chenyang Lei","Xiaoxiao Long","Chang-Tien Lu"],"pdf_url":"https://arxiv.org/pdf/2405.17705v3.pdf","comment":"10 pages,7 figures;project page:\n  https://linhanwang.github.io/dcgaussian/; Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2404.00318v2","updated":"2024-11-05T17:51:36Z","published":"2024-03-30T10:54:59Z","title":"Cognitive Planning for Object Goal Navigation using Generative AI Models","summary":"  Recent advancements in Generative AI, particularly in Large Language Models\n(LLMs) and Large Vision-Language Models (LVLMs), offer new possibilities for\nintegrating cognitive planning into robotic systems. In this work, we present a\nnovel framework for solving the object goal navigation problem that generates\nefficient exploration strategies. Our approach enables a robot to navigate\nunfamiliar environments by leveraging LLMs and LVLMs to understand the semantic\nstructure of the scene. To address the challenge of representing complex\nenvironments without overwhelming the system, we propose a 3D modular scene\nrepresentation, enriched with semantic descriptions. This representation is\ndynamically pruned using an LLM-based mechanism, which filters irrelevant\ninformation and focuses on task-specific data. By combining these elements, our\nsystem generates high-level sub-goals that guide the exploration of the robot\ntoward the target object. We validate our approach in simulated environments,\ndemonstrating its ability to enhance object search efficiency while maintaining\nscalability in complex settings.\n","authors":["Arjun P S","Andrew Melnik","Gora Chand Nandi"],"pdf_url":"https://arxiv.org/pdf/2404.00318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03286v1","updated":"2024-11-05T17:35:41Z","published":"2024-11-05T17:35:41Z","title":"DiT4Edit: Diffusion Transformer for Image Editing","summary":"  Despite recent advances in UNet-based image editing, methods for shape-aware\nobject editing in high-resolution images are still lacking. Compared to UNet,\nDiffusion Transformers (DiT) demonstrate superior capabilities to effectively\ncapture the long-range dependencies among patches, leading to higher-quality\nimage generation. In this paper, we propose DiT4Edit, the first Diffusion\nTransformer-based image editing framework. Specifically, DiT4Edit uses the\nDPM-Solver inversion algorithm to obtain the inverted latents, reducing the\nnumber of steps compared to the DDIM inversion algorithm commonly used in\nUNet-based frameworks. Additionally, we design unified attention control and\npatches merging, tailored for transformer computation streams. This integration\nallows our framework to generate higher-quality edited images faster. Our\ndesign leverages the advantages of DiT, enabling it to surpass UNet structures\nin image editing, especially in high-resolution and arbitrary-size images.\nExtensive experiments demonstrate the strong performance of DiT4Edit across\nvarious editing scenarios, highlighting the potential of Diffusion Transformers\nin supporting image editing.\n","authors":["Kunyu Feng","Yue Ma","Bingyuan Wang","Chenyang Qi","Haozhe Chen","Qifeng Chen","Zeyu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03260v1","updated":"2024-11-05T16:59:06Z","published":"2024-11-05T16:59:06Z","title":"ShadowMamba: State-Space Model with Boundary-Region Selective Scan for\n  Shadow Removal","summary":"  Image shadow removal is a typical low-level vision problem, where the\npresence of shadows leads to abrupt changes in brightness in certain regions,\naffecting the accuracy of upstream tasks. Current shadow removal methods still\nface challenges such as residual boundary artifacts, and capturing feature\ninformation at shadow boundaries is crucial for removing shadows and\neliminating residual boundary artifacts. Recently, Mamba has achieved\nremarkable success in computer vision by globally modeling long-sequence\ninformation with linear complexity. However, when applied to image shadow\nremoval, the original Mamba scanning method overlooks the semantic continuity\nof shadow boundaries as well as the continuity of semantics within the same\nregion. Based on the unique characteristics of shadow images, this paper\nproposes a novel selective scanning method called boundary-region selective\nscanning. This method scans boundary regions, shadow regions, and non-shadow\nregions independently, bringing pixels of the same region type closer together\nin the long sequence, especially focusing on the local information at the\nboundaries, which is crucial for shadow removal. This method combines with\nglobal scanning and channel scanning to jointly accomplish the shadow removal.\nWe name our model ShadowMamba, the first Mamba-based model for shadow removal.\nExtensive experimental results show that our method outperforms current\nstate-of-the-art models across most metrics on multiple datasets. The code for\nShadowMamba is available at (Code will be released upon acceptance).\n","authors":["Xiujin Zhu","Chee-Onn Chow","Joon Huang Chuah"],"pdf_url":"https://arxiv.org/pdf/2411.03260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17387v3","updated":"2024-11-05T16:52:39Z","published":"2024-03-26T05:12:18Z","title":"Decoupled Pseudo-labeling for Semi-Supervised Monocular 3D Object\n  Detection","summary":"  We delve into pseudo-labeling for semi-supervised monocular 3D object\ndetection (SSM3OD) and discover two primary issues: a misalignment between the\nprediction quality of 3D and 2D attributes and the tendency of depth\nsupervision derived from pseudo-labels to be noisy, leading to significant\noptimization conflicts with other reliable forms of supervision. We introduce a\nnovel decoupled pseudo-labeling (DPL) approach for SSM3OD. Our approach\nfeatures a Decoupled Pseudo-label Generation (DPG) module, designed to\nefficiently generate pseudo-labels by separately processing 2D and 3D\nattributes. This module incorporates a unique homography-based method for\nidentifying dependable pseudo-labels in BEV space, specifically for 3D\nattributes. Additionally, we present a DepthGradient Projection (DGP) module to\nmitigate optimization conflicts caused by noisy depth supervision of\npseudo-labels, effectively decoupling the depth gradient and removing\nconflicting gradients. This dual decoupling strategy-at both the pseudo-label\ngeneration and gradient levels-significantly improves the utilization of\npseudo-labels in SSM3OD. Our comprehensive experiments on the KITTI benchmark\ndemonstrate the superiority of our method over existing approaches.\n","authors":["Jiacheng Zhang","Jiaming Li","Xiangru Lin","Wei Zhang","Xiao Tan","Junyu Han","Errui Ding","Jingdong Wang","Guanbin Li"],"pdf_url":"https://arxiv.org/pdf/2403.17387v3.pdf","comment":"accepted to CVPR2024"},{"id":"http://arxiv.org/abs/2405.15199v2","updated":"2024-11-05T16:40:01Z","published":"2024-05-24T04:10:34Z","title":"ODGEN: Domain-specific Object Detection Data Generation with Diffusion\n  Models","summary":"  Modern diffusion-based image generative models have made significant progress\nand become promising to enrich training data for the object detection task.\nHowever, the generation quality and the controllability for complex scenes\ncontaining multi-class objects and dense objects with occlusions remain\nlimited. This paper presents ODGEN, a novel method to generate high-quality\nimages conditioned on bounding boxes, thereby facilitating data synthesis for\nobject detection. Given a domain-specific object detection dataset, we first\nfine-tune a pre-trained diffusion model on both cropped foreground objects and\nentire images to fit target distributions. Then we propose to control the\ndiffusion model using synthesized visual prompts with spatial constraints and\nobject-wise textual descriptions. ODGEN exhibits robustness in handling complex\nscenes and specific domains. Further, we design a dataset synthesis pipeline to\nevaluate ODGEN on 7 domain-specific benchmarks to demonstrate its\neffectiveness. Adding training data generated by ODGEN improves up to 25.3%\nmAP@.50:.95 with object detectors like YOLOv5 and YOLOv7, outperforming prior\ncontrollable generative methods. In addition, we design an evaluation protocol\nbased on COCO-2014 to validate ODGEN in general domains and observe an\nadvantage up to 5.6% in mAP@.50:.95 against existing methods.\n","authors":["Jingyuan Zhu","Shiyu Li","Yuxuan Liu","Ping Huang","Jiulong Shan","Huimin Ma","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2405.15199v2.pdf","comment":"Accepted by NeurIPS2024"},{"id":"http://arxiv.org/abs/2411.03239v1","updated":"2024-11-05T16:37:30Z","published":"2024-11-05T16:37:30Z","title":"Decoupling Fine Detail and Global Geometry for Compressed Depth Map\n  Super-Resolution","summary":"  Recovering high-quality depth maps from compressed sources has gained\nsignificant attention due to the limitations of consumer-grade depth cameras\nand the bandwidth restrictions during data transmission. However, current\nmethods still suffer from two challenges. First, bit-depth compression produces\na uniform depth representation in regions with subtle variations, hindering the\nrecovery of detailed information. Second, densely distributed random noise\nreduces the accuracy of estimating the global geometric structure of the scene.\nTo address these challenges, we propose a novel framework, termed\ngeometry-decoupled network (GDNet), for compressed depth map super-resolution\nthat decouples the high-quality depth map reconstruction process by handling\nglobal and detailed geometric features separately. To be specific, we propose\nthe fine geometry detail encoder (FGDE), which is designed to aggregate fine\ngeometry details in high-resolution low-level image features while\nsimultaneously enriching them with complementary information from\nlow-resolution context-level image features. In addition, we develop the global\ngeometry encoder (GGE) that aims at suppressing noise and extracting global\ngeometric information effectively via constructing compact feature\nrepresentation in a low-rank space. We conduct experiments on multiple\nbenchmark datasets, demonstrating that our GDNet significantly outperforms\ncurrent methods in terms of geometric consistency and detail recovery. In the\nECCV 2024 AIM Compressed Depth Upsampling Challenge, our solution won the 1st\nplace award. Our codes will be available.\n","authors":["Huan Zheng","Wencheng Han","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2411.03239v1.pdf","comment":"The 1st solution for the ECCV 2024 AIM Compressed Depth Upsampling\n  Challenge"},{"id":"http://arxiv.org/abs/2311.17898v3","updated":"2024-11-05T16:31:24Z","published":"2023-11-29T18:51:46Z","title":"Contextual Knowledge Pursuit for Faithful Visual Synthesis","summary":"  Modern text-to-vision generative models often hallucinate when the prompt\ndescribing the scene to be generated is underspecified. In large language\nmodels (LLMs), a prevalent strategy to reduce hallucinations is to retrieve\nfactual knowledge from an external database. While such retrieval augmentation\nstrategies have great potential to enhance text-to-vision generators, existing\nstatic top-K retrieval methods explore the knowledge pool once, missing the\nbroader context necessary for high-quality generation. Furthermore, LLMs\ninternally possess rich world knowledge learned during large-scale training\n(parametric knowledge) that could mitigate the need for external data\nretrieval. This paper proposes Contextual Knowledge Pursuit (CKPT), a framework\nthat leverages the complementary strengths of external and parametric knowledge\nto help generators produce reliable visual content. Instead of the one-time\nretrieval of facts from an external database to improve a given prompt, CKPT\nuses (1) an LLM to decide whether to seek external knowledge or to self-elicit\ndescriptions from LLM parametric knowledge, (2) a knowledge pursuit process to\ncontextually seek and sequentially gather most relevant facts, (3) a knowledge\naggregator for prompt enhancement with the gathered fact context, and (4) a\nfiltered fine-tuning objective to improve visual synthesis with richer prompts.\nWe evaluate CKPT across multiple text-driven generative tasks (image, 3D\nrendering, and video) on datasets of rare objects and daily scenarios. Our\nresults show that CKPT is capable of generating faithful and semantically rich\ncontent across diverse visual domains, offering a promising data source for\nzero-shot synthesis and filtered fine-tuning of text-to-vision generative\nmodels.\n","authors":["Jinqi Luo","Kwan Ho Ryan Chan","Dimitris Dimos","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2311.17898v3.pdf","comment":"Accepted in ECCV 2024 SDCV Workshop. GitHub repository at\n  https://github.com/peterljq/Contextual-Knowledge-Pursuit"},{"id":"http://arxiv.org/abs/2409.18336v2","updated":"2024-11-05T16:30:30Z","published":"2024-09-26T23:18:25Z","title":"DeBaRA: Denoising-Based 3D Room Arrangement Generation","summary":"  Generating realistic and diverse layouts of furnished indoor 3D scenes\nunlocks multiple interactive applications impacting a wide range of industries.\nThe inherent complexity of object interactions, the limited amount of available\ndata and the requirement to fulfill spatial constraints all make generative\nmodeling for 3D scene synthesis and arrangement challenging. Current methods\naddress these challenges autoregressively or by using off-the-shelf diffusion\nobjectives by simultaneously predicting all attributes without 3D reasoning\nconsiderations. In this paper, we introduce DeBaRA, a score-based model\nspecifically tailored for precise, controllable and flexible arrangement\ngeneration in a bounded environment. We argue that the most critical component\nof a scene synthesis system is to accurately establish the size and position of\nvarious objects within a restricted area. Based on this insight, we propose a\nlightweight conditional score-based model designed with 3D spatial awareness at\nits core. We demonstrate that by focusing on spatial attributes of objects, a\nsingle trained DeBaRA model can be leveraged at test time to perform several\ndownstream applications such as scene synthesis, completion and re-arrangement.\nFurther, we introduce a novel Self Score Evaluation procedure so it can be\noptimally employed alongside external LLM models. We evaluate our approach\nthrough extensive experiments and demonstrate significant improvement upon\nstate-of-the-art approaches in a range of scenarios.\n","authors":["Léopold Maillard","Nicolas Sereyjol-Garros","Tom Durand","Maks Ovsjanikov"],"pdf_url":"https://arxiv.org/pdf/2409.18336v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2311.16484v2","updated":"2024-11-05T16:25:05Z","published":"2023-11-26T05:14:06Z","title":"Seeing Eye to AI: Comparing Human Gaze and Model Attention in Video\n  Memorability","summary":"  Understanding what makes a video memorable has important applications in\nadvertising or education technology. Towards this goal, we investigate\nspatio-temporal attention mechanisms underlying video memorability. Different\nfrom previous works that fuse multiple features, we adopt a simple\nCNN+Transformer architecture that enables analysis of spatio-temporal attention\nwhile matching state-of-the-art (SoTA) performance on video memorability\nprediction. We compare model attention against human gaze fixations collected\nthrough a small-scale eye-tracking study where humans perform the video memory\ntask. We uncover the following insights: (i) Quantitative saliency metrics show\nthat our model, trained only to predict a memorability score, exhibits similar\nspatial attention patterns to human gaze, especially for more memorable videos.\n(ii) The model assigns greater importance to initial frames in a video,\nmimicking human attention patterns. (iii) Panoptic segmentation reveals that\nboth (model and humans) assign a greater share of attention to things and less\nattention to stuff as compared to their occurrence probability.\n","authors":["Prajneya Kumar","Eshika Khandelwal","Makarand Tapaswi","Vishnu Sreekumar"],"pdf_url":"https://arxiv.org/pdf/2311.16484v2.pdf","comment":"Accepted to WACV 2025"},{"id":"http://arxiv.org/abs/2411.03228v1","updated":"2024-11-05T16:20:14Z","published":"2024-11-05T16:20:14Z","title":"Topograph: An efficient Graph-Based Framework for Strictly Topology\n  Preserving Image Segmentation","summary":"  Topological correctness plays a critical role in many image segmentation\ntasks, yet most networks are trained using pixel-wise loss functions, such as\nDice, neglecting topological accuracy. Existing topology-aware methods often\nlack robust topological guarantees, are limited to specific use cases, or\nimpose high computational costs. In this work, we propose a novel, graph-based\nframework for topologically accurate image segmentation that is both\ncomputationally efficient and generally applicable. Our method constructs a\ncomponent graph that fully encodes the topological information of both the\nprediction and ground truth, allowing us to efficiently identify topologically\ncritical regions and aggregate a loss based on local neighborhood information.\nFurthermore, we introduce a strict topological metric capturing the homotopy\nequivalence between the union and intersection of prediction-label pairs. We\nformally prove the topological guarantees of our approach and empirically\nvalidate its effectiveness on binary and multi-class datasets. Our loss\ndemonstrates state-of-the-art performance with up to fivefold faster loss\ncomputation compared to persistent homology methods.\n","authors":["Laurin Lux","Alexander H. Berger","Alexander Weers","Nico Stucki","Daniel Rueckert","Ulrich Bauer","Johannes C. Paetzold"],"pdf_url":"https://arxiv.org/pdf/2411.03228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03226v1","updated":"2024-11-05T16:18:57Z","published":"2024-11-05T16:18:57Z","title":"Kernel Orthogonality does not necessarily imply a Decrease in Feature\n  Map Redundancy in CNNs: Convolutional Similarity Minimization","summary":"  Convolutional Neural Networks (CNNs) have been heavily used in Deep Learning\ndue to their success in various tasks. Nonetheless, it has been observed that\nCNNs suffer from redundancy in feature maps, leading to inefficient capacity\nutilization. Efforts to mitigate and solve this problem led to the emergence of\nmultiple methods, amongst which is kernel orthogonality through variant means.\nIn this work, we challenge the common belief that kernel orthogonality leads to\na decrease in feature map redundancy, which is, supposedly, the ultimate\nobjective behind kernel orthogonality. We prove, theoretically and empirically,\nthat kernel orthogonality has an unpredictable effect on feature map similarity\nand does not necessarily decrease it. Based on our theoretical result, we\npropose an effective method to reduce feature map similarity independently of\nthe input of the CNN. This is done by minimizing a novel loss function we call\nConvolutional Similarity. Empirical results show that minimizing the\nConvolutional Similarity increases the performance of classification models and\ncan accelerate their convergence. Furthermore, using our proposed method pushes\ntowards a more efficient use of the capacity of models, allowing the use of\nsignificantly smaller models to achieve the same levels of performance.\n","authors":["Zakariae Belmekki","Jun Li","Patrick Reuter","David Antonio Gómez Jáuregui","Karl Jenkins"],"pdf_url":"https://arxiv.org/pdf/2411.03226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24010v2","updated":"2024-11-05T16:16:29Z","published":"2024-10-31T15:10:38Z","title":"Re-assembling the past: The RePAIR dataset and benchmark for real world\n  2D and 3D puzzle solving","summary":"  This paper proposes the RePAIR dataset that represents a challenging\nbenchmark to test modern computational and data driven methods for\npuzzle-solving and reassembly tasks. Our dataset has unique properties that are\nuncommon to current benchmarks for 2D and 3D puzzle solving. The fragments and\nfractures are realistic, caused by a collapse of a fresco during a World War II\nbombing at the Pompeii archaeological park. The fragments are also eroded and\nhave missing pieces with irregular shapes and different dimensions, challenging\nfurther the reassembly algorithms. The dataset is multi-modal providing high\nresolution images with characteristic pictorial elements, detailed 3D scans of\nthe fragments and meta-data annotated by the archaeologists. Ground truth has\nbeen generated through several years of unceasing fieldwork, including the\nexcavation and cleaning of each fragment, followed by manual puzzle solving by\narchaeologists of a subset of approx. 1000 pieces among the 16000 available.\nAfter digitizing all the fragments in 3D, a benchmark was prepared to challenge\ncurrent reassembly and puzzle-solving methods that often solve more simplistic\nsynthetic scenarios. The tested baselines show that there clearly exists a gap\nto fill in solving this computationally complex problem.\n","authors":["Theodore Tsesmelis","Luca Palmieri","Marina Khoroshiltseva","Adeela Islam","Gur Elkin","Ofir Itzhak Shahar","Gianluca Scarpellini","Stefano Fiorini","Yaniv Ohayon","Nadav Alali","Sinem Aslan","Pietro Morerio","Sebastiano Vascon","Elena Gravina","Maria Cristina Napolitano","Giuseppe Scarpati","Gabriel Zuchtriegel","Alexandra Spühler","Michel E. Fuchs","Stuart James","Ohad Ben-Shahar","Marcello Pelillo","Alessio Del Bue"],"pdf_url":"https://arxiv.org/pdf/2410.24010v2.pdf","comment":"NeurIPS 2024, Track Datasets and Benchmarks, 10 pages"},{"id":"http://arxiv.org/abs/2411.03225v1","updated":"2024-11-05T16:15:33Z","published":"2024-11-05T16:15:33Z","title":"Knowledge Graphs of Driving Scenes to Empower the Emerging Capabilities\n  of Neurosymbolic AI","summary":"  In the era of Generative AI, Neurosymbolic AI is emerging as a powerful\napproach for tasks spanning from perception to cognition. The use of\nNeurosymbolic AI has been shown to achieve enhanced capabilities, including\nimproved grounding, alignment, explainability, and reliability. However, due to\nits nascent stage, there is a lack of widely available real-world benchmark\ndatasets tailored to Neurosymbolic AI tasks. To address this gap and support\nthe evaluation of current and future methods, we introduce DSceneKG -- a suite\nof knowledge graphs of driving scenes built from real-world, high-quality\nscenes from multiple open autonomous driving datasets. In this article, we\ndetail the construction process of DSceneKG and highlight its application in\nseven different tasks. DSceneKG is publicly accessible at:\nhttps://github.com/ruwantw/DSceneKG\n","authors":["Ruwan Wickramarachchi","Cory Henson","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2411.03225v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.09918v4","updated":"2024-11-05T15:37:00Z","published":"2024-03-14T23:31:41Z","title":"Attention-based Class-Conditioned Alignment for Multi-Source Domain\n  Adaptation of Object Detectors","summary":"  Domain adaptation methods for object detection (OD) strive to mitigate the\nimpact of distribution shifts by promoting feature alignment across source and\ntarget domains. Multi-source domain adaptation (MSDA) allows leveraging\nmultiple annotated source datasets and unlabeled target data to improve the\naccuracy and robustness of the detection model. Most state-of-the-art MSDA\nmethods for OD perform feature alignment in a class-agnostic manner. This is\nchallenging since the objects have unique modal information due to variations\nin object appearance across domains. A recent prototype-based approach proposed\na class-wise alignment, yet it suffers from error accumulation due to noisy\npseudo-labels that can negatively affect adaptation with imbalanced data. To\novercome these limitations, we propose an attention-based class-conditioned\nalignment method for MSDA that aligns instances of each object category across\ndomains. In particular, an attention module coupled with an adversarial domain\nclassifier allows learning domain-invariant and class-specific instance\nrepresentations. Experimental results on multiple benchmarking MSDA datasets\nindicate that our method outperforms the state-of-the-art methods and is robust\nto class imbalance using a conceptually simple class-conditioning method. Our\ncode is available at https://github.com/imatif17/ACIA.\n","authors":["Atif Belal","Akhil Meethal","Francisco Perdigon Romero","Marco Pedersoli","Eric Granger"],"pdf_url":"https://arxiv.org/pdf/2403.09918v4.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2309.14950"},{"id":"http://arxiv.org/abs/2411.03177v1","updated":"2024-11-05T15:22:26Z","published":"2024-11-05T15:22:26Z","title":"On Improved Conditioning Mechanisms and Pre-training Strategies for\n  Diffusion Models","summary":"  Large-scale training of latent diffusion models (LDMs) has enabled\nunprecedented quality in image generation. However, the key components of the\nbest performing LDM training recipes are oftentimes not available to the\nresearch community, preventing apple-to-apple comparisons and hindering the\nvalidation of progress in the field. In this work, we perform an in-depth study\nof LDM training recipes focusing on the performance of models and their\ntraining efficiency. To ensure apple-to-apple comparisons, we re-implement five\npreviously published models with their corresponding recipes. Through our\nstudy, we explore the effects of (i)~the mechanisms used to condition the\ngenerative model on semantic information (e.g., text prompt) and control\nmetadata (e.g., crop size, random flip flag, etc.) on the model performance,\nand (ii)~the transfer of the representations learned on smaller and\nlower-resolution datasets to larger ones on the training efficiency and model\nperformance. We then propose a novel conditioning mechanism that disentangles\nsemantic and control metadata conditionings and sets a new state-of-the-art in\nclass-conditional generation on the ImageNet-1k dataset -- with FID\nimprovements of 7% on 256 and 8% on 512 resolutions -- as well as text-to-image\ngeneration on the CC12M dataset -- with FID improvements of 8% on 256 and 23%\non 512 resolution.\n","authors":["Tariq Berrada Ifriqi","Pietro Astolfi","Melissa Hall","Reyhane Askari-Hemmat","Yohann Benchetrit","Marton Havasi","Matthew Muckley","Karteek Alahari","Adriana Romero-Soriano","Jakob Verbeek","Michal Drozdzal"],"pdf_url":"https://arxiv.org/pdf/2411.03177v1.pdf","comment":"Accepted as a conference paper (poster) for NeurIPS 2024"},{"id":"http://arxiv.org/abs/2309.05756v3","updated":"2024-11-05T15:18:15Z","published":"2023-09-11T18:35:14Z","title":"GlobalDoc: A Cross-Modal Vision-Language Framework for Real-World\n  Document Image Retrieval and Classification","summary":"  Visual document understanding (VDU) has rapidly advanced with the development\nof powerful multi-modal language models. However, these models typically\nrequire extensive document pre-training data to learn intermediate\nrepresentations and often suffer a significant performance drop in real-world\nonline industrial settings. A primary issue is their heavy reliance on OCR\nengines to extract local positional information within document pages, which\nlimits the models' ability to capture global information and hinders their\ngeneralizability, flexibility, and robustness. In this paper, we introduce\nGlobalDoc, a cross-modal transformer-based architecture pre-trained in a\nself-supervised manner using three novel pretext objective tasks. GlobalDoc\nimproves the learning of richer semantic concepts by unifying language and\nvisual representations, resulting in more transferable models. For proper\nevaluation, we also propose two novel document-level downstream VDU tasks,\nFew-Shot Document Image Classification (DIC) and Content-based Document Image\nRetrieval (DIR), designed to simulate industrial scenarios more closely.\nExtensive experimentation has been conducted to demonstrate GlobalDoc's\neffectiveness in practical settings.\n","authors":["Souhail Bakkali","Sanket Biswas","Zuheng Ming","Mickaël Coustaty","Marçal Rusiñol","Oriol Ramos Terrades","Josep Lladós"],"pdf_url":"https://arxiv.org/pdf/2309.05756v3.pdf","comment":"Accepted at WACV 2025"},{"id":"http://arxiv.org/abs/2411.03169v1","updated":"2024-11-05T15:18:02Z","published":"2024-11-05T15:18:02Z","title":"Pre-trained Visual Dynamics Representations for Efficient Policy\n  Learning","summary":"  Pre-training for Reinforcement Learning (RL) with purely video data is a\nvaluable yet challenging problem. Although in-the-wild videos are readily\navailable and inhere a vast amount of prior world knowledge, the absence of\naction annotations and the common domain gap with downstream tasks hinder\nutilizing videos for RL pre-training. To address the challenge of pre-training\nwith videos, we propose Pre-trained Visual Dynamics Representations (PVDR) to\nbridge the domain gap between videos and downstream tasks for efficient policy\nlearning. By adopting video prediction as a pre-training task, we use a\nTransformer-based Conditional Variational Autoencoder (CVAE) to learn visual\ndynamics representations. The pre-trained visual dynamics representations\ncapture the visual dynamics prior knowledge in the videos. This abstract prior\nknowledge can be readily adapted to downstream tasks and aligned with\nexecutable actions through online adaptation. We conduct experiments on a\nseries of robotics visual control tasks and verify that PVDR is an effective\nform for pre-training with videos to promote policy learning.\n","authors":["Hao Luo","Bohan Zhou","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2411.03169v1.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2410.02401v5","updated":"2024-11-05T14:38:30Z","published":"2024-10-03T11:29:09Z","title":"SynCo: Synthetic Hard Negatives in Contrastive Learning for Better\n  Unsupervised Visual Representations","summary":"  Contrastive learning has become a dominant approach in self-supervised visual\nrepresentation learning. Hard negatives - samples closely resembling the anchor\n- are key to enhancing learned representations' discriminative power. However,\nefficiently leveraging hard negatives remains challenging. We introduce SynCo\n(Synthetic Negatives in Contrastive learning), a novel approach that improves\nmodel performance by generating synthetic hard negatives on the representation\nspace. Building on the MoCo framework, SynCo introduces six strategies for\ncreating diverse synthetic hard negatives on-the-fly with minimal computational\noverhead. SynCo achieves faster training and better representation learning,\nreaching 67.9% top-1 accuracy on ImageNet ILSVRC-2012 linear evaluation after\n200 pretraining epochs, surpassing MoCo's 67.5% using the same ResNet-50\nencoder. It also transfers more effectively to detection tasks: on PASCAL VOC,\nit outperforms both the supervised baseline and MoCo with 82.5% AP; on COCO, it\nsets new benchmarks with 40.9% AP for bounding box detection and 35.5% AP for\ninstance segmentation. Our synthetic hard negative generation approach\nsignificantly enhances visual representations learned through self-supervised\ncontrastive learning. Code is available at\nhttps://github.com/giakoumoglou/synco.\n","authors":["Nikolaos Giakoumoglou","Tania Stathaki"],"pdf_url":"https://arxiv.org/pdf/2410.02401v5.pdf","comment":"10 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2411.02293v2","updated":"2024-11-05T14:33:41Z","published":"2024-11-04T17:21:42Z","title":"Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and\n  Image-to-3D Generation","summary":"  While 3D generative models have greatly improved artists' workflows, the\nexisting diffusion models for 3D generation suffer from slow generation and\npoor generalization. To address this issue, we propose a two-stage approach\nnamed Hunyuan3D-1.0 including a lite version and a standard version, that both\nsupport text- and image-conditioned generation. In the first stage, we employ a\nmulti-view diffusion model that efficiently generates multi-view RGB in\napproximately 4 seconds. These multi-view images capture rich details of the 3D\nasset from different viewpoints, relaxing the tasks from single-view to\nmulti-view reconstruction. In the second stage, we introduce a feed-forward\nreconstruction model that rapidly and faithfully reconstructs the 3D asset\ngiven the generated multi-view images in approximately 7 seconds. The\nreconstruction network learns to handle noises and in-consistency introduced by\nthe multi-view diffusion and leverages the available information from the\ncondition image to efficiently recover the 3D structure. Our framework involves\nthe text-to-image model, i.e., Hunyuan-DiT, making it a unified framework to\nsupport both text- and image-conditioned 3D generation. Our standard version\nhas 3x more parameters than our lite and other existing model. Our\nHunyuan3D-1.0 achieves an impressive balance between speed and quality,\nsignificantly reducing generation time while maintaining the quality and\ndiversity of the produced assets.\n","authors":["Xianghui Yang","Huiwen Shi","Bowen Zhang","Fan Yang","Jiacheng Wang","Hongxu Zhao","Xinhai Liu","Xinzhou Wang","Qingxiang Lin","Jiaao Yu","Lifu Wang","Zhuo Chen","Sicong Liu","Yuhong Liu","Yong Yang","Di Wang","Jie Jiang","Chunchao Guo"],"pdf_url":"https://arxiv.org/pdf/2411.02293v2.pdf","comment":"Technical Report; 3D Generation"},{"id":"http://arxiv.org/abs/2411.03129v1","updated":"2024-11-05T14:21:01Z","published":"2024-11-05T14:21:01Z","title":"MA^2: A Self-Supervised and Motion Augmenting Autoencoder for Gait-Based\n  Automatic Disease Detection","summary":"  Ground reaction force (GRF) is the force exerted by the ground on a body in\ncontact with it. GRF-based automatic disease detection (ADD) has become an\nemerging medical diagnosis method, which aims to learn and identify disease\npatterns corresponding to different gait pressures based on deep learning\nmethods. Although existing ADD methods can save doctors time in making\ndiagnoses, training deep models still struggles with the cost caused by the\nlabeling engineering for a large number of gait diagnostic data for subjects.\nOn the other hand, the accuracy of the deep model under the unified benchmark\nGRF dataset and the generalization ability on scalable gait datasets need to be\nfurther improved. To address these issues, we propose MA2, a GRF-based\nself-supervised and motion augmenting auto-encoder, which models the ADD task\nas an encoder-decoder paradigm. In the encoder, we introduce an embedding block\nincluding the 3-layer 1D convolution for extracting the token and a mask\ngenerator to randomly mask out the sequence of tokens to maximize the model's\npotential to capture high-level, discriminative, intrinsic representations.\nwhereafter, the decoder utilizes this information to reconstruct the pixel\nsequence of the origin input and calculate the reconstruction loss to optimize\nthe network. Moreover, the backbone of an auto-encoder is multi-head\nself-attention that can consider the global information of the token from the\ninput, not just the local neighborhood. This allows the model to capture\ngeneralized contextual information. Extensive experiments demonstrate MA2 has\nSOTA performance of 90.91% accuracy on 1% limited pathological GRF samples with\nlabels, and good generalization ability of 78.57% accuracy on scalable\nParkinson disease dataset.\n","authors":["Yiqun Liu","Ke Zhang","Yin Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.03129v1.pdf","comment":"8 pages, 11 figures, article"},{"id":"http://arxiv.org/abs/2410.20595v3","updated":"2024-11-05T14:13:56Z","published":"2024-10-27T21:02:37Z","title":"A Framework for Real-Time Volcano-Seismic Event Recognition Based on\n  Multi-Station Seismograms and Semantic Segmentation Models","summary":"  In volcano monitoring, effective recognition of seismic events is essential\nfor understanding volcanic activity and raising timely warning alerts.\nTraditional methods rely on manual analysis, which can be subjective and\nlabor-intensive. Furthermore, current automatic approaches often tackle\ndetection and classification separately, mostly rely on single station\ninformation and generally require tailored preprocessing and representations to\nperform predictions. These limitations often hinder their application to\nreal-time monitoring and utilization across different volcano conditions. This\nstudy introduces a novel approach that utilizes Semantic Segmentation models to\nautomate seismic event recognition by applying a straight forward\ntransformation of multi-channel 1D signals into 2D representations, enabling\ntheir use as images. Our framework employs a data-driven, end-to-end design\nthat integrates multi-station seismic data with minimal preprocessing,\nperforming both detection and classification simultaneously for five seismic\nevent classes. We evaluated four state-of-the-art segmentation models (UNet,\nUNet++, DeepLabV3+ and SwinUNet) on approximately 25.000 seismic events\nrecorded at four different Chilean volcanoes: Nevados del Chill\\'an Volcanic\nComplex, Laguna del Maule, Villarrica and Puyehue-Cord\\'on Caulle. Among these\nmodels, the UNet architecture was identified as the most effective model,\nachieving mean F1 and Intersection over Union (IoU) scores of up to 0.91 and\n0.88, respectively, and demonstrating superior noise robustness and model\nflexibility to unseen volcano datasets.\n","authors":["Camilo Espinosa-Curilem","Millaray Curilem","Daniel Basualto"],"pdf_url":"https://arxiv.org/pdf/2410.20595v3.pdf","comment":"10 pages, 9 figures. This is a pre-print, it is currently under\n  review for publication"},{"id":"http://arxiv.org/abs/2312.05327v3","updated":"2024-11-05T14:12:40Z","published":"2023-12-08T19:24:05Z","title":"Better, Not Just More: Data-Centric Machine Learning for Earth\n  Observation","summary":"  Recent developments and research in modern machine learning have led to\nsubstantial improvements in the geospatial field. Although numerous deep\nlearning architectures and models have been proposed, the majority of them have\nbeen solely developed on benchmark datasets that lack strong real-world\nrelevance. Furthermore, the performance of many methods has already saturated\non these datasets. We argue that a shift from a model-centric view to a\ncomplementary data-centric perspective is necessary for further improvements in\naccuracy, generalization ability, and real impact on end-user applications.\nFurthermore, considering the entire machine learning cycle-from problem\ndefinition to model deployment with feedback-is crucial for enhancing machine\nlearning models that can be reliable in unforeseen situations. This work\npresents a definition as well as a precise categorization and overview of\nautomated data-centric learning approaches for geospatial data. It highlights\nthe complementary role of data-centric learning with respect to model-centric\nin the larger machine learning deployment cycle. We review papers across the\nentire geospatial field and categorize them into different groups. A set of\nrepresentative experiments shows concrete implementation examples. These\nexamples provide concrete steps to act on geospatial data with data-centric\nmachine learning approaches.\n","authors":["Ribana Roscher","Marc Rußwurm","Caroline Gevaert","Michael Kampffmeyer","Jefersson A. dos Santos","Maria Vakalopoulou","Ronny Hänsch","Stine Hansen","Keiller Nogueira","Jonathan Prexl","Devis Tuia"],"pdf_url":"https://arxiv.org/pdf/2312.05327v3.pdf","comment":"Accepted to Geoscience and Remote Sensing Magazine"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.03484v1","updated":"2024-11-05T20:08:23Z","published":"2024-11-05T20:08:23Z","title":"Automated, LLM enabled extraction of synthesis details for reticular\n  materials from scientific literature","summary":"  Automated knowledge extraction from scientific literature can potentially\naccelerate materials discovery. We have investigated an approach for extracting\nsynthesis protocols for reticular materials from scientific literature using\nlarge language models (LLMs). To that end, we introduce a Knowledge Extraction\nPipeline (KEP) that automatizes LLM-assisted paragraph classification and\ninformation extraction. By applying prompt engineering with in-context learning\n(ICL) to a set of open-source LLMs, we demonstrate that LLMs can retrieve\nchemical information from PDF documents, without the need for fine-tuning or\ntraining and at a reduced risk of hallucination. By comparing the performance\nof five open-source families of LLMs in both paragraph classification and\ninformation extraction tasks, we observe excellent model performance even if\nonly few example paragraphs are included in the ICL prompts. The results show\nthe potential of the KEP approach for reducing human annotations and data\ncuration efforts in automated scientific knowledge extraction.\n","authors":["Viviane Torres da Silva","Alexandre Rademaker","Krystelle Lionti","Ronaldo Giro","Geisa Lima","Sandro Fiorini","Marcelo Archanjo","Breno W. Carvalho","Rodrigo Neumann","Anaximandro Souza","João Pedro Souza","Gabriela de Valnisio","Carmen Nilda Paz","Renato Cerqueira","Mathias Steiner"],"pdf_url":"https://arxiv.org/pdf/2411.03484v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2406.04331v2","updated":"2024-11-05T15:43:18Z","published":"2024-06-06T17:59:10Z","title":"PaCE: Parsimonious Concept Engineering for Large Language Models","summary":"  Large Language Models (LLMs) are being used for a wide variety of tasks.\nWhile they are capable of generating human-like responses, they can also\nproduce undesirable output including potentially harmful information, racist or\nsexist language, and hallucinations. Alignment methods are designed to reduce\nsuch undesirable outputs via techniques such as fine-tuning, prompt\nengineering, and representation engineering. However, existing methods face\nseveral challenges: some require costly fine-tuning for every alignment task;\nsome do not adequately remove undesirable concepts, failing alignment; some\nremove benign concepts, lowering the linguistic capabilities of LLMs. To\naddress these issues, we propose Parsimonious Concept Engineering (PaCE), a\nnovel activation engineering framework for alignment. First, to sufficiently\nmodel the concepts, we construct a large-scale concept dictionary in the\nactivation space, in which each atom corresponds to a semantic concept. Given\nany alignment task, we instruct a concept partitioner to efficiently annotate\nthe concepts as benign or undesirable. Then, at inference time, we decompose\nthe LLM activations along the concept dictionary via sparse coding, to\naccurately represent the activations as linear combinations of benign and\nundesirable components. By removing the latter ones from the activations, we\nreorient the behavior of the LLM towards the alignment goal. We conduct\nexperiments on tasks such as response detoxification, faithfulness enhancement,\nand sentiment revising, and show that PaCE achieves state-of-the-art alignment\nperformance while maintaining linguistic capabilities.\n","authors":["Jinqi Luo","Tianjiao Ding","Kwan Ho Ryan Chan","Darshan Thaker","Aditya Chattopadhyay","Chris Callison-Burch","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2406.04331v2.pdf","comment":"Accepted in NeurIPS 2024. GitHub repository at\n  https://github.com/peterljq/Parsimonious-Concept-Engineering"},{"id":"http://arxiv.org/abs/2411.03143v1","updated":"2024-11-05T14:33:50Z","published":"2024-11-05T14:33:50Z","title":"Self-supervised Hierarchical Representation for Medication\n  Recommendation","summary":"  Medication recommender is to suggest appropriate medication combinations\nbased on a patient's health history, e.g., diagnoses and procedures. Existing\nworks represent different diagnoses/procedures well separated by one-hot\nencodings. However, they ignore the latent hierarchical structures of these\nmedical terms, undermining the generalization performance of the model. For\nexample, \"Respiratory Diseases\", \"Chronic Respiratory Diseases\" and \"Chronic\nBronchiti\" have a hierarchical relationship, progressing from general to\nspecific. To address this issue, we propose a novel hierarchical encoder named\nHIER to hierarchically represent diagnoses and procedures, which is based on\nstandard medical codes and compatible with any existing methods. Specifically,\nthe proposed method learns relation embedding with a self-supervised objective\nfor incorporating the neighbor hierarchical structure. Additionally, we develop\nthe position encoding to explicitly introduce global hierarchical position.\nExtensive experiments demonstrate significant and consistent improvements in\nrecommendation accuracy across four baselines and two real-world clinical\ndatasets.\n","authors":["Yuliang Liang","Yuting Liu","Yizhou Dang","Enneng Yang","Guibing Guo","Wei Cai","Jianzhe Zhao","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20598v2","updated":"2024-11-05T14:15:03Z","published":"2024-10-27T21:12:12Z","title":"R^3AG: First Workshop on Refined and Reliable Retrieval Augmented\n  Generation","summary":"  Retrieval-augmented generation (RAG) has gained wide attention as the key\ncomponent to improve generative models with external knowledge augmentation\nfrom information retrieval. It has shown great prominence in enhancing the\nfunctionality and performance of large language model (LLM)-based applications.\nHowever, with the comprehensive application of RAG, more and more problems and\nlimitations have been identified, thus urgently requiring further fundamental\nexploration to improve current RAG frameworks. This workshop aims to explore in\ndepth how to conduct refined and reliable RAG for downstream AI tasks.\n  To this end, we propose to organize the first R3AG workshop at SIGIR-AP 2024\nto call for participants to re-examine and formulate the basic principles and\npractical implementation of refined and reliable RAG. The workshop serves as a\nplatform for both academia and industry researchers to conduct discussions,\nshare insights, and foster research to build the next generation of RAG\nsystems. Participants will engage in discussions and presentations focusing on\nfundamental challenges, cutting-edge research, and potential pathways to\nimprove RAG. At the end of the workshop, we aim to have a clearer understanding\nof how to improve the reliability and applicability of RAG with more robust\ninformation retrieval and language generation.\n","authors":["Zihan Wang","Xuri Ge","Joemon M. Jose","Haitao Yu","Weizhi Ma","Zhaochun Ren","Xin Xin"],"pdf_url":"https://arxiv.org/pdf/2410.20598v2.pdf","comment":"R^3AG workshop overview at SIGIR-AP 2024"},{"id":"http://arxiv.org/abs/2309.14984v2","updated":"2024-11-05T12:09:18Z","published":"2023-09-26T14:56:56Z","title":"Facilitating Interdisciplinary Knowledge Transfer with Research Paper\n  Recommender Systems","summary":"  In the extensive recommender systems literature, novelty and diversity have\nbeen identified as key properties of useful recommendations. However, these\nproperties have received limited attention in the specific sub-field of\nresearch paper recommender systems. In this work, we argue for the importance\nof offering novel and diverse research paper recommendations to scientists.\nThis approach aims to reduce siloed reading, break down filter bubbles, and\npromote interdisciplinary research. We propose a novel framework for evaluating\nthe novelty and diversity of research paper recommendations that leverages\nmethods from network analysis and natural language processing. Using this\nframework, we show that the choice of representational method within a larger\nresearch paper recommendation system can have a measurable impact on the nature\nof downstream recommendations, specifically on their novelty and diversity. We\nhighlight a novel paper embedding method, which we demonstrate offers more\ninnovative and diverse recommendations without sacrificing precision, compared\nto other state-of-the-art baselines.\n","authors":["Eoghan Cunningham","Derek Greene","Barry Smyth"],"pdf_url":"https://arxiv.org/pdf/2309.14984v2.pdf","comment":"Under Review at QSS"},{"id":"http://arxiv.org/abs/2404.00243v2","updated":"2024-11-05T11:46:14Z","published":"2024-03-30T04:39:18Z","title":"DSFNet: Learning Disentangled Scenario Factorization for Multi-Scenario\n  Route Ranking","summary":"  Multi-scenario route ranking (MSRR) is crucial in many industrial mapping\nsystems. However, the industrial community mainly adopts interactive interfaces\nto encourage users to select pre-defined scenarios, which may hinder the\ndownstream ranking performance. In addition, in the academic community, the\nmulti-scenario ranking works only come from other fields, and there are no\nworks specifically focusing on route data due to lacking a publicly available\nMSRR dataset. Moreover, all the existing multi-scenario works still fail to\naddress the three specific challenges of MSRR simultaneously, i.e. explosion of\nscenario number, high entanglement, and high-capacity demand. Different from\nthe prior, to address MSRR, our key idea is to factorize the complicated\nscenario in route ranking into several disentangled factor scenario patterns.\nAccordingly, we propose a novel method, Disentangled Scenario Factorization\nNetwork (DSFNet), which flexibly composes scenario-dependent parameters based\non a high-capacity multi-factor-scenario-branch structure. Then, a novel\nregularization is proposed to induce the disentanglement of factor scenarios.\nFurthermore, two extra novel techniques, i.e. scenario-aware batch\nnormalization and scenario-aware feature filtering, are developed to improve\nthe network awareness of scenario representation. Additionally, to facilitate\nMSRR research in the academic community, we propose MSDR, the first large-scale\npublicly available annotated industrial Multi-Scenario Driving Route dataset.\nComprehensive experimental results demonstrate the superiority of our DSFNet,\nwhich has been successfully deployed in AMap to serve the major online traffic.\n","authors":["Jiahao Yu","Yihai Duan","Longfei Xu","Chao Chen","Shuliang Liu","Kaikui Liu","Fan Yang","Xiangxiang Chu","Ning Guo"],"pdf_url":"https://arxiv.org/pdf/2404.00243v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02992v1","updated":"2024-11-05T10:53:25Z","published":"2024-11-05T10:53:25Z","title":"Efficient and Effective Adaptation of Multimodal Foundation Models in\n  Sequential Recommendation","summary":"  Multimodal foundation models (MFMs) have revolutionized sequential\nrecommender systems through advanced representation learning. While\nParameter-efficient Fine-tuning (PEFT) is commonly used to adapt these models,\nstudies often prioritize parameter efficiency, neglecting GPU memory and\ntraining speed. To address this, we introduced the IISAN framework,\nsignificantly enhancing efficiency. However, IISAN was limited to symmetrical\nMFMs and identical text and image encoders, preventing the use of\nstate-of-the-art Large Language Models. To overcome this, we developed\nIISAN-Versa, a versatile plug-and-play architecture compatible with both\nsymmetrical and asymmetrical MFMs. IISAN-Versa employs a Decoupled PEFT\nstructure and utilizes both intra- and inter-modal adaptation. It effectively\nhandles asymmetry through a simple yet effective combination of group\nlayer-dropping and dimension transformation alignment. Our research\ndemonstrates that IISAN-Versa effectively adapts large text encoders, and we\nfurther identify a scaling effect where larger encoders generally perform\nbetter. IISAN-Versa also demonstrates strong versatility in our defined\nmultimodal scenarios, which include raw titles and captions generated from\nimages and videos. Additionally, IISAN-Versa achieved state-of-the-art\nperformance on the Microlens public benchmark. We will release our code and\ndatasets to support future research.\n","authors":["Junchen Fu","Xuri Ge","Xin Xin","Alexandros Karatzoglou","Ioannis Arapakis","Kaiwen Zheng","Yongxin Ni","Joemon M. Jose"],"pdf_url":"https://arxiv.org/pdf/2411.02992v1.pdf","comment":"The extension of IISAN in SIGIR2024"},{"id":"http://arxiv.org/abs/2411.02959v1","updated":"2024-11-05T09:58:36Z","published":"2024-11-05T09:58:36Z","title":"HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge\n  in RAG Systems","summary":"  Retrieval-Augmented Generation (RAG) has been shown to improve knowledge\ncapabilities and alleviate the hallucination problem of LLMs. The Web is a\nmajor source of external knowledge used in RAG systems, and many commercial\nsystems such as ChatGPT and Perplexity have used Web search engines as their\nmajor retrieval systems. Typically, such RAG systems retrieve search results,\ndownload HTML sources of the results, and then extract plain texts from the\nHTML sources. Plain text documents or chunks are fed into the LLMs to augment\nthe generation. However, much of the structural and semantic information\ninherent in HTML, such as headings and table structures, is lost during this\nplain-text-based RAG process. To alleviate this problem, we propose HtmlRAG,\nwhich uses HTML instead of plain text as the format of retrieved knowledge in\nRAG. We believe HTML is better than plain text in modeling knowledge in\nexternal documents, and most LLMs possess robust capacities to understand HTML.\nHowever, utilizing HTML presents new challenges. HTML contains additional\ncontent such as tags, JavaScript, and CSS specifications, which bring extra\ninput tokens and noise to the RAG system. To address this issue, we propose\nHTML cleaning, compression, and pruning strategies, to shorten the HTML while\nminimizing the loss of information. Specifically, we design a two-step\nblock-tree-based pruning method that prunes useless HTML blocks and keeps only\nthe relevant part of the HTML. Experiments on six QA datasets confirm the\nsuperiority of using HTML in RAG systems.\n","authors":["Jiejun Tan","Zhicheng Dou","Wen Wang","Mang Wang","Weipeng Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2411.02959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01135v2","updated":"2024-11-05T08:51:44Z","published":"2024-11-02T04:44:27Z","title":"Music Foundation Model as Generic Booster for Music Downstream Tasks","summary":"  We demonstrate the efficacy of using intermediate representations from a\nsingle foundation model to enhance various music downstream tasks. We introduce\nSoniDo, a music foundation model (MFM) designed to extract hierarchical\nfeatures from target music samples. By leveraging hierarchical intermediate\nfeatures, SoniDo constrains the information granularity, leading to improved\nperformance across various downstream tasks including both understanding and\ngenerative tasks. We specifically evaluated this approach on representative\ntasks such as music tagging, music transcription, music source separation, and\nmusic mixing. Our results reveal that the features extracted from foundation\nmodels provide valuable enhancements in training downstream task models. This\nhighlights the capability of using features extracted from music foundation\nmodels as a booster for downstream tasks. Our approach not only benefits\nexisting task-specific models but also supports music downstream tasks\nconstrained by data scarcity. This paves the way for more effective and\naccessible music processing solutions.\n","authors":["WeiHsiang Liao","Yuhta Takida","Yukara Ikemiya","Zhi Zhong","Chieh-Hsin Lai","Giorgio Fabbro","Kazuki Shimada","Keisuke Toyama","Kinwai Cheuk","Marco A. Martínez-Ramírez","Shusuke Takahashi","Stefan Uhlich","Taketo Akama","Woosung Choi","Yuichiro Koyama","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2411.01135v2.pdf","comment":"41 pages with 14 figures"},{"id":"http://arxiv.org/abs/2411.02864v1","updated":"2024-11-05T07:12:36Z","published":"2024-11-05T07:12:36Z","title":"Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document\n  Relation Extraction with Graph-of-Thoughts Reasoning","summary":"  Large language models (LLMs) pre-trained on massive corpora have demonstrated\nimpressive few-shot learning capability on many NLP tasks. Recasting an NLP\ntask into a text-to-text generation task is a common practice so that\ngenerative LLMs can be prompted to resolve it. However, performing\ndocument-level relation extraction (DocRE) tasks with generative LLM models is\nstill challenging due to the structured output format of DocRE, which\ncomplicates the conversion to plain text. Limited information available in\nfew-shot samples and prompt instructions induce further difficulties and\nchallenges in relation extraction for mentioned entities in a document. In this\npaper, we represent the structured output as a graph-style triplet rather than\nnatural language expressions and leverage generative LLMs for the DocRE task.\nOur approach, the Graph-DPEP framework is grounded in the reasoning behind\ntriplet explanation thoughts presented in natural language. In this framework,\nwe first introduce a ``decomposed-plug\" method for performing the generation\nfrom LLMs over prompts with type-space decomposition to alleviate the burden of\ndistinguishing all relation types. Second, we employ a verifier for calibrating\nthe generation and identifying overlooked query entity pairs. Third, we develop\n\"ensemble-play\", reapplying generation on the entire type list by leveraging\nthe reasoning thoughts embedded in a sub-graph associated with the missing\nquery pair to address the missingness issue. Through extensive comparisons with\nexisting prompt techniques and alternative Language Models (LLMs), our\nframework demonstrates superior performance on publicly available benchmarks in\nexperiments.\n","authors":["Tao Zhang","Ning Yan","Masood Mortazavi","Hoang H. Nguyen","Zhongfen Deng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2411.02864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03364v1","updated":"2024-11-05T06:54:38Z","published":"2024-11-05T06:54:38Z","title":"DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural\n  Networks","summary":"  Graph has become increasingly integral to the advancement of recommendation\nsystems, particularly with the fast development of graph neural network(GNN).\nBy exploring the virtue of rich node features and link information, GNN is\ndesigned to provide personalized and accurate suggestions. Meanwhile, the\nprivacy leakage of GNN in such contexts has also captured special attention.\nPrior work has revealed that a malicious user can utilize auxiliary knowledge\nto extract sensitive link data of the target graph, integral to recommendation\nsystems, via the decision made by the target GNN model. This poses a\nsignificant risk to the integrity and confidentiality of data used in\nrecommendation system. Though important, previous works on GNN's privacy\nleakage are still challenged in three aspects, i.e., limited stealing attack\nscenarios, sub-optimal attack performance, and adaptation against defense. To\naddress these issues, we propose a diffusion model based link stealing attack,\nnamed DM4Steal. It differs previous work from three critical aspects. (i)\nGenerality: aiming at six attack scenarios with limited auxiliary knowledge, we\npropose a novel training strategy for diffusion models so that DM4Steal is\ntransferable to diverse attack scenarios. (ii) Effectiveness: benefiting from\nthe retention of semantic structure in the diffusion model during the training\nprocess, DM4Steal is capable to learn the precise topology of the target graph\nthrough the GNN decision process. (iii) Adaptation: when GNN is defensive\n(e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling\nthe score model multiple times to keep performance degradation to a minimum,\nthus DM4Steal implements successful adaptive attack on defensive GNN.\n","authors":["Jinyin Chen","Haonan Ma","Haibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.03364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14900v3","updated":"2024-11-05T06:52:30Z","published":"2024-06-21T06:47:28Z","title":"Decoding Matters: Addressing Amplification Bias and Homogeneity Issue\n  for LLM-based Recommendation","summary":"  Adapting Large Language Models (LLMs) for recommendation requires careful\nconsideration of the decoding process, given the inherent differences between\ngenerating items and natural language. Existing approaches often directly apply\nLLMs' original decoding methods. However, we find these methods encounter\nsignificant challenges: 1) amplification bias -- where standard length\nnormalization inflates scores for items containing tokens with generation\nprobabilities close to 1 (termed ghost tokens), and 2) homogeneity issue --\ngenerating multiple similar or repetitive items for a user. To tackle these\nchallenges, we introduce a new decoding approach named Debiasing-Diversifying\nDecoding (D3). D3 disables length normalization for ghost tokens to alleviate\namplification bias, and it incorporates a text-free assistant model to\nencourage tokens less frequently generated by LLMs for counteracting\nrecommendation homogeneity. Extensive experiments on real-world datasets\ndemonstrate the method's effectiveness in enhancing accuracy and diversity. The\ncode is available at https://github.com/SAI990323/DecodingMatters.\n","authors":["Keqin Bao","Jizhi Zhang","Yang Zhang","Xinyue Huo","Chong Chen","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2406.14900v3.pdf","comment":"Accepted at EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2411.02851v1","updated":"2024-11-05T06:49:14Z","published":"2024-11-05T06:49:14Z","title":"Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual\n  Visual Answer Localization","summary":"  The goal of Multilingual Visual Answer Localization (MVAL) is to locate a\nvideo segment that answers a given multilingual question. Existing methods\neither focus solely on visual modality or integrate visual and subtitle\nmodalities. However, these methods neglect the audio modality in videos,\nconsequently leading to incomplete input information and poor performance in\nthe MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span\nLocalization (AVTSL) method that incorporates audio modality to augment both\nvisual and textual representations for the MVAL task. Specifically, we\nintegrate features from three modalities and develop three predictors, each\ntailored to the unique contributions of the fused modalities: an audio-visual\npredictor, a visual predictor, and a textual predictor. Each predictor\ngenerates predictions based on its respective modality. To maintain consistency\nacross the predicted results, we introduce an Audio-Visual-Textual Consistency\nmodule. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing\neach modality's predictor to dynamically learn from the others. This\ncollaborative learning ensures that the model generates consistent and\ncomprehensive answers. Extensive experiments show that our proposed method\noutperforms several state-of-the-art (SOTA) methods, which demonstrates the\neffectiveness of the audio modality.\n","authors":["Zhibin Wen","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.02851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02850v1","updated":"2024-11-05T06:44:15Z","published":"2024-11-05T06:44:15Z","title":"WASHtsApp -- A RAG-powered WhatsApp Chatbot for supporting rural African\n  clean water access, sanitation and hygiene","summary":"  This paper introduces WASHtsApp, a WhatsApp-based chatbot designed to educate\nrural African communities on clean water access, sanitation, and hygiene (WASH)\nprinciples. WASHtsApp leverages a Retrieval-Augmented Generation (RAG) approach\nto address the limitations of previous approaches with limited reach or missing\ncontextualization. The paper details the development process, employing Design\nScience Research Methodology. The evaluation consisted of two phases: content\nvalidation by four WASH experts and community validation by potential users.\nContent validation confirmed WASHtsApp's ability to provide accurate and\nrelevant WASH-related information. Community validation indicated high user\nacceptance and perceived usefulness of the chatbot. The paper concludes by\ndiscussing the potential for further development, including incorporating local\nlanguages and user data analysis for targeted interventions. It also proposes\nfuture research cycles focused on wider deployment and leveraging user data for\neducational purposes.\n","authors":["Simon Kloker","Alex Cedric Luyima","Matthew Bazanya"],"pdf_url":"https://arxiv.org/pdf/2411.02850v1.pdf","comment":"Working Paper"},{"id":"http://arxiv.org/abs/2411.02831v1","updated":"2024-11-05T06:03:55Z","published":"2024-11-05T06:03:55Z","title":"Enhancing EmoBot: An In-Depth Analysis of User Satisfaction and Faults\n  in an Emotion-Aware Chatbot","summary":"  The research community has traditionally shown a keen interest in emotion\nmodeling, with a notable emphasis on the detection aspect. In contrast, the\nexploration of emotion generation has received less attention.This study delves\ninto an existing state-of-the-art emotional chatbot, EmoBot, designed for\ngenerating emotions in general-purpose conversations. This research involves a\ncomprehensive examination, including a survey to evaluate EmoBot's proficiency\nin key dimensions like usability, accuracy, and overall user satisfaction, with\na specific focus on fault tolerance. By closely examining the chatbot's\noperations, we identified some noteworthy shortcomings in the existing model.\nWe propose some solutions designed to address and overcome the identified\nissues.\n","authors":["Taseen Mubassira","Mehedi Hasan","A. B. M. Alim Al Iislam"],"pdf_url":"https://arxiv.org/pdf/2411.02831v1.pdf","comment":"3 pages, extended abstract"},{"id":"http://arxiv.org/abs/2411.02810v1","updated":"2024-11-05T04:57:55Z","published":"2024-11-05T04:57:55Z","title":"Leveraging Vision-Language Models for Manufacturing Feature Recognition\n  in CAD Designs","summary":"  Automatic feature recognition (AFR) is essential for transforming design\nknowledge into actionable manufacturing information. Traditional AFR methods,\nwhich rely on predefined geometric rules and large datasets, are often\ntime-consuming and lack generalizability across various manufacturing features.\nTo address these challenges, this study investigates vision-language models\n(VLMs) for automating the recognition of a wide range of manufacturing features\nin CAD designs without the need for extensive training datasets or predefined\nrules. Instead, prompt engineering techniques, such as multi-view query images,\nfew-shot learning, sequential reasoning, and chain-of-thought, are applied to\nenable recognition. The approach is evaluated on a newly developed CAD dataset\ncontaining designs of varying complexity relevant to machining, additive\nmanufacturing, sheet metal forming, molding, and casting. Five VLMs, including\nthree closed-source models (GPT-4o, Claude-3.5-Sonnet, and Claude-3.0-Opus) and\ntwo open-source models (LLava and MiniCPM), are evaluated on this dataset with\nground truth features labelled by experts. Key metrics include feature quantity\naccuracy, feature name matching accuracy, hallucination rate, and mean absolute\nerror (MAE). Results show that Claude-3.5-Sonnet achieves the highest feature\nquantity accuracy (74%) and name-matching accuracy (75%) with the lowest MAE\n(3.2), while GPT-4o records the lowest hallucination rate (8%). In contrast,\nopen-source models have higher hallucination rates (>30%) and lower accuracies\n(<40%). This study demonstrates the potential of VLMs to automate feature\nrecognition in CAD designs within diverse manufacturing scenarios.\n","authors":["Muhammad Tayyab Khan","Lequn Chen","Ye Han Ng","Wenhe Feng","Nicholas Yew Jin Tan","Seung Ki Moon"],"pdf_url":"https://arxiv.org/pdf/2411.02810v1.pdf","comment":"Paper has been submitted to The ASME Journal of Computing and\n  Information Science in Engineering (JCISE)"},{"id":"http://arxiv.org/abs/2411.02791v1","updated":"2024-11-05T04:01:41Z","published":"2024-11-05T04:01:41Z","title":"Language Models and Cycle Consistency for Self-Reflective Machine\n  Translation","summary":"  This paper introduces a novel framework that leverages large language models\n(LLMs) for machine translation (MT). We start with one conjecture: an ideal\ntranslation should contain complete and accurate information for a strong\nenough LLM to recover the original sentence. We generate multiple translation\ncandidates from a source language A to a target language B, and subsequently\ntranslate these candidates back to the original language A. By evaluating the\ncycle consistency between the original and back-translated sentences using\nmetrics such as token-level precision and accuracy, we implicitly estimate the\ntranslation quality in language B, without knowing its ground-truth. This also\nhelps to evaluate the LLM translation capability, only with monolingual\ncorpora. For each source sentence, we identify the translation candidate with\noptimal cycle consistency with the original sentence as the final answer. Our\nexperiments demonstrate that larger LLMs, or the same LLM with more forward\npasses during inference, exhibit increased cycle consistency, aligning with the\nLLM model size scaling law and test-time computation scaling law. This work\nprovide methods for, 1) to implicitly evaluate translation quality of a\nsentence in the target language, 2), to evaluate capability of LLM for\nany-to-any-language translation, and 3), how to generate a better translation\nfor a specific LLM.\n","authors":["Jianqiao Wangni"],"pdf_url":"https://arxiv.org/pdf/2411.02791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02790v1","updated":"2024-11-05T03:55:25Z","published":"2024-11-05T03:55:25Z","title":"Memory Augmented Cross-encoders for Controllable Personalized Search","summary":"  Personalized search represents a problem where retrieval models condition on\nhistorical user interaction data in order to improve retrieval results.\nHowever, personalization is commonly perceived as opaque and not amenable to\ncontrol by users. Further, personalization necessarily limits the space of\nitems that users are exposed to. Therefore, prior work notes a tension between\npersonalization and users' ability for discovering novel items. While discovery\nof novel items in personalization setups may be resolved through search result\ndiversification, these approaches do little to allow user control over\npersonalization. Therefore, in this paper, we introduce an approach for\ncontrollable personalized search. Our model, CtrlCE presents a novel\ncross-encoder model augmented with an editable memory constructed from users\nhistorical items. Our proposed memory augmentation allows cross-encoder models\nto condition on large amounts of historical user data and supports interaction\nfrom users permitting control over personalization. Further, controllable\npersonalization for search must account for queries which don't require\npersonalization, and in turn user control. For this, we introduce a calibrated\nmixing model which determines when personalization is necessary. This allows\nsystem designers using CtrlCE to only obtain user input for control when\nnecessary. In multiple datasets of personalized search, we show CtrlCE to\nresult in effective personalization as well as fulfill various key goals for\ncontrollable personalized search.\n","authors":["Sheshera Mysore","Garima Dhanania","Kishor Patil","Surya Kallumadi","Andrew McCallum","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2411.02790v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.09359v2","updated":"2024-11-05T03:45:24Z","published":"2024-10-12T04:00:55Z","title":"Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient\n  Algorithm Performance","summary":"  As recommender systems become increasingly prevalent, the environmental\nimpact and energy efficiency of training large-scale models have come under\nscrutiny. This paper investigates the potential for energy-efficient algorithm\nperformance by optimizing dataset sizes through downsampling techniques in the\ncontext of Green Recommender Systems. We conducted experiments on the MovieLens\n100K, 1M, 10M, and Amazon Toys and Games datasets, analyzing the performance of\nvarious recommender algorithms under different portions of dataset size. Our\nresults indicate that while more training data generally leads to higher\nalgorithm performance, certain algorithms, such as FunkSVD and BiasedMF,\nparticularly with unbalanced and sparse datasets like Amazon Toys and Games,\nmaintain high-quality recommendations with up to a 50% reduction in training\ndata, achieving nDCG@10 scores within approximately 13% of full dataset\nperformance. These findings suggest that strategic dataset reduction can\ndecrease computational and environmental costs without substantially\ncompromising recommendation quality. This study advances sustainable and green\nrecommender systems by providing insights for reducing energy consumption while\nmaintaining effectiveness.\n","authors":["Ardalan Arabzadeh","Tobias Vente","Joeran Beel"],"pdf_url":"https://arxiv.org/pdf/2410.09359v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09180v2","updated":"2024-11-05T03:34:10Z","published":"2023-11-15T18:19:58Z","title":"Pearl: Personalizing Large Language Model Writing Assistants with\n  Generation-Calibrated Retrievers","summary":"  Powerful large language models have facilitated the development of writing\nassistants that promise to significantly improve the quality and efficiency of\ncomposition and communication. However, a barrier to effective assistance is\nthe lack of personalization in LLM outputs to the author's communication style,\nspecialized knowledge, and values. In this paper, we address this challenge by\nproposing Pearl, a LLM writing assistant personalized with a retriever that is\ntrained to be generation-calibrated for personalization. Generation calibration\nensures that our retriever selects historic user authored documents to augment\nan LLM prompt such that they are likely to help an LLM generation better adhere\nto a users' preferences. We propose two key novelties for training such a\nretriever: (1) A training data selection method that identifies user requests\nlikely to benefit from personalization and documents that provide that benefit;\nand (2) A scale-calibrating KL-divergence objective that ensures that our\nretriever scores remain proportional to the downstream generation quality from\nusing the document for personalized generation. In a series of holistic\nevaluations, we demonstrate the effectiveness of Pearl in generating long-form\ntexts on multiple social media datasets. Finally, we demonstrate how a\ngeneration-calibrated retriever can double as a performance predictor --\ndetecting low quality retrieval, and improving potentially under-performing\noutputs via revision with LLMs.\n","authors":["Sheshera Mysore","Zhuoran Lu","Mengting Wan","Longqi Yang","Bahareh Sarrafzadeh","Steve Menezes","Tina Baghaee","Emmanuel Barajas Gonzalez","Jennifer Neville","Tara Safavi"],"pdf_url":"https://arxiv.org/pdf/2311.09180v2.pdf","comment":"Accepted to Workshop on Customizable NLP at EMNLP 2024"},{"id":"http://arxiv.org/abs/2408.09698v4","updated":"2024-11-05T03:32:31Z","published":"2024-08-19T04:44:32Z","title":"Harnessing Multimodal Large Language Models for Multimodal Sequential\n  Recommendation","summary":"  Recent advances in Large Language Models (LLMs) have demonstrated significant\npotential in the field of Recommendation Systems (RSs). Most existing studies\nhave focused on converting user behavior logs into textual prompts and\nleveraging techniques such as prompt tuning to enable LLMs for recommendation\ntasks. Meanwhile, research interest has recently grown in multimodal\nrecommendation systems that integrate data from images, text, and other sources\nusing modality fusion techniques. This introduces new challenges to the\nexisting LLM-based recommendation paradigm which relies solely on text modality\ninformation. Moreover, although Multimodal Large Language Models (MLLMs)\ncapable of processing multi-modal inputs have emerged, how to equip MLLMs with\nmulti-modal recommendation capabilities remains largely unexplored. To this\nend, in this paper, we propose the Multimodal Large Language Model-enhanced\nMultimodaln Sequential Recommendation (MLLM-MSR) model. To capture the dynamic\nuser preference, we design a two-stage user preference summarization method.\nSpecifically, we first utilize an MLLM-based item-summarizer to extract image\nfeature given an item and convert the image into text. Then, we employ a\nrecurrent user preference summarization generation paradigm to capture the\ndynamic changes in user preferences based on an LLM-based user-summarizer.\nFinally, to enable the MLLM for multi-modal recommendation task, we propose to\nfine-tune a MLLM-based recommender using Supervised Fine-Tuning (SFT)\ntechniques. Extensive evaluations across various datasets validate the\neffectiveness of MLLM-MSR, showcasing its superior ability to capture and adapt\nto the evolving dynamics of user preferences.\n","authors":["Yuyang Ye","Zhi Zheng","Yishan Shen","Tianshu Wang","Hengruo Zhang","Peijun Zhu","Runlong Yu","Kai Zhang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2408.09698v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00077v3","updated":"2024-11-05T02:25:16Z","published":"2024-06-22T15:32:53Z","title":"Differentially Private Graph Diffusion with Applications in Personalized\n  PageRanks","summary":"  Graph diffusion, which iteratively propagates real-valued substances among\nthe graph, is used in numerous graph/network-involved applications. However,\nreleasing diffusion vectors may reveal sensitive linking information in the\ndata such as transaction information in financial network data. However,\nprotecting the privacy of graph data is challenging due to its interconnected\nnature. This work proposes a novel graph diffusion framework with edge-level\ndifferential privacy guarantees by using noisy diffusion iterates. The\nalgorithm injects Laplace noise per diffusion iteration and adopts a\ndegree-based thresholding function to mitigate the high sensitivity induced by\nlow-degree nodes. Our privacy loss analysis is based on Privacy Amplification\nby Iteration (PABI), which to our best knowledge, is the first effort that\nanalyzes PABI with Laplace noise and provides relevant applications. We also\nintroduce a novel Infinity-Wasserstein distance tracking method, which tightens\nthe analysis of privacy leakage and makes PABI more applicable in practice. We\nevaluate this framework by applying it to Personalized Pagerank computation for\nranking tasks. Experiments on real-world network data demonstrate the\nsuperiority of our method under stringent privacy conditions.\n","authors":["Rongzhe Wei","Eli Chien","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2407.00077v3.pdf","comment":"Appear in NeurIPS 2024. In this version, we provide a more rigorous\n  analysis of graph distortion by establishing a tight bound, then update our\n  corresponding experimental results, which are better than the previous\n  version"},{"id":"http://arxiv.org/abs/2411.02695v1","updated":"2024-11-05T00:46:25Z","published":"2024-11-05T00:46:25Z","title":"JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase","summary":"  Knowledge Graphs have emerged as a compelling abstraction for capturing key\nrelationship among the entities of interest to enterprises and for integrating\ndata from heterogeneous sources. JPMorgan Chase (JPMC) is leading this trend by\nleveraging knowledge graphs across the organization for multiple mission\ncritical applications such as risk assessment, fraud detection, investment\nadvice, etc. A core problem in leveraging a knowledge graph is to link mentions\n(e.g., company names) that are encountered in textual sources to entities in\nthe knowledge graph. Although several techniques exist for entity linking, they\nare tuned for entities that exist in Wikipedia, and fail to generalize for the\nentities that are of interest to an enterprise. In this paper, we propose a\nnovel end-to-end neural entity linking model (JEL) that uses minimal context\ninformation and a margin loss to generate entity embeddings, and a Wide & Deep\nLearning model to match character and semantic information respectively. We\nshow that JEL achieves the state-of-the-art performance to link mentions of\ncompany names in financial news with entities in our knowledge graph. We report\non our efforts to deploy this model in the company-wide system to generate\nalerts in response to financial news. The methodology used for JEL is directly\napplicable and usable by other enterprises who need entity linking solutions\nfor data that are unique to their respective situations.\n","authors":["Wanying Ding","Vinay K. Chaudhri","Naren Chittar","Krishna Konakanchi"],"pdf_url":"https://arxiv.org/pdf/2411.02695v1.pdf","comment":"8 pages, 4 figures, IAAI-21"},{"id":"http://arxiv.org/abs/2411.02692v1","updated":"2024-11-05T00:39:22Z","published":"2024-11-05T00:39:22Z","title":"JPEC: A Novel Graph Neural Network for Competitor Retrieval in Financial\n  Knowledge Graphs","summary":"  Knowledge graphs have gained popularity for their ability to organize and\nanalyze complex data effectively. When combined with graph embedding\ntechniques, such as graph neural networks (GNNs), knowledge graphs become a\npotent tool in providing valuable insights. This study explores the application\nof graph embedding in identifying competitors from a financial knowledge graph.\nExisting state-of-the-art(SOTA) models face challenges due to the unique\nattributes of our knowledge graph, including directed and undirected\nrelationships, attributed nodes, and minimal annotated competitor connections.\nTo address these challenges, we propose a novel graph embedding model,\nJPEC(JPMorgan Proximity Embedding for Competitor Detection), which utilizes\ngraph neural network to learn from both first-order and second-order node\nproximity together with vital features for competitor retrieval. JPEC had\noutperformed most existing models in extensive experiments, showcasing its\neffectiveness in competitor retrieval.\n","authors":["Wanying Ding","Manoj Cherukumalli","Santosh Chikoti","Vinay K. Chaudhri"],"pdf_url":"https://arxiv.org/pdf/2411.02692v1.pdf","comment":"5 pages, 4 figures, accepted by SIGIR'24"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.03109v1","updated":"2024-11-05T13:56:44Z","published":"2024-11-05T13:56:44Z","title":"pTSE-T: Presentation Target Speaker Extraction using Unaligned Text Cues","summary":"  TSE aims to extract the clean speech of the target speaker in an audio\nmixture, thus eliminating irrelevant background noise and speech. While prior\nwork has explored various auxiliary cues including pre-recorded speech, visual\ninformation (e.g., lip motions and gestures), and spatial information, the\nacquisition and selection of such strong cues are infeasible in many practical\nscenarios. Unlike all existing work, in this paper, we condition the TSE\nalgorithm on semantic cues extracted from limited and unaligned text content,\nsuch as condensed points from a presentation slide. This method is particularly\nuseful in scenarios like meetings, poster sessions, or lecture presentations,\nwhere acquiring other cues in real-time is challenging. To this end, we design\ntwo different networks. Specifically, our proposed TPE fuses audio features\nwith content-based semantic cues to facilitate time-frequency mask generation\nto filter out extraneous noise, while another proposal, namely TSR, employs the\ncontrastive learning technique to associate blindly separated speech signals\nwith semantic cues. The experimental results show the efficacy in accurately\nidentifying the target speaker by utilizing semantic cues derived from limited\nand unaligned text, resulting in SI-SDRi of 12.16 dB, SDRi of 12.66 dB, PESQi\nof 0.830 and STOIi of 0.150, respectively. Dataset and source code will be\npublicly available. Project demo page: https://slideTSE.github.io/.\n","authors":["Ziyang Jiang","Xinquan Qian","Jiahe Lei","Zexu Pan","Wei Xue","Xu-cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2411.03109v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03085v1","updated":"2024-11-05T13:30:27Z","published":"2024-11-05T13:30:27Z","title":"Speech Separation with Pretrained Frontend to Minimize Domain Mismatch","summary":"  Speech separation seeks to separate individual speech signals from a speech\nmixture. Typically, most separation models are trained on synthetic data due to\nthe unavailability of target reference in real-world cocktail party scenarios.\nAs a result, there exists a domain gap between real and synthetic data when\ndeploying speech separation models in real-world applications. In this paper,\nwe propose a self-supervised domain-invariant pretrained (DIP) frontend that is\nexposed to mixture data without the need for target reference speech. The DIP\nfrontend utilizes a Siamese network with two innovative pretext tasks, mixture\npredictive coding (MPC) and mixture invariant coding (MIC), to capture shared\ncontextual cues between real and synthetic unlabeled mixtures. Subsequently, we\nfreeze the DIP frontend as a feature extractor when training the downstream\nspeech separation models on synthetic data. By pretraining the DIP frontend\nwith the contextual cues, we expect that the speech separation skills learned\nfrom synthetic data can be effectively transferred to real data. To benefit\nfrom the DIP frontend, we introduce a novel separation pipeline to align the\nfeature resolution of the separation models. We evaluate the speech separation\nquality on standard benchmarks and real-world datasets. The results confirm the\nsuperiority of our DIP frontend over existing speech separation models. This\nstudy underscores the potential of large-scale pretraining to enhance the\nquality and intelligibility of speech separation in real-world applications.\n","authors":["Wupeng Wang","Zexu Pan","Xinke Li","Shuai Wang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2411.03085v1.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing"},{"id":"http://arxiv.org/abs/2411.03034v1","updated":"2024-11-05T12:14:57Z","published":"2024-11-05T12:14:57Z","title":"HumanVLM: Foundation for Human-Scene Vision-Language Model","summary":"  Human-scene vision-language tasks are increasingly prevalent in diverse\nsocial applications, yet recent advancements predominantly rely on models\nspecifically tailored to individual tasks. Emerging research indicates that\nlarge vision-language models (VLMs) can enhance performance across various\ndownstream vision-language understanding tasks. However, general-domain models\noften underperform in specialized fields. This study introduces a\ndomain-specific Large Vision-Language Model, Human-Scene Vision-Language Model\n(HumanVLM), designed to provide a foundation for human-scene Vision-Language\ntasks. Specifically, (1) we create a large-scale human-scene multimodal\nimage-text dataset (HumanCaption-10M) sourced from the Internet to facilitate\ndomain-specific alignment; (2) develop a captioning approach for human-centered\nimages, capturing human faces, bodies, and backgrounds, and construct a\nhigh-quality Human-Scene image-text dataset (HumanCaptionHQ, about 311k pairs)\nthat contain as much detailed information as possible about human; (3) Using\nHumanCaption-10M and HumanCaptionHQ, we train a HumanVLM. In the experiments,\nwe then evaluate our HumanVLM across varous downstream tasks, where it\ndemonstrates superior overall performance among multimodal models of comparable\nscale, particularly excelling in human-related tasks and significantly\noutperforming similar models, including Qwen2VL and ChatGPT-4o. HumanVLM,\nalongside the data introduced, will stimulate the research in human-around\nfields.\n","authors":["Dawei Dai","Xu Long","Li Yutang","Zhang Yuanhui","Shuyin Xia"],"pdf_url":"https://arxiv.org/pdf/2411.03034v1.pdf","comment":"34 pages,11 figures"},{"id":"http://arxiv.org/abs/2411.03010v1","updated":"2024-11-05T11:18:43Z","published":"2024-11-05T11:18:43Z","title":"Learning-based Lossless Event Data Compression","summary":"  Emerging event cameras acquire visual information by detecting time domain\nbrightness changes asynchronously at the pixel level and, unlike conventional\ncameras, are able to provide high temporal resolution, very high dynamic range,\nlow latency, and low power consumption. Considering the huge amount of data\ninvolved, efficient compression solutions are very much needed. In this\ncontext, this paper presents a novel deep-learning-based lossless event data\ncompression scheme based on octree partitioning and a learned hyperprior model.\nThe proposed method arranges the event stream as a 3D volume and employs an\noctree structure for adaptive partitioning. A deep neural network-based entropy\nmodel, using a hyperprior, is then applied. Experimental results demonstrate\nthat the proposed method outperforms traditional lossless data compression\ntechniques in terms of compression ratio and bits per event.\n","authors":["Ahmadreza Sezavar","Catarina Brites","Joao Ascenso"],"pdf_url":"https://arxiv.org/pdf/2411.03010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.02905v3","updated":"2024-11-05T10:51:30Z","published":"2023-08-05T15:54:06Z","title":"FASTER: A Font-Agnostic Scene Text Editing and Rendering Framework","summary":"  Scene Text Editing (STE) is a challenging research problem, that primarily\naims towards modifying existing texts in an image while preserving the\nbackground and the font style of the original text. Despite its utility in\nnumerous real-world applications, existing style-transfer-based approaches have\nshown sub-par editing performance due to (1) complex image backgrounds, (2)\ndiverse font attributes, and (3) varying word lengths within the text. To\naddress such limitations, in this paper, we propose a novel font-agnostic scene\ntext editing and rendering framework, named FASTER, for simultaneously\ngenerating text in arbitrary styles and locations while preserving a natural\nand realistic appearance and structure. A combined fusion of target mask\ngeneration and style transfer units, with a cascaded self-attention mechanism\nhas been proposed to focus on multi-level text region edits to handle varying\nword lengths. Extensive evaluation on a real-world database with further\nsubjective human evaluation study indicates the superiority of FASTER in both\nscene text editing and rendering tasks, in terms of model performance and\nefficiency. Our code will be released upon acceptance.\n","authors":["Alloy Das","Sanket Biswas","Prasun Roy","Subhankar Ghosh","Umapada Pal","Michael Blumenstein","Josep Lladós","Saumik Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2308.02905v3.pdf","comment":"Accepted in WACV 2025"},{"id":"http://arxiv.org/abs/2411.02860v1","updated":"2024-11-05T07:09:14Z","published":"2024-11-05T07:09:14Z","title":"Continual Audio-Visual Sound Separation","summary":"  In this paper, we introduce a novel continual audio-visual sound separation\ntask, aiming to continuously separate sound sources for new classes while\npreserving performance on previously learned classes, with the aid of visual\nguidance. This problem is crucial for practical visually guided auditory\nperception as it can significantly enhance the adaptability and robustness of\naudio-visual sound separation models, making them more applicable for\nreal-world scenarios where encountering new sound sources is commonplace. The\ntask is inherently challenging as our models must not only effectively utilize\ninformation from both modalities in current tasks but also preserve their\ncross-modal association in old tasks to mitigate catastrophic forgetting during\naudio-visual continual learning. To address these challenges, we propose a\nnovel approach named ContAV-Sep (\\textbf{Cont}inual\n\\textbf{A}udio-\\textbf{V}isual Sound \\textbf{Sep}aration). ContAV-Sep presents\na novel Cross-modal Similarity Distillation Constraint (CrossSDC) to uphold the\ncross-modal semantic similarity through incremental tasks and retain previously\nacquired knowledge of semantic similarity in old models, mitigating the risk of\ncatastrophic forgetting. The CrossSDC can seamlessly integrate into the\ntraining process of different audio-visual sound separation frameworks.\nExperiments demonstrate that ContAV-Sep can effectively mitigate catastrophic\nforgetting and achieve significantly better performance compared to other\ncontinual learning baselines for audio-visual sound separation. Code is\navailable at: \\url{https://github.com/weiguoPian/ContAV-Sep_NeurIPS2024}.\n","authors":["Weiguo Pian","Yiyang Nan","Shijian Deng","Shentong Mo","Yunhui Guo","Yapeng Tian"],"pdf_url":"https://arxiv.org/pdf/2411.02860v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02851v1","updated":"2024-11-05T06:49:14Z","published":"2024-11-05T06:49:14Z","title":"Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual\n  Visual Answer Localization","summary":"  The goal of Multilingual Visual Answer Localization (MVAL) is to locate a\nvideo segment that answers a given multilingual question. Existing methods\neither focus solely on visual modality or integrate visual and subtitle\nmodalities. However, these methods neglect the audio modality in videos,\nconsequently leading to incomplete input information and poor performance in\nthe MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span\nLocalization (AVTSL) method that incorporates audio modality to augment both\nvisual and textual representations for the MVAL task. Specifically, we\nintegrate features from three modalities and develop three predictors, each\ntailored to the unique contributions of the fused modalities: an audio-visual\npredictor, a visual predictor, and a textual predictor. Each predictor\ngenerates predictions based on its respective modality. To maintain consistency\nacross the predicted results, we introduce an Audio-Visual-Textual Consistency\nmodule. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing\neach modality's predictor to dynamically learn from the others. This\ncollaborative learning ensures that the model generates consistent and\ncomprehensive answers. Extensive experiments show that our proposed method\noutperforms several state-of-the-art (SOTA) methods, which demonstrates the\neffectiveness of the audio modality.\n","authors":["Zhibin Wen","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.02851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04828v3","updated":"2024-11-05T02:32:06Z","published":"2024-09-07T13:41:37Z","title":"POINTS: Improving Your Vision-language Model with Affordable Strategies","summary":"  In recent years, vision-language models have made significant strides,\nexcelling in tasks like optical character recognition and geometric\nproblem-solving. However, several critical issues remain: 1) Proprietary models\noften lack transparency about their architectures, while open-source models\nneed more detailed ablations of their training strategies. 2) Pre-training data\nin open-source works is under-explored, with datasets added empirically, making\nthe process cumbersome. 3) Fine-tuning often focuses on adding datasets,\nleading to diminishing returns. To address these issues, we propose the\nfollowing contributions: 1) We trained a robust baseline model using the latest\nadvancements in vision-language models, introducing effective improvements and\nconducting comprehensive ablation and validation for each technique. 2)\nInspired by recent work on large language models, we filtered pre-training data\nusing perplexity, selecting the lowest perplexity data for training. This\napproach allowed us to train on a curated 1M dataset, achieving competitive\nperformance. 3) During visual instruction tuning, we used model soup on\ndifferent datasets when adding more datasets yielded marginal improvements.\nThese innovations resulted in a 9B parameter model that performs competitively\nwith state-of-the-art models. Our strategies are efficient and lightweight,\nmaking them easily adoptable by the community.\n","authors":["Yuan Liu","Zhongyin Zhao","Ziyuan Zhuang","Le Tian","Xiao Zhou","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.04828v3.pdf","comment":"v2"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.03562v1","updated":"2024-11-05T23:55:23Z","published":"2024-11-05T23:55:23Z","title":"Large Language Models Orchestrating Structured Reasoning Achieve Kaggle\n  Grandmaster Level","summary":"  We introduce Agent K v1.0, an end-to-end autonomous data science agent\ndesigned to automate, optimise, and generalise across diverse data science\ntasks. Fully automated, Agent K v1.0 manages the entire data science life cycle\nby learning from experience. It leverages a highly flexible structured\nreasoning framework to enable it to dynamically process memory in a nested\nstructure, effectively learning from accumulated experience stored to handle\ncomplex reasoning tasks. It optimises long- and short-term memory by\nselectively storing and retrieving key information, guiding future decisions\nbased on environmental rewards. This iterative approach allows it to refine\ndecisions without fine-tuning or backpropagation, achieving continuous\nimprovement through experiential learning. We evaluate our agent's apabilities\nusing Kaggle competitions as a case study. Following a fully automated\nprotocol, Agent K v1.0 systematically addresses complex and multimodal data\nscience tasks, employing Bayesian optimisation for hyperparameter tuning and\nfeature engineering. Our new evaluation framework rigorously assesses Agent K\nv1.0's end-to-end capabilities to generate and send submissions starting from a\nKaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\\%\nsuccess rate across tasks, spanning tabular, computer vision, NLP, and\nmultimodal domains. When benchmarking against 5,856 human Kaggle competitors by\ncalculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\\%,\ndemonstrating an overall skill level comparable to Expert-level users. Notably,\nits Elo-MMR score falls between the first and third quartiles of scores\nachieved by human Grandmasters. Furthermore, our results indicate that Agent K\nv1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a\nrecord of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's\nprogression system.\n","authors":["Antoine Grosnit","Alexandre Maraval","James Doran","Giuseppe Paolo","Albert Thomas","Refinath Shahul Hameed Nabeezath Beevi","Jonas Gonzalez","Khyati Khandelwal","Ignacio Iacobacci","Abdelhakim Benechehab","Hamza Cherkaoui","Youssef Attia El-Hili","Kun Shao","Jianye Hao","Jun Yao","Balazs Kegl","Haitham Bou-Ammar","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15612v3","updated":"2024-11-05T23:14:28Z","published":"2023-05-24T23:01:56Z","title":"Density Ratio Estimation-based Bayesian Optimization with\n  Semi-Supervised Learning","summary":"  Bayesian optimization has attracted huge attention from diverse research\nareas in science and engineering, since it is capable of efficiently finding a\nglobal optimum of an expensive-to-evaluate black-box function. In general, a\nprobabilistic regression model is widely used as a surrogate function to model\nan explicit distribution over function evaluations given an input to estimate\nand a training dataset. Beyond the probabilistic regression-based methods,\ndensity ratio estimation-based Bayesian optimization has been suggested in\norder to estimate a density ratio of the groups relatively close and relatively\nfar to a global optimum. Developing this line of research further, supervised\nclassifiers are employed to estimate a class probability for the two groups\ninstead of a density ratio. However, the supervised classifiers used in this\nstrategy are prone to be overconfident for known knowledge on global solution\ncandidates. Supposing that we have access to unlabeled points, e.g., predefined\nfixed-size pools, we propose density ratio estimation-based Bayesian\noptimization with semi-supervised learning to solve this challenge. Finally, we\nshow the empirical results of our methods and several baseline methods in two\ndistinct scenarios with unlabeled point sampling and a fixed-size pool and\nanalyze the validity of our proposed methods in diverse experiments.\n","authors":["Jungtaek Kim"],"pdf_url":"https://arxiv.org/pdf/2305.15612v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05369v2","updated":"2024-11-05T23:14:03Z","published":"2024-05-08T18:52:47Z","title":"Model Reconstruction Using Counterfactual Explanations: A Perspective\n  From Polytope Theory","summary":"  Counterfactual explanations provide ways of achieving a favorable model\noutcome with minimum input perturbation. However, counterfactual explanations\ncan also be leveraged to reconstruct the model by strategically training a\nsurrogate model to give similar predictions as the original (target) model. In\nthis work, we analyze how model reconstruction using counterfactuals can be\nimproved by further leveraging the fact that the counterfactuals also lie quite\nclose to the decision boundary. Our main contribution is to derive novel\ntheoretical relationships between the error in model reconstruction and the\nnumber of counterfactual queries required using polytope theory. Our\ntheoretical analysis leads us to propose a strategy for model reconstruction\nthat we call Counterfactual Clamping Attack (CCA) which trains a surrogate\nmodel using a unique loss function that treats counterfactuals differently than\nordinary instances. Our approach also alleviates the related problem of\ndecision boundary shift that arises in existing model reconstruction approaches\nwhen counterfactuals are treated as ordinary instances. Experimental results\ndemonstrate that our strategy improves fidelity between the target and\nsurrogate model predictions on several datasets.\n","authors":["Pasan Dissanayake","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2405.05369v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.00120v3","updated":"2024-11-05T22:50:49Z","published":"2024-05-31T18:22:09Z","title":"Reward Machines for Deep RL in Noisy and Uncertain Environments","summary":"  Reward Machines provide an automaton-inspired structure for specifying\ninstructions, safety constraints, and other temporally extended reward-worthy\nbehaviour. By exposing the underlying structure of a reward function, they\nenable the decomposition of an RL task, leading to impressive gains in sample\nefficiency. Although Reward Machines and similar formal specifications have a\nrich history of application towards sequential decision-making problems, they\ncritically rely on a ground-truth interpretation of the domain-specific\nvocabulary that forms the building blocks of the reward function--such\nground-truth interpretations are elusive in the real world due in part to\npartial observability and noisy sensing. In this work, we explore the use of\nReward Machines for Deep RL in noisy and uncertain environments. We\ncharacterize this problem as a POMDP and propose a suite of RL algorithms that\nexploit task structure under uncertain interpretation of the domain-specific\nvocabulary. Through theory and experiments, we expose pitfalls in naive\napproaches to this problem while simultaneously demonstrating how task\nstructure can be successfully leveraged under noisy interpretations of the\nvocabulary.\n","authors":["Andrew C. Li","Zizhao Chen","Toryn Q. Klassen","Pashootan Vaezipoor","Rodrigo Toro Icarte","Sheila A. McIlraith"],"pdf_url":"https://arxiv.org/pdf/2406.00120v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18905v2","updated":"2024-11-05T22:45:52Z","published":"2024-04-29T17:44:28Z","title":"Detecting critical treatment effect bias in small subgroups","summary":"  Randomized trials are considered the gold standard for making informed\ndecisions in medicine, yet they often lack generalizability to the patient\npopulations in clinical practice. Observational studies, on the other hand,\ncover a broader patient population but are prone to various biases. Thus,\nbefore using an observational study for decision-making, it is crucial to\nbenchmark its treatment effect estimates against those derived from a\nrandomized trial. We propose a novel strategy to benchmark observational\nstudies beyond the average treatment effect. First, we design a statistical\ntest for the null hypothesis that the treatment effects estimated from the two\nstudies, conditioned on a set of relevant features, differ up to some\ntolerance. We then estimate an asymptotically valid lower bound on the maximum\nbias strength for any subgroup in the observational study. Finally, we validate\nour benchmarking strategy in a real-world setting and show that it leads to\nconclusions that align with established medical knowledge.\n","authors":["Piersilvio De Bartolomeis","Javier Abad","Konstantin Donhauser","Fanny Yang"],"pdf_url":"https://arxiv.org/pdf/2404.18905v2.pdf","comment":"Accepted for presentation at the Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2024"},{"id":"http://arxiv.org/abs/2411.03541v1","updated":"2024-11-05T22:42:49Z","published":"2024-11-05T22:42:49Z","title":"Do Mice Grok? Glimpses of Hidden Progress During Overtraining in Sensory\n  Cortex","summary":"  Does learning of task-relevant representations stop when behavior stops\nchanging? Motivated by recent theoretical advances in machine learning and the\nintuitive observation that human experts continue to learn from practice even\nafter mastery, we hypothesize that task-specific representation learning can\ncontinue, even when behavior plateaus. In a novel reanalysis of recently\npublished neural data, we find evidence for such learning in posterior piriform\ncortex of mice following continued training on a task, long after behavior\nsaturates at near-ceiling performance (\"overtraining\"). This learning is marked\nby an increase in decoding accuracy from piriform neural populations and\nimproved performance on held-out generalization tests. We demonstrate that\nclass representations in cortex continue to separate during overtraining, so\nthat examples that were incorrectly classified at the beginning of overtraining\ncan abruptly be correctly classified later on, despite no changes in behavior\nduring that time. We hypothesize this hidden yet rich learning takes the form\nof approximate margin maximization; we validate this and other predictions in\nthe neural data, as well as build and interpret a simple synthetic model that\nrecapitulates these phenomena. We conclude by showing how this model of\nlate-time feature learning implies an explanation for the empirical puzzle of\novertraining reversal in animal learning, where task-specific representations\nare more robust to particular task changes because the learned features can be\nreused.\n","authors":["Tanishq Kumar","Blake Bordelon","Cengiz Pehlevan","Venkatesh N. Murthy","Samuel J. Gershman"],"pdf_url":"https://arxiv.org/pdf/2411.03541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13971v2","updated":"2024-11-05T22:41:13Z","published":"2024-01-25T06:06:31Z","title":"Stochastic Weakly Convex Optimization Beyond Lipschitz Continuity","summary":"  This paper considers stochastic weakly convex optimization without the\nstandard Lipschitz continuity assumption. Based on new adaptive regularization\n(stepsize) strategies, we show that a wide class of stochastic algorithms,\nincluding the stochastic subgradient method, preserve the $\\mathcal{O} ( 1 /\n\\sqrt{K})$ convergence rate with constant failure rate. Our analyses rest on\nrather weak assumptions: the Lipschitz parameter can be either bounded by a\ngeneral growth function of $\\|x\\|$ or locally estimated through independent\nrandom samples.\n","authors":["Wenzhi Gao","Qi Deng"],"pdf_url":"https://arxiv.org/pdf/2401.13971v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03538v1","updated":"2024-11-05T22:37:43Z","published":"2024-11-05T22:37:43Z","title":"Long Context RAG Performance of Large Language Models","summary":"  Retrieval Augmented Generation (RAG) has emerged as a crucial technique for\nenhancing the accuracy of Large Language Models (LLMs) by incorporating\nexternal information. With the advent of LLMs that support increasingly longer\ncontext lengths, there is a growing interest in understanding how these models\nperform in RAG scenarios. Can these new long context models improve RAG\nperformance? This paper presents a comprehensive study of the impact of\nincreased context length on RAG performance across 20 popular open source and\ncommercial LLMs. We ran RAG workflows while varying the total context length\nfrom 2,000 to 128,000 tokens (and 2 million tokens when possible) on three\ndomain-specific datasets, and report key insights on the benefits and\nlimitations of long context in RAG applications. Our findings reveal that while\nretrieving more documents can improve performance, only a handful of the most\nrecent state of the art LLMs can maintain consistent accuracy at long context\nabove 64k tokens. We also identify distinct failure modes in long context\nscenarios, suggesting areas for future research.\n","authors":["Quinn Leng","Jacob Portes","Sam Havens","Matei Zaharia","Michael Carbin"],"pdf_url":"https://arxiv.org/pdf/2411.03538v1.pdf","comment":"2024 NeurIPS workshop on Adaptive Foundation Models: Evolving AI for\n  Personalized and Efficient Learning"},{"id":"http://arxiv.org/abs/2411.03537v1","updated":"2024-11-05T22:36:17Z","published":"2024-11-05T22:36:17Z","title":"Two-Stage Pretraining for Molecular Property Prediction in the Wild","summary":"  Accurate property prediction is crucial for accelerating the discovery of new\nmolecules. Although deep learning models have achieved remarkable success,\ntheir performance often relies on large amounts of labeled data that are\nexpensive and time-consuming to obtain. Thus, there is a growing need for\nmodels that can perform well with limited experimentally-validated data. In\nthis work, we introduce MoleVers, a versatile pretrained model designed for\nvarious types of molecular property prediction in the wild, i.e., where\nexperimentally-validated molecular property labels are scarce. MoleVers adopts\na two-stage pretraining strategy. In the first stage, the model learns\nmolecular representations from large unlabeled datasets via masked atom\nprediction and dynamic denoising, a novel task enabled by a new branching\nencoder architecture. In the second stage, MoleVers is further pretrained using\nauxiliary labels obtained with inexpensive computational methods, enabling\nsupervised learning without the need for costly experimental data. This\ntwo-stage framework allows MoleVers to learn representations that generalize\neffectively across various downstream datasets. We evaluate MoleVers on a new\nbenchmark comprising 22 molecular datasets with diverse types of properties,\nthe majority of which contain 50 or fewer training labels reflecting real-world\nconditions. MoleVers achieves state-of-the-art results on 20 out of the 22\ndatasets, and ranks second among the remaining two, highlighting its ability to\nbridge the gap between data-hungry models and real-world conditions where\npractically-useful labels are scarce.\n","authors":["Kevin Tirta Wijaya","Minghao Guo","Michael Sun","Hans-Peter Seidel","Wojciech Matusik","Vahid Babaei"],"pdf_url":"https://arxiv.org/pdf/2411.03537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02401v2","updated":"2024-11-05T22:33:52Z","published":"2023-12-05T00:11:09Z","title":"Enhancing Content Moderation with Culturally-Aware Models","summary":"  Content moderation on a global scale must navigate a complex array of local\ncultural distinctions, which can hinder effective enforcement. While global\npolicies aim for consistency and broad applicability, they often miss the\nsubtleties of regional language interpretation, cultural beliefs, and local\nlegislation. This work introduces a flexible framework that enhances foundation\nlanguage models with cultural knowledge. Our approach involves fine-tuning\nencoder-decoder models on media-diet data to capture cultural nuances, and\napplies a continued training regime to effectively integrate these models into\na content moderation pipeline. We evaluate this framework in a case study of an\nonline podcast platform with content spanning various regions. The results show\nthat our culturally adapted models improve the accuracy of local violation\ndetection and offer explanations that align more closely with regional cultural\nnorms. Our findings reinforce the need for an adaptable content moderation\napproach that remains flexible in response to the diverse cultural landscapes\nit operates in and represents a step towards a more equitable and culturally\nsensitive framework for content moderation, demonstrating what is achievable in\nthis domain.\n","authors":["Alex J. Chan","José Luis Redondo García","Fabrizio Silvestri","Colm O'Donnell","Konstantina Palla"],"pdf_url":"https://arxiv.org/pdf/2312.02401v2.pdf","comment":"7 pages, 7 Figures. Supplementary material"},{"id":"http://arxiv.org/abs/2411.03535v1","updated":"2024-11-05T22:26:51Z","published":"2024-11-05T22:26:51Z","title":"The Differentiable Feasibility Pump","summary":"  Although nearly 20 years have passed since its conception, the feasibility\npump algorithm remains a widely used heuristic to find feasible primal\nsolutions to mixed-integer linear problems. Many extensions of the initial\nalgorithm have been proposed. Yet, its core algorithm remains centered around\ntwo key steps: solving the linear relaxation of the original problem to obtain\na solution that respects the constraints, and rounding it to obtain an integer\nsolution. This paper shows that the traditional feasibility pump and many of\nits follow-ups can be seen as gradient-descent algorithms with specific\nparameters. A central aspect of this reinterpretation is observing that the\ntraditional algorithm differentiates the solution of the linear relaxation with\nrespect to its cost. This reinterpretation opens many opportunities for\nimproving the performance of the original algorithm. We study how to modify the\ngradient-update step as well as extending its loss function. We perform\nextensive experiments on MIPLIB instances and show that these modifications can\nsubstantially reduce the number of iterations needed to find a solution.\n","authors":["Matteo Cacciola","Alexandre Forel","Antonio Frangioni","Andrea Lodi"],"pdf_url":"https://arxiv.org/pdf/2411.03535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05269v3","updated":"2024-11-05T22:08:14Z","published":"2023-12-07T19:19:25Z","title":"LifelongMemory: Leveraging LLMs for Answering Queries in Long-form\n  Egocentric Videos","summary":"  In this paper we introduce LifelongMemory, a new framework for accessing\nlong-form egocentric videographic memory through natural language question\nanswering and retrieval. LifelongMemory generates concise video activity\ndescriptions of the camera wearer and leverages the zero-shot capabilities of\npretrained large language models to perform reasoning over long-form video\ncontext. Furthermore, LifelongMemory uses a confidence and explanation module\nto produce confident, high-quality, and interpretable answers. Our approach\nachieves state-of-the-art performance on the EgoSchema benchmark for question\nanswering and is highly competitive on the natural language query (NLQ)\nchallenge of Ego4D. Code is available at\nhttps://github.com/agentic-learning-ai-lab/lifelong-memory.\n","authors":["Ying Wang","Yanlai Yang","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2312.05269v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21696v2","updated":"2024-11-05T22:03:21Z","published":"2024-10-29T03:27:08Z","title":"The Effects of Multi-Task Learning on ReLU Neural Network Functions","summary":"  This paper studies the properties of solutions to multi-task shallow ReLU\nneural network learning problems, wherein the network is trained to fit a\ndataset with minimal sum of squared weights. Remarkably, the solutions learned\nfor each individual task resemble those obtained by solving a kernel method,\nrevealing a novel connection between neural networks and kernel methods. It is\nknown that single-task neural network training problems are equivalent to\nminimum norm interpolation problem in a non-Hilbertian Banach space, and that\nthe solutions of such problems are generally non-unique. In contrast, we prove\nthat the solutions to univariate-input, multi-task neural network interpolation\nproblems are almost always unique, and coincide with the solution to a\nminimum-norm interpolation problem in a Sobolev (Reproducing Kernel) Hilbert\nSpace. We also demonstrate a similar phenomenon in the multivariate-input case;\nspecifically, we show that neural network learning problems with large numbers\nof diverse tasks are approximately equivalent to an $\\ell^2$ (Hilbert space)\nminimization problem over a fixed kernel determined by the optimal neurons.\n","authors":["Julia Nakhleh","Joseph Shenouda","Robert D. Nowak"],"pdf_url":"https://arxiv.org/pdf/2410.21696v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03527v1","updated":"2024-11-05T22:03:14Z","published":"2024-11-05T22:03:14Z","title":"PACE: Pacing Operator Learning to Accurate Optical Field Simulation for\n  Complicated Photonic Devices","summary":"  Electromagnetic field simulation is central to designing, optimizing, and\nvalidating photonic devices and circuits. However, costly computation\nassociated with numerical simulation poses a significant bottleneck, hindering\nscalability and turnaround time in the photonic circuit design process. Neural\noperators offer a promising alternative, but existing SOTA approaches,\nNeurOLight, struggle with predicting high-fidelity fields for real-world\ncomplicated photonic devices, with the best reported 0.38 normalized mean\nabsolute error in NeurOLight. The inter-plays of highly complex light-matter\ninteraction, e.g., scattering and resonance, sensitivity to local structure\ndetails, non-uniform learning complexity for full-domain simulation, and rich\nfrequency information, contribute to the failure of existing neural PDE\nsolvers. In this work, we boost the prediction fidelity to an unprecedented\nlevel for simulating complex photonic devices with a novel operator design\ndriven by the above challenges. We propose a novel cross-axis factorized PACE\noperator with a strong long-distance modeling capacity to connect the\nfull-domain complex field pattern with local device structures. Inspired by\nhuman learning, we further divide and conquer the simulation task for extremely\nhard cases into two progressively easy tasks, with a first-stage model learning\nan initial solution refined by a second model. On various complicated photonic\ndevice benchmarks, we demonstrate one sole PACE model is capable of achieving\n73% lower error with 50% fewer parameters compared with various recent ML for\nPDE solvers. The two-stage setup further advances high-fidelity simulation for\neven more intricate cases. In terms of runtime, PACE demonstrates 154-577x and\n11.8-12x simulation speedup over numerical solver using scipy or\nhighly-optimized pardiso solver, respectively. We open sourced the code and\ndataset.\n","authors":["Hanqing Zhu","Wenyan Cong","Guojin Chen","Shupeng Ning","Ray T. Chen","Jiaqi Gu","David Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2411.03527v1.pdf","comment":"Accepeted by Neurips 2024, 21 pages"},{"id":"http://arxiv.org/abs/2411.03522v1","updated":"2024-11-05T21:57:38Z","published":"2024-11-05T21:57:38Z","title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs","summary":"  Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.\n","authors":["Wei Wang","Zhichao Hou","Xiaorui Liu","Xinxia Peng"],"pdf_url":"https://arxiv.org/pdf/2411.03522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03202v3","updated":"2024-11-05T21:56:51Z","published":"2023-06-05T19:22:02Z","title":"Nonlinear Distributionally Robust Optimization","summary":"  This article focuses on a class of distributionally robust optimization (DRO)\nproblems where, unlike the growing body of the literature, the objective\nfunction is potentially nonlinear in the distribution. Existing methods to\noptimize nonlinear functions in probability space use the Frechet derivatives,\nwhich present theoretical and computational challenges. Motivated by this, we\npropose an alternative notion for the derivative and corresponding smoothness\nbased on Gateaux (G)-derivative for generic risk measures. These concepts are\nexplained via three running risk measure examples of variance, entropic risk,\nand risk on finite support sets. We then propose a G-derivative-based\nFrank-Wolfe (FW) algorithm for generic nonlinear optimization problems in\nprobability spaces and establish its convergence under the proposed notion of\nsmoothness in a completely norm-independent manner. We use the set-up of the FW\nalgorithm to devise a methodology to compute a saddle point of the nonlinear\nDRO problem. Finally, we validate our theoretical results on two cases of the\n$entropic$ and $variance$ risk measures in the context of portfolio selection\nproblems. In particular, we analyze their regularity conditions and \"sufficient\nstatistic\", compute the respective FW-oracle in various settings, and confirm\nthe theoretical outcomes through numerical validation.\n","authors":["Mohammed Rayyan Sheriff","Peyman Mohajerin Esfahani"],"pdf_url":"https://arxiv.org/pdf/2306.03202v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03520v1","updated":"2024-11-05T21:54:50Z","published":"2024-11-05T21:54:50Z","title":"Forecasting Outside the Box: Application-Driven Optimal Pointwise\n  Forecasts for Stochastic Optimization","summary":"  The exponential growth in data availability in recent years has led to new\nformulations of data-driven optimization problems. One such formulation is that\nof stochastic optimization problems with contextual information, where the goal\nis to optimize the expected value of a certain function given some contextual\ninformation (also called features) that accompany the main data of interest.\nThe contextual information then allows for a better estimation of the quantity\nof interest via machine learning methods, thereby leading to better solutions.\nOftentimes, however, machine learning methods yield just a pointwise estimate\ninstead of an entire distribution. In this paper we show that, when the problem\nto be solved is a class of two-stage stochastic programs (namely, those with\nfixed recourse matrix and fixed costs), under mild assumptions the problem can\nbe solved with just one scenario. While such a scenario - which does not have\nbe unique - is usually unknown, we present an integrated learning and\noptimization procedure that yields the best approximation of that scenario\nwithin the modeler's pre-specified set of parameterized forecast functions.\nNumerical results conducted with inventory problems from the literature (with\nsynthetic data) as well as a bike-sharing problem with real data demonstrate\nthat the proposed approach performs well when compared to benchmark methods\nfrom the literature.\n","authors":["Tito Homem-de-Mello","Juan Valencia","Felipe Lagos","Guido Lagos"],"pdf_url":"https://arxiv.org/pdf/2411.03520v1.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2411.03519v1","updated":"2024-11-05T21:54:14Z","published":"2024-11-05T21:54:14Z","title":"AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation\n  with Out-of-order Execution","summary":"  With more advanced natural language understanding and reasoning capabilities,\nlarge language model (LLM)-powered agents are increasingly developed in\nsimulated environments to perform complex tasks, interact with other agents,\nand exhibit emergent behaviors relevant to social science and gaming. However,\ncurrent multi-agent simulations frequently suffer from inefficiencies due to\nthe limited parallelism caused by false dependencies, resulting in performance\nbottlenecks. In this paper, we introduce AI Metropolis, a simulation engine\nthat improves the efficiency of LLM agent simulations by incorporating\nout-of-order execution scheduling. By dynamically tracking real dependencies\nbetween agents, AI Metropolis minimizes false dependencies, enhancing\nparallelism and enabling efficient hardware utilization. Our evaluations\ndemonstrate that AI Metropolis achieves speedups from 1.3x to 4.15x over\nstandard parallel simulation with global synchronization, approaching optimal\nperformance as the number of agents increases.\n","authors":["Zhiqiang Xie","Hao Kang","Ying Sheng","Tushar Krishna","Kayvon Fatahalian","Christos Kozyrakis"],"pdf_url":"https://arxiv.org/pdf/2411.03519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12352v2","updated":"2024-11-05T21:46:50Z","published":"2023-05-21T05:11:30Z","title":"Pre-trained Mixed Integer Optimization through Multi-variable\n  Cardinality Branching","summary":"  In this paper, we propose a Pre-trained Mixed Integer Optimization framework\n(PreMIO) that accelerates online mixed integer program (MIP) solving with\noffline datasets and machine learning models. Our method is based on a\ndata-driven multi-variable cardinality branching procedure that splits the MIP\nfeasible region using hyperplanes chosen by the concentration inequalities.\nUnlike most previous ML+MIP approaches that either require complicated\nimplementation or suffer from a lack of theoretical justification, our method\nis simple, flexible, provable, and explainable. Numerical experiments on both\nclassical OR benchmark datasets and real-life instances validate the efficiency\nof our proposed method.\n","authors":["Yanguang Chen","Wenzhi Gao","Dongdong Ge","Yinyu Ye"],"pdf_url":"https://arxiv.org/pdf/2305.12352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03517v1","updated":"2024-11-05T21:43:05Z","published":"2024-11-05T21:43:05Z","title":"Understanding Contrastive Learning via Gaussian Mixture Models","summary":"  Contrastive learning attempts to learn representations from un-labeled data;\nit does so via a loss function that encourages the embedding of a point to be\nclose to that of its augmentations, and far from the embeddings of random other\npoints. This simple idea performs remarkably well, yet it is not precisely\ntheoretically understood why this is the case. In this paper we analyze\ncontrastive learning (specifically, the InfoNCE loss) in a natural context:\ndimensionality reduction in Gaussian Mixture Models. Crucially, we define an\naugmentation of a data point as being another independent draw from the same\nunderlying mixture component. We show that vanilla InfoNCE is able to find the\noptimal lower-dimensional subspace even when the Gaussians are not isotropic --\nsomething that vanilla spectral techniques cannot do. We further extend our\nanalyses to multi-modal contrastive learning algorithms (e.g., CLIP). In this\nsetting we show that contrastive learning learns the subset of fisher-optimal\nsubspace, effectively filtering out all the noise from the learnt\nrepresentations.\n","authors":["Parikshit Bansal","Ali Kavis","Sujay Sanghavi"],"pdf_url":"https://arxiv.org/pdf/2411.03517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12136v2","updated":"2024-11-05T21:28:34Z","published":"2024-08-22T05:38:48Z","title":"Domain Adaptation for Offline Reinforcement Learning with Limited\n  Samples","summary":"  Offline reinforcement learning (RL) learns effective policies from a static\ntarget dataset. Despite state-of-the-art (SOTA) offline RL algorithms being\npromising, they highly rely on the quality of the target dataset. The\nperformance of SOTA algorithms can degrade in scenarios with limited samples in\nthe target dataset, which is often the case in real-world applications. To\naddress this issue, domain adaptation that leverages auxiliary samples from\nrelated source datasets (such as simulators) can be beneficial. In this\ncontext, determining the optimal way to trade off the source and target\ndatasets remains a critical challenge in offline RL. To the best of our\nknowledge, this paper proposes the first framework that theoretically and\nexperimentally explores how the weight assigned to each dataset affects the\nperformance of offline RL. We establish the performance bounds and convergence\nneighborhood of our framework, both of which depend on the selection of the\nweight. Furthermore, we identify the existence of an optimal weight for\nbalancing the two datasets. All theoretical guarantees and optimal weight\ndepend on the quality of the source dataset and the size of the target dataset.\nOur empirical results on the well-known Procgen Benchmark substantiate our\ntheoretical contributions.\n","authors":["Weiqin Chen","Sandipan Mishra","Santiago Paternain"],"pdf_url":"https://arxiv.org/pdf/2408.12136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02304v5","updated":"2024-11-05T21:27:42Z","published":"2024-02-04T00:07:05Z","title":"Efficient Numerical Wave Propagation Enhanced By An End-to-End Deep\n  Learning Model","summary":"  In a variety of scientific and engineering domains, the need for\nhigh-fidelity and efficient solutions for high-frequency wave propagation holds\ngreat significance. Recent advances in wave modeling use sufficiently accurate\nfine solver outputs to train a neural network that enhances the accuracy of a\nfast but inaccurate coarse solver. In this paper we build upon the work of\nNguyen and Tsai (2023) and present a novel unified system that integrates a\nnumerical solver with a deep learning component into an end-to-end framework.\nIn the proposed setting, we investigate refinements to the network architecture\nand data generation algorithm. A stable and fast solver further allows the use\nof Parareal, a parallel-in-time algorithm to correct high-frequency wave\ncomponents. Our results show that the cohesive structure improves performance\nwithout sacrificing speed, and demonstrate the importance of temporal dynamics,\nas well as Parareal, for accurate wave propagation.\n","authors":["Luis Kaiser","Richard Tsai","Christian Klingenberg"],"pdf_url":"https://arxiv.org/pdf/2402.02304v5.pdf","comment":"To appear in the proceedings of ENUMATH 2023"},{"id":"http://arxiv.org/abs/2406.06420v2","updated":"2024-11-05T21:26:58Z","published":"2024-06-10T16:12:32Z","title":"An Improved Empirical Fisher Approximation for Natural Gradient Descent","summary":"  Approximate Natural Gradient Descent (NGD) methods are an important family of\noptimisers for deep learning models, which use approximate Fisher information\nmatrices to pre-condition gradients during training. The empirical Fisher (EF)\nmethod approximates the Fisher information matrix empirically by reusing the\nper-sample gradients collected during back-propagation. Despite its ease of\nimplementation, the EF approximation has its theoretical and practical\nlimitations. This paper investigates the inversely-scaled projection issue of\nEF, which is shown to be a major cause of its poor empirical approximation\nquality. An improved empirical Fisher (iEF) method is proposed to address this\nissue, which is motivated as a generalised NGD method from a loss reduction\nperspective, meanwhile retaining the practical convenience of EF. The exact iEF\nand EF methods are experimentally evaluated using practical deep learning\nsetups. Optimisation experiments show that applying exact iEF directly as an\noptimiser provides strong convergence and generalisation. Additionally, under a\nnovel empirical evaluation framework, the proposed iEF method shows\nconsistently better approximation quality to exact Natural Gradient updates\nthan both the EF and the more expensive sampled Fisher methods, meanwhile\ndemonstrating the superior property of being robust to the choice of damping\nacross tasks and training stages. Improving existing approximate NGD optimisers\nwith iEF is expected to lead to better convergence and robustness. Furthermore,\nthe iEF method also serves as a better approximation method to the Fisher\ninformation matrix itself, which enables the improvement of a variety of\nFisher-based methods, not limited to the scope of optimisation.\n","authors":["Xiaodong Wu","Wenyi Yu","Chao Zhang","Philip Woodland"],"pdf_url":"https://arxiv.org/pdf/2406.06420v2.pdf","comment":"37 pages, 15 figures, 8 tables"},{"id":"http://arxiv.org/abs/2411.03513v1","updated":"2024-11-05T21:19:49Z","published":"2024-11-05T21:19:49Z","title":"Change Is the Only Constant: Dynamic LLM Slicing based on Layer\n  Redundancy","summary":"  This paper introduces a novel model compression approach through dynamic\nlayer-specific pruning in Large Language Models (LLMs), enhancing the\ntraditional methodology established by SliceGPT. By transitioning from constant\nto dynamic slicing, our method leverages the newly proposed Layer Redundancy\n(LR) score, which assesses how much change each layer changes its input by\nmeasuring the cosine similarity of the input to the output of the layer. We use\nthis score to prune parts of individual layers based on redundancy in such a\nway that the average pruned percentage for all layers is a fixed value. We\nconducted extensive experiments using models like Llama3-8B and Mistral-7B on\nmultiple datasets, evaluating different slicing bases and percentages to\ndetermine optimal configurations that balance efficiency and performance. Our\nfindings show that our dynamic slicing approach not only maintains but, in many\ncases, enhances model performance compared to the baseline established by\nconstant slicing methods. For instance, in several settings, we see performance\nimprovements of up to 5% over the SliceGPT baseline. Additionally, a perplexity\ndecrease by as much as 7% was observed across multiple benchmarks, validating\nthe effectiveness of our method. The code, model weights, and datasets are\nopen-sourced at https://github.com/RazvanDu/DynamicSlicing.\n","authors":["Razvan-Gabriel Dumitru","Paul-Ioan Clotan","Vikas Yadav","Darius Peteleaza","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2411.03513v1.pdf","comment":"Accepted at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2312.14322v3","updated":"2024-11-05T21:18:45Z","published":"2023-12-21T22:27:32Z","title":"Data needs and challenges for quantum dot devices automation","summary":"  Gate-defined quantum dots are a promising candidate system for realizing\nscalable, coupled qubit systems and serving as a fundamental building block for\nquantum computers. However, present-day quantum dot devices suffer from\nimperfections that must be accounted for, which hinders the characterization,\ntuning, and operation process. Moreover, with an increasing number of quantum\ndot qubits, the relevant parameter space grows sufficiently to make heuristic\ncontrol infeasible. Thus, it is imperative that reliable and scalable\nautonomous tuning approaches are developed. This meeting report outlines\ncurrent challenges in automating quantum dot device tuning and operation with a\nparticular focus on datasets, benchmarking, and standardization. We also\npresent insights and ideas put forward by the quantum dot community on how to\novercome them. We aim to provide guidance and inspiration to researchers\ninvested in automation efforts.\n","authors":["Justyna P. Zwolak","Jacob M. Taylor","Reed W. Andrews","Jared Benson","Garnett W. Bryant","Donovan Buterakos","Anasua Chatterjee","Sankar Das Sarma","Mark A. Eriksson","Eliška Greplová","Michael J. Gullans","Fabian Hader","Tyler J. Kovach","Pranav S. Mundada","Mick Ramsey","Torbjørn Rasmussen","Brandon Severin","Anthony Sigillito","Brennan Undseth","Brian Weber"],"pdf_url":"https://arxiv.org/pdf/2312.14322v3.pdf","comment":"A meeting report from a workshop held at the National Institute of\n  Standards and Technology, Gaithersburg, MD"},{"id":"http://arxiv.org/abs/2409.06343v2","updated":"2024-11-05T21:17:46Z","published":"2024-09-10T08:52:24Z","title":"Compute-Update Federated Learning: A Lattice Coding Approach\n  Over-the-Air","summary":"  This paper introduces a federated learning framework that enables\nover-the-air computation via digital communications, using a new joint\nsource-channel coding scheme. Without relying on channel state information at\ndevices, this scheme employs lattice codes to both quantize model parameters\nand exploit interference from the devices. We propose a novel receiver\nstructure at the server, designed to reliably decode an integer combination of\nthe quantized model parameters as a lattice point for the purpose of\naggregation. We present a mathematical approach to derive a convergence bound\nfor the proposed scheme and offer design remarks. In this context, we suggest\nan aggregation metric and a corresponding algorithm to determine effective\ninteger coefficients for the aggregation in each communication round. Our\nresults illustrate that, regardless of channel dynamics and data heterogeneity,\nour scheme consistently delivers superior learning accuracy across various\nparameters and markedly surpasses other over-the-air methodologies.\n","authors":["Seyed Mohammad Azimi-Abarghouyi","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2409.06343v2.pdf","comment":"Extended version of the preprint available at arXiv:2403.01023"},{"id":"http://arxiv.org/abs/2411.01803v2","updated":"2024-11-05T21:16:44Z","published":"2024-11-04T05:04:18Z","title":"Gradient Methods with Online Scaling","summary":"  We introduce a framework to accelerate the convergence of gradient-based\nmethods with online learning. The framework learns to scale the gradient at\neach iteration through an online learning algorithm and provably accelerates\ngradient-based methods asymptotically. In contrast with previous literature,\nwhere convergence is established based on worst-case analysis, our framework\nprovides a strong convergence guarantee with respect to the optimal scaling\nmatrix for the iteration trajectory. For smooth strongly convex optimization,\nour results provide an $O(\\kappa^\\star \\log(1/\\varepsilon)$) complexity result,\nwhere $\\kappa^\\star$ is the condition number achievable by the optimal\npreconditioner, improving on the previous $O(\\sqrt{n}\\kappa^\\star\n\\log(1/\\varepsilon))$ result. In particular, a variant of our method achieves\nsuperlinear convergence on convex quadratics. For smooth convex optimization,\nwe show for the first time that the widely-used hypergradient descent heuristic\nimproves on the convergence of gradient descent.\n","authors":["Wenzhi Gao","Ya-Chi Chu","Yinyu Ye","Madeleine Udell"],"pdf_url":"https://arxiv.org/pdf/2411.01803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00143v2","updated":"2024-11-05T21:04:23Z","published":"2024-02-29T21:49:31Z","title":"Tree-Averaging Algorithms for Ensemble-Based Unsupervised Discontinuous\n  Constituency Parsing","summary":"  We address unsupervised discontinuous constituency parsing, where we observe\na high variance in the performance of the only previous model in the\nliterature. We propose to build an ensemble of different runs of the existing\ndiscontinuous parser by averaging the predicted trees, to stabilize and boost\nperformance. To begin with, we provide comprehensive computational complexity\nanalysis (in terms of P and NP-complete) for tree averaging under different\nsetups of binarity and continuity. We then develop an efficient exact algorithm\nto tackle the task, which runs in a reasonable time for all samples in our\nexperiments. Results on three datasets show our method outperforms all\nbaselines in all metrics; we also provide in-depth analyses of our approach.\n","authors":["Behzad Shayegh","Yuqiao Wen","Lili Mou"],"pdf_url":"https://arxiv.org/pdf/2403.00143v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01645v2","updated":"2024-11-05T21:02:11Z","published":"2024-11-03T17:45:00Z","title":"Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive\n  Ablation Study for Ensemble Classifiers","summary":"  Feature engineering is crucial for optimizing machine learning model\nperformance, particularly in tabular data classification tasks. Leveraging\nadvancements in natural language processing, this study presents a systematic\napproach to enrich tabular datasets with features derived from large language\nmodel embeddings. Through a comprehensive ablation study on diverse datasets,\nwe assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,\nincluding Random Forest, XGBoost, and CatBoost. Results indicate that\nintegrating embeddings with traditional numerical and categorical features\noften enhances predictive performance, especially on datasets with class\nimbalance or limited features and samples, such as UCI Adult, Heart Disease,\nTitanic, and Pima Indian Diabetes, with improvements particularly notable in\nXGBoost and CatBoost classifiers. Additionally, feature importance analysis\nreveals that LLM-derived features frequently rank among the most impactful for\nthe predictions. This study provides a structured approach to embedding-based\nfeature enrichment and illustrates its benefits in ensemble learning for\ntabular data.\n","authors":["Gjergji Kasneci","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2411.01645v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04090v2","updated":"2024-11-05T20:51:06Z","published":"2024-06-06T14:01:28Z","title":"Interpretable Lightweight Transformer via Unrolling of Learned Graph\n  Smoothness Priors","summary":"  We build interpretable and lightweight transformer-like neural networks by\nunrolling iterative optimization algorithms that minimize graph smoothness\npriors -- the quadratic graph Laplacian regularizer (GLR) and the $\\ell_1$-norm\ngraph total variation (GTV) -- subject to an interpolation constraint. The\ncrucial insight is that a normalized signal-dependent graph learning module\namounts to a variant of the basic self-attention mechanism in conventional\ntransformers. Unlike \"black-box\" transformers that require learning of large\nkey, query and value matrices to compute scaled dot products as affinities and\nsubsequent output embeddings, resulting in huge parameter sets, our unrolled\nnetworks employ shallow CNNs to learn low-dimensional features per node to\nestablish pairwise Mahalanobis distances and construct sparse similarity\ngraphs. At each layer, given a learned graph, the target interpolated signal is\nsimply a low-pass filtered output derived from the minimization of an assumed\ngraph smoothness prior, leading to a dramatic reduction in parameter count.\nExperiments for two image interpolation applications verify the restoration\nperformance, parameter efficiency and robustness to covariate shift of our\ngraph-based unrolled networks compared to conventional transformers.\n","authors":["Tam Thuc Do","Parham Eftekhar","Seyed Alireza Hosseini","Gene Cheung","Philip Chou"],"pdf_url":"https://arxiv.org/pdf/2406.04090v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03494v1","updated":"2024-11-05T20:18:29Z","published":"2024-11-05T20:18:29Z","title":"An Open-source Sim2Real Approach for Sensor-independent Robot Navigation\n  in a Grid","summary":"  This paper presents a Sim2Real (Simulation to Reality) approach to bridge the\ngap between a trained agent in a simulated environment and its real-world\nimplementation in navigating a robot in a similar setting. Specifically, we\nfocus on navigating a quadruped robot in a real-world grid-like environment\ninspired by the Gymnasium Frozen Lake -- a highly user-friendly and free\nApplication Programming Interface (API) to develop and test Reinforcement\nLearning (RL) algorithms. We detail the development of a pipeline to transfer\nmotion policies learned in the Frozen Lake simulation to a physical quadruped\nrobot, thus enabling autonomous navigation and obstacle avoidance in a grid\nwithout relying on expensive localization and mapping sensors. The work\ninvolves training an RL agent in the Frozen Lake environment and utilizing the\nresulting Q-table to control a 12 Degrees-of-Freedom (DOF) quadruped robot. In\naddition to detailing the RL implementation, inverse kinematics-based quadruped\ngaits, and the transfer policy pipeline, we open-source the project on GitHub\nand include a demonstration video of our Sim2Real transfer approach. This work\nprovides an accessible, straightforward, and low-cost framework for\nresearchers, students, and hobbyists to explore and implement RL-based robot\nnavigation in real-world grid environments.\n","authors":["Murad Mehrab Abrar","Souryadeep Mondal","Michelle Hickner"],"pdf_url":"https://arxiv.org/pdf/2411.03494v1.pdf","comment":"Accepted for publication at the 9th IEEE International Conference on\n  Robotics and Automation Engineering (IEEE ICRAE 2024), Singapore"},{"id":"http://arxiv.org/abs/2411.03493v1","updated":"2024-11-05T20:18:28Z","published":"2024-11-05T20:18:28Z","title":"LASER: Attention with Exponential Transformation","summary":"  Transformers have had tremendous impact for several sequence related tasks,\nlargely due to their ability to retrieve from any part of the sequence via\nsoftmax based dot-product attention. This mechanism plays a crucial role in\nTransformer's performance. We analyze the gradients backpropagated through the\nsoftmax operation in the attention mechanism and observe that these gradients\ncan often be small. This poor gradient signal backpropagation can lead to\ninefficient learning of parameters preceeding the attention operations. To this\nend, we introduce a new attention mechanism called LASER, which we analytically\nshow to admit a larger gradient signal. We show that LASER Attention can be\nimplemented by making small modifications to existing attention\nimplementations. We conduct experiments on autoregressive large language models\n(LLMs) with upto 2.2 billion parameters where we show upto 3.38% and an average\nof ~1% improvement over standard attention on downstream evaluations. Using\nLASER gives the following relative improvements in generalization performance\nacross a variety of tasks (vision, text and speech): 4.67% accuracy in Vision\nTransformer (ViT) on Imagenet, 2.25% error rate in Conformer on the Librispeech\nspeech-to-text and 0.93% fraction of incorrect predictions in BERT with 2.2\nbillion parameters.\n","authors":["Sai Surya Duvvuri","Inderjit S. Dhillon"],"pdf_url":"https://arxiv.org/pdf/2411.03493v1.pdf","comment":"15 pages, under review in ICLR 2025"},{"id":"http://arxiv.org/abs/2401.08426v4","updated":"2024-11-05T19:57:19Z","published":"2024-01-16T15:11:29Z","title":"GD doesn't make the cut: Three ways that non-differentiability affects\n  neural network training","summary":"  This paper investigates the distinctions between gradient methods applied to\nnon-differentiable functions (NGDMs) and classical gradient descents (GDs)\ndesigned for differentiable functions. First, we demonstrate significant\ndifferences in the convergence properties of NGDMs compared to GDs, challenging\nthe applicability of the extensive neural network convergence literature based\non $L-smoothness$ to non-smooth neural networks. Next, we demonstrate the\nparadoxical nature of NGDM solutions for $L_{1}$-regularized problems, showing\nthat increasing the regularization penalty leads to an increase in the $L_{1}$\nnorm of optimal solutions in NGDMs. Consequently, we show that widely adopted\n$L_{1}$ penalization-based techniques for network pruning do not yield expected\nresults. Additionally, we dispel the common belief that optimization algorithms\nlike Adam and RMSProp perform similarly in non-differentiable contexts.\nFinally, we explore the Edge of Stability phenomenon, indicating its\ninapplicability even to Lipschitz continuous convex differentiable functions,\nleaving its relevance to non-convex non-differentiable neural networks\ninconclusive. Our analysis exposes misguided interpretations of NGDMs in widely\nreferenced papers and texts due to an overreliance on strong smoothness\nassumptions, emphasizing the necessity for a nuanced understanding of\nfoundational assumptions in the analysis of these systems.\n","authors":["Siddharth Krishna Kumar"],"pdf_url":"https://arxiv.org/pdf/2401.08426v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01137v4","updated":"2024-11-05T19:47:03Z","published":"2024-10-02T00:19:20Z","title":"Explain Like I'm Five: Using LLMs to Improve PDE Surrogate Models with\n  Text","summary":"  Solving Partial Differential Equations (PDEs) is ubiquitous in science and\nengineering. Computational complexity and difficulty in writing numerical\nsolvers has motivated the development of machine learning techniques to\ngenerate solutions quickly. Many existing methods are purely data driven,\nrelying solely on numerical solution fields, rather than known system\ninformation such as boundary conditions and governing equations. However, the\nrecent rise in popularity of Large Language Models (LLMs) has enabled easy\nintegration of text in multimodal machine learning models. In this work, we use\npretrained LLMs to integrate various amounts known system information into PDE\nlearning. Our multimodal approach significantly outperforms our baseline model,\nFactFormer, in both next-step prediction and autoregressive rollout performance\non the 2D Heat, Burgers, Navier-Stokes, and Shallow Water equations. Further\nanalysis shows that pretrained LLMs provide highly structured latent space that\nis consistent with the amount of system information provided through text.\n","authors":["Cooper Lorsung","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2410.01137v4.pdf","comment":"22 pages, 15 figures, 7 tables"},{"id":"http://arxiv.org/abs/2408.07079v2","updated":"2024-11-05T19:44:03Z","published":"2024-08-07T14:04:50Z","title":"Anatomical Foundation Models for Brain MRIs","summary":"  Deep Learning (DL) in neuroimaging has become increasingly relevant for\ndetecting neurological conditions and neurodegenerative disorders. One of the\nmost predominant biomarkers in neuroimaging is represented by brain age, which\nhas been shown to be a good indicator for different conditions, such as\nAlzheimer's Disease. Using brain age for pretraining DL models in transfer\nlearning settings has also recently shown promising results, especially when\ndealing with data scarcity of different conditions. On the other hand,\nanatomical information of brain MRIs (e.g. cortical thickness) can provide\nimportant information for learning good representations that can be transferred\nto many downstream tasks. In this work, we propose AnatCL, an anatomical\nfoundation model for brain MRIs that i.) leverages anatomical information with\na weakly contrastive learning approach and ii.) achieves state-of-the-art\nperformances in many different downstream tasks. To validate our approach we\nconsider 12 different downstream tasks for diagnosis classification, and\nprediction of 10 different clinical assessment scores. Pretrained models can be\nfound at https://github.com/EIDOSLAB/AnatCL.\n","authors":["Carlo Alberto Barbano","Matteo Brunello","Benoit Dufumier","Marco Grangetto"],"pdf_url":"https://arxiv.org/pdf/2408.07079v2.pdf","comment":"12 pages; added source url"},{"id":"http://arxiv.org/abs/2401.08468v3","updated":"2024-11-05T19:38:30Z","published":"2024-01-16T16:18:17Z","title":"Nonparametric Evaluation of Noisy ICA Solutions","summary":"  Independent Component Analysis (ICA) was introduced in the 1980's as a model\nfor Blind Source Separation (BSS), which refers to the process of recovering\nthe sources underlying a mixture of signals, with little knowledge about the\nsource signals or the mixing process. While there are many sophisticated\nalgorithms for estimation, different methods have different shortcomings. In\nthis paper, we develop a nonparametric score to adaptively pick the right\nalgorithm for ICA with arbitrary Gaussian noise. The novelty of this score\nstems from the fact that it just assumes a finite second moment of the data and\nuses the characteristic function to evaluate the quality of the estimated\nmixing matrix without any knowledge of the parameters of the noise\ndistribution. In addition, we propose some new contrast functions and\nalgorithms that enjoy the same fast computability as existing algorithms like\nFASTICA and JADE but work in domains where the former may fail. While these\nalso may have weaknesses, our proposed diagnostic, as shown by our simulations,\ncan remedy them. Finally, we propose a theoretical framework to analyze the\nlocal and global convergence properties of our algorithms.\n","authors":["Syamantak Kumar","Purnamrita Sarkar","Peter Bickel","Derek Bean"],"pdf_url":"https://arxiv.org/pdf/2401.08468v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19202v4","updated":"2024-11-05T19:24:50Z","published":"2024-05-29T15:42:10Z","title":"Vulnerable Road User Detection and Safety Enhancement: A Comprehensive\n  Survey","summary":"  Traffic incidents involving vulnerable road users (VRUs) constitute a\nsignificant proportion of global road accidents. Advances in traffic\ncommunication ecosystems, coupled with sophisticated signal processing and\nmachine learning techniques, have facilitated the utilization of data from\ndiverse sensors. Despite these advancements and the availability of extensive\ndatasets, substantial progress is required to mitigate traffic casualties. This\npaper provides a comprehensive survey of state-of-the-art technologies and\nmethodologies to enhance the safety of VRUs. The study delves into the\ncommunication networks between vehicles and VRUs, emphasizing the integration\nof advanced sensors and the availability of relevant datasets. It explores\npreprocessing techniques and data fusion methods to enhance sensor data\nquality. Furthermore, our study assesses critical simulation environments\nessential for developing and testing VRU safety systems. Our research also\nhighlights recent advances in VRU detection and classification algorithms,\naddressing challenges such as variable environmental conditions. Additionally,\nwe cover cutting-edge research in predicting VRU intentions and behaviors,\nwhich is crucial for proactive collision avoidance strategies. Through this\nsurvey, we aim to provide a comprehensive understanding of the current\nlandscape of VRU safety technologies, identifying areas of progress and areas\nneeding further research and development.\n","authors":["Renato M. Silva","Gregório F. Azevedo","Matheus V. V. Berto","Jean R. Rocha","Eduardo C. Fidelis","Matheus V. Nogueira","Pedro H. Lisboa","Tiago A. Almeida"],"pdf_url":"https://arxiv.org/pdf/2405.19202v4.pdf","comment":"57 pages, 18 tables, 8 figures, citing 339 (up-to-date) papers,\n  preprint submitted to Expert Systems with Applications (Elsevier)"},{"id":"http://arxiv.org/abs/2411.03460v1","updated":"2024-11-05T19:20:30Z","published":"2024-11-05T19:20:30Z","title":"Pathway-Guided Optimization of Deep Generative Molecular Design Models\n  for Cancer Therapy","summary":"  The data-driven drug design problem can be formulated as an optimization task\nof a potentially expensive black-box objective function over a huge\nhigh-dimensional and structured molecular space. The junction tree variational\nautoencoder (JTVAE) has been shown to be an efficient generative model that can\nbe used for suggesting legitimate novel drug-like small molecules with improved\nproperties. While the performance of the generative molecular design (GMD)\nscheme strongly depends on the initial training data, one can improve its\nsampling efficiency for suggesting better molecules with enhanced properties by\noptimizing the latent space. In this work, we propose how mechanistic models -\nsuch as pathway models described by differential equations - can be used for\neffective latent space optimization(LSO) of JTVAEs and other similar models for\nGMD. To demonstrate the potential of our proposed approach, we show how a\npharmacodynamic model, assessing the therapeutic efficacy of a drug-like small\nmolecule by predicting how it modulates a cancer pathway, can be incorporated\nfor effective LSO of data-driven models for GMD.\n","authors":["Alif Bin Abdul Qayyum","Susan D. Mertins","Amanda K. Paulson","Nathan M. Urban","Byung-Jun Yoon"],"pdf_url":"https://arxiv.org/pdf/2411.03460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07240v4","updated":"2024-11-05T19:12:37Z","published":"2024-02-11T16:36:48Z","title":"Oja's Algorithm for Streaming Sparse PCA","summary":"  Oja's algorithm for Streaming Principal Component Analysis (PCA) for $n$\ndata-points in a $d$ dimensional space achieves the same sin-squared error\n$O(r_{\\mathsf{eff}}/n)$ as the offline algorithm in $O(d)$ space and $O(nd)$\ntime and a single pass through the datapoints. Here $r_{\\mathsf{eff}}$ is the\neffective rank (ratio of the trace and the principal eigenvalue of the\npopulation covariance matrix $\\Sigma$). Under this computational budget, we\nconsider the problem of sparse PCA, where the principal eigenvector of $\\Sigma$\nis $s$-sparse, and $r_{\\mathsf{eff}}$ can be large. In this setting, to our\nknowledge, \\textit{there are no known single-pass algorithms} that achieve the\nminimax error bound in $O(d)$ space and $O(nd)$ time without either requiring\nstrong initialization conditions or assuming further structure (e.g., spiked)\nof the covariance matrix. We show that a simple single-pass procedure that\nthresholds the output of Oja's algorithm (the Oja vector) can achieve the\nminimax error bound under some regularity conditions in $O(d)$ space and\n$O(nd)$ time. We present a nontrivial and novel analysis of the entries of the\nunnormalized Oja vector, which involves the projection of a product of\nindependent random matrices on a random initial vector. This is completely\ndifferent from previous analyses of Oja's algorithm and matrix products, which\nhave been done when the $r_{\\mathsf{eff}}$ is bounded.\n","authors":["Syamantak Kumar","Purnamrita Sarkar"],"pdf_url":"https://arxiv.org/pdf/2402.07240v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03450v1","updated":"2024-11-05T19:07:26Z","published":"2024-11-05T19:07:26Z","title":"Fourier Analysis of Variational Quantum Circuits for Supervised Learning","summary":"  VQC can be understood through the lens of Fourier analysis. It is already\nwell-known that the function space represented by any circuit architecture can\nbe described through a truncated Fourier sum. We show that the spectrum\navailable to that truncated Fourier sum is not entirely determined by the\nencoding gates of the circuit, since the variational part of the circuit can\nconstrain certain coefficients to zero, effectively removing that frequency\nfrom the spectrum. To the best of our knowledge, we give the first description\nof the functional dependence of the Fourier coefficients on the variational\nparameters as trigonometric polynomials. This allows us to provide an algorithm\nwhich computes the exact spectrum of any given circuit and the corresponding\nFourier coefficients. Finally, we demonstrate that by comparing the Fourier\ntransform of the dataset to the available spectra, it is possible to predict\nwhich \\gls{VQC} out of a given list of choices will be able to best fit the\ndata.\n","authors":["Marco Wiedmann","Maniraman Periyasamy","Daniel D. Scherer"],"pdf_url":"https://arxiv.org/pdf/2411.03450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03445v1","updated":"2024-11-05T19:00:34Z","published":"2024-11-05T19:00:34Z","title":"Solving Trojan Detection Competitions with Linear Weight Classification","summary":"  Neural networks can conceal malicious Trojan backdoors that allow a trigger\nto covertly change the model behavior. Detecting signs of these backdoors,\nparticularly without access to any triggered data, is the subject of ongoing\nresearch and open challenges. In one common formulation of the problem, we are\ngiven a set of clean and poisoned models and need to predict whether a given\ntest model is clean or poisoned. In this paper, we introduce a detector that\nworks remarkably well across many of the existing datasets and domains. It is\nobtained by training a binary classifier on a large number of models' weights\nafter performing a few different pre-processing steps including feature\nselection and standardization, reference model weights subtraction, and model\nalignment prior to detection. We evaluate this algorithm on a diverse set of\nTrojan detection benchmarks and domains and examine the cases where the\napproach is most and least effective.\n","authors":["Todd Huster","Peter Lin","Razvan Stefanescu","Emmanuel Ekwedike","Ritu Chadha"],"pdf_url":"https://arxiv.org/pdf/2411.03445v1.pdf","comment":"9 pages, 4 Figures"},{"id":"http://arxiv.org/abs/2411.03312v1","updated":"2024-11-05T18:54:21Z","published":"2024-11-05T18:54:21Z","title":"Inference Optimal VLMs Need Only One Visual Token but Larger Models","summary":"  Vision Language Models (VLMs) have demonstrated strong capabilities across\nvarious visual understanding and reasoning tasks. However, their real-world\ndeployment is often constrained by high latency during inference due to\nsubstantial compute required to process the large number of input tokens\n(predominantly from the image) by the LLM. To reduce inference costs, one can\neither downsize the LLM or reduce the number of input image-tokens, the latter\nof which has been the focus of many recent works around token compression.\nHowever, it is unclear what the optimal trade-off is, as both the factors\ndirectly affect the VLM performance. We first characterize this optimal\ntrade-off between the number of visual tokens and LLM parameters by\nestablishing scaling laws that capture variations in performance with these two\nfactors. Our results reveal a surprising trend: for visual reasoning tasks, the\ninference-optimal behavior in VLMs, i.e., minimum downstream error at any given\nfixed inference compute, is achieved when using the largest LLM that fits\nwithin the inference budget while minimizing visual token count - often to a\nsingle token. While the token reduction literature has mainly focused on\nmaintaining base model performance by modestly reducing the token count (e.g.,\n$5-10\\times$), our results indicate that the compute-optimal inference regime\nrequires operating under even higher token compression ratios. Based on these\ninsights, we take some initial steps towards building approaches tailored for\nhigh token compression settings. Code is available at\nhttps://github.com/locuslab/llava-token-compression.\n","authors":["Kevin Y. Li","Sachin Goyal","Joao D. Semedo","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2411.03312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01810v5","updated":"2024-11-05T18:54:14Z","published":"2024-02-02T11:41:21Z","title":"Parameter uncertainties for imperfect surrogate models in the low-noise\n  regime","summary":"  Bayesian regression determines model parameters by minimizing the expected\nloss, an upper bound to the true generalization error. However, the loss\nignores misspecification, where models are imperfect. Parameter uncertainties\nfrom Bayesian regression are thus significantly underestimated and vanish in\nthe large data limit. This is particularly problematic when building models of\nlow-noise, or near-deterministic, calculations, as the main source of\nuncertainty is neglected. We analyze the generalization error of misspecified,\nnear-deterministic surrogate models, a regime of broad relevance in science and\nengineering. We show posterior distributions must cover every training point to\navoid a divergent generalization error and design an ansatz that respects this\nconstraint, which for linear models incurs minimal overhead. This is\ndemonstrated on model problems before application to thousand dimensional\ndatasets in atomistic machine learning. Our efficient misspecification-aware\nscheme gives accurate prediction and bounding of test errors where existing\nschemes fail, allowing this important source of uncertainty to be incorporated\nin computational workflows.\n","authors":["Thomas D Swinburne","Danny Perez"],"pdf_url":"https://arxiv.org/pdf/2402.01810v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01720v2","updated":"2024-11-05T18:45:22Z","published":"2024-01-26T18:37:21Z","title":"Deep Learning Based Amharic Chatbot for FAQs in Universities","summary":"  University students often spend a considerable amount of time seeking answers\nto common questions from administrators or teachers. This can become tedious\nfor both parties, leading to a need for a solution. In response, this paper\nproposes a chatbot model that utilizes natural language processing and deep\nlearning techniques to answer frequently asked questions (FAQs) in the Amharic\nlanguage. Chatbots are computer programs that simulate human conversation\nthrough the use of artificial intelligence (AI), acting as a virtual assistant\nto handle questions and other tasks. The proposed chatbot program employs\ntokenization, normalization, stop word removal, and stemming to analyze and\ncategorize Amharic input sentences. Three machine learning model algorithms\nwere used to classify tokens and retrieve appropriate responses: Support Vector\nMachine (SVM), Multinomial Na\\\"ive Bayes, and deep neural networks implemented\nthrough TensorFlow, Keras, and NLTK. The deep learning model achieved the best\nresults with 91.55% accuracy and a validation loss of 0.3548 using an Adam\noptimizer and SoftMax activation function. The chatbot model was integrated\nwith Facebook Messenger and deployed on a Heroku server for 24-hour\naccessibility. The experimental results demonstrate that the chatbot framework\nachieved its objectives and effectively addressed challenges such as Amharic\nFidel variation, morphological variation, and lexical gaps. Future research\ncould explore the integration of Amharic WordNet to narrow the lexical gap and\nsupport more complex questions.\n","authors":["Goitom Ybrah Hailu","Hadush Hailu","Shishay Welay"],"pdf_url":"https://arxiv.org/pdf/2402.01720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05438v2","updated":"2024-11-05T18:44:55Z","published":"2024-10-07T19:04:24Z","title":"DAAL: Density-Aware Adaptive Line Margin Loss for Multi-Modal Deep\n  Metric Learning","summary":"  Multi-modal deep metric learning is crucial for effectively capturing diverse\nrepresentations in tasks such as face verification, fine-grained object\nrecognition, and product search. Traditional approaches to metric learning,\nwhether based on distance or margin metrics, primarily emphasize class\nseparation, often overlooking the intra-class distribution essential for\nmulti-modal feature learning. In this context, we propose a novel loss function\ncalled Density-Aware Adaptive Margin Loss(DAAL), which preserves the density\ndistribution of embeddings while encouraging the formation of adaptive\nsub-clusters within each class. By employing an adaptive line strategy, DAAL\nnot only enhances intra-class variance but also ensures robust inter-class\nseparation, facilitating effective multi-modal representation. Comprehensive\nexperiments on benchmark fine-grained datasets demonstrate the superior\nperformance of DAAL, underscoring its potential in advancing retrieval\napplications and multi-modal deep metric learning.\n","authors":["Hadush Hailu Gebrerufael","Anil Kumar Tiwari","Gaurav Neupane","Goitom Ybrah Hailu"],"pdf_url":"https://arxiv.org/pdf/2410.05438v2.pdf","comment":"13 pages, 4 fugues, 2 tables"},{"id":"http://arxiv.org/abs/2411.03402v1","updated":"2024-11-05T18:37:51Z","published":"2024-11-05T18:37:51Z","title":"Climate AI for Corporate Decarbonization Metrics Extraction","summary":"  Corporate Greenhouse Gas (GHG) emission targets are important metrics in\nsustainable investing [12, 16]. To provide a comprehensive view of company\nemission objectives, we propose an approach to source these metrics from\ncompany public disclosures. Without automation, curating these metrics manually\nis a labor-intensive process that requires combing through lengthy corporate\nsustainability disclosures that often do not follow a standard format.\nFurthermore, the resulting dataset needs to be validated thoroughly by Subject\nMatter Experts (SMEs), further lengthening the time-to-market. We introduce the\nClimate Artificial Intelligence for Corporate Decarbonization Metrics\nExtraction (CAI) model and pipeline, a novel approach utilizing Large Language\nModels (LLMs) to extract and validate linked metrics from corporate\ndisclosures. We demonstrate that the process improves data collection\nefficiency and accuracy by automating data curation, validation, and metric\nscoring from public corporate disclosures. We further show that our results are\nagnostic to the choice of LLMs. This framework can be applied broadly to\ninformation extraction from textual data.\n","authors":["Aditya Dave","Mengchen Zhu","Dapeng Hu","Sachin Tiwari"],"pdf_url":"https://arxiv.org/pdf/2411.03402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00593v2","updated":"2024-11-05T18:35:39Z","published":"2024-11-01T13:53:14Z","title":"Adapting Language Models via Token Translation","summary":"  Modern large language models use a fixed tokenizer to effectively compress\ntext drawn from a source domain. However, applying the same tokenizer to a new\ntarget domain often leads to inferior compression, more costly inference, and\nreduced semantic alignment. To address this deficiency, we introduce Sparse\nSinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the\ntarget domain and learns to translate between target and source tokens,\nenabling more effective reuse of the pre-trained next-source-token predictor.\nIn our experiments with finetuned English language models, S2T2 improves both\nthe perplexity and the compression of out-of-domain protein sequences,\noutperforming direct finetuning with either the source or target tokenizer. In\naddition, we find that token translations learned for smaller, less expensive\nmodels can be directly transferred to larger, more powerful models to reap the\nbenefits of S2T2 at lower cost.\n","authors":["Zhili Feng","Tanya Marwah","Nicolo Fusi","David Alvarez-Melis","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2411.00593v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02040v3","updated":"2024-11-05T18:27:28Z","published":"2024-04-02T15:34:47Z","title":"Transformers as Transducers","summary":"  We study the sequence-to-sequence mapping capacity of transformers by\nrelating them to finite transducers, and find that they can express\nsurprisingly large classes of transductions. We do so using variants of RASP, a\nprogramming language designed to help people \"think like transformers,\" as an\nintermediate representation. We extend the existing Boolean variant B-RASP to\nsequence-to-sequence functions and show that it computes exactly the\nfirst-order rational functions (such as string rotation). Then, we introduce\ntwo new extensions. B-RASP[pos] enables calculations on positions (such as\ncopying the first half of a string) and contains all first-order regular\nfunctions. S-RASP adds prefix sum, which enables additional arithmetic\noperations (such as squaring a string) and contains all first-order polyregular\nfunctions. Finally, we show that masked average-hard attention transformers can\nsimulate S-RASP.\n","authors":["Lena Strobl","Dana Angluin","David Chiang","Jonathan Rawski","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2404.02040v3.pdf","comment":"To appear in Transactions of the Association for Computational\n  Linguistics"},{"id":"http://arxiv.org/abs/2403.15855v3","updated":"2024-11-05T18:27:11Z","published":"2024-03-23T14:24:36Z","title":"Initialisation and Network Effects in Decentralised Federated Learning","summary":"  Fully decentralised federated learning enables collaborative training of\nindividual machine learning models on a distributed network of communicating\ndevices while keeping the training data localised on each node. This approach\navoids central coordination, enhances data privacy and eliminates the risk of a\nsingle point of failure. Our research highlights that the effectiveness of\ndecentralised federated learning is significantly influenced by the network\ntopology of connected devices and the learning models' initial conditions. We\npropose a strategy for uncoordinated initialisation of the artificial neural\nnetworks based on the distribution of eigenvector centralities of the\nunderlying communication network, leading to a radically improved training\nefficiency. Additionally, our study explores the scaling behaviour and the\nchoice of environmental parameters under our proposed initialisation strategy.\nThis work paves the way for more efficient and scalable artificial neural\nnetwork training in a distributed and uncoordinated environment, offering a\ndeeper understanding of the intertwining roles of network structure and\nlearning dynamics.\n","authors":["Arash Badie-Modiri","Chiara Boldrini","Lorenzo Valerio","János Kertész","Márton Karsai"],"pdf_url":"https://arxiv.org/pdf/2403.15855v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11113v2","updated":"2024-11-05T18:26:53Z","published":"2024-10-14T21:46:57Z","title":"Statistical Properties of Deep Neural Networks with Dependent Data","summary":"  This paper establishes statistical properties of deep neural network (DNN)\nestimators under dependent data. Two general results for nonparametric sieve\nestimators directly applicable to DNN estimators are given. The first\nestablishes rates for convergence in probability under nonstationary data. The\nsecond provides non-asymptotic probability bounds on $\\mathcal{L}^{2}$-errors\nunder stationary $\\beta$-mixing data. I apply these results to DNN estimators\nin both regression and classification contexts imposing only a standard\nH\\\"older smoothness assumption. The DNN architectures considered are common in\napplications, featuring fully connected feedforward networks with any\ncontinuous piecewise linear activation function, unbounded weights, and a width\nand depth that grows with sample size. The framework provided also offers\npotential for research into other DNN architectures and time-series\napplications.\n","authors":["Chad Brown"],"pdf_url":"https://arxiv.org/pdf/2410.11113v2.pdf","comment":"85 pages, 2 figures, removed partially linear model section and\n  uploaded as a separate paper (arXiv:2410.22574v1)"},{"id":"http://arxiv.org/abs/2407.02961v2","updated":"2024-11-05T18:16:21Z","published":"2024-07-03T09:54:58Z","title":"Towards a Scalable Reference-Free Evaluation of Generative Models","summary":"  While standard evaluation scores for generative models are mostly\nreference-based, a reference-dependent assessment of generative models could be\ngenerally difficult due to the unavailability of applicable reference datasets.\nRecently, the reference-free entropy scores, VENDI and RKE, have been proposed\nto evaluate the diversity of generated data. However, estimating these scores\nfrom data leads to significant computational costs for large-scale generative\nmodels. In this work, we leverage the random Fourier features framework to\nreduce the computational price and propose the Fourier-based Kernel Entropy\nApproximation (FKEA) method. We utilize FKEA's approximated eigenspectrum of\nthe kernel matrix to efficiently estimate the mentioned entropy scores.\nFurthermore, we show the application of FKEA's proxy eigenvectors to reveal the\nmethod's identified modes in evaluating the diversity of produced samples. We\nprovide a stochastic implementation of the FKEA assessment algorithm with a\ncomplexity $O(n)$ linearly growing with sample size $n$. We extensively\nevaluate FKEA's numerical performance in application to standard image, text,\nand video datasets. Our empirical results indicate the method's scalability and\ninterpretability applied to large-scale generative models. The codebase is\navailable at https://github.com/aziksh-ospanov/FKEA.\n","authors":["Azim Ospanov","Jingwei Zhang","Mohammad Jalali","Xuenan Cao","Andrej Bogdanov","Farzan Farnia"],"pdf_url":"https://arxiv.org/pdf/2407.02961v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03387v1","updated":"2024-11-05T18:14:49Z","published":"2024-11-05T18:14:49Z","title":"Quantifying Aleatoric Uncertainty of the Treatment Effect: A Novel\n  Orthogonal Learner","summary":"  Estimating causal quantities from observational data is crucial for\nunderstanding the safety and effectiveness of medical treatments. However, to\nmake reliable inferences, medical practitioners require not only estimating\naveraged causal quantities, such as the conditional average treatment effect,\nbut also understanding the randomness of the treatment effect as a random\nvariable. This randomness is referred to as aleatoric uncertainty and is\nnecessary for understanding the probability of benefit from treatment or\nquantiles of the treatment effect. Yet, the aleatoric uncertainty of the\ntreatment effect has received surprisingly little attention in the causal\nmachine learning community. To fill this gap, we aim to quantify the aleatoric\nuncertainty of the treatment effect at the covariate-conditional level, namely,\nthe conditional distribution of the treatment effect (CDTE). Unlike average\ncausal quantities, the CDTE is not point identifiable without strong additional\nassumptions. As a remedy, we employ partial identification to obtain sharp\nbounds on the CDTE and thereby quantify the aleatoric uncertainty of the\ntreatment effect. We then develop a novel, orthogonal learner for the bounds on\nthe CDTE, which we call AU-learner. We further show that our AU-learner has\nseveral strengths in that it satisfies Neyman-orthogonality and is doubly\nrobust. Finally, we propose a fully-parametric deep learning instantiation of\nour AU-learner.\n","authors":["Valentyn Melnychuk","Stefan Feuerriegel","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2411.03387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03384v1","updated":"2024-11-05T18:11:25Z","published":"2024-11-05T18:11:25Z","title":"Solving stochastic partial differential equations using neural networks\n  in the Wiener chaos expansion","summary":"  In this paper, we solve stochastic partial differential equations (SPDEs)\nnumerically by using (possibly random) neural networks in the truncated Wiener\nchaos expansion of their corresponding solution. Moreover, we provide some\napproximation rates for learning the solution of SPDEs with additive and/or\nmultiplicative noise. Finally, we apply our results in numerical examples to\napproximate the solution of three SPDEs: the stochastic heat equation, the\nHeath-Jarrow-Morton equation, and the Zakai equation.\n","authors":["Ariel Neufeld","Philipp Schmocker"],"pdf_url":"https://arxiv.org/pdf/2411.03384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07448v2","updated":"2024-11-05T17:40:13Z","published":"2024-09-11T17:52:37Z","title":"Introducing Perturb-ability Score (PS) to Enhance Robustness Against\n  Evasion Adversarial Attacks on ML-NIDS","summary":"  As network security threats continue to evolve, safeguarding Machine Learning\n(ML)-based Network Intrusion Detection Systems (NIDS) from adversarial attacks\nis crucial. This paper introduces the notion of feature perturb-ability and\npresents a novel Perturb-ability Score (PS) metric that identifies NIDS\nfeatures susceptible to manipulation in the problem-space by an attacker. By\nquantifying a feature's susceptibility to perturbations within the\nproblem-space, the PS facilitates the selection of features that are inherently\nmore robust against evasion adversarial attacks on ML-NIDS during the feature\nselection phase. These features exhibit natural resilience to perturbations, as\nthey are heavily constrained by the problem-space limitations and correlations\nof the NIDS domain. Furthermore, manipulating these features may either disrupt\nthe malicious function of evasion adversarial attacks on NIDS or render the\nnetwork traffic invalid for processing (or both). This proposed novel approach\nemploys a fresh angle by leveraging network domain constraints as a defense\nmechanism against problem-space evasion adversarial attacks targeting ML-NIDS.\nWe demonstrate the effectiveness of our PS-guided feature selection defense in\nenhancing NIDS robustness. Experimental results across various ML-based NIDS\nmodels and public datasets show that selecting only robust features (low-PS\nfeatures) can maintain solid detection performance while significantly reducing\nvulnerability to evasion adversarial attacks. Additionally, our findings verify\nthat the PS effectively identifies NIDS features highly vulnerable to\nproblem-space perturbations.\n","authors":["Mohamed elShehaby","Ashraf Matrawy"],"pdf_url":"https://arxiv.org/pdf/2409.07448v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03279v1","updated":"2024-11-05T17:20:53Z","published":"2024-11-05T17:20:53Z","title":"Oblivious Defense in ML Models: Backdoor Removal without Detection","summary":"  As society grows more reliant on machine learning, ensuring the security of\nmachine learning systems against sophisticated attacks becomes a pressing\nconcern. A recent result of Goldwasser, Kim, Vaikuntanathan, and Zamir (2022)\nshows that an adversary can plant undetectable backdoors in machine learning\nmodels, allowing the adversary to covertly control the model's behavior.\nBackdoors can be planted in such a way that the backdoored machine learning\nmodel is computationally indistinguishable from an honest model without\nbackdoors.\n  In this paper, we present strategies for defending against backdoors in ML\nmodels, even if they are undetectable. The key observation is that it is\nsometimes possible to provably mitigate or even remove backdoors without\nneeding to detect them, using techniques inspired by the notion of random\nself-reducibility. This depends on properties of the ground-truth labels\n(chosen by nature), and not of the proposed ML model (which may be chosen by an\nattacker).\n  We give formal definitions for secure backdoor mitigation, and proceed to\nshow two types of results. First, we show a \"global mitigation\" technique,\nwhich removes all backdoors from a machine learning model under the assumption\nthat the ground-truth labels are close to a Fourier-heavy function. Second, we\nconsider distributions where the ground-truth labels are close to a linear or\npolynomial function in $\\mathbb{R}^n$. Here, we show \"local mitigation\"\ntechniques, which remove backdoors with high probability for every inputs of\ninterest, and are computationally cheaper than global mitigation. All of our\nconstructions are black-box, so our techniques work without needing access to\nthe model's representation (i.e., its code or parameters). Along the way we\nprove a simple result for robust mean estimation.\n","authors":["Shafi Goldwasser","Jonathan Shafer","Neekon Vafa","Vinod Vaikuntanathan"],"pdf_url":"https://arxiv.org/pdf/2411.03279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03273v1","updated":"2024-11-05T17:16:56Z","published":"2024-11-05T17:16:56Z","title":"Graph-Based Semi-Supervised Segregated Lipschitz Learning","summary":"  This paper presents an approach to semi-supervised learning for the\nclassification of data using the Lipschitz Learning on graphs. We develop a\ngraph-based semi-supervised learning framework that leverages the properties of\nthe infinity Laplacian to propagate labels in a dataset where only a few\nsamples are labeled. By extending the theory of spatial segregation from the\nLaplace operator to the infinity Laplace operator, both in continuum and\ndiscrete settings, our approach provides a robust method for dealing with class\nimbalance, a common challenge in machine learning. Experimental validation on\nseveral benchmark datasets demonstrates that our method not only improves\nclassification accuracy compared to existing methods but also ensures efficient\nlabel propagation in scenarios with limited labeled data.\n","authors":["Farid Bozorgnia","Yassine Belkheiri","Abderrahim Elmoataz"],"pdf_url":"https://arxiv.org/pdf/2411.03273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03270v1","updated":"2024-11-05T17:14:46Z","published":"2024-11-05T17:14:46Z","title":"Stable Matching with Ties: Approximation Ratios and Learning","summary":"  We study the problem of matching markets with ties, where one side of the\nmarket does not necessarily have strict preferences over members at its other\nside. For example, workers do not always have strict preferences over jobs,\nstudents can give the same ranking for different schools and more. In\nparticular, assume w.l.o.g. that workers' preferences are determined by their\nutility from being matched to each job, which might admit ties. Notably, in\ncontrast to classical two-sided markets with strict preferences, there is no\nlonger a single stable matching that simultaneously maximizes the utility for\nall workers.\n  We aim to guarantee each worker the largest possible share from the utility\nin her best possible stable matching. We call the ratio between the worker's\nbest possible stable utility and its assigned utility the \\emph{Optimal Stable\nShare} (OSS)-ratio. We first prove that distributions over stable matchings\ncannot guarantee an OSS-ratio that is sublinear in the number of workers.\nInstead, randomizing over possibly non-stable matchings, we show how to achieve\na tight logarithmic OSS-ratio. Then, we analyze the case where the real utility\nis not necessarily known and can only be approximated. In particular, we\nprovide an algorithm that guarantees a similar fraction of the utility compared\nto the best possible utility. Finally, we move to a bandit setting, where we\nselect a matching at each round and only observe the utilities for matches we\nperform. We show how to utilize our results for approximate utilities to\ngracefully interpolate between problems without ties and problems with\nstatistical ties (small suboptimality gaps).\n","authors":["Shiyun Lin","Simon Mauras","Nadav Merlis","Vianney Perchet"],"pdf_url":"https://arxiv.org/pdf/2411.03270v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03263v1","updated":"2024-11-05T17:02:29Z","published":"2024-11-05T17:02:29Z","title":"Proxy-informed Bayesian transfer learning with unknown sources","summary":"  Generalization outside the scope of one's training data requires leveraging\nprior knowledge about the effects that transfer, and the effects that don't,\nbetween different data sources. Bayesian transfer learning is a principled\nparadigm for specifying this knowledge, and refining it on the basis of data\nfrom the source (training) and target (prediction) tasks. We address the\nchallenging transfer learning setting where the learner (i) cannot fine-tune in\nthe target task, and (ii) does not know which source data points correspond to\nthe same task (i.e., the data sources are unknown). We propose a proxy-informed\nrobust method for probabilistic transfer learning (PROMPT), which provides a\nposterior predictive estimate tailored to the structure of the target task,\nwithout requiring the learner have access to any outcome information from the\ntarget task. Instead, PROMPT relies on the availability of proxy information.\nPROMPT uses the same proxy information for two purposes: (i) estimation of\neffects specific to the target task, and (ii) construction of a robust\nreweighting of the source data for estimation of effects that transfer between\ntasks. We provide theoretical results on the effect of this reweighting on the\nrisk of negative transfer, and demonstrate application of PROMPT in two\nsynthetic settings.\n","authors":["Sabina J. Sloman","Julien Martinelli","Samuel Kaski"],"pdf_url":"https://arxiv.org/pdf/2411.03263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01530v3","updated":"2024-11-05T16:55:11Z","published":"2023-12-03T23:08:29Z","title":"Evaluation of Active Feature Acquisition Methods for Time-varying\n  Feature Settings","summary":"  Machine learning methods often assume that input features are available at no\ncost. However, in domains like healthcare, where acquiring features could be\nexpensive or harmful, it is necessary to balance a feature's acquisition cost\nagainst its predictive value. The task of training an AI agent to decide which\nfeatures to acquire is called active feature acquisition (AFA). By deploying an\nAFA agent, we effectively alter the acquisition strategy and trigger a\ndistribution shift. To safely deploy AFA agents under this distribution shift,\nwe present the problem of active feature acquisition performance evaluation\n(AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating\nthat acquisitions do not affect the underlying feature values; and ii) a no\nunobserved confounding (NUC) assumption, stating that retrospective feature\nacquisition decisions were only based on observed features. We show that one\ncan apply missing data methods under the NDE assumption and offline\nreinforcement learning under the NUC assumption. When NUC and NDE hold, we\npropose a novel semi-offline reinforcement learning framework. This framework\nrequires a weaker positivity assumption and introduces three new estimators: A\ndirect method (DM), an inverse probability weighting (IPW), and a double\nreinforcement learning (DRL) estimator.\n","authors":["Henrik von Kleist","Alireza Zamanian","Ilya Shpitser","Narges Ahmidi"],"pdf_url":"https://arxiv.org/pdf/2312.01530v3.pdf","comment":"61 pages, 4 tables, 11 Figures"},{"id":"http://arxiv.org/abs/2411.03253v1","updated":"2024-11-05T16:50:54Z","published":"2024-11-05T16:50:54Z","title":"Discovering Data Structures: Nearest Neighbor Search and Beyond","summary":"  We propose a general framework for end-to-end learning of data structures.\nOur framework adapts to the underlying data distribution and provides\nfine-grained control over query and space complexity. Crucially, the data\nstructure is learned from scratch, and does not require careful initialization\nor seeding with candidate data structures/algorithms. We first apply this\nframework to the problem of nearest neighbor search. In several settings, we\nare able to reverse-engineer the learned data structures and query algorithms.\nFor 1D nearest neighbor search, the model discovers optimal distribution\n(in)dependent algorithms such as binary search and variants of interpolation\nsearch. In higher dimensions, the model learns solutions that resemble k-d\ntrees in some regimes, while in others, they have elements of\nlocality-sensitive hashing. The model can also learn useful representations of\nhigh-dimensional data and exploit them to design effective data structures. We\nalso adapt our framework to the problem of estimating frequencies over a data\nstream, and believe it could also be a powerful discovery tool for new\nproblems.\n","authors":["Omar Salemohamed","Laurent Charlin","Shivam Garg","Vatsal Sharan","Gregory Valiant"],"pdf_url":"https://arxiv.org/pdf/2411.03253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06484v4","updated":"2024-11-05T16:48:53Z","published":"2024-06-10T17:24:42Z","title":"Parallelizing Linear Transformers with the Delta Rule over Sequence\n  Length","summary":"  Transformers with linear attention (i.e., linear transformers) and\nstate-space models have recently been suggested as a viable linear-time\nalternative to transformers with softmax attention. However, these models still\nunderperform transformers especially on tasks that require in-context\nretrieval. While more expressive variants of linear transformers which replace\nthe additive update in linear transformers with the delta rule (DeltaNet) have\nbeen found to be more effective at associative recall, existing algorithms for\ntraining such models do not parallelize over sequence length and are thus\ninefficient to train on modern hardware. This work describes a\nhardware-efficient algorithm for training linear transformers with the delta\nrule, which exploits a memory-efficient representation for computing products\nof Householder matrices. This algorithm allows us to scale up DeltaNet to\nstandard language modeling settings. We train a 1.3B model for 100B tokens and\nfind that it outperforms recent linear-time baselines such as Mamba and GLA in\nterms of perplexity and zero-shot performance on downstream tasks. We also\nexperiment with two hybrid models which combine DeltaNet layers with (1)\nsliding-window attention layers every other layer or (2) two global attention\nlayers, and find that these hybrids outperform strong transformer baselines.\n","authors":["Songlin Yang","Bailin Wang","Yu Zhang","Yikang Shen","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2406.06484v4.pdf","comment":"NeurIPS 2024 camera ready"},{"id":"http://arxiv.org/abs/2411.03250v1","updated":"2024-11-05T16:47:53Z","published":"2024-11-05T16:47:53Z","title":"DiffLM: Controllable Synthetic Data Generation via Diffusion Language\n  Models","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced their knowledge and generative capabilities, leading to a surge of\ninterest in leveraging LLMs for high-quality data synthesis. However, synthetic\ndata generation via prompting LLMs remains challenging due to LLMs' limited\nunderstanding of target data distributions and the complexity of prompt\nengineering, especially for structured formatted data. To address these issues,\nwe introduce DiffLM, a controllable data synthesis framework based on\nvariational autoencoder (VAE), which further (1) leverages diffusion models to\nreserve more information of original distribution and format structure in the\nlearned latent distribution and (2) decouples the learning of target\ndistribution knowledge from the LLM's generative objectives via a plug-and-play\nlatent feature injection module. As we observed significant discrepancies\nbetween the VAE's latent representations and the real data distribution, the\nlatent diffusion module is introduced into our framework to learn a fully\nexpressive latent distribution. Evaluations on seven real-world datasets with\nstructured formatted data (i.e., Tabular, Code and Tool data) demonstrate that\nDiffLM generates high-quality data, with performance on downstream tasks\nsurpassing that of real data by 2-7 percent in certain cases. The data and code\nwill be publicly available upon completion of internal review.\n","authors":["Ying Zhou","Xinyao Wang","Yulei Niu","Yaojie Shen","Lexin Tang","Fan Chen","Ben He","Le Sun","Longyin Wen"],"pdf_url":"https://arxiv.org/pdf/2411.03250v1.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2402.17747v4","updated":"2024-11-05T16:46:01Z","published":"2024-02-27T18:32:11Z","title":"When Your AIs Deceive You: Challenges of Partial Observability in\n  Reinforcement Learning from Human Feedback","summary":"  Past analyses of reinforcement learning from human feedback (RLHF) assume\nthat the human evaluators fully observe the environment. What happens when\nhuman feedback is based only on partial observations? We formally define two\nfailure cases: deceptive inflation and overjustification. Modeling the human as\nBoltzmann-rational w.r.t. a belief over trajectories, we prove conditions under\nwhich RLHF is guaranteed to result in policies that deceptively inflate their\nperformance, overjustify their behavior to make an impression, or both. Under\nthe new assumption that the human's partial observability is known and\naccounted for, we then analyze how much information the feedback process\nprovides about the return function. We show that sometimes, the human's\nfeedback determines the return function uniquely up to an additive constant,\nbut in other realistic cases, there is irreducible ambiguity. We propose\nexploratory research directions to help tackle these challenges, experimentally\nvalidate both the theoretical concerns and potential mitigations, and caution\nagainst blindly applying RLHF in partially observable settings.\n","authors":["Leon Lang","Davis Foote","Stuart Russell","Anca Dragan","Erik Jenner","Scott Emmons"],"pdf_url":"https://arxiv.org/pdf/2402.17747v4.pdf","comment":"Advances in Neural Information Processing Systems 37 (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2406.07428v3","updated":"2024-11-05T16:37:19Z","published":"2024-06-11T16:30:30Z","title":"GemNet: Menu-Based, Strategy-Proof Multi-Bidder Auctions Through Deep\n  Learning","summary":"  Automated mechanism design (AMD) uses computational methods for mechanism\ndesign. Differentiable economics is a form of AMD that uses deep learning to\nlearn mechanism designs and has enabled strong progress in AMD in recent years.\nNevertheless, a major open problem has been to learn multi-bidder, general, and\nfully strategy-proof (SP) auctions. We introduce GEneral Menu-based NETwork\n(GemNet), which significantly extends the menu-based approach of the\nsingle-bidder RochetNet (D\\\"utting et al., 2024) to the multi-bidder setting.\nThe challenge in achieving SP is to learn bidder-independent menus that are\nfeasible, so that the optimal menu choices for each bidder do not over-allocate\nitems when taken together (we call this menu compatibility). GemNet penalizes\nthe failure of menu compatibility during training, and transforms learned menus\nafter training through price changes, by considering a set of discretized\nbidder values and reasoning about Lipschitz smoothness to guarantee menu\ncompatibility on the entire value space. This approach is general, leaving\ntrained menus that already satisfy menu compatibility undisturbed and reducing\nto RochetNet for a single bidder. Mixed-integer linear programs are used for\nmenu transforms, and through a number of optimizations enabled by deep\nlearning, including adaptive grids and methods to skip menu elements, we scale\nto large auction design problems. GemNet learns auctions with better revenue\nthan affine maximization methods, achieves exact SP whereas previous general\nmulti-bidder methods are approximately SP, and offers greatly enhanced\ninterpretability.\n","authors":["Tonghan Wang","Yanchen Jiang","David C. Parkes"],"pdf_url":"https://arxiv.org/pdf/2406.07428v3.pdf","comment":"This paper received the Exemplary Paper Award for the AI track at the\n  Twenty-Fifth ACM Conference on Economics and Computation (ACM EC '24), where\n  it appeared as an extended abstract; The first two authors contributed\n  equally to this work"},{"id":"http://arxiv.org/abs/2411.03237v1","updated":"2024-11-05T16:36:51Z","published":"2024-11-05T16:36:51Z","title":"On the Detection of Non-Cooperative RISs: Scan B-Testing via Deep\n  Support Vector Data Description","summary":"  In this paper, we study the problem of promptly detecting the presence of\nnon-cooperative activity from one or more Reconfigurable Intelligent Surfaces\n(RISs) with unknown characteristics lying in the vicinity of a Multiple-Input\nMultiple-Output (MIMO) communication system using Orthogonal Frequency-Division\nMultiplexing (OFDM) transmissions. We first present a novel wideband channel\nmodel incorporating RISs as well as non-reconfigurable stationary surfaces,\nwhich captures both the effect of the RIS actuation time on the channel in the\nfrequency domain as well as the difference between changing phase\nconfigurations during or among transmissions. Considering that RISs may operate\nunder the coordination of a third-party system, and thus, may negatively impact\nthe communication of the intended MIMO OFDM system, we present a novel RIS\nactivity detection framework that is unaware of the distribution of the phase\nconfiguration of any of the non-cooperative RISs. In particular, capitalizing\non the knowledge of the data distribution at the multi-antenna receiver, we\ndesign a novel online change point detection statistic that combines a deep\nsupport vector data description model with the scan $B$-test. The presented\nnumerical investigations demonstrate the improved detection accuracy as well as\ndecreased computational complexity of the proposed RIS detection approach over\nexisting change point detection schemes.\n","authors":["George Stamatelis","Panagiotis Gavriilidis","Aymen Fakhreddine","George C. Alexandropoulos"],"pdf_url":"https://arxiv.org/pdf/2411.03237v1.pdf","comment":"6 pages, 4 figures, submitted to an IEEE conference"},{"id":"http://arxiv.org/abs/2411.03236v1","updated":"2024-11-05T16:36:07Z","published":"2024-11-05T16:36:07Z","title":"Enhancing Transformer Training Efficiency with Dynamic Dropout","summary":"  We introduce Dynamic Dropout, a novel regularization technique designed to\nenhance the training efficiency of Transformer models by dynamically adjusting\nthe dropout rate based on training epochs or validation loss improvements. This\napproach addresses the challenge of balancing regularization and model\ncapacity, which is crucial for achieving fast convergence and high performance.\nOur method involves modifying the GPT model to accept a variable dropout rate\nand updating dropout layers during training using schedules such as linear\ndecay, exponential decay, and validation loss-based adjustments. Extensive\nexperiments on the Shakespeare\\_char dataset demonstrate that Dynamic Dropout\nsignificantly accelerates training and improves inference efficiency compared\nto a baseline model with a fixed dropout rate. The validation loss-based\nadjustment schedule provided the best overall performance, highlighting the\npotential of Dynamic Dropout as a valuable technique for training large-scale\nTransformer models.\n","authors":["Hanrui Yan","Dan Shao"],"pdf_url":"https://arxiv.org/pdf/2411.03236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02774v2","updated":"2024-11-05T16:34:46Z","published":"2024-02-05T07:14:18Z","title":"Accelerating Matroid Optimization through Fast Imprecise Oracles","summary":"  Querying complex models for precise information (e.g. traffic models,\ndatabase systems, large ML models) often entails intense computations and\nresults in long response times. Thus, weaker models which give imprecise\nresults quickly can be advantageous, provided inaccuracies can be resolved\nusing few queries to a stronger model. In the fundamental problem of computing\na maximum-weight basis of a matroid, a well-known generalization of many\ncombinatorial optimization problems, algorithms have access to a clean oracle\nto query matroid information. We additionally equip algorithms with a fast but\ndirty oracle modelling an unknown, potentially different matroid. We design and\nanalyze practical algorithms which only use few clean queries w.r.t. the\nquality of the dirty oracle, while maintaining robustness against arbitrarily\npoor dirty matroids, approaching the performance of classic algorithms for the\ngiven problem. Notably, we prove that our algorithms are, in many respects,\nbest-possible. Further, we outline extensions to other matroid oracle types,\nnon-free dirty oracles and other matroid problems.\n","authors":["Franziska Eberle","Felix Hommelsheim","Alexander Lindermayr","Zhenwei Liu","Nicole Megow","Jens Schlöter"],"pdf_url":"https://arxiv.org/pdf/2402.02774v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.19101v2","updated":"2024-11-05T16:32:43Z","published":"2024-05-29T14:06:51Z","title":"Poseidon: Efficient Foundation Models for PDEs","summary":"  We introduce Poseidon, a foundation model for learning the solution operators\nof PDEs. It is based on a multiscale operator transformer, with\ntime-conditioned layer norms that enable continuous-in-time evaluations. A\nnovel training strategy leveraging the semi-group property of time-dependent\nPDEs to allow for significant scaling-up of the training data is also proposed.\nPoseidon is pretrained on a diverse, large scale dataset for the governing\nequations of fluid dynamics. It is then evaluated on a suite of 15 challenging\ndownstream tasks that include a wide variety of PDE types and operators. We\nshow that Poseidon exhibits excellent performance across the board by\noutperforming baselines significantly, both in terms of sample efficiency and\naccuracy. Poseidon also generalizes very well to new physics that is not seen\nduring pretraining. Moreover, Poseidon scales with respect to model and data\nsize, both for pretraining and for downstream tasks. Taken together, our\nresults showcase the surprising ability of Poseidon to learn effective\nrepresentations from a very small set of PDEs during pretraining in order to\ngeneralize well to unseen and unrelated PDEs downstream, demonstrating its\npotential as an effective, general purpose PDE foundation model. Finally, the\nPoseidon model as well as underlying pretraining and downstream datasets are\nopen sourced, with code being available at\nhttps://github.com/camlab-ethz/poseidon and pretrained models and datasets at\nhttps://huggingface.co/camlab-ethz.\n","authors":["Maximilian Herde","Bogdan Raonić","Tobias Rohner","Roger Käppeli","Roberto Molinaro","Emmanuel de Bézenac","Siddhartha Mishra"],"pdf_url":"https://arxiv.org/pdf/2405.19101v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17898v3","updated":"2024-11-05T16:31:24Z","published":"2023-11-29T18:51:46Z","title":"Contextual Knowledge Pursuit for Faithful Visual Synthesis","summary":"  Modern text-to-vision generative models often hallucinate when the prompt\ndescribing the scene to be generated is underspecified. In large language\nmodels (LLMs), a prevalent strategy to reduce hallucinations is to retrieve\nfactual knowledge from an external database. While such retrieval augmentation\nstrategies have great potential to enhance text-to-vision generators, existing\nstatic top-K retrieval methods explore the knowledge pool once, missing the\nbroader context necessary for high-quality generation. Furthermore, LLMs\ninternally possess rich world knowledge learned during large-scale training\n(parametric knowledge) that could mitigate the need for external data\nretrieval. This paper proposes Contextual Knowledge Pursuit (CKPT), a framework\nthat leverages the complementary strengths of external and parametric knowledge\nto help generators produce reliable visual content. Instead of the one-time\nretrieval of facts from an external database to improve a given prompt, CKPT\nuses (1) an LLM to decide whether to seek external knowledge or to self-elicit\ndescriptions from LLM parametric knowledge, (2) a knowledge pursuit process to\ncontextually seek and sequentially gather most relevant facts, (3) a knowledge\naggregator for prompt enhancement with the gathered fact context, and (4) a\nfiltered fine-tuning objective to improve visual synthesis with richer prompts.\nWe evaluate CKPT across multiple text-driven generative tasks (image, 3D\nrendering, and video) on datasets of rare objects and daily scenarios. Our\nresults show that CKPT is capable of generating faithful and semantically rich\ncontent across diverse visual domains, offering a promising data source for\nzero-shot synthesis and filtered fine-tuning of text-to-vision generative\nmodels.\n","authors":["Jinqi Luo","Kwan Ho Ryan Chan","Dimitris Dimos","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2311.17898v3.pdf","comment":"Accepted in ECCV 2024 SDCV Workshop. GitHub repository at\n  https://github.com/peterljq/Contextual-Knowledge-Pursuit"},{"id":"http://arxiv.org/abs/2411.03228v1","updated":"2024-11-05T16:20:14Z","published":"2024-11-05T16:20:14Z","title":"Topograph: An efficient Graph-Based Framework for Strictly Topology\n  Preserving Image Segmentation","summary":"  Topological correctness plays a critical role in many image segmentation\ntasks, yet most networks are trained using pixel-wise loss functions, such as\nDice, neglecting topological accuracy. Existing topology-aware methods often\nlack robust topological guarantees, are limited to specific use cases, or\nimpose high computational costs. In this work, we propose a novel, graph-based\nframework for topologically accurate image segmentation that is both\ncomputationally efficient and generally applicable. Our method constructs a\ncomponent graph that fully encodes the topological information of both the\nprediction and ground truth, allowing us to efficiently identify topologically\ncritical regions and aggregate a loss based on local neighborhood information.\nFurthermore, we introduce a strict topological metric capturing the homotopy\nequivalence between the union and intersection of prediction-label pairs. We\nformally prove the topological guarantees of our approach and empirically\nvalidate its effectiveness on binary and multi-class datasets. Our loss\ndemonstrates state-of-the-art performance with up to fivefold faster loss\ncomputation compared to persistent homology methods.\n","authors":["Laurin Lux","Alexander H. Berger","Alexander Weers","Nico Stucki","Daniel Rueckert","Ulrich Bauer","Johannes C. Paetzold"],"pdf_url":"https://arxiv.org/pdf/2411.03228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03226v1","updated":"2024-11-05T16:18:57Z","published":"2024-11-05T16:18:57Z","title":"Kernel Orthogonality does not necessarily imply a Decrease in Feature\n  Map Redundancy in CNNs: Convolutional Similarity Minimization","summary":"  Convolutional Neural Networks (CNNs) have been heavily used in Deep Learning\ndue to their success in various tasks. Nonetheless, it has been observed that\nCNNs suffer from redundancy in feature maps, leading to inefficient capacity\nutilization. Efforts to mitigate and solve this problem led to the emergence of\nmultiple methods, amongst which is kernel orthogonality through variant means.\nIn this work, we challenge the common belief that kernel orthogonality leads to\na decrease in feature map redundancy, which is, supposedly, the ultimate\nobjective behind kernel orthogonality. We prove, theoretically and empirically,\nthat kernel orthogonality has an unpredictable effect on feature map similarity\nand does not necessarily decrease it. Based on our theoretical result, we\npropose an effective method to reduce feature map similarity independently of\nthe input of the CNN. This is done by minimizing a novel loss function we call\nConvolutional Similarity. Empirical results show that minimizing the\nConvolutional Similarity increases the performance of classification models and\ncan accelerate their convergence. Furthermore, using our proposed method pushes\ntowards a more efficient use of the capacity of models, allowing the use of\nsignificantly smaller models to achieve the same levels of performance.\n","authors":["Zakariae Belmekki","Jun Li","Patrick Reuter","David Antonio Gómez Jáuregui","Karl Jenkins"],"pdf_url":"https://arxiv.org/pdf/2411.03226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03375v1","updated":"2024-11-05T16:18:47Z","published":"2024-11-05T16:18:47Z","title":"Kernel Approximation using Analog In-Memory Computing","summary":"  Kernel functions are vital ingredients of several machine learning\nalgorithms, but often incur significant memory and computational costs. We\nintroduce an approach to kernel approximation in machine learning algorithms\nsuitable for mixed-signal Analog In-Memory Computing (AIMC) architectures.\nAnalog In-Memory Kernel Approximation addresses the performance bottlenecks of\nconventional kernel-based methods by executing most operations in approximate\nkernel methods directly in memory. The IBM HERMES Project Chip, a\nstate-of-the-art phase-change memory based AIMC chip, is utilized for the\nhardware demonstration of kernel approximation. Experimental results show that\nour method maintains high accuracy, with less than a 1% drop in kernel-based\nridge classification benchmarks and within 1% accuracy on the Long Range Arena\nbenchmark for kernelized attention in Transformer neural networks. Compared to\ntraditional digital accelerators, our approach is estimated to deliver superior\nenergy efficiency and lower power consumption. These findings highlight the\npotential of heterogeneous AIMC architectures to enhance the efficiency and\nscalability of machine learning applications.\n","authors":["Julian Büchel","Giacomo Camposampiero","Athanasios Vasilopoulos","Corey Lammie","Manuel Le Gallo","Abbas Rahimi","Abu Sebastian"],"pdf_url":"https://arxiv.org/pdf/2411.03375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03224v1","updated":"2024-11-05T16:15:25Z","published":"2024-11-05T16:15:25Z","title":"Interpretable Predictive Models for Healthcare via Rational Logistic\n  Regression","summary":"  The healthcare sector has experienced a rapid accumulation of digital data\nrecently, especially in the form of electronic health records (EHRs). EHRs\nconstitute a precious resource that IS researchers could utilize for clinical\napplications (e.g., morbidity prediction). Deep learning seems like the obvious\nchoice to exploit this surfeit of data. However, numerous studies have shown\nthat deep learning does not enjoy the same kind of success on EHR data as it\nhas in other domains; simple models like logistic regression are frequently as\ngood as sophisticated deep learning ones. Inspired by this observation, we\ndevelop a novel model called rational logistic regression (RLR) that has\nstandard logistic regression (LR) as its special case (and thus inherits LR's\ninductive bias that aligns with EHR data). RLR has rational series as its\ntheoretical underpinnings, works on longitudinal time-series data, and learns\ninterpretable patterns. Empirical comparisons on real-world clinical tasks\ndemonstrate RLR's efficacy.\n","authors":["Thiti Suttaket","L Vivek Harsha Vardhan","Stanley Kok"],"pdf_url":"https://arxiv.org/pdf/2411.03224v1.pdf","comment":"ICIS 2021 Proceedings ( see\n  https://aisel.aisnet.org/icis2021/is_health/is_health/18 )"},{"id":"http://arxiv.org/abs/2411.03217v1","updated":"2024-11-05T16:09:28Z","published":"2024-11-05T16:09:28Z","title":"A Personal data Value at Risk Approach","summary":"  What if the main data protection vulnerability is risk management? Data\nProtection merges three disciplines: data protection law, information security,\nand risk management. Nonetheless, very little research has been made on the\nfield of data protection risk management, where subjectivity and superficiality\nare the dominant state of the art. Since the GDPR tells you what to do, but not\nhow to do it, the solution for approaching GDPR compliance is still a gray\nzone, where the trend is using the rule of thumb. Considering that the most\nimportant goal of risk management is to reduce uncertainty in order to take\ninformed decisions, risk management for the protection of the rights and\nfreedoms of the data subjects cannot be disconnected from the impact\nmaterialization that data controllers and processors need to assess. This paper\nproposes a quantitative approach to data protection risk-based compliance from\na data controllers perspective, with the aim of proposing a mindset change,\nwhere data protection impact assessments can be improved by using data\nprotection analytics, quantitative risk analysis, and calibrating expert\nopinions.\n","authors":["Luis Enriquez"],"pdf_url":"https://arxiv.org/pdf/2411.03217v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2407.19448v2","updated":"2024-11-05T16:06:20Z","published":"2024-07-28T09:53:02Z","title":"Piecewise deterministic generative models","summary":"  We introduce a novel class of generative models based on piecewise\ndeterministic Markov processes (PDMPs), a family of non-diffusive stochastic\nprocesses consisting of deterministic motion and random jumps at random times.\nSimilarly to diffusions, such Markov processes admit time reversals that turn\nout to be PDMPs as well. We apply this observation to three PDMPs considered in\nthe literature: the Zig-Zag process, Bouncy Particle Sampler, and Randomised\nHamiltonian Monte Carlo. For these three particular instances, we show that the\njump rates and kernels of the corresponding time reversals admit explicit\nexpressions depending on some conditional densities of the PDMP under\nconsideration before and after a jump. Based on these results, we propose\nefficient training procedures to learn these characteristics and consider\nmethods to approximately simulate the reverse process. Finally, we provide\nbounds in the total variation distance between the data distribution and the\nresulting distribution of our model in the case where the base distribution is\nthe standard $d$-dimensional Gaussian distribution. Promising numerical\nsimulations support further investigations into this class of models.\n","authors":["Andrea Bertazzi","Dario Shariatian","Umut Simsekli","Eric Moulines","Alain Durmus"],"pdf_url":"https://arxiv.org/pdf/2407.19448v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.17779v2","updated":"2024-11-05T15:56:14Z","published":"2024-05-28T03:19:15Z","title":"Online Analytic Exemplar-Free Continual Learning with Large Models for\n  Imbalanced Autonomous Driving Task","summary":"  In autonomous driving, even a meticulously trained model can encounter\nfailures when facing unfamiliar scenarios. One of these scenarios can be\nformulated as an online continual learning (OCL) problem. That is, data come in\nan online fashion, and models are updated according to these streaming data.\nTwo major OCL challenges are catastrophic forgetting and data imbalance. To\naddress these challenges, in this paper, we propose an Analytic Exemplar-Free\nOnline Continual Learning algorithm (AEF-OCL). The AEF-OCL leverages analytic\ncontinual learning principles and employs ridge regression as a classifier for\nfeatures extracted by a large backbone network. It solves the OCL problem by\nrecursively calculating the analytical solution, ensuring an equalization\nbetween the continual learning and its joint-learning counterpart, and works\nwithout the need to save any used samples (i.e., exemplar-free). Additionally,\nwe introduce a Pseudo-Features Generator (PFG) module that recursively\nestimates the mean and the variance of real features for each class. It\nover-samples offset pseudo-features from the same normal distribution as the\nreal features, thereby addressing the data imbalance issue. Experimental\nresults demonstrate that despite being an exemplar-free strategy, our method\noutperforms various methods on the autonomous driving SODA10M dataset. Source\ncode is available at https://github.com/ZHUANGHP/Analytic-continual-learning.\n","authors":["Huiping Zhuang","Di Fang","Kai Tong","Yuchen Liu","Ziqian Zeng","Xu Zhou","Cen Chen"],"pdf_url":"https://arxiv.org/pdf/2405.17779v2.pdf","comment":"This paper is to be published in IEEE Transactions on Vehicular\n  Technology"},{"id":"http://arxiv.org/abs/2406.04331v2","updated":"2024-11-05T15:43:18Z","published":"2024-06-06T17:59:10Z","title":"PaCE: Parsimonious Concept Engineering for Large Language Models","summary":"  Large Language Models (LLMs) are being used for a wide variety of tasks.\nWhile they are capable of generating human-like responses, they can also\nproduce undesirable output including potentially harmful information, racist or\nsexist language, and hallucinations. Alignment methods are designed to reduce\nsuch undesirable outputs via techniques such as fine-tuning, prompt\nengineering, and representation engineering. However, existing methods face\nseveral challenges: some require costly fine-tuning for every alignment task;\nsome do not adequately remove undesirable concepts, failing alignment; some\nremove benign concepts, lowering the linguistic capabilities of LLMs. To\naddress these issues, we propose Parsimonious Concept Engineering (PaCE), a\nnovel activation engineering framework for alignment. First, to sufficiently\nmodel the concepts, we construct a large-scale concept dictionary in the\nactivation space, in which each atom corresponds to a semantic concept. Given\nany alignment task, we instruct a concept partitioner to efficiently annotate\nthe concepts as benign or undesirable. Then, at inference time, we decompose\nthe LLM activations along the concept dictionary via sparse coding, to\naccurately represent the activations as linear combinations of benign and\nundesirable components. By removing the latter ones from the activations, we\nreorient the behavior of the LLM towards the alignment goal. We conduct\nexperiments on tasks such as response detoxification, faithfulness enhancement,\nand sentiment revising, and show that PaCE achieves state-of-the-art alignment\nperformance while maintaining linguistic capabilities.\n","authors":["Jinqi Luo","Tianjiao Ding","Kwan Ho Ryan Chan","Darshan Thaker","Aditya Chattopadhyay","Chris Callison-Burch","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2406.04331v2.pdf","comment":"Accepted in NeurIPS 2024. GitHub repository at\n  https://github.com/peterljq/Parsimonious-Concept-Engineering"},{"id":"http://arxiv.org/abs/2411.03195v1","updated":"2024-11-05T15:40:53Z","published":"2024-11-05T15:40:53Z","title":"Online Data Collection for Efficient Semiparametric Inference","summary":"  While many works have studied statistical data fusion, they typically assume\nthat the various datasets are given in advance. However, in practice,\nestimation requires difficult data collection decisions like determining the\navailable data sources, their costs, and how many samples to collect from each\nsource. Moreover, this process is often sequential because the data collected\nat a given time can improve collection decisions in the future. In our setup,\ngiven access to multiple data sources and budget constraints, the agent must\nsequentially decide which data source to query to efficiently estimate a target\nparameter. We formalize this task using Online Moment Selection, a\nsemiparametric framework that applies to any parameter identified by a set of\nmoment conditions. Interestingly, the optimal budget allocation depends on the\n(unknown) true parameters. We present two online data collection policies,\nExplore-then-Commit and Explore-then-Greedy, that use the parameter estimates\nat a given time to optimally allocate the remaining budget in the future steps.\nWe prove that both policies achieve zero regret (assessed by asymptotic MSE)\nrelative to an oracle policy. We empirically validate our methods on both\nsynthetic and real-world causal effect estimation tasks, demonstrating that the\nonline data collection policies outperform their fixed counterparts.\n","authors":["Shantanu Gupta","Zachary C. Lipton","David Childers"],"pdf_url":"https://arxiv.org/pdf/2411.03195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09918v4","updated":"2024-11-05T15:37:00Z","published":"2024-03-14T23:31:41Z","title":"Attention-based Class-Conditioned Alignment for Multi-Source Domain\n  Adaptation of Object Detectors","summary":"  Domain adaptation methods for object detection (OD) strive to mitigate the\nimpact of distribution shifts by promoting feature alignment across source and\ntarget domains. Multi-source domain adaptation (MSDA) allows leveraging\nmultiple annotated source datasets and unlabeled target data to improve the\naccuracy and robustness of the detection model. Most state-of-the-art MSDA\nmethods for OD perform feature alignment in a class-agnostic manner. This is\nchallenging since the objects have unique modal information due to variations\nin object appearance across domains. A recent prototype-based approach proposed\na class-wise alignment, yet it suffers from error accumulation due to noisy\npseudo-labels that can negatively affect adaptation with imbalanced data. To\novercome these limitations, we propose an attention-based class-conditioned\nalignment method for MSDA that aligns instances of each object category across\ndomains. In particular, an attention module coupled with an adversarial domain\nclassifier allows learning domain-invariant and class-specific instance\nrepresentations. Experimental results on multiple benchmarking MSDA datasets\nindicate that our method outperforms the state-of-the-art methods and is robust\nto class imbalance using a conceptually simple class-conditioning method. Our\ncode is available at https://github.com/imatif17/ACIA.\n","authors":["Atif Belal","Akhil Meethal","Francisco Perdigon Romero","Marco Pedersoli","Eric Granger"],"pdf_url":"https://arxiv.org/pdf/2403.09918v4.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2309.14950"},{"id":"http://arxiv.org/abs/2411.03186v1","updated":"2024-11-05T15:31:16Z","published":"2024-11-05T15:31:16Z","title":"Insights into Lunar Mineralogy: An Unsupervised Approach for Clustering\n  of the Moon Mineral Mapper (M3) spectral data","summary":"  This paper presents a novel method for mapping spectral features of the Moon\nusing machine learning-based clustering of hyperspectral data from the Moon\nMineral Mapper (M3) imaging spectrometer. The method uses a convolutional\nvariational autoencoder to reduce the dimensionality of the spectral data and\nextract features of the spectra. Then, a k-means algorithm is applied to\ncluster the latent variables into five distinct groups, corresponding to\ndominant spectral features, which are related to the mineral composition of the\nMoon's surface. The resulting global spectral cluster map shows the\ndistribution of the five clusters on the Moon, which consist of a mixture of,\namong others, plagioclase, pyroxene, olivine, and Fe-bearing minerals across\nthe Moon's surface. The clusters are compared to the mineral maps from the\nKaguya mission, which showed that the locations of the clusters overlap with\nthe locations of high wt% of minerals such as plagioclase, clinopyroxene, and\nolivine. The paper demonstrates the usefulness of unbiased unsupervised\nlearning for lunar mineral exploration and provides a comprehensive analysis of\nlunar mineralogy.\n","authors":["Freja Thoresen","Igor Drozdovskiy","Aidan Cowley","Magdelena Laban","Sebastien Besse","Sylvain Blunier"],"pdf_url":"https://arxiv.org/pdf/2411.03186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14558v2","updated":"2024-11-05T15:31:12Z","published":"2024-05-23T13:37:26Z","title":"FUSE: Fast Unified Simulation and Estimation for PDEs","summary":"  The joint prediction of continuous fields and statistical estimation of the\nunderlying discrete parameters is a common problem for many physical systems,\ngoverned by PDEs. Hitherto, it has been separately addressed by employing\noperator learning surrogates for field prediction while using simulation-based\ninference (and its variants) for statistical parameter determination. Here, we\nargue that solving both problems within the same framework can lead to\nconsistent gains in accuracy and robustness. To this end, We propose a novel\nand flexible formulation of the operator learning problem that allows jointly\npredicting continuous quantities and inferring distributions of discrete\nparameters, and thus amortizing the cost of both the inverse and the surrogate\nmodels to a joint pre-training step. We present the capabilities of the\nproposed methodology for predicting continuous and discrete biomarkers in\nfull-body haemodynamics simulations under different levels of missing\ninformation. We also consider a test case for atmospheric large-eddy simulation\nof a two-dimensional dry cold bubble, where we infer both continuous\ntime-series and information about the systems conditions. We present\ncomparisons against different baselines to showcase significantly increased\naccuracy in both the inverse and the surrogate tasks.\n","authors":["Levi E. Lingsch","Dana Grund","Siddhartha Mishra","Georgios Kissas"],"pdf_url":"https://arxiv.org/pdf/2405.14558v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03664v2","updated":"2024-11-05T15:27:04Z","published":"2024-08-07T10:06:04Z","title":"AI-Driven approach for sustainable extraction of earth's subsurface\n  renewable energy while minimizing seismic activity","summary":"  Deep Geothermal Energy, Carbon Capture and Storage, and Hydrogen Storage hold\nconsiderable promise for meeting the energy sector's large-scale requirements\nand reducing CO$_2$ emissions. However, the injection of fluids into the\nEarth's crust, essential for these activities, can induce or trigger\nearthquakes. In this paper, we highlight a new approach based on Reinforcement\nLearning for the control of human-induced seismicity in the highly complex\nenvironment of an underground reservoir. This complex system poses significant\nchallenges in the control design due to parameter uncertainties and unmodeled\ndynamics. We show that the reinforcement learning algorithm can interact\nefficiently with a robust controller, by choosing the controller parameters in\nreal-time, reducing human-induced seismicity and allowing the consideration of\nfurther production objectives, \\textit{e.g.}, minimal control power.\nSimulations are presented for a simplified underground reservoir under various\nenergy demand scenarios, demonstrating the reliability and effectiveness of the\nproposed control-reinforcement learning approach.\n","authors":["Diego Gutierrez-Oribio","Alexandros Stathas","Ioannis Stefanou"],"pdf_url":"https://arxiv.org/pdf/2408.03664v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09045v2","updated":"2024-11-05T15:26:50Z","published":"2023-09-16T16:52:49Z","title":"Temporal Smoothness Regularisers for Neural Link Predictors","summary":"  Most algorithms for representation learning and link prediction on relational\ndata are designed for static data. However, the data to which they are applied\ntypically evolves over time, including online social networks or interactions\nbetween users and items in recommender systems. This is also the case for\ngraph-structured knowledge bases -- knowledge graphs -- which contain facts\nthat are valid only for specific points in time. In such contexts, it becomes\ncrucial to correctly identify missing links at a precise time point, i.e. the\ntemporal prediction link task. Recently, Lacroix et al. and Sadeghian et al.\nproposed a solution to the problem of link prediction for knowledge graphs\nunder temporal constraints inspired by the canonical decomposition of 4-order\ntensors, where they regularise the representations of time steps by enforcing\ntemporal smoothing, i.e. by learning similar transformation for adjacent\ntimestamps. However, the impact of the choice of temporal regularisation terms\nis still poorly understood. In this work, we systematically analyse several\nchoices of temporal smoothing regularisers using linear functions and recurrent\narchitectures. In our experiments, we show that by carefully selecting the\ntemporal smoothing regulariser and regularisation weight, a simple method like\nTNTComplEx can produce significantly more accurate results than\nstate-of-the-art methods on three widely used temporal link prediction\ndatasets. Furthermore, we evaluate the impact of a wide range of temporal\nsmoothing regularisers on two state-of-the-art temporal link prediction models.\nOur work shows that simple tensor factorisation models can produce new\nstate-of-the-art results using newly proposed temporal regularisers,\nhighlighting a promising avenue for future research.\n","authors":["Manuel Dileo","Pasquale Minervini","Matteo Zignani","Sabrina Gaito"],"pdf_url":"https://arxiv.org/pdf/2309.09045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03172v1","updated":"2024-11-05T15:20:23Z","published":"2024-11-05T15:20:23Z","title":"Blind Estimation of Sub-band Acoustic Parameters from Ambisonics\n  Recordings using Spectro-Spatial Covariance Features","summary":"  Estimating frequency-varying acoustic parameters is essential for enhancing\nimmersive perception in realistic spatial audio creation. In this paper, we\npropose a unified framework that blindly estimates reverberation time (T60),\ndirect-to-reverberant ratio (DRR), and clarity (C50) across 10 frequency bands\nusing first-order Ambisonics (FOA) speech recordings as inputs. The proposed\nframework utilizes a novel feature named Spectro-Spatial Covariance Vector\n(SSCV), efficiently representing temporal, spectral as well as spatial\ninformation of the FOA signal. Our models significantly outperform existing\nsingle-channel methods with only spectral information, reducing estimation\nerrors by more than half for all three acoustic parameters. Additionally, we\nintroduce FOA-Conv3D, a novel back-end network for effectively utilising the\nSSCV feature with a 3D convolutional encoder. FOA-Conv3D outperforms the\nconvolutional neural network (CNN) and recurrent convolutional neural network\n(CRNN) backends, achieving lower estimation errors and accounting for a higher\nproportion of variance (PoV) for all 3 acoustic parameters.\n","authors":["Hanyu Meng","Jeroen Breebaart","Jeremy Stoddard","Vidhyasaharan Sethu","Eliathamby Ambikairajah"],"pdf_url":"https://arxiv.org/pdf/2411.03172v1.pdf","comment":"Submitted to ICASSP2025"},{"id":"http://arxiv.org/abs/2405.15699v3","updated":"2024-11-05T15:19:55Z","published":"2024-05-24T16:43:26Z","title":"Dimension-free deterministic equivalents and scaling laws for random\n  feature regression","summary":"  In this work we investigate the generalization performance of random feature\nridge regression (RFRR). Our main contribution is a general deterministic\nequivalent for the test error of RFRR. Specifically, under a certain\nconcentration property, we show that the test error is well approximated by a\nclosed-form expression that only depends on the feature map eigenvalues.\nNotably, our approximation guarantee is non-asymptotic, multiplicative, and\nindependent of the feature map dimension -- allowing for infinite-dimensional\nfeatures. We expect this deterministic equivalent to hold broadly beyond our\ntheoretical analysis, and we empirically validate its predictions on various\nreal and synthetic datasets. As an application, we derive sharp excess error\nrates under standard power-law assumptions of the spectrum and target decay. In\nparticular, we provide a tight result for the smallest number of features\nachieving optimal minimax error rate.\n","authors":["Leonardo Defilippis","Bruno Loureiro","Theodor Misiakiewicz"],"pdf_url":"https://arxiv.org/pdf/2405.15699v3.pdf","comment":"NeurIPS 2024 camera-ready version"},{"id":"http://arxiv.org/abs/2411.03169v1","updated":"2024-11-05T15:18:02Z","published":"2024-11-05T15:18:02Z","title":"Pre-trained Visual Dynamics Representations for Efficient Policy\n  Learning","summary":"  Pre-training for Reinforcement Learning (RL) with purely video data is a\nvaluable yet challenging problem. Although in-the-wild videos are readily\navailable and inhere a vast amount of prior world knowledge, the absence of\naction annotations and the common domain gap with downstream tasks hinder\nutilizing videos for RL pre-training. To address the challenge of pre-training\nwith videos, we propose Pre-trained Visual Dynamics Representations (PVDR) to\nbridge the domain gap between videos and downstream tasks for efficient policy\nlearning. By adopting video prediction as a pre-training task, we use a\nTransformer-based Conditional Variational Autoencoder (CVAE) to learn visual\ndynamics representations. The pre-trained visual dynamics representations\ncapture the visual dynamics prior knowledge in the videos. This abstract prior\nknowledge can be readily adapted to downstream tasks and aligned with\nexecutable actions through online adaptation. We conduct experiments on a\nseries of robotics visual control tasks and verify that PVDR is an effective\nform for pre-training with videos to promote policy learning.\n","authors":["Hao Luo","Bohan Zhou","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2411.03169v1.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2405.15593v2","updated":"2024-11-05T15:15:13Z","published":"2024-05-24T14:25:23Z","title":"MicroAdam: Accurate Adaptive Optimization with Low Space Overhead and\n  Provable Convergence","summary":"  We propose a new variant of the Adam optimizer called MicroAdam that\nspecifically minimizes memory overheads, while maintaining theoretical\nconvergence guarantees. We achieve this by compressing the gradient information\nbefore it is fed into the optimizer state, thereby reducing its memory\nfootprint significantly. We control the resulting compression error via a novel\ninstance of the classical \\emph{error feedback} mechanism from distributed\noptimization in which *the error correction information is itself compressed*\nto allow for practical memory gains. We prove that the resulting approach\nmaintains theoretical convergence guarantees competitive to those of AMSGrad,\nwhile providing good practical performance. Specifically, we show that\nMicroAdam can be implemented efficiently on GPUs: on both million-scale (BERT)\nand billion-scale (LLaMA) models, MicroAdam provides practical convergence\ncompetitive to that of the uncompressed Adam baseline, with lower memory usage\nand similar running time. Our code is available at\nhttps://github.com/IST-DASLab/MicroAdam.\n","authors":["Ionut-Vlad Modoranu","Mher Safaryan","Grigory Malinovsky","Eldar Kurtic","Thomas Robert","Peter Richtarik","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2405.15593v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03163v1","updated":"2024-11-05T15:07:20Z","published":"2024-11-05T15:07:20Z","title":"Efficient Hamiltonian, structure and trace distance learning of Gaussian\n  states","summary":"  In this work, we initiate the study of Hamiltonian learning for positive\ntemperature bosonic Gaussian states, the quantum generalization of the widely\nstudied problem of learning Gaussian graphical models. We obtain efficient\nprotocols, both in sample and computational complexity, for the task of\ninferring the parameters of their underlying quadratic Hamiltonian under the\nassumption of bounded temperature, squeezing, displacement and maximal degree\nof the interaction graph. Our protocol only requires heterodyne measurements,\nwhich are often experimentally feasible, and has a sample complexity that\nscales logarithmically with the number of modes. Furthermore, we show that it\nis possible to learn the underlying interaction graph in a similar setting and\nsample complexity. Taken together, our results put the status of the quantum\nHamiltonian learning problem for continuous variable systems in a much more\nadvanced state when compared to spins, where state-of-the-art results are\neither unavailable or quantitatively inferior to ours. In addition, we use our\ntechniques to obtain the first results on learning Gaussian states in trace\ndistance with a quadratic scaling in precision and polynomial in the number of\nmodes, albeit imposing certain restrictions on the Gaussian states. Our main\ntechnical innovations are several continuity bounds for the covariance and\nHamiltonian matrix of a Gaussian state, which are of independent interest,\ncombined with what we call the local inversion technique. In essence, the local\ninversion technique allows us to reliably infer the Hamiltonian of a Gaussian\nstate by only estimating in parallel submatrices of the covariance matrix whose\nsize scales with the desired precision, but not the number of modes. This way\nwe bypass the need to obtain precise global estimates of the covariance matrix,\ncontrolling the sample complexity.\n","authors":["Marco Fanizza","Cambyse Rouzé","Daniel Stilck França"],"pdf_url":"https://arxiv.org/pdf/2411.03163v1.pdf","comment":"43 pages, 1 figure"},{"id":"http://arxiv.org/abs/2209.12713v2","updated":"2024-11-05T15:05:38Z","published":"2022-09-26T14:08:03Z","title":"Multi-Agent Coordination via Multi-Level Communication","summary":"  The partial observability and stochasticity in multi-agent settings can be\nmitigated by accessing more information about others via communication.\nHowever, the coordination problem still exists since agents cannot communicate\nactual actions with each other at the same time due to the circular\ndependencies. In this paper, we propose a novel multi-level communication\nscheme, Sequential Communication (SeqComm). SeqComm treats agents\nasynchronously (the upper-level agents make decisions before the lower-level\nones) and has two communication phases. In the negotiation phase, agents\ndetermine the priority of decision-making by communicating hidden states of\nobservations and comparing the value of intention, obtained by modeling the\nenvironment dynamics. In the launching phase, the upper-level agents take the\nlead in making decisions and then communicate their actions with the\nlower-level agents. Theoretically, we prove the policies learned by SeqComm are\nguaranteed to improve monotonically and converge. Empirically, we show that\nSeqComm outperforms existing methods in various cooperative multi-agent tasks.\n","authors":["Ziluo Ding","Zeyuan Liu","Zhirui Fang","Kefan Su","Liwen Zhu","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2209.12713v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03162v1","updated":"2024-11-05T15:05:23Z","published":"2024-11-05T15:05:23Z","title":"A Machine Learning Approach for the Efficient Estimation of Ground-Level\n  Air Temperature in Urban Areas","summary":"  The increasingly populated cities of the 21st Century face the challenge of\nbeing sustainable and resilient spaces for their inhabitants. However, climate\nchange, among other problems, makes these objectives difficult to achieve. The\nUrban Heat Island (UHI) phenomenon that occurs in cities, increasing their\nthermal stress, is one of the stumbling blocks to achieve a more sustainable\ncity. The ability to estimate temperatures with a high degree of accuracy\nallows for the identification of the highest priority areas in cities where\nurban improvements need to be made to reduce thermal discomfort. In this work\nwe explore the usefulness of image-to-image deep neural networks (DNNs) for\ncorrelating spatial and meteorological variables of a urban area with\nstreet-level air temperature. The air temperature at street-level is estimated\nboth spatially and temporally for a specific use case, and compared with\nexisting, well-established numerical models. Based on the obtained results,\ndeep neural networks are confirmed to be faster and less computationally\nexpensive alternative for ground-level air temperature compared to numerical\nmodels.\n","authors":["Iñigo Delgado-Enales","Joshua Lizundia-Loiola","Patricia Molina-Costa","Javier Del Ser"],"pdf_url":"https://arxiv.org/pdf/2411.03162v1.pdf","comment":"39 pages, 8 figures, 2 tables, under review"},{"id":"http://arxiv.org/abs/2411.01076v2","updated":"2024-11-05T15:03:45Z","published":"2024-11-01T23:14:30Z","title":"Privacy Risks of Speculative Decoding in Large Language Models","summary":"  Speculative decoding in large language models (LLMs) accelerates token\ngeneration by speculatively predicting multiple tokens cheaply and verifying\nthem in parallel, and has been widely deployed. In this paper, we provide the\nfirst study demonstrating the privacy risks of speculative decoding. We observe\nthat input-dependent patterns of correct and incorrect predictions can be\nleaked out to an adversary monitoring token generation times and packet sizes,\nleading to privacy breaches. By observing the pattern of correctly and\nincorrectly speculated tokens, we show that a malicious adversary can\nfingerprint queries and learn private user inputs with more than $90\\%$\naccuracy across three different speculative decoding techniques - REST (almost\n$100\\%$ accuracy), LADE (up to $92\\%$ accuracy), and BiLD (up to $95\\%$\naccuracy). We show that an adversary can also leak out confidential\nintellectual property used to design these techniques, such as data from\ndata-stores used for prediction (in REST) at a rate of more than $25$ tokens\nper second, or even hyper-parameters used for prediction (in LADE). We also\ndiscuss mitigation strategies, such as aggregating tokens across multiple\niterations and padding packets with additional bytes, to avoid such privacy or\nconfidentiality breaches.\n","authors":["Jiankun Wei","Abdulrahman Abdulrazzag","Tianchen Zhang","Adel Muursepp","Gururaj Saileshwar"],"pdf_url":"https://arxiv.org/pdf/2411.01076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05237v2","updated":"2024-11-05T15:00:24Z","published":"2024-07-07T02:35:55Z","title":"Privacy of the last iterate in cyclically-sampled DP-SGD on nonconvex\n  composite losses","summary":"  Differentially-private stochastic gradient descent (DP-SGD) is a family of\niterative machine learning training algorithms that privatize gradients to\ngenerate a sequence of differentially-private (DP) model parameters. It is also\nthe standard tool used to train DP models in practice, even though most users\nare only interested in protecting the privacy of the final model. Tight DP\naccounting for the last iterate would minimize the amount of noise required\nwhile maintaining the same privacy guarantee and potentially increasing model\nutility. However, last-iterate accounting is challenging, and existing works\nrequire strong assumptions not satisfied by most implementations. These include\nassuming (i) the global sensitivity constant is known - to avoid gradient\nclipping; (ii) the loss function is Lipschitz or convex; and (iii) input\nbatches are sampled randomly.\n  In this work, we forego any unrealistic assumptions and provide privacy\nbounds for the most commonly used variant of DP-SGD, in which data is traversed\ncyclically, gradients are clipped, and only the last model is released. More\nspecifically, we establish new Renyi differential privacy (RDP) upper bounds\nfor the last iterate under realistic assumptions of small stepsize and\nLipschitz smoothness of the loss function. Our general bounds also recover the\nspecial-case convex bounds when the weak-convexity parameter of the objective\nfunction approaches zero and no clipping is performed. The approach itself\nleverages optimal transport techniques for last iterate bounds, which is a\nnontrivial task when the data is traversed cyclically and the loss function is\nnonconvex.\n","authors":["Weiwei Kong","Mónica Ribero"],"pdf_url":"https://arxiv.org/pdf/2407.05237v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03156v1","updated":"2024-11-05T14:58:31Z","published":"2024-11-05T14:58:31Z","title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery","summary":"  For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.\n","authors":["Lev Novitskiy","Vladimir Lazarev","Mikhail Tiutiulnikov","Nikita Vakhrameev","Roman Eremin","Innokentiy Humonen","Andrey Kuznetsov","Denis Dimitrov","Semen Budennyy"],"pdf_url":"https://arxiv.org/pdf/2411.03156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04825v7","updated":"2024-11-05T14:42:08Z","published":"2022-09-11T09:53:14Z","title":"Arithmetical Binary Decision Tree Traversals","summary":"  This paper introduces a series of methodes for traversing binary decision\ntrees using arithmetic operations. We present a suite of binary tree traversal\nalgorithms that leverage novel representation matrices to flatten the full\nbinary tree structure and embed the aggregated internal node Boolean tests into\na single bitvector. Our approach, grounded in maximum inner product search,\noffers new insights into decision tree.\n","authors":["Jinxiong Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.04825v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10932v3","updated":"2024-11-05T14:31:28Z","published":"2023-01-26T04:35:28Z","title":"On the Global Convergence of Risk-Averse Policy Gradient Methods with\n  Expected Conditional Risk Measures","summary":"  Risk-sensitive reinforcement learning (RL) has become a popular tool for\ncontrolling the risk of uncertain outcomes and ensuring reliable performance in\nhighly stochastic sequential decision-making problems. While Policy Gradient\n(PG) methods have been developed for risk-sensitive RL, it remains unclear if\nthese methods enjoy the same global convergence guarantees as in the\nrisk-neutral case\n\\citep{mei2020global,agarwal2021theory,cen2022fast,bhandari2024global}. In this\npaper, we consider a class of dynamic time-consistent risk measures, named\nExpected Conditional Risk Measures (ECRMs), and derive PG and Natural Policy\nGradient (NPG) updates for ECRMs-based RL problems. We provide global\noptimality {and iteration complexities} of the proposed algorithms under the\nfollowing four settings: (i) PG with constrained direct parameterization, (ii)\nPG with softmax parameterization and log barrier regularization, (iii) NPG with\nsoftmax parameterization and entropy regularization, and (iv) approximate NPG\nwith inexact policy evaluation. Furthermore, we test a risk-averse REINFORCE\nalgorithm \\citep{williams1992simple} and a risk-averse NPG algorithm\n\\citep{kakade2001natural} on a stochastic Cliffwalk environment to demonstrate\nthe efficacy of our methods and the importance of risk control.\n","authors":["Xian Yu","Lei Ying"],"pdf_url":"https://arxiv.org/pdf/2301.10932v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11935v2","updated":"2024-11-05T14:23:27Z","published":"2024-09-18T12:50:28Z","title":"Reinforcement Learning with Lie Group Orientations for Robotics","summary":"  Handling orientations of robots and objects is a crucial aspect of many\napplications. Yet, ever so often, there is a lack of mathematical correctness\nwhen dealing with orientations, especially in learning pipelines involving, for\nexample, artificial neural networks. In this paper, we investigate\nreinforcement learning with orientations and propose a simple modification of\nthe network's input and output that adheres to the Lie group structure of\norientations. As a result, we obtain an easy and efficient implementation that\nis directly usable with existing learning libraries and achieves significantly\nbetter performance than other common orientation representations. We briefly\nintroduce Lie theory specifically for orientations in robotics to motivate and\noutline our approach. Subsequently, a thorough empirical evaluation of\ndifferent combinations of orientation representations for states and actions\ndemonstrates the superior performance of our proposed approach in different\nscenarios, including: direct orientation control, end effector orientation\ncontrol, and pick-and-place tasks.\n","authors":["Martin Schuck","Jan Brüdigam","Sandra Hirche","Angela Schoellig"],"pdf_url":"https://arxiv.org/pdf/2409.11935v2.pdf","comment":"Submitted to ICRA 2025"},{"id":"http://arxiv.org/abs/2410.14970v2","updated":"2024-11-05T14:21:26Z","published":"2024-10-19T04:28:44Z","title":"Taming the Long Tail in Human Mobility Prediction","summary":"  With the popularity of location-based services, human mobility prediction\nplays a key role in enhancing personalized navigation, optimizing\nrecommendation systems, and facilitating urban mobility and planning. This\ninvolves predicting a user's next POI (point-of-interest) visit using their\npast visit history. However, the uneven distribution of visitations over time\nand space, namely the long-tail problem in spatial distribution, makes it\ndifficult for AI models to predict those POIs that are less visited by humans.\nIn light of this issue, we propose the Long-Tail Adjusted Next POI Prediction\n(LoTNext) framework for mobility prediction, combining a Long-Tailed Graph\nAdjustment module to reduce the impact of the long-tailed nodes in the user-POI\ninteraction graph and a novel Long-Tailed Loss Adjustment module to adjust loss\nby logit score and sample weight adjustment strategy. Also, we employ the\nauxiliary prediction task to enhance generalization and accuracy. Our\nexperiments with two real-world trajectory datasets demonstrate that LoTNext\nsignificantly surpasses existing state-of-the-art works. Our code is available\nat https://github.com/Yukayo/LoTNext.\n","authors":["Xiaohang Xu","Renhe Jiang","Chuang Yang","Zipei Fan","Kaoru Sezaki"],"pdf_url":"https://arxiv.org/pdf/2410.14970v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03127v1","updated":"2024-11-05T14:18:09Z","published":"2024-11-05T14:18:09Z","title":"User Centric Semantic Communications","summary":"  Current studies on semantic communications mainly focus on efficiently\nextracting semantic information to reduce bandwidth usage between a transmitter\nand a user. Although significant process has been made in the semantic\ncommunications, a fundamental design problem is that the semantic information\nis extracted based on certain criteria at the transmitter side along, without\nconsidering the user's actual requirements. As a result, critical information\nthat is of primary concern to the user may be lost. In such cases, the semantic\ntransmission becomes meaningless to the user, as all received information is\nirrelevant to the user's interests. To solve this problem, this paper presents\na user centric semantic communication system, where the user sends its request\nfor the desired semantic information to the transmitter at the start of each\ntransmission. Then, the transmitter extracts the required semantic information\naccordingly. A key challenge is how the transmitter can understand the user's\nrequests for semantic information and extract the required semantic information\nin a reasonable and robust manner. We solve this challenge by designing a\nwell-structured framework and leveraging off-the-shelf products, such as GPT-4,\nalong with several specialized tools for detection and estimation. Evaluation\nresults demonstrate the feasibility and effectiveness of the proposed user\ncentric semantic communication system.\n","authors":["Xunze Liu","Yifei Sun","Zhaorui Wang","Lizhao You","Haoyuan Pan","Fangxin Wang","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2411.03127v1.pdf","comment":null}]},"2024-11-04T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.02607v1","updated":"2024-11-04T21:01:03Z","published":"2024-11-04T21:01:03Z","title":"Towards Context-Aware Adaptation in Extended Reality: A Design Space for\n  XR Interfaces and an Adaptive Placement Strategy","summary":"  By converting the entire 3D space around the user into a screen, Extended\nReality (XR) can ameliorate traditional displays' space limitations and\nfacilitate the consumption of multiple pieces of information at a time.\nHowever, if designed inappropriately, these XR interfaces can overwhelm the\nuser and complicate information access. In this work, we explored the design\ndimensions that can be adapted to enable suitable presentation and interaction\nwithin an XR interface. To investigate a specific use case of context-aware\nadaptations within our proposed design space, we concentrated on the spatial\nlayout of the XR content and investigated non-adaptive and adaptive placement\nstrategies. In this paper, we (1) present a comprehensive design space for XR\ninterfaces, (2) propose Environment-referenced, an adaptive placement strategy\nthat uses a relevant intermediary from the environment within a Hybrid Frame of\nReference (FoR) for each XR object, and (3) evaluate the effectiveness of this\nadaptive placement strategy and a non-adaptive Body-Fixed placement strategy in\nfour contextual scenarios varying in terms of social setting and user mobility\nin the environment. The performance of these placement strategies from our\nwithin-subjects user study emphasized the importance of intermediaries'\nrelevance to the user's focus. These findings underscore the importance of\ncontext-aware interfaces, indicating that the appropriate use of an adaptive\ncontent placement strategy in a context can significantly improve task\nefficiency, accuracy, and usability.\n","authors":["Shakiba Davari","Doug A. Bowman"],"pdf_url":"https://arxiv.org/pdf/2411.02607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02571v1","updated":"2024-11-04T20:06:34Z","published":"2024-11-04T20:06:34Z","title":"MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs","summary":"  State-of-the-art retrieval models typically address a straightforward search\nscenario, where retrieval tasks are fixed (e.g., finding a passage to answer a\nspecific question) and only a single modality is supported for both queries and\nretrieved results. This paper introduces techniques for advancing information\nretrieval with multimodal large language models (MLLMs), enabling a broader\nsearch scenario, termed universal multimodal retrieval, where multiple\nmodalities and diverse retrieval tasks are accommodated. To this end, we first\nstudy fine-tuning an MLLM as a bi-encoder retriever on 10 datasets with 16\nretrieval tasks. Our empirical results show that the fine-tuned MLLM retriever\nis capable of understanding challenging queries, composed of both text and\nimage, but underperforms a smaller CLIP retriever in cross-modal retrieval\ntasks due to modality bias from MLLMs. To address the issue, we propose\nmodality-aware hard negative mining to mitigate the modality bias exhibited by\nMLLM retrievers. Second, we propose to continually fine-tune the universal\nmultimodal retriever to enhance its text retrieval capability while maintaining\nmultimodal retrieval capability. As a result, our model, MM-Embed, achieves\nstate-of-the-art performance on the multimodal retrieval benchmark M-BEIR,\nwhich spans multiple domains and tasks, while also surpassing the\nstate-of-the-art text retrieval model, NV-Embed-v1, on MTEB retrieval\nbenchmark. Finally, we explore to prompt the off-the-shelf MLLMs as the\nzero-shot rerankers to refine the ranking of the candidates from the multimodal\nretriever. We find that through prompt-and-reranking, MLLMs can further improve\nmultimodal retrieval when the user queries (e.g., text-image composed queries)\nare more complex and challenging to understand. These findings also pave the\nway to advance universal multimodal retrieval in the future.\n","authors":["Sheng-Chieh Lin","Chankyu Lee","Mohammad Shoeybi","Jimmy Lin","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2411.02571v1.pdf","comment":"We release the model weights at:\n  https://huggingface.co/nvidia/MM-Embed"},{"id":"http://arxiv.org/abs/2411.02537v1","updated":"2024-11-04T19:16:53Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v1.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.02284v1","updated":"2024-11-04T17:11:14Z","published":"2024-11-04T17:11:14Z","title":"Training on the Test Model: Contamination in Ranking Distillation","summary":"  Neural approaches to ranking based on pre-trained language models are highly\neffective in ad-hoc search. However, the computational expense of these models\ncan limit their application. As such, a process known as knowledge distillation\nis frequently applied to allow a smaller, efficient model to learn from an\neffective but expensive model. A key example of this is the distillation of\nexpensive API-based commercial Large Language Models into smaller\nproduction-ready models. However, due to the opacity of training data and\nprocesses of most commercial models, one cannot ensure that a chosen test\ncollection has not been observed previously, creating the potential for\ninadvertent data contamination. We, therefore, investigate the effect of a\ncontaminated teacher model in a distillation setting. We evaluate several\ndistillation techniques to assess the degree to which contamination occurs\nduring distillation. By simulating a ``worst-case'' setting where the degree of\ncontamination is known, we find that contamination occurs even when the test\ndata represents a small fraction of the teacher's training samples. We,\ntherefore, encourage caution when training using black-box teacher models where\ndata provenance is ambiguous.\n","authors":["Vishakha Suresh Kalal","Andrew Parry","Sean MacAvaney"],"pdf_url":"https://arxiv.org/pdf/2411.02284v1.pdf","comment":"4 pages"},{"id":"http://arxiv.org/abs/2411.02041v1","updated":"2024-11-04T12:43:12Z","published":"2024-11-04T12:43:12Z","title":"Enhancing ID-based Recommendation with Large Language Models","summary":"  Large Language Models (LLMs) have recently garnered significant attention in\nvarious domains, including recommendation systems. Recent research leverages\nthe capabilities of LLMs to improve the performance and user modeling aspects\nof recommender systems. These studies primarily focus on utilizing LLMs to\ninterpret textual data in recommendation tasks. However, it's worth noting that\nin ID-based recommendations, textual data is absent, and only ID data is\navailable. The untapped potential of LLMs for ID data within the ID-based\nrecommendation paradigm remains relatively unexplored. To this end, we\nintroduce a pioneering approach called \"LLM for ID-based Recommendation\"\n(LLM4IDRec). This innovative approach integrates the capabilities of LLMs while\nexclusively relying on ID data, thus diverging from the previous reliance on\ntextual data. The basic idea of LLM4IDRec is that by employing LLM to augment\nID data, if augmented ID data can improve recommendation performance, it\ndemonstrates the ability of LLM to interpret ID data effectively, exploring an\ninnovative way for the integration of LLM in ID-based recommendation. We\nevaluate the effectiveness of our LLM4IDRec approach using three widely-used\ndatasets. Our results demonstrate a notable improvement in recommendation\nperformance, with our approach consistently outperforming existing methods in\nID-based recommendation by solely augmenting input data.\n","authors":["Lei Chen","Chen Gao","Xiaoyi Du","Hengliang Luo","Depeng Jin","Yong Li","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2411.02041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01843v1","updated":"2024-11-04T06:31:52Z","published":"2024-11-04T06:31:52Z","title":"Dissertation: On the Theoretical Foundation of Model Comparison and\n  Evaluation for Recommender System","summary":"  Recommender systems have become increasingly important with the rise of the\nweb as a medium for electronic and business transactions. One of the key\ndrivers of this technology is the ease with which users can provide feedback\nabout their likes and dislikes through simple clicks of a mouse. This feedback\nis commonly collected in the form of ratings, but can also be inferred from a\nuser's browsing and purchasing history. Recommender systems utilize users'\nhistorical data to infer customer interests and provide personalized\nrecommendations. The basic principle of recommendations is that significant\ndependencies exist between user- and item-centric activity, which can be\nlearned in a data-driven manner to make accurate predictions. Collaborative\nfiltering is one family of recommendation algorithms that uses ratings from\nmultiple users to predict missing ratings or uses binary click information to\npredict potential clicks. However, recommender systems can be more complex and\nincorporate auxiliary data such as content-based attributes, user interactions,\nand contextual information.\n","authors":["Dong Li"],"pdf_url":"https://arxiv.org/pdf/2411.01843v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2312.08517"},{"id":"http://arxiv.org/abs/2411.01785v1","updated":"2024-11-04T04:16:11Z","published":"2024-11-04T04:16:11Z","title":"Transferable Sequential Recommendation via Vector Quantized Meta\n  Learning","summary":"  While sequential recommendation achieves significant progress on capturing\nuser-item transition patterns, transferring such large-scale recommender\nsystems remains challenging due to the disjoint user and item groups across\ndomains. In this paper, we propose a vector quantized meta learning for\ntransferable sequential recommenders (MetaRec). Without requiring additional\nmodalities or shared information across domains, our approach leverages\nuser-item interactions from multiple source domains to improve the target\ndomain performance. To solve the input heterogeneity issue, we adopt vector\nquantization that maps item embeddings from heterogeneous input spaces to a\nshared feature space. Moreover, our meta transfer paradigm exploits limited\ntarget data to guide the transfer of source domain knowledge to the target\ndomain (i.e., learn to transfer). In addition, MetaRec adaptively transfers\nfrom multiple source tasks by rescaling meta gradients based on the\nsource-target domain similarity, enabling selective learning to improve\nrecommendation performance. To validate the effectiveness of our approach, we\nperform extensive experiments on benchmark datasets, where MetaRec consistently\noutperforms baseline methods by a considerable margin.\n","authors":["Zhenrui Yue","Huimin Zeng","Yang Zhang","Julian McAuley","Dong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.01785v1.pdf","comment":"Accepted to BigData 2024"},{"id":"http://arxiv.org/abs/2403.00801v2","updated":"2024-11-04T03:07:30Z","published":"2024-02-23T18:45:35Z","title":"Self-Retrieval: End-to-End Information Retrieval with One Large Language\n  Model","summary":"  The rise of large language models (LLMs) has significantly transformed both\nthe construction and application of information retrieval (IR) systems.\nHowever, current interactions between IR systems and LLMs remain limited, with\nLLMs merely serving as part of components within IR systems, and IR systems\nbeing constructed independently of LLMs. This separated architecture restricts\nknowledge sharing and deep collaboration between them. In this paper, we\nintroduce Self-Retrieval, a novel end-to-end LLM-driven information retrieval\narchitecture. Self-Retrieval unifies all essential IR functions within a single\nLLM, leveraging the inherent capabilities of LLMs throughout the IR process.\nSpecifically, Self-Retrieval internalizes the retrieval corpus through\nself-supervised learning, transforms the retrieval process into sequential\npassage generation, and performs relevance assessment for reranking.\nExperimental results demonstrate that Self-Retrieval not only outperforms\nexisting retrieval approaches by a significant margin, but also substantially\nenhances the performance of LLM-driven downstream applications like\nretrieval-augmented generation.\n","authors":["Qiaoyu Tang","Jiawei Chen","Zhuoqun Li","Bowen Yu","Yaojie Lu","Cheng Fu","Haiyang Yu","Hongyu Lin","Fei Huang","Ben He","Xianpei Han","Le Sun","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2403.00801v2.pdf","comment":"NeurIPS 2024 Camera-ready Version. Code:\n  https://github.com/icip-cas/SelfRetrieval"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.02607v1","updated":"2024-11-04T21:01:03Z","published":"2024-11-04T21:01:03Z","title":"Towards Context-Aware Adaptation in Extended Reality: A Design Space for\n  XR Interfaces and an Adaptive Placement Strategy","summary":"  By converting the entire 3D space around the user into a screen, Extended\nReality (XR) can ameliorate traditional displays' space limitations and\nfacilitate the consumption of multiple pieces of information at a time.\nHowever, if designed inappropriately, these XR interfaces can overwhelm the\nuser and complicate information access. In this work, we explored the design\ndimensions that can be adapted to enable suitable presentation and interaction\nwithin an XR interface. To investigate a specific use case of context-aware\nadaptations within our proposed design space, we concentrated on the spatial\nlayout of the XR content and investigated non-adaptive and adaptive placement\nstrategies. In this paper, we (1) present a comprehensive design space for XR\ninterfaces, (2) propose Environment-referenced, an adaptive placement strategy\nthat uses a relevant intermediary from the environment within a Hybrid Frame of\nReference (FoR) for each XR object, and (3) evaluate the effectiveness of this\nadaptive placement strategy and a non-adaptive Body-Fixed placement strategy in\nfour contextual scenarios varying in terms of social setting and user mobility\nin the environment. The performance of these placement strategies from our\nwithin-subjects user study emphasized the importance of intermediaries'\nrelevance to the user's focus. These findings underscore the importance of\ncontext-aware interfaces, indicating that the appropriate use of an adaptive\ncontent placement strategy in a context can significantly improve task\nefficiency, accuracy, and usability.\n","authors":["Shakiba Davari","Doug A. Bowman"],"pdf_url":"https://arxiv.org/pdf/2411.02607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02551v1","updated":"2024-11-04T19:34:13Z","published":"2024-11-04T19:34:13Z","title":"PIAST: A Multimodal Piano Dataset with Audio, Symbolic and Text","summary":"  While piano music has become a significant area of study in Music Information\nRetrieval (MIR), there is a notable lack of datasets for piano solo music with\ntext labels. To address this gap, we present PIAST (PIano dataset with Audio,\nSymbolic, and Text), a piano music dataset. Utilizing a piano-specific taxonomy\nof semantic tags, we collected 9,673 tracks from YouTube and added human\nannotations for 2,023 tracks by music experts, resulting in two subsets:\nPIAST-YT and PIAST-AT. Both include audio, text, tag annotations, and\ntranscribed MIDI utilizing state-of-the-art piano transcription and beat\ntracking models. Among many possible tasks with the multi-modal dataset, we\nconduct music tagging and retrieval using both audio and MIDI data and report\nbaseline performances to demonstrate its potential as a valuable resource for\nMIR research.\n","authors":["Hayeon Bang","Eunjin Choi","Megan Finch","Seungheon Doh","Seolhee Lee","Gyeong-Hoon Lee","Juan Nam"],"pdf_url":"https://arxiv.org/pdf/2411.02551v1.pdf","comment":"Accepted for publication at the 3rd Workshop on NLP for Music and\n  Audio (NLP4MusA 2024)"},{"id":"http://arxiv.org/abs/2411.02334v1","updated":"2024-11-04T17:58:54Z","published":"2024-11-04T17:58:54Z","title":"Diffusion-based Generative Multicasting with Intent-aware Semantic\n  Decomposition","summary":"  Generative diffusion models (GDMs) have recently shown great success in\nsynthesizing multimedia signals with high perceptual quality enabling highly\nefficient semantic communications in future wireless networks. In this paper,\nwe develop an intent-aware generative semantic multicasting framework utilizing\npre-trained diffusion models. In the proposed framework, the transmitter\ndecomposes the source signal to multiple semantic classes based on the\nmulti-user intent, i.e. each user is assumed to be interested in details of\nonly a subset of the semantic classes. The transmitter then sends to each user\nonly its intended classes, and multicasts a highly compressed semantic map to\nall users over shared wireless resources that allows them to locally synthesize\nthe other classes, i.e. non-intended classes, utilizing pre-trained diffusion\nmodels. The signal retrieved at each user is thereby partially reconstructed\nand partially synthesized utilizing the received semantic map. This improves\nutilization of the wireless resources, with better preserving privacy of the\nnon-intended classes. We design a communication/computation-aware scheme for\nper-class adaptation of the communication parameters, such as the transmission\npower and compression rate to minimize the total latency of retrieving signals\nat multiple receivers, tailored to the prevailing channel conditions as well as\nthe users reconstruction/synthesis distortion/perception requirements. The\nsimulation results demonstrate significantly reduced per-user latency compared\nwith non-generative and intent-unaware multicasting benchmarks while\nmaintaining high perceptual quality of the signals retrieved at the users.\n","authors":["Xinkai Liu","Mahdi Boloursaz Mashhadi","Li Qiao","Yi Ma","Rahim Tafazolli","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2411.02334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02236v1","updated":"2024-11-04T16:30:14Z","published":"2024-11-04T16:30:14Z","title":"3D Audio-Visual Segmentation","summary":"  Recognizing the sounding objects in scenes is a longstanding objective in\nembodied AI, with diverse applications in robotics and AR/VR/MR. To that end,\nAudio-Visual Segmentation (AVS), taking as condition an audio signal to\nidentify the masks of the target sounding objects in an input image with\nsynchronous camera and microphone sensors, has been recently advanced. However,\nthis paradigm is still insufficient for real-world operation, as the mapping\nfrom 2D images to 3D scenes is missing. To address this fundamental limitation,\nwe introduce a novel research problem, 3D Audio-Visual Segmentation, extending\nthe existing AVS to the 3D output space. This problem poses more challenges due\nto variations in camera extrinsics, audio scattering, occlusions, and diverse\nacoustics across sounding object categories. To facilitate this research, we\ncreate the very first simulation based benchmark, 3DAVS-S34-O7, providing\nphotorealistic 3D scene environments with grounded spatial audio under\nsingle-instance and multi-instance settings, across 34 scenes and 7 object\ncategories. This is made possible by re-purposing the Habitat simulator to\ngenerate comprehensive annotations of sounding object locations and\ncorresponding 3D masks. Subsequently, we propose a new approach, EchoSegnet,\ncharacterized by integrating the ready-to-use knowledge from pretrained 2D\naudio-visual foundation models synergistically with 3D visual scene\nrepresentation through spatial audio-aware mask alignment and refinement.\nExtensive experiments demonstrate that EchoSegnet can effectively segment\nsounding objects in 3D space on our new benchmark, representing a significant\nadvancement in the field of embodied AI. Project page:\nhttps://surrey-uplab.github.io/research/3d-audio-visual-segmentation/\n","authors":["Artem Sokolov","Swapnil Bhosale","Xiatian Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.02236v1.pdf","comment":"Accepted at the NeurIPS 2024 Workshop on Audio Imagination"},{"id":"http://arxiv.org/abs/2407.05645v3","updated":"2024-11-04T09:14:03Z","published":"2024-07-08T06:14:37Z","title":"OneDiff: A Generalist Model for Image Difference Captioning","summary":"  In computer vision, Image Difference Captioning (IDC) is crucial for\naccurately describing variations between closely related images. Traditional\nIDC methods often rely on specialist models, which restrict their applicability\nacross varied contexts. This paper introduces the OneDiff model, a novel\ngeneralist approach that utilizes a robust vision-language model architecture,\nintegrating a siamese image encoder with a Visual Delta Module. This innovative\nconfiguration allows for the precise detection and articulation of fine-grained\ndifferences between image pairs. OneDiff is trained through a dual-phase\nstrategy, encompassing Coupled Sample Training and multi-task learning across a\ndiverse array of data types, supported by our newly developed DiffCap Dataset.\nThis dataset merges real-world and synthetic data, enhancing the training\nprocess and bolstering the model's robustness. Extensive testing on diverse IDC\nbenchmarks, such as Spot-the-Diff, Image-Editing-Request, and Birds-to-Words,\nshows that OneDiff consistently outperforms existing state-of-the-art models in\naccuracy and adaptability, achieving improvements of up to 97% CIDEr points in\naverage. By setting a new benchmark in IDC, OneDiff paves the way for more\nversatile and effective applications in detecting and describing visual\ndifferences. The code, models, and data will be made publicly available.\n","authors":["Erdong Hu","Longteng Guo","Tongtian Yue","Zijia Zhao","Shuning Xue","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2407.05645v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01805v1","updated":"2024-11-04T05:17:44Z","published":"2024-11-04T05:17:44Z","title":"MoMu-Diffusion: On Learning Long-Term Motion-Music Synchronization and\n  Correspondence","summary":"  Motion-to-music and music-to-motion have been studied separately, each\nattracting substantial research interest within their respective domains. The\ninteraction between human motion and music is a reflection of advanced human\nintelligence, and establishing a unified relationship between them is\nparticularly important. However, to date, there has been no work that considers\nthem jointly to explore the modality alignment within. To bridge this gap, we\npropose a novel framework, termed MoMu-Diffusion, for long-term and synchronous\nmotion-music generation. Firstly, to mitigate the huge computational costs\nraised by long sequences, we propose a novel Bidirectional Contrastive Rhythmic\nVariational Auto-Encoder (BiCoR-VAE) that extracts the modality-aligned latent\nrepresentations for both motion and music inputs. Subsequently, leveraging the\naligned latent spaces, we introduce a multi-modal Transformer-based diffusion\nmodel and a cross-guidance sampling strategy to enable various generation\ntasks, including cross-modal, multi-modal, and variable-length generation.\nExtensive experiments demonstrate that MoMu-Diffusion surpasses recent\nstate-of-the-art methods both qualitatively and quantitatively, and can\nsynthesize realistic, diverse, long-term, and beat-matched music or motion\nsequences. The generated samples and codes are available at\nhttps://momu-diffusion.github.io/\n","authors":["Fuming You","Minghui Fang","Li Tang","Rongjie Huang","Yongqi Wang","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.01805v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2305.15748v2","updated":"2024-11-04T00:48:12Z","published":"2023-05-25T05:55:53Z","title":"ReactFace: Online Multiple Appropriate Facial Reaction Generation in\n  Dyadic Interactions","summary":"  In dyadic interaction, predicting the listener's facial reactions is\nchallenging as different reactions could be appropriate in response to the same\nspeaker's behaviour. Previous approaches predominantly treated this task as an\ninterpolation or fitting problem, emphasizing deterministic outcomes but\nignoring the diversity and uncertainty of human facial reactions. Furthermore,\nthese methods often failed to model short-range and long-range dependencies\nwithin the interaction context, leading to issues in the synchrony and\nappropriateness of the generated facial reactions. To address these\nlimitations, this paper reformulates the task as an extrapolation or prediction\nproblem, and proposes an novel framework (called ReactFace) to generate\nmultiple different but appropriate facial reactions from a speaker behaviour\nrather than merely replicating the corresponding listener facial behaviours.\nOur ReactFace generates multiple different but appropriate photo-realistic\nhuman facial reactions by: (i) learning an appropriate facial reaction\ndistribution representing multiple different but appropriate facial reactions;\nand (ii) synchronizing the generated facial reactions with the speaker verbal\nand non-verbal behaviours at each time stamp, resulting in realistic 2D facial\nreaction sequences. Experimental results demonstrate the effectiveness of our\napproach in generating multiple diverse, synchronized, and appropriate facial\nreactions from each speaker's behaviour. The quality of the generated facial\nreactions is intimately tied to the speaker's speech and facial expressions,\nachieved through our novel speaker-listener interaction modules. Our code is\nmade publicly available at \\url{https://github.com/lingjivoo/ReactFace}.\n","authors":["Cheng Luo","Siyang Song","Weicheng Xie","Micol Spitale","Zongyuan Ge","Linlin Shen","Hatice Gunes"],"pdf_url":"https://arxiv.org/pdf/2305.15748v2.pdf","comment":"Accepted to IEEE Transactions on Visualization and Computer Graphics\n  (TVCG), 18 pages, 10 figures"}]},"2024-11-03T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.23300v2","updated":"2024-11-03T22:11:35Z","published":"2024-10-15T21:54:13Z","title":"Understanding and Scaling Collaborative Filtering Optimization from the\n  Perspective of Matrix Rank","summary":"  Collaborative Filtering (CF) methods dominate real-world recommender systems\ngiven their ability to learn high-quality, sparse ID-embedding tables that\neffectively capture user preferences. These tables scale linearly with the\nnumber of users and items, and are trained to ensure high similarity between\nembeddings of interacted user-item pairs, while maintaining low similarity for\nnon-interacted pairs. Despite their high performance, encouraging dispersion\nfor non-interacted pairs necessitates expensive regularization (e.g., negative\nsampling), hurting runtime and scalability. Existing research tends to address\nthese challenges by simplifying the learning process, either by reducing model\ncomplexity or sampling data, trading performance for runtime. In this work, we\nmove beyond model-level modifications and study the properties of the embedding\ntables under different learning strategies. Through theoretical analysis, we\nfind that the singular values of the embedding tables are intrinsically linked\nto different CF loss functions. These findings are empirically validated on\nreal-world datasets, demonstrating the practical benefits of higher stable\nrank, a continuous version of matrix rank which encodes the distribution of\nsingular values. Based on these insights, we propose an efficient warm-start\nstrategy that regularizes the stable rank of the user and item embeddings. We\nshow that stable rank regularization during early training phases can promote\nhigher-quality embeddings, resulting in training speed improvements of up to\n66%. Additionally, stable rank regularization can act as a proxy for negative\nsampling, allowing for performance gains of up to 21% over loss functions with\nsmall negative sampling ratios. Overall, our analysis unifies current CF\nmethods under a new perspective, their optimization of stable rank, motivating\na flexible regularization method.\n","authors":["Donald Loveland","Xinyi Wu","Tong Zhao","Danai Koutra","Neil Shah","Mingxuan Ju"],"pdf_url":"https://arxiv.org/pdf/2410.23300v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01690v1","updated":"2024-11-03T21:32:07Z","published":"2024-11-03T21:32:07Z","title":"Co-clustering for Federated Recommender System","summary":"  As data privacy and security attract increasing attention, Federated\nRecommender System (FRS) offers a solution that strikes a balance between\nproviding high-quality recommendations and preserving user privacy. However,\nthe presence of statistical heterogeneity in FRS, commonly observed due to\npersonalized decision-making patterns, can pose challenges. To address this\nissue and maximize the benefit of collaborative filtering (CF) in FRS, it is\nintuitive to consider clustering clients (users) as well as items into\ndifferent groups and learning group-specific models. Existing methods either\nresort to client clustering via user representations-risking privacy leakage,\nor employ classical clustering strategies on item embeddings or gradients,\nwhich we found are plagued by the curse of dimensionality. In this paper, we\ndelve into the inefficiencies of the K-Means method in client grouping,\nattributing failures due to the high dimensionality as well as data sparsity\noccurring in FRS, and propose CoFedRec, a novel Co-clustering Federated\nRecommendation mechanism, to address clients heterogeneity and enhance the\ncollaborative filtering within the federated framework. Specifically, the\nserver initially formulates an item membership from the client-provided item\nnetworks. Subsequently, clients are grouped regarding a specific item category\npicked from the item membership during each communication round, resulting in\nan intelligently aggregated group model. Meanwhile, to comprehensively capture\nthe global inter-relationships among items, we incorporate an additional\nsupervised contrastive learning term based on the server-side generated item\nmembership into the local training phase for each client. Extensive experiments\non four datasets are provided, which verify the effectiveness of the proposed\nCoFedRec.\n","authors":["Xinrui He","Shuo Liu","Jackey Keung","Jingrui He"],"pdf_url":"https://arxiv.org/pdf/2411.01690v1.pdf","comment":"WWW '24: Proceedings of the ACM Web Conference 2024"},{"id":"http://arxiv.org/abs/2411.02454v1","updated":"2024-11-03T20:36:44Z","published":"2024-11-03T20:36:44Z","title":"Graph-based Confidence Calibration for Large Language Models","summary":"  One important approach to improving the reliability of large language models\n(LLMs) is to provide accurate confidence estimations regarding the correctness\nof their answers. However, developing a well-calibrated confidence estimation\nmodel is challenging, as mistakes made by LLMs can be difficult to detect. We\npropose a novel method combining the LLM's self-consistency with labeled data\nand training an auxiliary model to estimate the correctness of its responses to\nquestions. This auxiliary model predicts the correctness of responses based\nsolely on their consistent information. To set up the learning problem, we use\na weighted graph to represent the consistency among the LLM's multiple\nresponses to a question. Correctness labels are assigned to these responses\nbased on their similarity to the correct answer. We then train a graph neural\nnetwork to estimate the probability of correct responses. Experiments\ndemonstrate that the proposed approach substantially outperforms several of the\nmost recent methods in confidence calibration across multiple widely adopted\nbenchmark datasets. Furthermore, the proposed approach significantly improves\nthe generalization capability of confidence calibration on out-of-domain (OOD)\ndata.\n","authors":["Yukun Li","Sijia Wang","Lifu Huang","Li-Ping Liu"],"pdf_url":"https://arxiv.org/pdf/2411.02454v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01611v1","updated":"2024-11-03T15:37:37Z","published":"2024-11-03T15:37:37Z","title":"Stochastic Communication Avoidance for Recommendation Systems","summary":"  One of the major bottlenecks for efficient deployment of neural network based\nrecommendation systems is the memory footprint of their embedding tables.\nAlthough many neural network based recommendation systems could benefit from\nthe faster on-chip memory access and increased computational power of hardware\naccelerators, the large embedding tables in these models often cannot fit on\nthe constrained memory of accelerators. Despite the pervasiveness of these\nmodels, prior methods in memory optimization and parallelism fail to address\nthe memory and communication costs of large embedding tables on accelerators.\nAs a result, the majority of models are trained on CPUs, while current\nimplementations of accelerators are hindered by issues such as bottlenecks in\ninter-device communication and main memory lookups. In this paper, we propose a\ntheoretical framework that analyses the communication costs of arbitrary\ndistributed systems that use lookup tables. We use this framework to propose\nalgorithms that maximize throughput subject to memory, computation, and\ncommunication constraints. Furthermore, we demonstrate that our method achieves\nstrong theoretical performance across dataset distributions and memory\nconstraints, applicable to a wide range of use cases from mobile federated\nlearning to warehouse-scale computation. We implement our framework and\nalgorithms in PyTorch and achieve up to 6x increases in training throughput on\nGPU systems over baselines, on the Criteo Terabytes dataset.\n","authors":["Lutfi Eren Erdogan","Vijay Anand Raghava Kanakagiri","Kurt Keutzer","Zhen Dong"],"pdf_url":"https://arxiv.org/pdf/2411.01611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01561v1","updated":"2024-11-03T13:23:07Z","published":"2024-11-03T13:23:07Z","title":"Multimodal Graph Neural Network for Recommendation with Dynamic\n  De-redundancy and Modality-Guided Feature De-noisy","summary":"  Graph neural networks (GNNs) have become crucial in multimodal recommendation\ntasks because of their powerful ability to capture complex relationships\nbetween neighboring nodes. However, increasing the number of propagation layers\nin GNNs can lead to feature redundancy, which may negatively impact the overall\nrecommendation performance. In addition, the existing recommendation task\nmethod directly maps the preprocessed multimodal features to the\nlow-dimensional space, which will bring the noise unrelated to user preference,\nthus affecting the representation ability of the model. To tackle the\naforementioned challenges, we propose Multimodal Graph Neural Network for\nRecommendation (MGNM) with Dynamic De-redundancy and Modality-Guided Feature\nDe-noisy, which is divided into local and global interaction. Initially, in the\nlocal interaction process,we integrate a dynamic de-redundancy (DDR) loss\nfunction which is achieved by utilizing the product of the feature coefficient\nmatrix and the feature matrix as a penalization factor. It reduces the feature\nredundancy effects of multimodal and behavioral features caused by the stacking\nof multiple GNN layers. Subsequently, in the global interaction process, we\ndeveloped modality-guided global feature purifiers for each modality to\nalleviate the impact of modality noise. It is a two-fold guiding mechanism\neliminating modality features that are irrelevant to user preferences and\ncaptures complex relationships within the modality. Experimental results\ndemonstrate that MGNM achieves superior performance on multimodal information\ndenoising and removal of redundant information compared to the state-of-the-art\nmethods.\n","authors":["Feng Mo","Lin Xiao","Qiya Song","Xieping Gao","Eryao Liang"],"pdf_url":"https://arxiv.org/pdf/2411.01561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01540v1","updated":"2024-11-03T12:10:20Z","published":"2024-11-03T12:10:20Z","title":"Efficient and Robust Regularized Federated Recommendation","summary":"  Recommender systems play a pivotal role across practical scenarios,\nshowcasing remarkable capabilities in user preference modeling. However, the\ncentralized learning paradigm predominantly used raises serious privacy\nconcerns. The federated recommender system (FedRS) addresses this by updating\nmodels on clients, while a central server orchestrates training without\naccessing private data. Existing FedRS approaches, however, face unresolved\nchallenges, including non-convex optimization, vulnerability, potential privacy\nleakage risk, and communication inefficiency. This paper addresses these\nchallenges by reformulating the federated recommendation problem as a convex\noptimization issue, ensuring convergence to the global optimum. Based on this,\nwe devise a novel method, RFRec, to tackle this optimization problem\nefficiently. In addition, we propose RFRecF, a highly efficient version that\nincorporates non-uniform stochastic gradient descent to improve communication\nefficiency. In user preference modeling, both methods learn local and global\nmodels, collaboratively learning users' common and personalized interests under\nthe federated learning setting. Moreover, both methods significantly enhance\ncommunication efficiency, robustness, and privacy protection, with theoretical\nsupport. Comprehensive evaluations on four benchmark datasets demonstrate RFRec\nand RFRecF's superior performance compared to diverse baselines.\n","authors":["Langming Liu","Wanyu Wang","Xiangyu Zhao","Zijian Zhang","Chunxu Zhang","Shanru Lin","Yiqi Wang","Lixin Zou","Zitao Liu","Xuetao Wei","Hongzhi Yin","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2411.01540v1.pdf","comment":"CIKM 2024"},{"id":"http://arxiv.org/abs/2411.01537v1","updated":"2024-11-03T11:56:00Z","published":"2024-11-03T11:56:00Z","title":"LinRec: Linear Attention Mechanism for Long-term Sequential Recommender\n  Systems","summary":"  Transformer models have achieved remarkable success in sequential recommender\nsystems (SRSs). However, computing the attention matrix in traditional\ndot-product attention mechanisms results in a quadratic complexity with\nsequence lengths, leading to high computational costs for long-term sequential\nrecommendation. Motivated by the above observation, we propose a novel\nL2-Normalized Linear Attention for the Transformer-based Sequential Recommender\nSystems (LinRec), which theoretically improves efficiency while preserving the\nlearning capabilities of the traditional dot-product attention. Specifically,\nby thoroughly examining the equivalence conditions of efficient attention\nmechanisms, we show that LinRec possesses linear complexity while preserving\nthe property of attention mechanisms. In addition, we reveal its latent\nefficiency properties by interpreting the proposed LinRec mechanism through a\nstatistical lens. Extensive experiments are conducted based on two public\nbenchmark datasets, demonstrating that the combination of LinRec and\nTransformer models achieves comparable or even superior performance than\nstate-of-the-art Transformer-based SRS models while significantly improving\ntime and memory efficiency.\n","authors":["Langming Liu","Xiangyu Zhao","Chi Zhang","Jingtong Gao","Wanyu Wang","Wenqi Fan","Yiqi Wang","Ming He","Zitao Liu","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2411.01537v1.pdf","comment":"SIGIR 2023"},{"id":"http://arxiv.org/abs/2411.02451v1","updated":"2024-11-03T10:06:14Z","published":"2024-11-03T10:06:14Z","title":"High-performance automated abstract screening with large language model\n  ensembles","summary":"  Large language models (LLMs) excel in tasks requiring processing and\ninterpretation of input text. Abstract screening is a labour-intensive\ncomponent of systematic review involving repetitive application of inclusion\nand exclusion criteria on a large volume of studies identified by a literature\nsearch. Here, LLMs (GPT-3.5 Turbo, GPT-4 Turbo, GPT-4o, Llama 3 70B, Gemini 1.5\nPro, and Claude Sonnet 3.5) were trialled on systematic reviews in a full issue\nof the Cochrane Library to evaluate their accuracy in zero-shot binary\nclassification for abstract screening. Trials over a subset of 800 records\nidentified optimal prompting strategies and demonstrated superior performance\nof LLMs to human researchers in terms of sensitivity (LLMmax = 1.000, humanmax\n= 0.775), precision (LLMmax = 0.927, humanmax = 0.911), and balanced accuracy\n(LLMmax = 0.904, humanmax = 0.865). The best performing LLM-prompt combinations\nwere trialled across every replicated search result (n = 119,691), and\nexhibited consistent sensitivity (range 0.756-1.000) but diminished precision\n(range 0.004-0.096). 66 LLM-human and LLM-LLM ensembles exhibited perfect\nsensitivity with a maximal precision of 0.458, with less observed performance\ndrop in larger trials. Significant variation in performance was observed\nbetween reviews, highlighting the importance of domain-specific validation\nbefore deployment. LLMs may reduce the human labour cost of systematic review\nwith maintained or improved accuracy and sensitivity. Systematic review is the\nfoundation of evidence-based medicine, and LLMs can contribute to increasing\nthe efficiency and quality of this mode of research.\n","authors":["Rohan Sanghera","Arun James Thirunavukarasu","Marc El Khoury","Jessica O'Logbon","Yuqing Chen","Archie Watt","Mustafa Mahmood","Hamid Butt","George Nishimura","Andrew Soltan"],"pdf_url":"https://arxiv.org/pdf/2411.02451v1.pdf","comment":"RS and AJT are joint-first authors"},{"id":"http://arxiv.org/abs/2410.18634v2","updated":"2024-11-03T08:14:34Z","published":"2024-10-24T10:47:30Z","title":"Little Giants: Synthesizing High-Quality Embedding Data at Scale","summary":"  Synthetic data generation has become an increasingly popular way of training\nmodels without the need for large, manually labeled datasets. For tasks like\ntext embedding, synthetic data offers diverse and scalable training examples,\nsignificantly reducing the cost of human annotation. However, most current\napproaches rely heavily on proprietary models like GPT-4, which are expensive\nand inefficient for generating large-scale embedding data. In this paper, we\nintroduce SPEED, a framework that aligns open-source small models (8B) to\nefficiently generate large-scale synthetic embedding data. Through supervised\nfine-tuning, preference optimization, and self-improvement, SPEED enables small\nopen-source models to produce high-quality data. Remarkably, SPEED uses only\nless than 1/10 of the GPT API calls, outperforming the state-of-the-art\nembedding model E5_mistral when both are trained solely on their synthetic\ndata. Using this efficient generator, we conduct a comprehensive study on how\nvarious factors within the alignment pipeline impact data quality and reveal\nthe scaling law for synthetic embedding data.\n","authors":["Haonan Chen","Liang Wang","Nan Yang","Yutao Zhu","Ziliang Zhao","Furu Wei","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2410.18634v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01457v1","updated":"2024-11-03T06:47:45Z","published":"2024-11-03T06:47:45Z","title":"Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential\n  Recommendation","summary":"  Sequential recommendation (SR) systems excel at capturing users' dynamic\npreferences by leveraging their interaction histories. Most existing SR systems\nassign a single embedding vector to each item to represent its features, and\nvarious types of models are adopted to combine these item embeddings into a\nsequence representation vector to capture the user intent. However, we argue\nthat this representation alone is insufficient to capture an item's\nmulti-faceted nature (e.g., movie genres, starring actors). Besides, users\noften exhibit complex and varied preferences within these facets (e.g., liking\nboth action and musical films in the facet of genre), which are challenging to\nfully represent. To address the issues above, we propose a novel structure\ncalled Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential\nRecommendation (FAME). We leverage sub-embeddings from each head in the last\nmulti-head attention layer to predict the next item separately. This approach\ncaptures the potential multi-faceted nature of items without increasing model\ncomplexity. A gating mechanism integrates recommendations from each head and\ndynamically determines their importance. Furthermore, we introduce a\nMixture-of-Experts (MoE) network in each attention head to disentangle various\nuser preferences within each facet. Each expert within the MoE focuses on a\nspecific preference. A learnable router network is adopted to compute the\nimportance weight for each expert and aggregate them. We conduct extensive\nexperiments on four public sequential recommendation datasets and the results\ndemonstrate the effectiveness of our method over existing baseline models.\n","authors":["Mingrui Liu","Sixiao Zhang","Cheng Long"],"pdf_url":"https://arxiv.org/pdf/2411.01457v1.pdf","comment":"This paper has been accepted by WSDM'25. The final camera-ready\n  version will be available soon"}],"Multimedia":[{"id":"http://arxiv.org/abs/2403.14468v4","updated":"2024-11-03T21:16:54Z","published":"2024-03-21T15:15:00Z","title":"AnyV2V: A Tuning-Free Framework For Any Video-to-Video Editing Tasks","summary":"  In the dynamic field of digital content creation using generative models,\nstate-of-the-art video editing models still do not offer the level of quality\nand control that users desire. Previous works on video editing either extended\nfrom image-based generative models in a zero-shot manner or necessitated\nextensive fine-tuning, which can hinder the production of fluid video edits.\nFurthermore, these methods frequently rely on textual input as the editing\nguidance, leading to ambiguities and limiting the types of edits they can\nperform. Recognizing these challenges, we introduce AnyV2V, a novel tuning-free\nparadigm designed to simplify video editing into two primary steps: (1)\nemploying an off-the-shelf image editing model to modify the first frame, (2)\nutilizing an existing image-to-video generation model to generate the edited\nvideo through temporal feature injection. AnyV2V can leverage any existing\nimage editing tools to support an extensive array of video editing tasks,\nincluding prompt-based editing, reference-based style transfer, subject-driven\nediting, and identity manipulation, which were unattainable by previous\nmethods. AnyV2V can also support any video length. Our evaluation shows that\nAnyV2V achieved CLIP-scores comparable to other baseline methods. Furthermore,\nAnyV2V significantly outperformed these baselines in human evaluations,\ndemonstrating notable improvements in visual consistency with the source video\nwhile producing high-quality edits across all editing tasks.\n","authors":["Max Ku","Cong Wei","Weiming Ren","Harry Yang","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14468v4.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR 2024)\n  (11/2024)"},{"id":"http://arxiv.org/abs/2406.13743v3","updated":"2024-11-03T20:22:32Z","published":"2024-06-19T18:00:07Z","title":"GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual\n  Generation","summary":"  While text-to-visual models now produce photo-realistic images and videos,\nthey struggle with compositional text prompts involving attributes,\nrelationships, and higher-order reasoning such as logic and comparison. In this\nwork, we conduct an extensive human study on GenAI-Bench to evaluate the\nperformance of leading image and video generation models in various aspects of\ncompositional text-to-visual generation. We also compare automated evaluation\nmetrics against our collected human ratings and find that VQAScore -- a metric\nmeasuring the likelihood that a VQA model views an image as accurately\ndepicting the prompt -- significantly outperforms previous metrics such as\nCLIPScore. In addition, VQAScore can improve generation in a black-box manner\n(without finetuning) via simply ranking a few (3 to 9) candidate images.\nRanking by VQAScore is 2x to 3x more effective than other scoring methods like\nPickScore, HPSv2, and ImageReward at improving human alignment ratings for\nDALL-E 3 and Stable Diffusion, especially on compositional prompts that require\nadvanced visio-linguistic reasoning. We release a new GenAI-Rank benchmark with\nover 40,000 human ratings to evaluate scoring metrics on ranking images\ngenerated from the same prompt. Lastly, we discuss promising areas for\nimprovement in VQAScore, such as addressing fine-grained visual details. We\nwill release all human ratings (over 80,000) to facilitate scientific\nbenchmarking of both generative models and automated metrics.\n","authors":["Baiqi Li","Zhiqiu Lin","Deepak Pathak","Jiayao Li","Yixin Fei","Kewen Wu","Tiffany Ling","Xide Xia","Pengchuan Zhang","Graham Neubig","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2406.13743v3.pdf","comment":"We open-source our dataset, model, and code at:\n  https://linzhiqiu.github.io/papers/genai_bench ; Project page:\n  https://linzhiqiu.github.io/papers/genai_bench ; GenAI-Bench was first\n  introduced in arxiv:2404.01291. This article extends it with an additional\n  GenAI-Rank benchmark"},{"id":"http://arxiv.org/abs/2411.01561v1","updated":"2024-11-03T13:23:07Z","published":"2024-11-03T13:23:07Z","title":"Multimodal Graph Neural Network for Recommendation with Dynamic\n  De-redundancy and Modality-Guided Feature De-noisy","summary":"  Graph neural networks (GNNs) have become crucial in multimodal recommendation\ntasks because of their powerful ability to capture complex relationships\nbetween neighboring nodes. However, increasing the number of propagation layers\nin GNNs can lead to feature redundancy, which may negatively impact the overall\nrecommendation performance. In addition, the existing recommendation task\nmethod directly maps the preprocessed multimodal features to the\nlow-dimensional space, which will bring the noise unrelated to user preference,\nthus affecting the representation ability of the model. To tackle the\naforementioned challenges, we propose Multimodal Graph Neural Network for\nRecommendation (MGNM) with Dynamic De-redundancy and Modality-Guided Feature\nDe-noisy, which is divided into local and global interaction. Initially, in the\nlocal interaction process,we integrate a dynamic de-redundancy (DDR) loss\nfunction which is achieved by utilizing the product of the feature coefficient\nmatrix and the feature matrix as a penalization factor. It reduces the feature\nredundancy effects of multimodal and behavioral features caused by the stacking\nof multiple GNN layers. Subsequently, in the global interaction process, we\ndeveloped modality-guided global feature purifiers for each modality to\nalleviate the impact of modality noise. It is a two-fold guiding mechanism\neliminating modality features that are irrelevant to user preferences and\ncaptures complex relationships within the modality. Experimental results\ndemonstrate that MGNM achieves superior performance on multimodal information\ndenoising and removal of redundant information compared to the state-of-the-art\nmethods.\n","authors":["Feng Mo","Lin Xiao","Qiya Song","Xieping Gao","Eryao Liang"],"pdf_url":"https://arxiv.org/pdf/2411.01561v1.pdf","comment":null}]},"2024-11-02T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.01376v1","updated":"2024-11-02T22:59:36Z","published":"2024-11-02T22:59:36Z","title":"Multi-Channel Hypergraph Contrastive Learning for Matrix Completion","summary":"  Rating is a typical user explicit feedback that visually reflects how much a\nuser likes a related item. The (rating) matrix completion is essentially a\nrating prediction process, which is also a significant problem in recommender\nsystems. Recently, graph neural networks (GNNs) have been widely used in matrix\ncompletion, which captures users' preferences over items by formulating a\nrating matrix as a bipartite graph. However, existing methods are susceptible\ndue to data sparsity and long-tail distribution in real-world scenarios.\nMoreover, the messaging mechanism of GNNs makes it difficult to capture\nhigh-order correlations and constraints between nodes, which are essentially\nuseful in recommendation tasks. To tackle these challenges, we propose a\nMulti-Channel Hypergraph Contrastive Learning framework for matrix completion,\nnamed MHCL. Specifically, MHCL adaptively learns hypergraph structures to\ncapture high-order correlations between nodes and jointly captures local and\nglobal collaborative relationships through attention-based cross-view\naggregation. Additionally, to consider the magnitude and order information of\nratings, we treat different rating subgraphs as different channels, encourage\nalignment between adjacent ratings, and further achieve the mutual enhancement\nbetween different ratings through multi-channel cross-rating contrastive\nlearning. Extensive experiments on five public datasets demonstrate that the\nproposed method significantly outperforms the current state-of-the-art\napproaches.\n","authors":["Xiang Li","Changsheng Shui","Yanwei Yu","Chao Huang","Zhongying Zhao","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2411.01376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01368v1","updated":"2024-11-02T21:53:20Z","published":"2024-11-02T21:53:20Z","title":"Combining Financial Data and News Articles for Stock Price Movement\n  Prediction Using Large Language Models","summary":"  Predicting financial markets and stock price movements requires analyzing a\ncompany's performance, historic price movements, industry-specific events\nalongside the influence of human factors such as social media and press\ncoverage. We assume that financial reports (such as income statements, balance\nsheets, and cash flow statements), historical price data, and recent news\narticles can collectively represent aforementioned factors. We combine\nfinancial data in tabular format with textual news articles and employ\npre-trained Large Language Models (LLMs) to predict market movements. Recent\nresearch in LLMs has demonstrated that they are able to perform both tabular\nand text classification tasks, making them our primary model to classify the\nmulti-modal data. We utilize retrieval augmentation techniques to retrieve and\nattach relevant chunks of news articles to financial metrics related to a\ncompany and prompt the LLMs in zero, two, and four-shot settings. Our dataset\ncontains news articles collected from different sources, historic stock price,\nand financial report data for 20 companies with the highest trading volume\nacross different industries in the stock market. We utilized recently released\nlanguage models for our LLM-based classifier, including GPT- 3 and 4, and\nLLaMA- 2 and 3 models. We introduce an LLM-based classifier capable of\nperforming classification tasks using combination of tabular (structured) and\ntextual (unstructured) data. By using this model, we predicted the movement of\na given stock's price in our dataset with a weighted F1-score of 58.5% and\n59.1% and Matthews Correlation Coefficient of 0.175 for both 3-month and\n6-month periods.\n","authors":["Ali Elahi","Fatemeh Taghvaei"],"pdf_url":"https://arxiv.org/pdf/2411.01368v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.01354v1","updated":"2024-11-02T20:05:31Z","published":"2024-11-02T20:05:31Z","title":"Online and Offline Evaluations of Collaborative Filtering and Content\n  Based Recommender Systems","summary":"  Recommender systems are widely used AI applications designed to help users\nefficiently discover relevant items. The effectiveness of such systems is tied\nto the satisfaction of both users and providers. However, user satisfaction is\ncomplex and cannot be easily framed mathematically using information retrieval\nand accuracy metrics. While many studies evaluate accuracy through offline\ntests, a growing number of researchers argue that online evaluation methods\nsuch as A/B testing are better suited for this purpose. We have employed a\nvariety of algorithms on different types of datasets divergent in size and\nsubject, producing recommendations in various platforms, including media\nstreaming services, digital publishing websites, e-commerce systems, and news\nbroadcasting networks. Notably, our target websites and datasets are in Persian\n(Farsi) language.\n  This study provides a comparative analysis of a large-scale recommender\nsystem that has been operating for the past year across about 70 websites in\nIran, processing roughly 300 requests per second collectively. The system\nemploys user-based and item-based recommendations using content-based,\ncollaborative filtering, trend-based methods, and hybrid approaches. Through\nboth offline and online evaluations, we aim to identify where these algorithms\nperform most efficiently and determine the best method for our specific needs,\nconsidering the dataset and system scale. Our methods of evaluation include\nmanual evaluation, offline tests including accuracy and ranking metrics like\nhit-rate@k and nDCG, and online tests consisting of click-through rate (CTR).\nAdditionally we analyzed and proposed methods to address cold-start and\npopularity bias.\n","authors":["Ali Elahi","Armin Zirak"],"pdf_url":"https://arxiv.org/pdf/2411.01354v1.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.07865v6","updated":"2024-11-02T16:56:36Z","published":"2023-03-14T12:56:47Z","title":"Predicting the Geolocation of Tweets Using transformer models on\n  Customized Data","summary":"  This research is aimed to solve the tweet/user geolocation prediction task\nand provide a flexible methodology for the geotagging of textual big data. The\nsuggested approach implements neural networks for natural language processing\n(NLP) to estimate the location as coordinate pairs (longitude, latitude) and\ntwo-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models\nhas been finetuned on a Twitter dataset using pretrained Bidirectional Encoder\nRepresentations from Transformers (BERT) as base models. Performance metrics\nshow a median error of fewer than 30 km on a worldwide-level, and fewer than 15\nkm on the US-level datasets for the models trained and evaluated on text\nfeatures of tweets' content and metadata context. Our source code and data are\navailable at https://github.com/K4TEL/geo-twitter.git\n","authors":["Kateryna Lutsai","Christoph H. Lampert"],"pdf_url":"https://arxiv.org/pdf/2303.07865v6.pdf","comment":"31 pages, 5 tables, 9 figures"},{"id":"http://arxiv.org/abs/2411.01304v1","updated":"2024-11-02T16:39:45Z","published":"2024-11-02T16:39:45Z","title":"Towards a Knowledge Graph for Teaching Knowledge Graphs","summary":"  This poster paper describes the ongoing research project for the creation of\na use-case-driven Knowledge Graph resource tailored to the needs of teaching\neducation in Knowledge Graphs (KGs). We gather resources related to KG courses\nfrom lectures offered by the Semantic Web community, with the help of the COST\nAction Distributed Knowledge Graphs and the interest group on KGs at The Alan\nTuring Institute. Our goal is to create a resource-focused KG with multiple\ninterconnected semantic layers that interlink topics, courses, and materials\nwith each lecturer. Our approach formulates a domain KG in teaching and relates\nit with multiple Personal KGs created for the lecturers.\n","authors":["Eleni Ilkou","Ernesto Jiménez-Ruiz"],"pdf_url":"https://arxiv.org/pdf/2411.01304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22844v2","updated":"2024-11-02T15:23:36Z","published":"2024-10-30T09:23:14Z","title":"Understanding and Improving Adversarial Collaborative Filtering for\n  Robust Recommendation","summary":"  Adversarial Collaborative Filtering (ACF), which typically applies\nadversarial perturbations at user and item embeddings through adversarial\ntraining, is widely recognized as an effective strategy for enhancing the\nrobustness of Collaborative Filtering (CF) recommender systems against\npoisoning attacks. Besides, numerous studies have empirically shown that ACF\ncan also improve recommendation performance compared to traditional CF. Despite\nthese empirical successes, the theoretical understanding of ACF's effectiveness\nin terms of both performance and robustness remains unclear. To bridge this\ngap, in this paper, we first theoretically show that ACF can achieve a lower\nrecommendation error compared to traditional CF with the same training epochs\nin both clean and poisoned data contexts. Furthermore, by establishing bounds\nfor reductions in recommendation error during ACF's optimization process, we\nfind that applying personalized magnitudes of perturbation for different users\nbased on their embedding scales can further improve ACF's effectiveness.\nBuilding on these theoretical understandings, we propose Personalized Magnitude\nAdversarial Collaborative Filtering (PamaCF). Extensive experiments demonstrate\nthat PamaCF effectively defends against various types of poisoning attacks\nwhile significantly enhancing recommendation performance.\n","authors":["Kaike Zhang","Qi Cao","Yunfan Wu","Fei Sun","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.22844v2.pdf","comment":"To appear in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02442v1","updated":"2024-11-02T14:36:03Z","published":"2024-11-02T14:36:03Z","title":"TODO: Enhancing LLM Alignment with Ternary Preferences","summary":"  Aligning large language models (LLMs) with human intent is critical for\nenhancing their performance across a variety of tasks. Standard alignment\ntechniques, such as Direct Preference Optimization (DPO), often rely on the\nbinary Bradley-Terry (BT) model, which can struggle to capture the complexities\nof human preferences -- particularly in the presence of noisy or inconsistent\nlabels and frequent ties. To address these limitations, we introduce the\nTie-rank Oriented Bradley-Terry model (TOBT), an extension of the BT model that\nexplicitly incorporates ties, enabling more nuanced preference representation.\nBuilding on this, we propose Tie-rank Oriented Direct Preference Optimization\n(TODO), a novel alignment algorithm that leverages TOBT's ternary ranking\nsystem to improve preference alignment. In evaluations on Mistral-7B and Llama\n3-8B models, TODO consistently outperforms DPO in modeling preferences across\nboth in-distribution and out-of-distribution datasets. Additional assessments\nusing MT Bench and benchmarks such as Piqa, ARC-c, and MMLU further demonstrate\nTODO's superior alignment performance. Notably, TODO also shows strong results\nin binary preference alignment, highlighting its versatility and potential for\nbroader integration into LLM alignment. The implementation details can be found\nin https://github.com/XXares/TODO.\n","authors":["Yuxiang Guo","Lu Yin","Bo Jiang","Jiaqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.02442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01182v1","updated":"2024-11-02T08:50:11Z","published":"2024-11-02T08:50:11Z","title":"Graph Cross-Correlated Network for Recommendation","summary":"  Collaborative filtering (CF) models have demonstrated remarkable performance\nin recommender systems, which represent users and items as embedding vectors.\nRecently, due to the powerful modeling capability of graph neural networks for\nuser-item interaction graphs, graph-based CF models have gained increasing\nattention. They encode each user/item and its subgraph into a single super\nvector by combining graph embeddings after each graph convolution. However,\neach hop of the neighbor in the user-item subgraphs carries a specific semantic\nmeaning. Encoding all subgraph information into single vectors and inferring\nuser-item relations with dot products can weaken the semantic information\nbetween user and item subgraphs, thus leaving untapped potential. Exploiting\nthis untapped potential provides insight into improving performance for\nexisting recommendation models. To this end, we propose the Graph\nCross-correlated Network for Recommendation (GCR), which serves as a general\nrecommendation paradigm that explicitly considers correlations between\nuser/item subgraphs. GCR first introduces the Plain Graph Representation (PGR)\nto extract information directly from each hop of neighbors into corresponding\nPGR vectors. Then, GCR develops Cross-Correlated Aggregation (CCA) to construct\npossible cross-correlated terms between PGR vectors of user/item subgraphs.\nFinally, GCR comprehensively incorporates the cross-correlated terms for\nrecommendations. Experimental results show that GCR outperforms\nstate-of-the-art models on both interaction prediction and click-through rate\nprediction tasks.\n","authors":["Hao Chen","Yuanchen Bei","Wenbing Huang","Shengyuan Chen","Feiran Huang","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2411.01182v1.pdf","comment":"14 pages, accepted by TKDE"},{"id":"http://arxiv.org/abs/2411.01178v1","updated":"2024-11-02T08:36:16Z","published":"2024-11-02T08:36:16Z","title":"LLM4PR: Improving Post-Ranking in Search Engine with Large Language\n  Models","summary":"  Alongside the rapid development of Large Language Models (LLMs), there has\nbeen a notable increase in efforts to integrate LLM techniques in information\nretrieval (IR) and search engines (SE). Recently, an additional post-ranking\nstage is suggested in SE to enhance user satisfaction in practical\napplications. Nevertheless, research dedicated to enhancing the post-ranking\nstage through LLMs remains largely unexplored. In this study, we introduce a\nnovel paradigm named Large Language Models for Post-Ranking in search engine\n(LLM4PR), which leverages the capabilities of LLMs to accomplish the\npost-ranking task in SE. Concretely, a Query-Instructed Adapter (QIA) module is\ndesigned to derive the user/item representation vectors by incorporating their\nheterogeneous features. A feature adaptation step is further introduced to\nalign the semantics of user/item representations with the LLM. Finally, the\nLLM4PR integrates a learning to post-rank step, leveraging both a main task and\nan auxiliary task to fine-tune the model to adapt the post-ranking task.\nExperiment studies demonstrate that the proposed framework leads to significant\nimprovements and exhibits state-of-the-art performance compared with other\nalternatives.\n","authors":["Yang Yan","Yihao Wang","Chi Zhang","Wenyuan Hou","Kang Pan","Xingkai Ren","Zelun Wu","Zhixin Zhai","Enyun Yu","Wenwu Ou","Yang Song"],"pdf_url":"https://arxiv.org/pdf/2411.01178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17769v2","updated":"2024-11-02T08:06:32Z","published":"2024-04-27T03:37:12Z","title":"Two-stage Conformal Risk Control with Application to Ranked Retrieval","summary":"  Many practical machine learning systems, such as ranking and recommendation\nsystems, consist of two concatenated stages: retrieval and ranking. These\nsystems present significant challenges in accurately assessing and managing the\nuncertainty inherent in their predictions. To address these challenges, we\nextend the recently developed framework of conformal risk control, originally\ndesigned for single-stage problems, to accommodate the more complex two-stage\nsetup. We first demonstrate that a straightforward application of conformal\nrisk control, treating each stage independently, may fail to maintain risk at\ntheir pre-specified levels. Therefore, we propose an integrated approach that\nconsiders both stages simultaneously, devising algorithms to control the risk\nof each stage by jointly identifying thresholds for both stages. Our algorithm\nfurther optimizes for a weighted combination of prediction set sizes across all\nfeasible thresholds, resulting in more effective prediction sets. Finally, we\napply the proposed method to the critical task of two-stage ranked retrieval.\nWe validate the efficacy of our method through extensive experiments on two\nlarge-scale public datasets, MSLR-WEB and MS MARCO, commonly used for ranked\nretrieval tasks.\n","authors":["Yunpeng Xu","Mufang Ying","Wenge Guo","Zhi Wei"],"pdf_url":"https://arxiv.org/pdf/2404.17769v2.pdf","comment":"13 pages, 3 figures; 5 supplementary pages, 3 supplementary figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2409.00562v2","updated":"2024-11-02T22:31:05Z","published":"2024-08-31T23:22:30Z","title":"Comparative Analysis of Modality Fusion Approaches for Audio-Visual\n  Person Identification and Verification","summary":"  Multimodal learning involves integrating information from various modalities\nto enhance learning and comprehension. We compare three modality fusion\nstrategies in person identification and verification by processing two\nmodalities: voice and face. In this paper, a one-dimensional convolutional\nneural network is employed for x-vector extraction from voice, while the\npre-trained VGGFace2 network and transfer learning are utilized for face\nmodality. In addition, gammatonegram is used as speech representation in\nengagement with the Darknet19 pre-trained network. The proposed systems are\nevaluated using the K-fold cross-validation technique on the 118 speakers of\nthe test set of the VoxCeleb2 dataset. The comparative evaluations are done for\nsingle-modality and three proposed multimodal strategies in equal situations.\nResults demonstrate that the feature fusion strategy of gammatonegram and\nfacial features achieves the highest performance, with an accuracy of 98.37% in\nthe person identification task. However, concatenating facial features with the\nx-vector reaches 0.62% for EER in verification tasks.\n","authors":["Aref Farhadipour","Masoumeh Chapariniya","Teodora Vukovic","Volker Dellwo"],"pdf_url":"https://arxiv.org/pdf/2409.00562v2.pdf","comment":"This paper was accepted at the ICNLSP2024 conference"},{"id":"http://arxiv.org/abs/2410.22023v3","updated":"2024-11-02T12:52:23Z","published":"2024-10-29T13:13:30Z","title":"Multi-modal Speech Emotion Recognition via Feature Distribution\n  Adaptation Network","summary":"  In this paper, we propose a novel deep inductive transfer learning framework,\nnamed feature distribution adaptation network, to tackle the challenging\nmulti-modal speech emotion recognition problem. Our method aims to use deep\ntransfer learning strategies to align visual and audio feature distributions to\nobtain consistent representation of emotion, thereby improving the performance\nof speech emotion recognition. In our model, the pre-trained ResNet-34 is\nutilized for feature extraction for facial expression images and acoustic Mel\nspectrograms, respectively. Then, the cross-attention mechanism is introduced\nto model the intrinsic similarity relationships of multi-modal features.\nFinally, the multi-modal feature distribution adaptation is performed\nefficiently with feed-forward network, which is extended using the local\nmaximum mean discrepancy loss. Experiments are carried out on two benchmark\ndatasets, and the results demonstrate that our model can achieve excellent\nperformance compared with existing ones.\n","authors":["Shaokai Li","Yixuan Ji","Peng Song","Haoqin Sun","Wenming Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.22023v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18709v3","updated":"2024-11-02T11:09:37Z","published":"2023-10-28T13:37:52Z","title":"Audio-Visual Instance Segmentation","summary":"  In this paper, we propose a new multi-modal task, termed audio-visual\ninstance segmentation (AVIS), which aims to simultaneously identify, segment\nand track individual sounding object instances in audible videos. To facilitate\nthis research, we introduce a high-quality benchmark named AVISeg, containing\nover 90K instance masks from 26 semantic categories in 926 long videos.\nAdditionally, we propose a strong baseline model for this task. Our model first\nlocalizes sound source within each frame, and condenses object-specific\ncontexts into concise tokens. Then it builds long-range audio-visual\ndependencies between these tokens using window-based attention, and tracks\nsounding objects among the entire video sequences. Extensive experiments reveal\nthat our method performs best on AVISeg, surpassing the existing methods from\nrelated tasks. We further conduct the evaluation on several multi-modal large\nmodels; however, they exhibits subpar performance on instance-level sound\nsource localization and temporal perception. We expect that AVIS will inspire\nthe community towards a more comprehensive multi-modal understanding. The\ndataset and code will soon be released on https://github.com/ruohaoguo/avis.\n","authors":["Ruohao Guo","Xianghua Ying","Yaru Chen","Dantong Niu","Guangyao Li","Liao Qu","Yanyu Qi","Jinxing Zhou","Bowei Xing","Wenzhen Yue","Ji Shi","Qixun Wang","Peiliang Zhang","Buwen Liang"],"pdf_url":"https://arxiv.org/pdf/2310.18709v3.pdf","comment":"Project page: https://github.com/ruohaoguo/avis"},{"id":"http://arxiv.org/abs/2406.11161v2","updated":"2024-11-02T02:30:50Z","published":"2024-06-17T03:01:22Z","title":"Emotion-LLaMA: Multimodal Emotion Recognition and Reasoning with\n  Instruction Tuning","summary":"  Accurate emotion perception is crucial for various applications, including\nhuman-computer interaction, education, and counseling. However, traditional\nsingle-modality approaches often fail to capture the complexity of real-world\nemotional expressions, which are inherently multimodal. Moreover, existing\nMultimodal Large Language Models (MLLMs) face challenges in integrating audio\nand recognizing subtle facial micro-expressions. To address this, we introduce\nthe MERR dataset, containing 28,618 coarse-grained and 4,487 fine-grained\nannotated samples across diverse emotional categories. This dataset enables\nmodels to learn from varied scenarios and generalize to real-world\napplications. Furthermore, we propose Emotion-LLaMA, a model that seamlessly\nintegrates audio, visual, and textual inputs through emotion-specific encoders.\nBy aligning features into a shared space and employing a modified LLaMA model\nwith instruction tuning, Emotion-LLaMA significantly enhances both emotional\nrecognition and reasoning capabilities. Extensive evaluations show\nEmotion-LLaMA outperforms other MLLMs, achieving top scores in Clue Overlap\n(7.83) and Label Overlap (6.25) on EMER, an F1 score of 0.9036 on MER2023-SEMI\nchallenge, and the highest UAR (45.59) and WAR (59.37) in zero-shot evaluations\non DFEW dataset.\n","authors":["Zebang Cheng","Zhi-Qi Cheng","Jun-Yan He","Jingdong Sun","Kai Wang","Yuxiang Lin","Zheng Lian","Xiaojiang Peng","Alexander Hauptmann"],"pdf_url":"https://arxiv.org/pdf/2406.11161v2.pdf","comment":"Accepted at NeurIPS 2024. 49 pages, 13 figures, Project:\n  https://github.com/ZebangCheng/Emotion-LLaMA, Demo:\n  https://huggingface.co/spaces/ZebangCheng/Emotion-LLaMA"}]},"2024-11-01T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.13047v2","updated":"2024-11-01T23:39:14Z","published":"2024-10-16T21:17:18Z","title":"LLM Confidence Evaluation Measures in Zero-Shot CSS Classification","summary":"  Assessing classification confidence is critical for leveraging large language\nmodels (LLMs) in automated labeling tasks, especially in the sensitive domains\npresented by Computational Social Science (CSS) tasks. In this paper, we make\nthree key contributions: (1) we propose an uncertainty quantification (UQ)\nperformance measure tailored for data annotation tasks, (2) we compare, for the\nfirst time, five different UQ strategies across three distinct LLMs and CSS\ndata annotation tasks, (3) we introduce a novel UQ aggregation strategy that\neffectively identifies low-confidence LLM annotations and disproportionately\nuncovers data incorrectly labeled by the LLMs. Our results demonstrate that our\nproposed UQ aggregation strategy improves upon existing methods andcan be used\nto significantly improve human-in-the-loop data annotation processes.\n","authors":["David Farr","Iain Cruickshank","Nico Manzonelli","Nicholas Clark","Kate Starbird","Jevin West"],"pdf_url":"https://arxiv.org/pdf/2410.13047v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01039v1","updated":"2024-11-01T21:14:04Z","published":"2024-11-01T21:14:04Z","title":"Enhancing Question Answering Precision with Optimized Vector Retrieval\n  and Instructions","summary":"  Question-answering (QA) is an important application of Information Retrieval\n(IR) and language models, and the latest trend is toward pre-trained large\nneural networks with embedding parameters. Augmenting QA performances with\nthese LLMs requires intensive computational resources for fine-tuning. We\npropose an innovative approach to improve QA task performances by integrating\noptimized vector retrievals and instruction methodologies. Based on retrieval\naugmentation, the process involves document embedding, vector retrieval, and\ncontext construction for optimal QA results. We experiment with different\ncombinations of text segmentation techniques and similarity functions, and\nanalyze their impacts on QA performances. Results show that the model with a\nsmall chunk size of 100 without any overlap of the chunks achieves the best\nresult and outperforms the models based on semantic segmentation using\nsentences. We discuss related QA examples and offer insight into how model\nperformances are improved within the two-stage framework.\n","authors":["Lixiao Yang","Mengyang Xu","Weimao Ke"],"pdf_url":"https://arxiv.org/pdf/2411.01039v1.pdf","comment":"6 pages, 4 tables"},{"id":"http://arxiv.org/abs/2411.00744v1","updated":"2024-11-01T17:11:16Z","published":"2024-11-01T17:11:16Z","title":"CORAG: A Cost-Constrained Retrieval Optimization System for\n  Retrieval-Augmented Generation","summary":"  Large Language Models (LLMs) have demonstrated remarkable generation\ncapabilities but often struggle to access up-to-date information, which can\nlead to hallucinations. Retrieval-Augmented Generation (RAG) addresses this\nissue by incorporating knowledge from external databases, enabling more\naccurate and relevant responses. Due to the context window constraints of LLMs,\nit is impractical to input the entire external database context directly into\nthe model. Instead, only the most relevant information, referred to as chunks,\nis selectively retrieved. However, current RAG research faces three key\nchallenges. First, existing solutions often select each chunk independently,\noverlooking potential correlations among them. Second, in practice the utility\nof chunks is non-monotonic, meaning that adding more chunks can decrease\noverall utility. Traditional methods emphasize maximizing the number of\nincluded chunks, which can inadvertently compromise performance. Third, each\ntype of user query possesses unique characteristics that require tailored\nhandling, an aspect that current approaches do not fully consider. To overcome\nthese challenges, we propose a cost constrained retrieval optimization system\nCORAG for retrieval-augmented generation. We employ a Monte Carlo Tree Search\n(MCTS) based policy framework to find optimal chunk combinations sequentially,\nallowing for a comprehensive consideration of correlations among chunks.\nAdditionally, rather than viewing budget exhaustion as a termination condition,\nwe integrate budget constraints into the optimization of chunk combinations,\neffectively addressing the non-monotonicity of chunk utility.\n","authors":["Ziting Wang","Haitao Yuan","Wei Dong","Gao Cong","Feifei Li"],"pdf_url":"https://arxiv.org/pdf/2411.00744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00702v1","updated":"2024-11-01T16:05:59Z","published":"2024-11-01T16:05:59Z","title":"A graph-based approach to extracting narrative signals from public\n  discourse","summary":"  Narratives are key interpretative devices by which humans make sense of\npolitical reality. As the significance of narratives for understanding current\nsocietal issues such as polarization and misinformation becomes increasingly\nevident, there is a growing demand for methods that support their empirical\nanalysis. To this end, we propose a graph-based formalism and machine-guided\nmethod for extracting, representing, and analyzing selected narrative signals\nfrom digital textual corpora, based on Abstract Meaning Representation (AMR).\nThe formalism and method introduced here specifically cater to the study of\npolitical narratives that figure in texts from digital media such as archived\npolitical speeches, social media posts, political manifestos and transcripts of\nparliamentary debates. We conceptualize these political narratives as a type of\nontological narratives: stories by which actors position themselves as\npolitical beings, and which are akin to political worldviews in which actors\npresent their normative vision of the world, or aspects thereof. We approach\nthe study of such political narratives as a problem of information retrieval:\nstarting from a textual corpus, we first extract a graph-like representation of\nthe meaning of each sentence in the corpus using AMR. Drawing on transferable\nconcepts from narratology, we then apply a set of heuristics to filter these\ngraphs for representations of 1) actors, 2) the events in which these actors\nfigure, and 3) traces of the perspectivization of these events. We approach\nthese references to actors, events, and instances of perspectivization as core\nnarrative signals that initiate a further analysis by alluding to larger\npolitical narratives. By means of a case study of State of the European Union\naddresses, we demonstrate how the formalism can be used to inductively surface\nsignals of political narratives from public discourse.\n","authors":["Armin Pournaki","Tom Willaert"],"pdf_url":"https://arxiv.org/pdf/2411.00702v1.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.00677v1","updated":"2024-11-01T15:36:52Z","published":"2024-11-01T15:36:52Z","title":"Making Sense of Metadata Mess: Alignment & Risk Assessment for Diatom\n  Data Use Case","summary":"  Biologists study Diatoms, a fundamental algae, to assess the health of\naquatic systems. Diatom specimens have traditionally been preserved on analog\nslides, where a single slide can contain thousands of these microscopic\norganisms. Digitization of these collections presents both metadata challenges\nand opportunities. This paper reports on metadata research aimed at providing\naccess to a digital portion of the Academy of Natural Sciences' Diatom\nHerbarium, Drexel University. We report results of a 3-part study covering 1) a\nreview of relevant metadata standards and a microscopy metadata framework\nshared by Hammer et al., 2) a baseline metadata alignment mapping current\ndiatom metadata properties to standard metadata types, and 3) a metadata risk\nanalysis associated with the course of standard data curation practices. This\nresearch is part of an effort involving the transfer of these digital slides to\nan new system, DataFed, to support global accessible. The final section of this\npaper includes a conclusion and discusses next steps.\n","authors":["Kio Polson","Marina Potapova","Uttam Meena","Chad Peiper","Joshua Brown","Joshua Agar","Jane Greenberg"],"pdf_url":"https://arxiv.org/pdf/2411.00677v1.pdf","comment":"13 pages, 2 figures, 1 table, to be published in MTSR 2024 conference\n  proceedings"},{"id":"http://arxiv.org/abs/2411.00676v1","updated":"2024-11-01T15:35:56Z","published":"2024-11-01T15:35:56Z","title":"Enhancing Semantic Interoperability Across Materials Science With\n  HIVE4MAT","summary":"  HIVE4MAT is a linked data interactive application for navigating ontologies\nof value to materials science. HIVE enables automatic indexing of textual\nresources with standardized terminology. This article presents the motivation\nunderlying HIVE4MAT, explains the system architecture, reports on two\nevaluations, and discusses future plans.\n","authors":["Jane Greenberg","Kio Polson","Scott McClellan","Xintong Zhao","Alex Kalinowski","Yuan An"],"pdf_url":"https://arxiv.org/pdf/2411.00676v1.pdf","comment":"11 pages, 1 figures, 3 tables, to be published in SeMatS 2024\n  workshop proceedings"},{"id":"http://arxiv.org/abs/2407.10691v2","updated":"2024-11-01T14:08:31Z","published":"2024-07-15T13:04:09Z","title":"$\\texttt{MixGR}$: Enhancing Retriever Generalization for Scientific\n  Domain through Complementary Granularity","summary":"  Recent studies show the growing significance of document retrieval in the\ngeneration of LLMs, i.e., RAG, within the scientific domain by bridging their\nknowledge gap. However, dense retrievers often struggle with domain-specific\nretrieval and complex query-document relationships, particularly when query\nsegments correspond to various parts of a document. To alleviate such prevalent\nchallenges, this paper introduces $\\texttt{MixGR}$, which improves dense\nretrievers' awareness of query-document matching across various levels of\ngranularity in queries and documents using a zero-shot approach.\n$\\texttt{MixGR}$ fuses various metrics based on these granularities to a united\nscore that reflects a comprehensive query-document similarity. Our experiments\ndemonstrate that $\\texttt{MixGR}$ outperforms previous document retrieval by\n24.7%, 9.8%, and 6.9% on nDCG@5 with unsupervised, supervised, and LLM-based\nretrievers, respectively, averaged on queries containing multiple subqueries\nfrom five scientific retrieval datasets. Moreover, the efficacy of two\ndownstream scientific question-answering tasks highlights the advantage of\n$\\texttt{MixGR}$ to boost the application of LLMs in the scientific domain. The\ncode and experimental datasets are available.\n","authors":["Fengyu Cai","Xinran Zhao","Tong Chen","Sihao Chen","Hongming Zhang","Iryna Gurevych","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2407.10691v2.pdf","comment":"EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2411.00556v1","updated":"2024-11-01T13:09:30Z","published":"2024-11-01T13:09:30Z","title":"LLM-KT: A Versatile Framework for Knowledge Transfer from Large Language\n  Models to Collaborative Filtering","summary":"  We present LLM-KT, a flexible framework designed to enhance collaborative\nfiltering (CF) models by seamlessly integrating LLM (Large Language\nModel)-generated features. Unlike existing methods that rely on passing\nLLM-generated features as direct inputs, our framework injects these features\ninto an intermediate layer of any CF model, allowing the model to reconstruct\nand leverage the embeddings internally. This model-agnostic approach works with\na wide range of CF models without requiring architectural changes, making it\nadaptable to various recommendation scenarios. Our framework is built for easy\nintegration and modification, providing researchers and developers with a\npowerful tool for extending CF model capabilities through efficient knowledge\ntransfer. We demonstrate its effectiveness through experiments on the MovieLens\nand Amazon datasets, where it consistently improves baseline CF models.\nExperimental studies showed that LLM-KT is competitive with the\nstate-of-the-art methods in context-aware settings but can be applied to a\nbroader range of CF models than current approaches.\n","authors":["Nikita Severin","Aleksei Ziablitsev","Yulia Savelyeva","Valeriy Tashchilin","Ivan Bulychev","Mikhail Yushkov","Artem Kushneruk","Amaliya Zaryvnykh","Dmitrii Kiselev","Andrey Savchenko","Ilya Makarov"],"pdf_url":"https://arxiv.org/pdf/2411.00556v1.pdf","comment":"accepted at ICDM 2024 (demo track)"},{"id":"http://arxiv.org/abs/2411.00469v1","updated":"2024-11-01T09:34:36Z","published":"2024-11-01T09:34:36Z","title":"MIRFLEX: Music Information Retrieval Feature Library for Extraction","summary":"  This paper introduces an extendable modular system that compiles a range of\nmusic feature extraction models to aid music information retrieval research.\nThe features include musical elements like key, downbeats, and genre, as well\nas audio characteristics like instrument recognition, vocals/instrumental\nclassification, and vocals gender detection. The integrated models are\nstate-of-the-art or latest open-source. The features can be extracted as latent\nor post-processed labels, enabling integration into music applications such as\ngenerative music, recommendation, and playlist generation. The modular design\nallows easy integration of newly developed systems, making it a good\nbenchmarking and comparison tool. This versatile toolkit supports the research\ncommunity in developing innovative solutions by providing concrete musical\nfeatures.\n","authors":["Anuradha Chopra","Abhinaba Roy","Dorien Herremans"],"pdf_url":"https://arxiv.org/pdf/2411.00469v1.pdf","comment":"2 pages, 4 tables, submitted to Extended Abstracts for the\n  Late-Breaking Demo Session of the 25th Int. Society for Music Information\n  Retrieval Conf., San Francisco, United States, 2024"},{"id":"http://arxiv.org/abs/2411.00451v1","updated":"2024-11-01T08:57:29Z","published":"2024-11-01T08:57:29Z","title":"Improving Few-Shot Cross-Domain Named Entity Recognition by Instruction\n  Tuning a Word-Embedding based Retrieval Augmented Large Language Model","summary":"  Few-Shot Cross-Domain NER is the process of leveraging knowledge from\ndata-rich source domains to perform entity recognition on data scarce target\ndomains. Most previous state-of-the-art (SOTA) approaches use pre-trained\nlanguage models (PLMs) for cross-domain NER. However, these models are often\ndomain specific. To successfully use these models for new target domains, we\nneed to modify either the model architecture or perform model finetuning using\ndata from the new domains. Both of these result in the creation of entirely new\nNER models for each target domain which is infeasible for practical scenarios.\nRecently,several works have attempted to use LLMs to solve Few-Shot\nCross-Domain NER. However, most of these are either too expensive for practical\npurposes or struggle to follow LLM prompt instructions. In this paper, we\npropose IF-WRANER (Instruction Finetuned Word-embedding based Retrieval\nAugmented large language model for Named Entity Recognition), a retrieval\naugmented LLM, finetuned for the NER task. By virtue of the regularization\ntechniques used during LLM finetuning and the adoption of word-level embedding\nover sentence-level embedding during the retrieval of in-prompt examples,\nIF-WRANER is able to outperform previous SOTA Few-Shot Cross-Domain NER\napproaches. We have demonstrated the effectiveness of our model by benchmarking\nits performance on the open source CrossNER dataset, on which it shows more\nthan 2% F1 score improvement over the previous SOTA model. We have deployed the\nmodel for multiple customer care domains of an enterprise. Accurate entity\nprediction through IF-WRANER helps direct customers to automated workflows for\nthe domains, thereby reducing escalations to human agents by almost 15% and\nleading to millions of dollars in yearly savings for the company.\n","authors":["Subhadip Nandi","Neeraj Agrawal"],"pdf_url":"https://arxiv.org/pdf/2411.00451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00395v1","updated":"2024-11-01T06:49:39Z","published":"2024-11-01T06:49:39Z","title":"DivNet: Diversity-Aware Self-Correcting Sequential Recommendation\n  Networks","summary":"  As the last stage of a typical \\textit{recommendation system},\n\\textit{collective recommendation} aims to give the final touches to the\nrecommended items and their layout so as to optimize overall objectives such as\ndiversity and whole-page relevance. In practice, however, the interaction\ndynamics among the recommended items, their visual appearances and meta-data\nsuch as specifications are often too complex to be captured by experts'\nheuristics or simple models. To address this issue, we propose a\n\\textit{\\underline{div}ersity-aware self-correcting sequential recommendation\n\\underline{net}works} (\\textit{DivNet}) that is able to estimate utility by\ncapturing the complex interactions among sequential items and diversify\nrecommendations simultaneously. Experiments on both offline and online settings\ndemonstrate that \\textit{DivNet} can achieve better results compared to\nbaselines with or without collective recommendations.\n","authors":["Shuai Xiao","Zaifan Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.00395v1.pdf","comment":"Published at CIKM"},{"id":"http://arxiv.org/abs/2408.10159v3","updated":"2024-11-01T03:47:59Z","published":"2024-08-19T17:09:32Z","title":"Customizing Language Models with Instance-wise LoRA for Sequential\n  Recommendation","summary":"  Sequential recommendation systems predict the next interaction item based on\nusers' past interactions, aligning recommendations with individual preferences.\nLeveraging the strengths of Large Language Models (LLMs) in knowledge\ncomprehension and reasoning, recent approaches are eager to apply LLMs to\nsequential recommendation. A common paradigm is converting user behavior\nsequences into instruction data, and fine-tuning the LLM with\nparameter-efficient fine-tuning (PEFT) methods like Low-Rank Adaption (LoRA).\nHowever, the uniform application of LoRA across diverse user behaviors is\ninsufficient to capture individual variability, resulting in negative transfer\nbetween disparate sequences. To address these challenges, we propose\nInstance-wise LoRA (iLoRA). We innovatively treat the sequential recommendation\ntask as a form of multi-task learning, integrating LoRA with the Mixture of\nExperts (MoE) framework. This approach encourages different experts to capture\nvarious aspects of user behavior. Additionally, we introduce a sequence\nrepresentation guided gate function that generates customized expert\nparticipation weights for each user sequence, which allows dynamic parameter\nadjustment for instance-wise recommendations. In sequential recommendation,\niLoRA achieves an average relative improvement of 11.4\\% over basic LoRA in the\nhit ratio metric, with less than a 1\\% relative increase in trainable\nparameters. Extensive experiments on three benchmark datasets demonstrate the\neffectiveness of iLoRA, highlighting its superior performance compared to\nexisting methods in mitigating negative transfer and improving recommendation\naccuracy. Our data and code are available at\nhttps://github.com/AkaliKong/iLoRA.\n","authors":["Xiaoyu Kong","Jiancan Wu","An Zhang","Leheng Sheng","Hui Lin","Xiang Wang","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2408.10159v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00341v1","updated":"2024-11-01T03:43:50Z","published":"2024-11-01T03:43:50Z","title":"A Survey on Bundle Recommendation: Methods, Applications, and Challenges","summary":"  In recent years, bundle recommendation systems have gained significant\nattention in both academia and industry due to their ability to enhance user\nexperience and increase sales by recommending a set of items as a bundle rather\nthan individual items. This survey provides a comprehensive review on bundle\nrecommendation, beginning by a taxonomy for exploring product bundling. We\nclassify it into two categories based on bundling strategy from various\napplication domains, i.e., discriminative and generative bundle recommendation.\nThen we formulate the corresponding tasks of the two categories and\nsystematically review their methods: 1) representation learning from bundle and\nitem levels and interaction modeling for discriminative bundle recommendation;\n2) representation learning from item level and bundle generation for generative\nbundle recommendation. Subsequently, we survey the resources of bundle\nrecommendation including datasets and evaluation metrics, and conduct\nreproducibility experiments on mainstream models. Lastly, we discuss the main\nchallenges and highlight the promising future directions in the field of bundle\nrecommendation, aiming to serve as a useful resource for researchers and\npractitioners. Our code and datasets are publicly available at\nhttps://github.com/WUT-IDEA/bundle-recommendation-survey.\n","authors":["Meng Sun","Lin Li","Ming Li","Xiaohui Tao","Dong Zhang","Peipei Wang","Jimmy Xiangji Huang"],"pdf_url":"https://arxiv.org/pdf/2411.00341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20646v2","updated":"2024-11-01T03:12:44Z","published":"2024-05-31T07:24:42Z","title":"LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential\n  Recommendation","summary":"  Sequential recommender systems (SRS) aim to predict users' subsequent choices\nbased on their historical interactions and have found applications in diverse\nfields such as e-commerce and social media. However, in real-world systems,\nmost users interact with only a handful of items, while the majority of items\nare seldom consumed. These two issues, known as the long-tail user and\nlong-tail item challenges, often pose difficulties for existing SRS. These\nchallenges can adversely affect user experience and seller benefits, making\nthem crucial to address. Though a few works have addressed the challenges, they\nstill struggle with the seesaw or noisy issues due to the intrinsic scarcity of\ninteractions. The advancements in large language models (LLMs) present a\npromising solution to these problems from a semantic perspective. As one of the\npioneers in this field, we propose the Large Language Models Enhancement\nframework for Sequential Recommendation (LLM-ESR). This framework utilizes\nsemantic embeddings derived from LLMs to enhance SRS without adding extra\ninference load from LLMs. To address the long-tail item challenge, we design a\ndual-view modeling framework that combines semantics from LLMs and\ncollaborative signals from conventional SRS. For the long-tail user challenge,\nwe propose a retrieval augmented self-distillation method to enhance user\npreference representation using more informative interactions from similar\nusers. To verify the effectiveness and versatility of our proposed enhancement\nframework, we conduct extensive experiments on three real-world datasets using\nthree popular SRS models. The results show that our method surpasses existing\nbaselines consistently, and benefits long-tail users and items especially. The\nimplementation code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/LLM-ESR.\n","authors":["Qidong Liu","Xian Wu","Yejing Wang","Zijian Zhang","Feng Tian","Yefeng Zheng","Xiangyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.20646v2.pdf","comment":"accepted by NeruIPS'24 (Spotlight)"},{"id":"http://arxiv.org/abs/2411.00331v1","updated":"2024-11-01T03:09:28Z","published":"2024-11-01T03:09:28Z","title":"Beyond Utility: Evaluating LLM as Recommender","summary":"  With the rapid development of Large Language Models (LLMs), recent studies\nemployed LLMs as recommenders to provide personalized information services for\ndistinct users. Despite efforts to improve the accuracy of LLM-based\nrecommendation models, relatively little attention is paid to beyond-utility\ndimensions. Moreover, there are unique evaluation aspects of LLM-based\nrecommendation models, which have been largely ignored. To bridge this gap, we\nexplore four new evaluation dimensions and propose a multidimensional\nevaluation framework. The new evaluation dimensions include: 1) history length\nsensitivity, 2) candidate position bias, 3) generation-involved performance,\nand 4) hallucinations. All four dimensions have the potential to impact\nperformance, but are largely unnecessary for consideration in traditional\nsystems. Using this multidimensional evaluation framework, along with\ntraditional aspects, we evaluate the performance of seven LLM-based\nrecommenders, with three prompting strategies, comparing them with six\ntraditional models on both ranking and re-ranking tasks on four datasets. We\nfind that LLMs excel at handling tasks with prior knowledge and shorter input\nhistories in the ranking setting, and perform better in the re-ranking setting,\nbeating traditional models across multiple dimensions. However, LLMs exhibit\nsubstantial candidate position bias issues, and some models hallucinate\nnon-existent items much more often than others. We intend our evaluation\nframework and observations to benefit future research on the use of LLMs as\nrecommenders. The code and data are available at\nhttps://github.com/JiangDeccc/EvaLLMasRecommender.\n","authors":["Chumeng Jiang","Jiayin Wang","Weizhi Ma","Charles L. A. Clarke","Shuai Wang","Chuhan Wu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.00331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15235v3","updated":"2024-11-01T02:00:49Z","published":"2024-02-23T09:57:20Z","title":"MACRec: a Multi-Agent Collaboration Framework for Recommendation","summary":"  LLM-based agents have gained considerable attention for their decision-making\nskills and ability to handle complex tasks. Recognizing the current gap in\nleveraging agent capabilities for multi-agent collaboration in recommendation\nsystems, we introduce MACRec, a novel framework designed to enhance\nrecommendation systems through multi-agent collaboration. Unlike existing work\non using agents for user/item simulation, we aim to deploy multi-agents to\ntackle recommendation tasks directly. In our framework, recommendation tasks\nare addressed through the collaborative efforts of various specialized agents,\nincluding Manager, User/Item Analyst, Reflector, Searcher, and Task\nInterpreter, with different working flows. Furthermore, we provide application\nexamples of how developers can easily use MACRec on various recommendation\ntasks, including rating prediction, sequential recommendation, conversational\nrecommendation, and explanation generation of recommendation results. The\nframework and demonstration video are publicly available at\nhttps://github.com/wzf2000/MACRec.\n","authors":["Zhefan Wang","Yuanqing Yu","Wendi Zheng","Weizhi Ma","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.15235v3.pdf","comment":"Accepted by SIGIR2024"},{"id":"http://arxiv.org/abs/2410.23683v2","updated":"2024-11-01T01:21:04Z","published":"2024-10-31T07:19:22Z","title":"Unveiling User Satisfaction and Creator Productivity Trade-Offs in\n  Recommendation Platforms","summary":"  On User-Generated Content (UGC) platforms, recommendation algorithms\nsignificantly impact creators' motivation to produce content as they compete\nfor algorithmically allocated user traffic. This phenomenon subtly shapes the\nvolume and diversity of the content pool, which is crucial for the platform's\nsustainability. In this work, we demonstrate, both theoretically and\nempirically, that a purely relevance-driven policy with low exploration\nstrength boosts short-term user satisfaction but undermines the long-term\nrichness of the content pool. In contrast, a more aggressive exploration policy\nmay slightly compromise user satisfaction but promote higher content creation\nvolume. Our findings reveal a fundamental trade-off between immediate user\nsatisfaction and overall content production on UGC platforms. Building on this\nfinding, we propose an efficient optimization method to identify the optimal\nexploration strength, balancing user and creator engagement. Our model can\nserve as a pre-deployment audit tool for recommendation algorithms on UGC\nplatforms, helping to align their immediate objectives with sustainable,\nlong-term goals.\n","authors":["Fan Yao","Yiming Liao","Jingzhou Liu","Shaoliang Nie","Qifan Wang","Haifeng Xu","Hongning Wang"],"pdf_url":"https://arxiv.org/pdf/2410.23683v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00275v1","updated":"2024-11-01T00:13:46Z","published":"2024-11-01T00:13:46Z","title":"Improving Musical Instrument Classification with Advanced Machine\n  Learning Techniques","summary":"  Musical instrument classification, a key area in Music Information Retrieval,\nhas gained considerable interest due to its applications in education, digital\nmusic production, and consumer media. Recent advances in machine learning,\nspecifically deep learning, have enhanced the capability to identify and\nclassify musical instruments from audio signals. This study applies various\nmachine learning methods, including Naive Bayes, Support Vector Machines,\nRandom Forests, Boosting techniques like AdaBoost and XGBoost, as well as deep\nlearning models such as Convolutional Neural Networks and Artificial Neural\nNetworks. The effectiveness of these methods is evaluated on the NSynth\ndataset, a large repository of annotated musical sounds. By comparing these\napproaches, the analysis aims to showcase the advantages and limitations of\neach method, providing guidance for developing more accurate and efficient\nclassification systems. Additionally, hybrid model testing and discussion are\nincluded. This research aims to support further studies in instrument\nclassification by proposing new approaches and future research directions.\n","authors":["Joanikij Chulev"],"pdf_url":"https://arxiv.org/pdf/2411.00275v1.pdf","comment":"43 pages, 35 figures, 14 tables"}],"Multimedia":[{"id":"http://arxiv.org/abs/2409.20012v2","updated":"2024-11-01T08:40:28Z","published":"2024-09-30T07:14:31Z","title":"Towards Robust Multimodal Sentiment Analysis with Incomplete Data","summary":"  The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an\nemerging direction seeking to tackle the issue of data incompleteness.\nRecognizing that the language modality typically contains dense sentiment\ninformation, we consider it as the dominant modality and present an innovative\nLanguage-dominated Noise-resistant Learning Network (LNLN) to achieve robust\nMSA. The proposed LNLN features a dominant modality correction (DMC) module and\ndominant modality based multimodal learning (DMML) module, which enhances the\nmodel's robustness across various noise scenarios by ensuring the quality of\ndominant modality representations. Aside from the methodical design, we perform\ncomprehensive experiments under random data missing scenarios, utilizing\ndiverse and meaningful settings on several popular datasets (\\textit{e.g.,}\nMOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and\nfairness compared to existing evaluations in the literature. Empirically, LNLN\nconsistently outperforms existing baselines, demonstrating superior performance\nacross these challenging and extensive evaluation metrics.\n","authors":["Haoyu Zhang","Wenbin Wang","Tianshu Yu"],"pdf_url":"https://arxiv.org/pdf/2409.20012v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.00304v1","updated":"2024-11-01T01:51:31Z","published":"2024-11-01T01:51:31Z","title":"Unified Generative and Discriminative Training for Multi-modal Large\n  Language Models","summary":"  In recent times, Vision-Language Models (VLMs) have been trained under two\npredominant paradigms. Generative training has enabled Multimodal Large\nLanguage Models (MLLMs) to tackle various complex tasks, yet issues such as\nhallucinations and weak object discrimination persist. Discriminative training,\nexemplified by models like CLIP, excels in zero-shot image-text classification\nand retrieval, yet struggles with complex scenarios requiring fine-grained\nsemantic differentiation. This paper addresses these challenges by proposing a\nunified approach that integrates the strengths of both paradigms. Considering\ninterleaved image-text sequences as the general format of input samples, we\nintroduce a structure-induced training strategy that imposes semantic\nrelationships between input samples and the MLLM's hidden state. This approach\nenhances the MLLM's ability to capture global semantics and distinguish\nfine-grained semantics. By leveraging dynamic sequence alignment within the\nDynamic Time Warping framework and integrating a novel kernel for fine-grained\nsemantic differentiation, our method effectively balances generative and\ndiscriminative tasks. Extensive experiments demonstrate the effectiveness of\nour approach, achieving state-of-the-art results in multiple generative tasks,\nespecially those requiring cognitive and discrimination abilities.\nAdditionally, our method surpasses discriminative benchmarks in interleaved and\nfine-grained retrieval tasks. By employing a retrieval-augmented generation\nstrategy, our approach further enhances performance in some generative tasks\nwithin one model, offering a promising direction for future research in\nvision-language modeling.\n","authors":["Wei Chow","Juncheng Li","Qifan Yu","Kaihang Pan","Hao Fei","Zhiqi Ge","Shuai Yang","Siliang Tang","Hanwang Zhang","Qianru Sun"],"pdf_url":"https://arxiv.org/pdf/2411.00304v1.pdf","comment":null}]},"2024-11-07T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.05007v1","updated":"2024-11-07T18:59:58Z","published":"2024-11-07T18:59:58Z","title":"SVDQunat: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion\n  Models","summary":"  Diffusion models have been proven highly effective at generating high-quality\nimages. However, as these models grow larger, they require significantly more\nmemory and suffer from higher latency, posing substantial challenges for\ndeployment. In this work, we aim to accelerate diffusion models by quantizing\ntheir weights and activations to 4 bits. At such an aggressive level, both\nweights and activations are highly sensitive, where conventional post-training\nquantization methods for large language models like smoothing become\ninsufficient. To overcome this limitation, we propose SVDQuant, a new 4-bit\nquantization paradigm. Different from smoothing which redistributes outliers\nbetween weights and activations, our approach absorbs these outliers using a\nlow-rank branch. We first consolidate the outliers by shifting them from\nactivations to weights, then employ a high-precision low-rank branch to take in\nthe weight outliers with Singular Value Decomposition (SVD). This process eases\nthe quantization on both sides. However, na\\\"{\\i}vely running the low-rank\nbranch independently incurs significant overhead due to extra data movement of\nactivations, negating the quantization speedup. To address this, we co-design\nan inference engine Nunchaku that fuses the kernels of the low-rank branch into\nthose of the low-bit branch to cut off redundant memory access. It can also\nseamlessly support off-the-shelf low-rank adapters (LoRAs) without the need for\nre-quantization. Extensive experiments on SDXL, PixArt-$\\Sigma$, and FLUX.1\nvalidate the effectiveness of SVDQuant in preserving image quality. We reduce\nthe memory usage for the 12B FLUX.1 models by 3.5$\\times$, achieving\n3.0$\\times$ speedup over the 4-bit weight-only quantized baseline on the 16GB\nlaptop 4090 GPU, paving the way for more interactive applications on PCs. Our\nquantization library and inference engine are open-sourced.\n","authors":["Muyang Li","Yujun Lin","Zhekai Zhang","Tianle Cai","Xiuyu Li","Junxian Guo","Enze Xie","Chenlin Meng","Jun-Yan Zhu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2411.05007v1.pdf","comment":"Quantization Library: https://github.com/mit-han-lab/deepcompressor\n  Inference Engine: https://github.com/mit-han-lab/nunchaku Website:\n  https://hanlab.mit.edu/projects/svdquant Demo: https://svdquant.mit.edu Blog:\n  https://hanlab.mit.edu/blog/svdquant"},{"id":"http://arxiv.org/abs/2411.05006v1","updated":"2024-11-07T18:59:54Z","published":"2024-11-07T18:59:54Z","title":"ProEdit: Simple Progression is All You Need for High-Quality 3D Scene\n  Editing","summary":"  This paper proposes ProEdit - a simple yet effective framework for\nhigh-quality 3D scene editing guided by diffusion distillation in a novel\nprogressive manner. Inspired by the crucial observation that multi-view\ninconsistency in scene editing is rooted in the diffusion model's large\nfeasible output space (FOS), our framework controls the size of FOS and reduces\ninconsistency by decomposing the overall editing task into several subtasks,\nwhich are then executed progressively on the scene. Within this framework, we\ndesign a difficulty-aware subtask decomposition scheduler and an adaptive 3D\nGaussian splatting (3DGS) training strategy, ensuring high quality and\nefficiency in performing each subtask. Extensive evaluation shows that our\nProEdit achieves state-of-the-art results in various scenes and challenging\nediting tasks, all through a simple framework without any expensive or\nsophisticated add-ons like distillation losses, components, or training\nprocedures. Notably, ProEdit also provides a new way to control, preview, and\nselect the \"aggressivity\" of editing operation during the editing process.\n","authors":["Jun-Kun Chen","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05006v1.pdf","comment":"NeurIPS 2024. Project Page: https://immortalco.github.io/ProEdit/"},{"id":"http://arxiv.org/abs/2411.05005v1","updated":"2024-11-07T18:59:53Z","published":"2024-11-07T18:59:53Z","title":"Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion\n  Models","summary":"  Beyond high-fidelity image synthesis, diffusion models have recently\nexhibited promising results in dense visual perception tasks. However, most\nexisting work treats diffusion models as a standalone component for perception\ntasks, employing them either solely for off-the-shelf data augmentation or as\nmere feature extractors. In contrast to these isolated and thus sub-optimal\nefforts, we introduce a unified, versatile, diffusion-based framework,\nDiff-2-in-1, that can simultaneously handle both multi-modal data generation\nand dense visual perception, through a unique exploitation of the\ndiffusion-denoising process. Within this framework, we further enhance\ndiscriminative visual perception via multi-modal generation, by utilizing the\ndenoising network to create multi-modal data that mirror the distribution of\nthe original training set. Importantly, Diff-2-in-1 optimizes the utilization\nof the created diverse and faithful data by leveraging a novel self-improving\nlearning mechanism. Comprehensive experimental evaluations validate the\neffectiveness of our framework, showcasing consistent performance improvements\nacross various discriminative backbones and high-quality multi-modal data\ngeneration characterized by both realism and usefulness.\n","authors":["Shuhong Zheng","Zhipeng Bao","Ruoyu Zhao","Martial Hebert","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05005v1.pdf","comment":"26 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.05003v1","updated":"2024-11-07T18:59:45Z","published":"2024-11-07T18:59:45Z","title":"ReCapture: Generative Video Camera Controls for User-Provided Videos\n  using Masked Video Fine-Tuning","summary":"  Recently, breakthroughs in video modeling have allowed for controllable\ncamera trajectories in generated videos. However, these methods cannot be\ndirectly applied to user-provided videos that are not generated by a video\nmodel. In this paper, we present ReCapture, a method for generating new videos\nwith novel camera trajectories from a single user-provided video. Our method\nallows us to re-generate the reference video, with all its existing scene\nmotion, from vastly different angles and with cinematic camera motion. Notably,\nusing our method we can also plausibly hallucinate parts of the scene that were\nnot observable in the reference video. Our method works by (1) generating a\nnoisy anchor video with a new camera trajectory using multiview diffusion\nmodels or depth-based point cloud rendering and then (2) regenerating the\nanchor video into a clean and temporally consistent reangled video using our\nproposed masked video fine-tuning technique.\n","authors":["David Junhao Zhang","Roni Paiss","Shiran Zada","Nikhil Karnad","David E. Jacobs","Yael Pritch","Inbar Mosseri","Mike Zheng Shou","Neal Wadhwa","Nataniel Ruiz"],"pdf_url":"https://arxiv.org/pdf/2411.05003v1.pdf","comment":"project page: https://generative-video-camera-controls.github.io/"},{"id":"http://arxiv.org/abs/2411.05001v1","updated":"2024-11-07T18:59:28Z","published":"2024-11-07T18:59:28Z","title":"Analyzing The Language of Visual Tokens","summary":"  With the introduction of transformer-based models for vision and language\ntasks, such as LLaVA and Chameleon, there has been renewed interest in the\ndiscrete tokenized representation of images. These models often treat image\npatches as discrete tokens, analogous to words in natural language, learning\njoint alignments between visual and human languages. However, little is known\nabout the statistical behavior of these visual languages - whether they follow\nsimilar frequency distributions, grammatical structures, or topologies as\nnatural languages. In this paper, we take a natural-language-centric approach\nto analyzing discrete visual languages and uncover striking similarities and\nfundamental differences. We demonstrate that, although visual languages adhere\nto Zipfian distributions, higher token innovation drives greater entropy and\nlower compression, with tokens predominantly representing object parts,\nindicating intermediate granularity. We also show that visual languages lack\ncohesive grammatical structures, leading to higher perplexity and weaker\nhierarchical organization compared to natural languages. Finally, we\ndemonstrate that, while vision models align more closely with natural languages\nthan other models, this alignment remains significantly weaker than the\ncohesion found within natural languages. Through these experiments, we\ndemonstrate how understanding the statistical properties of discrete visual\nlanguages can inform the design of more effective computer vision models.\n","authors":["David M. Chan","Rodolfo Corona","Joonyong Park","Cheol Jun Cho","Yutong Bai","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2411.05001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04997v1","updated":"2024-11-07T18:59:16Z","published":"2024-11-07T18:59:16Z","title":"LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation","summary":"  CLIP is one of the most important multimodal foundational models today. What\npowers CLIP's capabilities? The rich supervision signals provided by natural\nlanguage, the carrier of human knowledge, shape a powerful cross-modal\nrepresentation space. However, with the rapid advancements in large language\nmodels LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and\ngeneration are continually being pushed. This raises an intriguing question:\ncan the capabilities of LLMs be harnessed to further improve multimodal\nrepresentation learning? The potential benefits of incorporating LLMs into CLIP\nare clear. LLMs' strong textual understanding can fundamentally improve CLIP's\nability to handle image captions, drastically enhancing its ability to process\nlong and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs\nare trained on a vast corpus of text, possessing open-world knowledge. This\nallows them to expand on caption information during training, increasing the\nefficiency of the learning process. In this paper, we propose LLM2CLIP, a novel\napproach that embraces the power of LLMs to unlock CLIP's potential. By\nfine-tuning the LLM in the caption space with contrastive learning, we extract\nits textual capabilities into the output embeddings, significantly improving\nthe output layer's textual discriminability. We then design an efficient\ntraining process where the fine-tuned LLM acts as a powerful teacher for CLIP's\nvisual encoder. Thanks to the LLM's presence, we can now incorporate longer and\nmore complex captions without being restricted by vanilla CLIP's text encoder's\ncontext window and ability limitations. Our experiments demonstrate that this\napproach brings substantial improvements in cross-modal tasks.\n","authors":["Weiquan Huang","Aoqi Wu","Yifan Yang","Xufang Luo","Yuqing Yang","Liang Hu","Qi Dai","Xiyang Dai","Dongdong Chen","Chong Luo","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2411.04997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04998v1","updated":"2024-11-07T18:59:16Z","published":"2024-11-07T18:59:16Z","title":"HourVideo: 1-Hour Video-Language Understanding","summary":"  We present HourVideo, a benchmark dataset for hour-long video-language\nunderstanding. Our dataset consists of a novel task suite comprising\nsummarization, perception (recall, tracking), visual reasoning (spatial,\ntemporal, predictive, causal, counterfactual), and navigation (room-to-room,\nobject retrieval) tasks. HourVideo includes 500 manually curated egocentric\nvideos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and\nfeatures 12,976 high-quality, five-way multiple-choice questions. Benchmarking\nresults reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve\nmarginal improvements over random chance. In stark contrast, human experts\nsignificantly outperform the state-of-the-art long-context multimodal model,\nGemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal\ncapabilities. Our benchmark, evaluation toolkit, prompts, and documentation are\navailable at https://hourvideo.stanford.edu\n","authors":["Keshigeyan Chandrasegaran","Agrim Gupta","Lea M. Hadzic","Taran Kota","Jimming He","Cristóbal Eyzaguirre","Zane Durante","Manling Li","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2411.04998v1.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track; 28 pages"},{"id":"http://arxiv.org/abs/2411.04995v1","updated":"2024-11-07T18:58:57Z","published":"2024-11-07T18:58:57Z","title":"LoFi: Scalable Local Image Reconstruction with Implicit Neural\n  Representation","summary":"  Neural fields or implicit neural representations (INRs) have attracted\nsignificant attention in machine learning and signal processing due to their\nefficient continuous representation of images and 3D volumes. In this work, we\nbuild on INRs and introduce a coordinate-based local processing framework for\nsolving imaging inverse problems, termed LoFi (Local Field). Unlike\nconventional methods for image reconstruction, LoFi processes local information\nat each coordinate \\textit{separately} by multi-layer perceptrons (MLPs),\nrecovering the object at that specific coordinate. Similar to INRs, LoFi can\nrecover images at any continuous coordinate, enabling image reconstruction at\nmultiple resolutions. With comparable or better performance than standard CNNs\nfor image reconstruction, LoFi achieves excellent generalization to\nout-of-distribution data and memory usage almost independent of image\nresolution. Remarkably, training on $1024 \\times 1024$ images requires just 3GB\nof memory -- over 20 times less than the memory typically needed by standard\nCNNs. Additionally, LoFi's local design allows it to train on extremely small\ndatasets with less than 10 samples, without overfitting or the need for\nregularization or early stopping. Finally, we use LoFi as a denoising prior in\na plug-and-play framework for solving general inverse problems to benefit from\nits continuous image representation and strong generalization. Although trained\non low-resolution images, LoFi can be used as a low-dimensional prior to solve\ninverse problems at any resolution. We validate our framework across a variety\nof imaging modalities, from low-dose computed tomography to radio\ninterferometric imaging.\n","authors":["AmirEhsan Khorashadizadeh","Tobías I. Liaudat","Tianlin Liu","Jason D. McEwen","Ivan Dokmanić"],"pdf_url":"https://arxiv.org/pdf/2411.04995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04989v1","updated":"2024-11-07T18:56:11Z","published":"2024-11-07T18:56:11Z","title":"SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation","summary":"  Methods for image-to-video generation have achieved impressive,\nphoto-realistic quality. However, adjusting specific elements in generated\nvideos, such as object motion or camera movement, is often a tedious process of\ntrial and error, e.g., involving re-generating videos with different random\nseeds. Recent techniques address this issue by fine-tuning a pre-trained model\nto follow conditioning signals, such as bounding boxes or point trajectories.\nYet, this fine-tuning procedure can be computationally expensive, and it\nrequires datasets with annotated object motion, which can be difficult to\nprocure. In this work, we introduce SG-I2V, a framework for controllable\nimage-to-video generation that is self-guided$\\unicode{x2013}$offering\nzero-shot control by relying solely on the knowledge present in a pre-trained\nimage-to-video diffusion model without the need for fine-tuning or external\nknowledge. Our zero-shot method outperforms unsupervised baselines while being\ncompetitive with supervised models in terms of visual quality and motion\nfidelity.\n","authors":["Koichi Namekata","Sherwin Bahmani","Ziyi Wu","Yash Kant","Igor Gilitschenski","David B. Lindell"],"pdf_url":"https://arxiv.org/pdf/2411.04989v1.pdf","comment":"Project page: https://kmcode1.github.io/Projects/SG-I2V/"},{"id":"http://arxiv.org/abs/2411.04984v1","updated":"2024-11-07T18:55:08Z","published":"2024-11-07T18:55:08Z","title":"Planar Reflection-Aware Neural Radiance Fields","summary":"  Neural Radiance Fields (NeRF) have demonstrated exceptional capabilities in\nreconstructing complex scenes with high fidelity. However, NeRF's view\ndependency can only handle low-frequency reflections. It falls short when\nhandling complex planar reflections, often interpreting them as erroneous scene\ngeometries and leading to duplicated and inaccurate scene representations. To\naddress this challenge, we introduce a reflection-aware NeRF that jointly\nmodels planar reflectors, such as windows, and explicitly casts reflected rays\nto capture the source of the high-frequency reflections. We query a single\nradiance field to render the primary color and the source of the reflection. We\npropose a sparse edge regularization to help utilize the true sources of\nreflections for rendering planar reflections rather than creating a duplicate\nalong the primary ray at the same depth. As a result, we obtain accurate scene\ngeometry. Rendering along the primary ray results in a clean, reflection-free\nview, while explicitly rendering along the reflected ray allows us to\nreconstruct highly detailed reflections. Our extensive quantitative and\nqualitative evaluations of real-world datasets demonstrate our method's\nenhanced performance in accurately handling reflections.\n","authors":["Chen Gao","Yipeng Wang","Changil Kim","Jia-Bin Huang","Johannes Kopf"],"pdf_url":"https://arxiv.org/pdf/2411.04984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04967v1","updated":"2024-11-07T18:43:17Z","published":"2024-11-07T18:43:17Z","title":"AsCAN: Asymmetric Convolution-Attention Networks for Efficient\n  Recognition and Generation","summary":"  Neural network architecture design requires making many crucial decisions.\nThe common desiderata is that similar decisions, with little modifications, can\nbe reused in a variety of tasks and applications. To satisfy that,\narchitectures must provide promising latency and performance trade-offs,\nsupport a variety of tasks, scale efficiently with respect to the amounts of\ndata and compute, leverage available data from other tasks, and efficiently\nsupport various hardware. To this end, we introduce AsCAN -- a hybrid\narchitecture, combining both convolutional and transformer blocks. We revisit\nthe key design principles of hybrid architectures and propose a simple and\neffective \\emph{asymmetric} architecture, where the distribution of\nconvolutional and transformer blocks is \\emph{asymmetric}, containing more\nconvolutional blocks in the earlier stages, followed by more transformer blocks\nin later stages. AsCAN supports a variety of tasks: recognition, segmentation,\nclass-conditional image generation, and features a superior trade-off between\nperformance and latency. We then scale the same architecture to solve a\nlarge-scale text-to-image task and show state-of-the-art performance compared\nto the most recent public and commercial models. Notably, even without any\ncomputation optimization for transformer blocks, our models still yield faster\ninference speed than existing works featuring efficient attention mechanisms,\nhighlighting the advantages and the value of our approach.\n","authors":["Anil Kag","Huseyin Coskun","Jierun Chen","Junli Cao","Willi Menapace","Aliaksandr Siarohin","Sergey Tulyakov","Jian Ren"],"pdf_url":"https://arxiv.org/pdf/2411.04967v1.pdf","comment":"NeurIPS 2024. Project Page:\n  https://snap-research.github.io/snap_image/"},{"id":"http://arxiv.org/abs/2401.09980v2","updated":"2024-11-07T18:43:06Z","published":"2024-01-18T13:51:20Z","title":"A Comparative Analysis of U-Net-based models for Segmentation of Cardiac\n  MRI","summary":"  Medical imaging refers to the technologies and methods utilized to view the\nhuman body and its inside, in order to diagnose, monitor, or even treat medical\ndisorders. This paper aims to explore the application of deep learning\ntechniques in the semantic segmentation of Cardiac short-axis MRI (Magnetic\nResonance Imaging) images, aiming to enhance the diagnosis, monitoring, and\ntreatment of medical disorders related to the heart. The focus centers on\nimplementing various architectures that are derivatives of U-Net, to\neffectively isolate specific parts of the heart for comprehensive anatomical\nand functional analysis. Through a combination of images, graphs, and\nquantitative metrics, the efficacy of the models and their predictions are\nshowcased. Additionally, this paper addresses encountered challenges and\noutline strategies for future improvements. This abstract provides a concise\noverview of the efforts in utilizing deep learning for cardiac image\nsegmentation, emphasizing both the accomplishments and areas for further\nrefinement.\n","authors":["Ketan Suhaas Saichandran"],"pdf_url":"https://arxiv.org/pdf/2401.09980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04963v1","updated":"2024-11-07T18:40:17Z","published":"2024-11-07T18:40:17Z","title":"VAIR: Visuo-Acoustic Implicit Representations for Low-Cost, Multi-Modal\n  Transparent Surface Reconstruction in Indoor Scenes","summary":"  Mobile robots operating indoors must be prepared to navigate challenging\nscenes that contain transparent surfaces. This paper proposes a novel method\nfor the fusion of acoustic and visual sensing modalities through implicit\nneural representations to enable dense reconstruction of transparent surfaces\nin indoor scenes. We propose a novel model that leverages generative latent\noptimization to learn an implicit representation of indoor scenes consisting of\ntransparent surfaces. We demonstrate that we can query the implicit\nrepresentation to enable volumetric rendering in image space or 3D geometry\nreconstruction (point clouds or mesh) with transparent surface prediction. We\nevaluate our method's effectiveness qualitatively and quantitatively on a new\ndataset collected using a custom, low-cost sensing platform featuring RGB-D\ncameras and ultrasonic sensors. Our method exhibits significant improvement\nover state-of-the-art for transparent surface reconstruction.\n","authors":["Advaith V. Sethuraman","Onur Bagoren","Harikrishnan Seetharaman","Dalton Richardson","Joseph Taylor","Katherine A. Skinner"],"pdf_url":"https://arxiv.org/pdf/2411.04963v1.pdf","comment":"https://umfieldrobotics.github.io/VAIR_site/"},{"id":"http://arxiv.org/abs/2411.04956v1","updated":"2024-11-07T18:32:00Z","published":"2024-11-07T18:32:00Z","title":"Uncovering Hidden Subspaces in Video Diffusion Models Using\n  Re-Identification","summary":"  Latent Video Diffusion Models can easily deceive casual observers and domain\nexperts alike thanks to the produced image quality and temporal consistency.\nBeyond entertainment, this creates opportunities around safe data sharing of\nfully synthetic datasets, which are crucial in healthcare, as well as other\ndomains relying on sensitive personal information. However, privacy concerns\nwith this approach have not fully been addressed yet, and models trained on\nsynthetic data for specific downstream tasks still perform worse than those\ntrained on real data. This discrepancy may be partly due to the sampling space\nbeing a subspace of the training videos, effectively reducing the training data\nsize for downstream models. Additionally, the reduced temporal consistency when\ngenerating long videos could be a contributing factor.\n  In this paper, we first show that training privacy-preserving models in\nlatent space is computationally more efficient and generalize better.\nFurthermore, to investigate downstream degradation factors, we propose to use a\nre-identification model, previously employed as a privacy preservation filter.\nWe demonstrate that it is sufficient to train this model on the latent space of\nthe video generator. Subsequently, we use these models to evaluate the subspace\ncovered by synthetic video datasets and thus introduce a new way to measure the\nfaithfulness of generative machine learning models. We focus on a specific\napplication in healthcare echocardiography to illustrate the effectiveness of\nour novel methods. Our findings indicate that only up to 30.8% of the training\nvideos are learned in latent video diffusion models, which could explain the\nlack of performance when training downstream tasks on synthetic data.\n","authors":["Mischa Dombrowski","Hadrien Reynaud","Bernhard Kainz"],"pdf_url":"https://arxiv.org/pdf/2411.04956v1.pdf","comment":"8 pages, 5 tables, 6 figures"},{"id":"http://arxiv.org/abs/2411.04954v1","updated":"2024-11-07T18:31:08Z","published":"2024-11-07T18:31:08Z","title":"CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM","summary":"  This paper aims to design a unified Computer-Aided Design (CAD) generation\nsystem that can easily generate CAD models based on the user's inputs in the\nform of textual description, images, point clouds, or even a combination of\nthem. Towards this goal, we introduce the CAD-MLLM, the first system capable of\ngenerating parametric CAD models conditioned on the multimodal input.\nSpecifically, within the CAD-MLLM framework, we leverage the command sequences\nof CAD models and then employ advanced large language models (LLMs) to align\nthe feature space across these diverse multi-modalities data and CAD models'\nvectorized representations. To facilitate the model training, we design a\ncomprehensive data construction and annotation pipeline that equips each CAD\nmodel with corresponding multimodal data. Our resulting dataset, named\nOmni-CAD, is the first multimodal CAD dataset that contains textual\ndescription, multi-view images, points, and command sequence for each CAD\nmodel. It contains approximately 450K instances and their CAD construction\nsequences. To thoroughly evaluate the quality of our generated CAD models, we\ngo beyond current evaluation metrics that focus on reconstruction quality by\nintroducing additional metrics that assess topology quality and surface\nenclosure extent. Extensive experimental results demonstrate that CAD-MLLM\nsignificantly outperforms existing conditional generative methods and remains\nhighly robust to noises and missing points. The project page and more\nvisualizations can be found at: https://cad-mllm.github.io/\n","authors":["Jingwei Xu","Chenyu Wang","Zibo Zhao","Wen Liu","Yi Ma","Shenghua Gao"],"pdf_url":"https://arxiv.org/pdf/2411.04954v1.pdf","comment":"Project page: https://cad-mllm.github.io/"},{"id":"http://arxiv.org/abs/2411.04952v1","updated":"2024-11-07T18:29:38Z","published":"2024-11-07T18:29:38Z","title":"M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page\n  Multi-document Understanding","summary":"  Document visual question answering (DocVQA) pipelines that answer questions\nfrom documents have broad applications. Existing methods focus on handling\nsingle-page documents with multi-modal language models (MLMs), or rely on\ntext-based retrieval-augmented generation (RAG) that uses text extraction tools\nsuch as optical character recognition (OCR). However, there are difficulties in\napplying these methods in real-world scenarios: (a) questions often require\ninformation across different pages or documents, where MLMs cannot handle many\nlong documents; (b) documents often have important information in visual\nelements such as figures, but text extraction tools ignore them. We introduce\nM3DocRAG, a novel multi-modal RAG framework that flexibly accommodates various\ndocument contexts (closed-domain and open-domain), question hops (single-hop\nand multi-hop), and evidence modalities (text, chart, figure, etc.). M3DocRAG\nfinds relevant documents and answers questions using a multi-modal retriever\nand an MLM, so that it can efficiently handle single or many documents while\npreserving visual information. Since previous DocVQA datasets ask questions in\nthe context of a specific document, we also present M3DocVQA, a new benchmark\nfor evaluating open-domain DocVQA over 3,000+ PDF documents with 40,000+ pages.\nIn three benchmarks (M3DocVQA/MMLongBench-Doc/MP-DocVQA), empirical results\nshow that M3DocRAG with ColPali and Qwen2-VL 7B achieves superior performance\nthan many strong baselines, including state-of-the-art performance in\nMP-DocVQA. We provide comprehensive analyses of different indexing, MLMs, and\nretrieval models. Lastly, we qualitatively show that M3DocRAG can successfully\nhandle various scenarios, such as when relevant information exists across\nmultiple pages and when answer evidence only exists in images.\n","authors":["Jaemin Cho","Debanjan Mahata","Ozan Irsoy","Yujie He","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2411.04952v1.pdf","comment":"Project webpage: https://m3docrag.github.io"},{"id":"http://arxiv.org/abs/2401.08426v5","updated":"2024-11-07T18:22:41Z","published":"2024-01-16T15:11:29Z","title":"GD doesn't make the cut: Three ways that non-differentiability affects\n  neural network training","summary":"  This paper critically examines the fundamental distinctions between gradient\nmethods applied to non-differentiable functions (NGDMs) and classical gradient\ndescents (GDs) for differentiable functions, revealing significant gaps in\ncurrent deep learning optimization theory. We demonstrate that NGDMs exhibit\nmarkedly different convergence properties compared to GDs, strongly challenging\nthe applicability of extensive neural network convergence literature based on\n$L-smoothness$ to non-smooth neural networks. Our analysis reveals paradoxical\nbehavior of NDGM solutions for $L_{1}$-regularized problems, where increasing\nregularization counterintuitively leads to larger $L_{1}$ norms of optimal\nsolutions. This finding calls into question widely adopted $L_{1}$ penalization\ntechniques for network pruning. We further challenge the common assumption that\noptimization algorithms like RMSProp behave similarly in differentiable and\nnon-differentiable contexts. Expanding on the Edge of Stability phenomenon, we\ndemonstrate its occurrence in a broader class of functions, including Lipschitz\ncontinuous convex differentiable functions. This finding raises important\nquestions about its relevance and interpretation in non-convex,\nnon-differentiable neural networks, particularly those using ReLU activations.\nOur work identifies critical misunderstandings of NDGMs in influential\nliterature, stemming from an overreliance on strong smoothness assumptions.\nThese findings necessitate a reevaluation of optimization dynamics in deep\nlearning, emphasizing the crucial need for more nuanced theoretical foundations\nin analyzing these complex systems.\n","authors":["Siddharth Krishna Kumar"],"pdf_url":"https://arxiv.org/pdf/2401.08426v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04942v1","updated":"2024-11-07T18:20:28Z","published":"2024-11-07T18:20:28Z","title":"A Reinforcement Learning-Based Automatic Video Editing Method Using\n  Pre-trained Vision-Language Model","summary":"  In this era of videos, automatic video editing techniques attract more and\nmore attention from industry and academia since they can reduce workloads and\nlower the requirements for human editors. Existing automatic editing systems\nare mainly scene- or event-specific, e.g., soccer game broadcasting, yet the\nautomatic systems for general editing, e.g., movie or vlog editing which covers\nvarious scenes and events, were rarely studied before, and converting the\nevent-driven editing method to a general scene is nontrivial. In this paper, we\npropose a two-stage scheme for general editing. Firstly, unlike previous works\nthat extract scene-specific features, we leverage the pre-trained\nVision-Language Model (VLM) to extract the editing-relevant representations as\nediting context. Moreover, to close the gap between the professional-looking\nvideos and the automatic productions generated with simple guidelines, we\npropose a Reinforcement Learning (RL)-based editing framework to formulate the\nediting problem and train the virtual editor to make better sequential editing\ndecisions. Finally, we evaluate the proposed method on a more general editing\ntask with a real movie dataset. Experimental results demonstrate the\neffectiveness and benefits of the proposed context representation and the\nlearning ability of our RL-based editing framework.\n","authors":["Panwen Hu","Nan Xiao","Feifei Li","Yongquan Chen","Rui Huang"],"pdf_url":"https://arxiv.org/pdf/2411.04942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04933v1","updated":"2024-11-07T18:12:49Z","published":"2024-11-07T18:12:49Z","title":"SaSR-Net: Source-Aware Semantic Representation Network for Enhancing\n  Audio-Visual Question Answering","summary":"  Audio-Visual Question Answering (AVQA) is a challenging task that involves\nanswering questions based on both auditory and visual information in videos. A\nsignificant challenge is interpreting complex multi-modal scenes, which include\nboth visual objects and sound sources, and connecting them to the given\nquestion. In this paper, we introduce the Source-aware Semantic Representation\nNetwork (SaSR-Net), a novel model designed for AVQA. SaSR-Net utilizes\nsource-wise learnable tokens to efficiently capture and align audio-visual\nelements with the corresponding question. It streamlines the fusion of audio\nand visual information using spatial and temporal attention mechanisms to\nidentify answers in multi-modal scenes. Extensive experiments on the Music-AVQA\nand AVQA-Yang datasets show that SaSR-Net outperforms state-of-the-art AVQA\nmethods.\n","authors":["ianyu Yang","Yiyang Nan","Lisen Dai","Zhenwen Liang","Yapeng Tian","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.04933v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.04928v1","updated":"2024-11-07T18:07:31Z","published":"2024-11-07T18:07:31Z","title":"DimensionX: Create Any 3D and 4D Scenes from a Single Image with\n  Controllable Video Diffusion","summary":"  In this paper, we introduce \\textbf{DimensionX}, a framework designed to\ngenerate photorealistic 3D and 4D scenes from just a single image with video\ndiffusion. Our approach begins with the insight that both the spatial structure\nof a 3D scene and the temporal evolution of a 4D scene can be effectively\nrepresented through sequences of video frames. While recent video diffusion\nmodels have shown remarkable success in producing vivid visuals, they face\nlimitations in directly recovering 3D/4D scenes due to limited spatial and\ntemporal controllability during generation. To overcome this, we propose\nST-Director, which decouples spatial and temporal factors in video diffusion by\nlearning dimension-aware LoRAs from dimension-variant data. This controllable\nvideo diffusion approach enables precise manipulation of spatial structure and\ntemporal dynamics, allowing us to reconstruct both 3D and 4D representations\nfrom sequential frames with the combination of spatial and temporal dimensions.\nAdditionally, to bridge the gap between generated videos and real-world scenes,\nwe introduce a trajectory-aware mechanism for 3D generation and an\nidentity-preserving denoising strategy for 4D generation. Extensive experiments\non various real-world and synthetic datasets demonstrate that DimensionX\nachieves superior results in controllable video generation, as well as in 3D\nand 4D scene generation, compared with previous methods.\n","authors":["Wenqiang Sun","Shuo Chen","Fangfu Liu","Zilong Chen","Yueqi Duan","Jun Zhang","Yikai Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04928v1.pdf","comment":"Project Page: https://chenshuo20.github.io/DimensionX/"},{"id":"http://arxiv.org/abs/2411.04925v1","updated":"2024-11-07T18:00:33Z","published":"2024-11-07T18:00:33Z","title":"StoryAgent: Customized Storytelling Video Generation via Multi-Agent\n  Collaboration","summary":"  The advent of AI-Generated Content (AIGC) has spurred research into automated\nvideo generation to streamline conventional processes. However, automating\nstorytelling video production, particularly for customized narratives, remains\nchallenging due to the complexity of maintaining subject consistency across\nshots. While existing approaches like Mora and AesopAgent integrate multiple\nagents for Story-to-Video (S2V) generation, they fall short in preserving\nprotagonist consistency and supporting Customized Storytelling Video Generation\n(CSVG). To address these limitations, we propose StoryAgent, a multi-agent\nframework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks\nassigned to specialized agents, mirroring the professional production process.\nNotably, our framework includes agents for story design, storyboard generation,\nvideo creation, agent coordination, and result evaluation. Leveraging the\nstrengths of different models, StoryAgent enhances control over the generation\nprocess, significantly improving character consistency. Specifically, we\nintroduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance\nintra-shot temporal consistency, while a novel storyboard generation pipeline\nis proposed to maintain subject consistency across shots. Extensive experiments\ndemonstrate the effectiveness of our approach in synthesizing highly consistent\nstorytelling videos, outperforming state-of-the-art methods. Our contributions\ninclude the introduction of StoryAgent, a versatile framework for video\ngeneration tasks, and novel techniques for preserving protagonist consistency.\n","authors":["Panwen Hu","Jin Jiang","Jianqi Chen","Mingfei Han","Shengcai Liao","Xiaojun Chang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2411.04925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04924v1","updated":"2024-11-07T17:59:31Z","published":"2024-11-07T17:59:31Z","title":"MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views","summary":"  We introduce MVSplat360, a feed-forward approach for 360{\\deg} novel view\nsynthesis (NVS) of diverse real-world scenes, using only sparse observations.\nThis setting is inherently ill-posed due to minimal overlap among input views\nand insufficient visual information provided, making it challenging for\nconventional methods to achieve high-quality results. Our MVSplat360 addresses\nthis by effectively combining geometry-aware 3D reconstruction with temporally\nconsistent video generation. Specifically, it refactors a feed-forward 3D\nGaussian Splatting (3DGS) model to render features directly into the latent\nspace of a pre-trained Stable Video Diffusion (SVD) model, where these features\nthen act as pose and visual cues to guide the denoising process and produce\nphotorealistic 3D-consistent views. Our model is end-to-end trainable and\nsupports rendering arbitrary views with as few as 5 sparse input views. To\nevaluate MVSplat360's performance, we introduce a new benchmark using the\nchallenging DL3DV-10K dataset, where MVSplat360 achieves superior visual\nquality compared to state-of-the-art methods on wide-sweeping or even 360{\\deg}\nNVS tasks. Experiments on the existing benchmark RealEstate10K also confirm the\neffectiveness of our model. The video results are available on our project\npage: https://donydchen.github.io/mvsplat360.\n","authors":["Yuedong Chen","Chuanxia Zheng","Haofei Xu","Bohan Zhuang","Andrea Vedaldi","Tat-Jen Cham","Jianfei Cai"],"pdf_url":"https://arxiv.org/pdf/2411.04924v1.pdf","comment":"NeurIPS 2024, Project page: https://donydchen.github.io/mvsplat360,\n  Code: https://github.com/donydchen/mvsplat360"},{"id":"http://arxiv.org/abs/2411.04923v1","updated":"2024-11-07T17:59:27Z","published":"2024-11-07T17:59:27Z","title":"VideoGLaMM: A Large Multimodal Model for Pixel-Level Visual Grounding in\n  Videos","summary":"  Fine-grained alignment between videos and text is challenging due to complex\nspatial and temporal dynamics in videos. Existing video-based Large Multimodal\nModels (LMMs) handle basic conversations but struggle with precise pixel-level\ngrounding in videos. To address this, we introduce VideoGLaMM, a LMM designed\nfor fine-grained pixel-level grounding in videos based on user-provided textual\ninputs. Our design seamlessly connects three key components: a Large Language\nModel, a dual vision encoder that emphasizes both spatial and temporal details,\nand a spatio-temporal decoder for accurate mask generation. This connection is\nfacilitated via tunable V-L and L-V adapters that enable close Vision-Language\n(VL) alignment. The architecture is trained to synchronize both spatial and\ntemporal elements of video content with textual instructions. To enable\nfine-grained grounding, we curate a multimodal dataset featuring detailed\nvisually-grounded conversations using a semiautomatic annotation pipeline,\nresulting in a diverse set of 38k video-QA triplets along with 83k objects and\n671k masks. We evaluate VideoGLaMM on three challenging tasks: Grounded\nConversation Generation, Visual Grounding, and Referring Video Segmentation.\nExperimental results show that our model consistently outperforms existing\napproaches across all three tasks.\n","authors":["Shehan Munasinghe","Hanan Gani","Wenqi Zhu","Jiale Cao","Eric Xing","Fahad Shahbaz Khan","Salman Khan"],"pdf_url":"https://arxiv.org/pdf/2411.04923v1.pdf","comment":"Technical Report of VideoGLaMM"},{"id":"http://arxiv.org/abs/2411.04919v1","updated":"2024-11-07T17:56:16Z","published":"2024-11-07T17:56:16Z","title":"Stem-OB: Generalizable Visual Imitation Learning with Stem-Like\n  Convergent Observation through Diffusion Inversion","summary":"  Visual imitation learning methods demonstrate strong performance, yet they\nlack generalization when faced with visual input perturbations, including\nvariations in lighting and textures, impeding their real-world application. We\npropose Stem-OB that utilizes pretrained image diffusion models to suppress\nlow-level visual differences while maintaining high-level scene structures.\nThis image inversion process is akin to transforming the observation into a\nshared representation, from which other observations stem, with extraneous\ndetails removed. Stem-OB contrasts with data-augmentation approaches as it is\nrobust to various unspecified appearance changes without the need for\nadditional training. Our method is a simple yet highly effective plug-and-play\nsolution. Empirical results confirm the effectiveness of our approach in\nsimulated tasks and show an exceptionally significant improvement in real-world\napplications, with an average increase of 22.2% in success rates compared to\nthe best baseline. See https://hukz18.github.io/Stem-Ob/ for more info.\n","authors":["Kaizhe Hu","Zihang Rui","Yao He","Yuyao Liu","Pu Hua","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2411.04919v1.pdf","comment":"Arxiv preprint version"},{"id":"http://arxiv.org/abs/2411.04912v1","updated":"2024-11-07T17:51:28Z","published":"2024-11-07T17:51:28Z","title":"Robust Iris Centre Localisation for Assistive Eye-Gaze Tracking","summary":"  In this research work, we address the problem of robust iris centre\nlocalisation in unconstrained conditions as a core component of our eye-gaze\ntracking platform. We investigate the application of U-Net variants for\nsegmentation-based and regression-based approaches to improve our iris centre\nlocalisation, which was previously based on Bayes' classification. The achieved\nresults are comparable to or better than the state-of-the-art, offering a\ndrastic improvement over those achieved by the Bayes' classifier, and without\nsacrificing the real-time performance of our eye-gaze tracking platform.\n","authors":["Nipun Sandamal Ranasekara Pathiranage","Stefania Cristina","Kenneth P. Camilleri"],"pdf_url":"https://arxiv.org/pdf/2411.04912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04892v1","updated":"2024-11-07T17:31:21Z","published":"2024-11-07T17:31:21Z","title":"In the Era of Prompt Learning with Vision-Language Models","summary":"  Large-scale foundation models like CLIP have shown strong zero-shot\ngeneralization but struggle with domain shifts, limiting their adaptability. In\nour work, we introduce \\textsc{StyLIP}, a novel domain-agnostic prompt learning\nstrategy for Domain Generalization (DG). StyLIP disentangles visual style and\ncontent in CLIP`s vision encoder by using style projectors to learn\ndomain-specific prompt tokens and combining them with content features. Trained\ncontrastively, this approach enables seamless adaptation across domains,\noutperforming state-of-the-art methods on multiple DG benchmarks. Additionally,\nwe propose AD-CLIP for unsupervised domain adaptation (DA), leveraging CLIP`s\nfrozen vision backbone to learn domain-invariant prompts through image style\nand content features. By aligning domains in embedding space with entropy\nminimization, AD-CLIP effectively handles domain shifts, even when only target\ndomain samples are available. Lastly, we outline future work on class discovery\nusing prompt learning for semantic segmentation in remote sensing, focusing on\nidentifying novel or rare classes in unstructured environments. This paves the\nway for more adaptive and generalizable models in complex, real-world\nscenarios.\n","authors":["Ankit Jha"],"pdf_url":"https://arxiv.org/pdf/2411.04892v1.pdf","comment":"ICVGIP 2024, Young Faculty Symposium"},{"id":"http://arxiv.org/abs/2410.03728v2","updated":"2024-11-07T17:19:26Z","published":"2024-09-30T10:50:12Z","title":"Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic\n  Analysis","summary":"  QUIC, a new and increasingly used transport protocol, addresses and resolves\nthe limitations of TCP by offering improved security, performance, and features\nsuch as stream multiplexing and connection migration. These features, however,\nalso present challenges for network operators who need to monitor and analyze\nweb traffic. In this paper, we introduce VisQUIC, a labeled dataset comprising\nover 100,000 QUIC traces from more than 44,000 websites (URLs), collected over\na four-month period. These traces provide the foundation for generating more\nthan seven million images, with configurable parameters of window length, pixel\nresolution, normalization, and labels. These images enable an observer looking\nat the interactions between a client and a server to analyze and gain insights\nabout QUIC encrypted connections. To illustrate the dataset's potential, we\noffer a use-case example of an observer estimating the number of HTTP/3\nresponses/requests pairs in a given QUIC, which can reveal server behavior,\nclient--server interactions, and the load imposed by an observed connection. We\nformulate the problem as a discrete regression problem, train a machine\nlearning (ML) model for it, and then evaluate it using the proposed dataset on\nan example use case.\n","authors":["Barak Gahtan","Robert J. Shahla","Alex M. Bronstein","Reuven Cohen"],"pdf_url":"https://arxiv.org/pdf/2410.03728v2.pdf","comment":"The dataset and the supplementary material can be provided upon\n  request"},{"id":"http://arxiv.org/abs/2407.16803v2","updated":"2024-11-07T17:10:15Z","published":"2024-07-23T19:06:44Z","title":"C3T: Cross-modal Transfer Through Time for Human Action Recognition","summary":"  In order to unlock the potential of diverse sensors, we investigate a method\nto transfer knowledge between modalities using the structure of a unified\nmultimodal representation space for Human Action Recognition (HAR). We\nformalize and explore an understudied cross-modal transfer setting we term\nUnsupervised Modality Adaptation (UMA), where the modality used in testing is\nnot used in supervised training, i.e. zero labeled instances of the test\nmodality are available during training. We develop three methods to perform\nUMA: Student-Teacher (ST), Contrastive Alignment (CA), and Cross-modal Transfer\nThrough Time (C3T). Our extensive experiments on various camera+IMU datasets\ncompare these methods to each other in the UMA setting, and to their empirical\nupper bound in the supervised setting. The results indicate C3T is the most\nrobust and highest performing by at least a margin of 8%, and nears the\nsupervised setting performance even in the presence of temporal noise. This\nmethod introduces a novel mechanism for aligning signals across time-varying\nlatent vectors, extracted from the receptive field of temporal convolutions.\nOur findings suggest that C3T has significant potential for developing\ngeneralizable models for time-series sensor data, opening new avenues for\nmulti-modal learning in various applications.\n","authors":["Abhi Kamboj","Anh Duy Nguyen","Minh Do"],"pdf_url":"https://arxiv.org/pdf/2407.16803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02397v2","updated":"2024-11-07T17:06:32Z","published":"2024-11-04T18:59:44Z","title":"Adaptive Caching for Faster Video Generation with Diffusion Transformers","summary":"  Generating temporally-consistent high-fidelity videos can be computationally\nexpensive, especially over longer temporal spans. More-recent Diffusion\nTransformers (DiTs) -- despite making significant headway in this context --\nhave only heightened such challenges as they rely on larger models and heavier\nattention mechanisms, resulting in slower inference speeds. In this paper, we\nintroduce a training-free method to accelerate video DiTs, termed Adaptive\nCaching (AdaCache), which is motivated by the fact that \"not all videos are\ncreated equal\": meaning, some videos require fewer denoising steps to attain a\nreasonable quality than others. Building on this, we not only cache\ncomputations through the diffusion process, but also devise a caching schedule\ntailored to each video generation, maximizing the quality-latency trade-off. We\nfurther introduce a Motion Regularization (MoReg) scheme to utilize video\ninformation within AdaCache, essentially controlling the compute allocation\nbased on motion content. Altogether, our plug-and-play contributions grant\nsignificant inference speedups (e.g. up to 4.7x on Open-Sora 720p - 2s video\ngeneration) without sacrificing the generation quality, across multiple video\nDiT baselines.\n","authors":["Kumara Kahatapitiya","Haozhe Liu","Sen He","Ding Liu","Menglin Jia","Chenyang Zhang","Michael S. Ryoo","Tian Xie"],"pdf_url":"https://arxiv.org/pdf/2411.02397v2.pdf","comment":"Project-page is available at https://adacache-dit.github.io"},{"id":"http://arxiv.org/abs/2411.04865v1","updated":"2024-11-07T16:58:18Z","published":"2024-11-07T16:58:18Z","title":"ZAHA: Introducing the Level of Facade Generalization and the Large-Scale\n  Point Cloud Facade Semantic Segmentation Benchmark Dataset","summary":"  Facade semantic segmentation is a long-standing challenge in photogrammetry\nand computer vision. Although the last decades have witnessed the influx of\nfacade segmentation methods, there is a lack of comprehensive facade classes\nand data covering the architectural variability. In ZAHA, we introduce Level of\nFacade Generalization (LoFG), novel hierarchical facade classes designed based\non international urban modeling standards, ensuring compatibility with\nreal-world challenging classes and uniform methods' comparison. Realizing the\nLoFG, we present to date the largest semantic 3D facade segmentation dataset,\nproviding 601 million annotated points at five and 15 classes of LoFG2 and\nLoFG3, respectively. Moreover, we analyze the performance of baseline semantic\nsegmentation methods on our introduced LoFG classes and data, complementing it\nwith a discussion on the unresolved challenges for facade segmentation. We\nfirmly believe that ZAHA shall facilitate further development of 3D facade\nsemantic segmentation methods, enabling robust segmentation indispensable in\ncreating urban digital twins.\n","authors":["Olaf Wysocki","Yue Tan","Thomas Froech","Yan Xia","Magdalena Wysocki","Ludwig Hoegner","Daniel Cremers","Christoph Holst"],"pdf_url":"https://arxiv.org/pdf/2411.04865v1.pdf","comment":"Accepted to WACV 2025 (IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV))"},{"id":"http://arxiv.org/abs/2411.04859v1","updated":"2024-11-07T16:49:25Z","published":"2024-11-07T16:49:25Z","title":"A multi-purpose automatic editing system based on lecture semantics for\n  remote education","summary":"  Remote teaching has become popular recently due to its convenience and\nsafety, especially under extreme circumstances like a pandemic. However, online\nstudents usually have a poor experience since the information acquired from the\nviews provided by the broadcast platforms is limited. One potential solution is\nto show more camera views simultaneously, but it is technically challenging and\ndistracting for the viewers. Therefore, an automatic multi-camera\ndirecting/editing system, which aims at selecting the most concerned view at\neach time instance to guide the attention of online students, is in urgent\ndemand. However, existing systems mostly make simple assumptions and focus on\ntracking the position of the speaker instead of the real lecture semantics, and\ntherefore have limited capacities to deliver optimal information flow. To this\nend, this paper proposes an automatic multi-purpose editing system based on the\nlecture semantics, which can both direct the multiple video streams for\nreal-time broadcasting and edit the optimal video offline for review purposes.\nOur system directs the views by semantically analyzing the class events while\nfollowing the professional directing rules, mimicking a human director to\ncapture the regions of interest from the viewpoint of the onsite students. We\nconduct both qualitative and quantitative analyses to verify the effectiveness\nof the proposed system and its components.\n","authors":["Panwen Hu","Rui Huang"],"pdf_url":"https://arxiv.org/pdf/2411.04859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04844v1","updated":"2024-11-07T16:32:29Z","published":"2024-11-07T16:32:29Z","title":"Differentiable Gaussian Representation for Incomplete CT Reconstruction","summary":"  Incomplete Computed Tomography (CT) benefits patients by reducing radiation\nexposure. However, reconstructing high-fidelity images from limited views or\nangles remains challenging due to the ill-posed nature of the problem. Deep\nLearning Reconstruction (DLR) methods have shown promise in enhancing image\nquality, but the paradox between training data diversity and high\ngeneralization ability remains unsolved. In this paper, we propose a novel\nGaussian Representation for Incomplete CT Reconstruction (GRCT) without the\nusage of any neural networks or full-dose CT data. Specifically, we model the\n3D volume as a set of learnable Gaussians, which are optimized directly from\nthe incomplete sinogram. Our method can be applied to multiple views and angles\nwithout changing the architecture. Additionally, we propose a differentiable\nFast CT Reconstruction method for efficient clinical usage. Extensive\nexperiments on multiple datasets and settings demonstrate significant\nimprovements in reconstruction quality metrics and high efficiency. We plan to\nrelease our code as open-source.\n","authors":["Shaokai Wu","Yuxiang Lu","Wei Ji","Suizhi Huang","Fengyu Yang","Shalayiding Sirejiding","Qichen He","Jing Tong","Yanbiao Ji","Yue Ding","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2411.04844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04826v1","updated":"2024-11-07T16:07:00Z","published":"2024-11-07T16:07:00Z","title":"D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic\n  Scenes","summary":"  Depth estimation is a crucial technology in robotics. Recently,\nself-supervised depth estimation methods have demonstrated great potential as\nthey can efficiently leverage large amounts of unlabelled real-world data.\nHowever, most existing methods are designed under the assumption of static\nscenes, which hinders their adaptability in dynamic environments. To address\nthis issue, we present D$^3$epth, a novel method for self-supervised depth\nestimation in dynamic scenes. It tackles the challenge of dynamic objects from\ntwo key perspectives. First, within the self-supervised framework, we design a\nreprojection constraint to identify regions likely to contain dynamic objects,\nallowing the construction of a dynamic mask that mitigates their impact at the\nloss level. Second, for multi-frame depth estimation, we introduce a cost\nvolume auto-masking strategy that leverages adjacent frames to identify regions\nassociated with dynamic objects and generate corresponding masks. This provides\nguidance for subsequent processes. Furthermore, we propose a spectral entropy\nuncertainty module that incorporates spectral entropy to guide uncertainty\nestimation during depth fusion, effectively addressing issues arising from cost\nvolume computation in dynamic environments. Extensive experiments on KITTI and\nCityscapes datasets demonstrate that the proposed method consistently\noutperforms existing self-supervised monocular depth estimation baselines. Code\nis available at \\url{https://github.com/Csyunling/D3epth}.\n","authors":["Siyu Chen","Hong Liu","Wenhao Li","Ying Zhu","Guoquan Wang","Jianbing Wu"],"pdf_url":"https://arxiv.org/pdf/2411.04826v1.pdf","comment":"Open sourced"},{"id":"http://arxiv.org/abs/2411.04821v1","updated":"2024-11-07T15:58:17Z","published":"2024-11-07T15:58:17Z","title":"End-to-end Inception-Unet based Generative Adversarial Networks for Snow\n  and Rain Removals","summary":"  The superior performance introduced by deep learning approaches in removing\natmospheric particles such as snow and rain from a single image; favors their\nusage over classical ones. However, deep learning-based approaches still suffer\nfrom challenges related to the particle appearance characteristics such as\nsize, type, and transparency. Furthermore, due to the unique characteristics of\nrain and snow particles, single network based deep learning approaches struggle\nin handling both degradation scenarios simultaneously. In this paper, a global\nframework that consists of two Generative Adversarial Networks (GANs) is\nproposed where each handles the removal of each particle individually. The\narchitectures of both desnowing and deraining GANs introduce the integration of\na feature extraction phase with the classical U-net generator network which in\nturn enhances the removal performance in the presence of severe variations in\nsize and appearance. Furthermore, a realistic dataset that contains pairs of\nsnowy images next to their groundtruth images estimated using a low-rank\napproximation approach; is presented. The experiments show that the proposed\ndesnowing and deraining approaches achieve significant improvements in\ncomparison to the state-of-the-art approaches when tested on both synthetic and\nrealistic datasets.\n","authors":["Ibrahim Kajo","Mohamed Kas","Yassine Ruichek"],"pdf_url":"https://arxiv.org/pdf/2411.04821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03794v2","updated":"2024-11-07T15:56:00Z","published":"2024-07-04T09:57:44Z","title":"CardioSpectrum: Comprehensive Myocardium Motion Analysis with 3D Deep\n  Learning and Geometric Insights","summary":"  The ability to map left ventricle (LV) myocardial motion using computed\ntomography angiography (CTA) is essential to diagnosing cardiovascular\nconditions and guiding interventional procedures. Due to their inherent\nlocality, conventional neural networks typically have difficulty predicting\nsubtle tangential movements, which considerably lessens the level of precision\nat which myocardium three-dimensional (3D) mapping can be performed. Using 3D\noptical flow techniques and Functional Maps (FMs), we present a comprehensive\napproach to address this problem. FMs are known for their capacity to capture\nglobal geometric features, thus providing a fuller understanding of 3D\ngeometry. As an alternative to traditional segmentation-based priors, we employ\nsurface-based two-dimensional (2D) constraints derived from spectral\ncorrespondence methods. Our 3D deep learning architecture, based on the ARFlow\nmodel, is optimized to handle complex 3D motion analysis tasks. By\nincorporating FMs, we can capture the subtle tangential movements of the\nmyocardium surface precisely, hence significantly improving the accuracy of 3D\nmapping of the myocardium. The experimental results confirm the effectiveness\nof this method in enhancing myocardium motion analysis. This approach can\ncontribute to improving cardiovascular diagnosis and treatment. Our code and\nadditional resources are available at:\nhttps://shaharzuler.github.io/CardioSpectrumPage\n","authors":["Shahar Zuler","Shai Tejman-Yarden","Dan Raviv"],"pdf_url":"https://arxiv.org/pdf/2407.03794v2.pdf","comment":"This paper has been early accepted to MICCAI 2024, LNCS 15005,\n  Springer, 2024"},{"id":"http://arxiv.org/abs/2411.04810v1","updated":"2024-11-07T15:47:07Z","published":"2024-11-07T15:47:07Z","title":"GANESH: Generalizable NeRF for Lensless Imaging","summary":"  Lensless imaging offers a significant opportunity to develop ultra-compact\ncameras by removing the conventional bulky lens system. However, without a\nfocusing element, the sensor's output is no longer a direct image but a complex\nmultiplexed scene representation. Traditional methods have attempted to address\nthis challenge by employing learnable inversions and refinement models, but\nthese methods are primarily designed for 2D reconstruction and do not\ngeneralize well to 3D reconstruction. We introduce GANESH, a novel framework\ndesigned to enable simultaneous refinement and novel view synthesis from\nmulti-view lensless images. Unlike existing methods that require scene-specific\ntraining, our approach supports on-the-fly inference without retraining on each\nscene. Moreover, our framework allows us to tune our model to specific scenes,\nenhancing the rendering and refinement quality. To facilitate research in this\narea, we also present the first multi-view lensless dataset, LenslessScenes.\nExtensive experiments demonstrate that our method outperforms current\napproaches in reconstruction accuracy and refinement quality. Code and video\nresults are available at https://rakesh-123-cryp.github.io/Rakesh.github.io/\n","authors":["Rakesh Raj Madavan","Akshat Kaimal","Badhrinarayanan K V","Vinayak Gupta","Rohit Choudhary","Chandrakala Shanmuganathan","Kaushik Mitra"],"pdf_url":"https://arxiv.org/pdf/2411.04810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01031v2","updated":"2024-11-07T15:41:48Z","published":"2024-10-01T19:45:01Z","title":"Pediatric Wrist Fracture Detection Using Feature Context Excitation\n  Modules in X-ray Images","summary":"  Children often suffer wrist trauma in daily life, while they usually need\nradiologists to analyze and interpret X-ray images before surgical treatment by\nsurgeons. The development of deep learning has enabled neural networks to serve\nas computer-assisted diagnosis (CAD) tools to help doctors and experts in\nmedical image diagnostics. Since YOLOv8 model has obtained the satisfactory\nsuccess in object detection tasks, it has been applied to various fracture\ndetection. This work introduces four variants of Feature Contexts\nExcitation-YOLOv8 (FCE-YOLOv8) model, each incorporating a different FCE module\n(i.e., modules of Squeeze-and-Excitation (SE), Global Context (GC),\nGather-Excite (GE), and Gaussian Context Transformer (GCT)) to enhance the\nmodel performance. Experimental results on GRAZPEDWRI-DX dataset demonstrate\nthat our proposed YOLOv8+GC-M3 model improves the mAP@50 value from 65.78% to\n66.32%, outperforming the state-of-the-art (SOTA) model while reducing\ninference time. Furthermore, our proposed YOLOv8+SE-M3 model achieves the\nhighest mAP@50 value of 67.07%, exceeding the SOTA performance. The\nimplementation of this work is available at\nhttps://github.com/RuiyangJu/FCE-YOLOv8.\n","authors":["Rui-Yang Ju","Chun-Tse Chien","Enkaer Xieerke","Jen-Shiun Chiang"],"pdf_url":"https://arxiv.org/pdf/2410.01031v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.03163"},{"id":"http://arxiv.org/abs/2411.03225v2","updated":"2024-11-07T15:41:20Z","published":"2024-11-05T16:15:33Z","title":"Knowledge Graphs of Driving Scenes to Empower the Emerging Capabilities\n  of Neurosymbolic AI","summary":"  In the era of Generative AI, Neurosymbolic AI is emerging as a powerful\napproach for tasks spanning from perception to cognition. The use of\nNeurosymbolic AI has been shown to achieve enhanced capabilities, including\nimproved grounding, alignment, explainability, and reliability. However, due to\nits nascent stage, there is a lack of widely available real-world benchmark\ndatasets tailored to Neurosymbolic AI tasks. To address this gap and support\nthe evaluation of current and future methods, we introduce DSceneKG -- a suite\nof knowledge graphs of driving scenes built from real-world, high-quality\nscenes from multiple open autonomous driving datasets. In this article, we\ndetail the construction process of DSceneKG and highlight its application in\nseven different tasks. DSceneKG is publicly accessible at:\nhttps://github.com/ruwantw/DSceneKG\n","authors":["Ruwan Wickramarachchi","Cory Henson","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2411.03225v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2310.13040v2","updated":"2024-11-07T15:40:09Z","published":"2023-10-19T17:59:12Z","title":"Interpreting CLIP: Insights on the Robustness to ImageNet Distribution\n  Shifts","summary":"  What distinguishes robust models from non-robust ones? While for ImageNet\ndistribution shifts it has been shown that such differences in robustness can\nbe traced back predominantly to differences in training data, so far it is not\nknown what that translates to in terms of what the model has learned. In this\nwork, we bridge this gap by probing the representation spaces of 16 robust\nzero-shot CLIP vision encoders with various backbones (ResNets and ViTs) and\npretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and {DataComp}),\nand comparing them to the representation spaces of less robust models with\nidentical backbones, but different (pre)training sets or objectives (CLIP\npretraining on ImageNet-Captions, and supervised training or finetuning on\nImageNet).Through this analysis, we generate three novel insights. Firstly, we\ndetect the presence of outlier features in robust zero-shot CLIP vision\nencoders, which to the best of our knowledge is the first time these are\nobserved in non-language and non-transformer models. Secondly, we find the\nexistence of outlier features to be an indication of ImageNet shift robustness\nin models, since we only find them in robust models in our analysis. Lastly, we\nalso investigate the number of unique encoded concepts in the representation\nspace and find zero-shot CLIP models to encode a higher number of unique\nconcepts in their representation space. However, we do not find this to be an\nindicator of ImageNet shift robustness and hypothesize that it is rather\nrelated to the language supervision. Since the presence of outlier features can\nbe detected without access to any data from shifted datasets, we believe that\nthey could be a useful tool for practitioners to get a feeling for the\ndistribution shift robustness of a pretrained model during deployment.\n","authors":["Jonathan Crabbé","Pau Rodríguez","Vaishaal Shankar","Luca Zappella","Arno Blaas"],"pdf_url":"https://arxiv.org/pdf/2310.13040v2.pdf","comment":"Published in TMLR"},{"id":"http://arxiv.org/abs/2411.04796v1","updated":"2024-11-07T15:36:49Z","published":"2024-11-07T15:36:49Z","title":"MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation","summary":"  Visual odometry (VO) is essential for enabling accurate point-goal navigation\nof embodied agents in indoor environments where GPS and compass sensors are\nunreliable and inaccurate. However, traditional VO methods face challenges in\nwide-baseline scenarios, where fast robot motions and low frames per second\n(FPS) during inference hinder their performance, leading to drift and\ncatastrophic failures in point-goal navigation. Recent deep-learned VO methods\nshow robust performance but suffer from sample inefficiency during training;\nhence, they require huge datasets and compute resources. So, we propose a\nrobust and sample-efficient VO pipeline based on motion priors available while\nan agent is navigating an environment. It consists of a training-free\naction-prior based geometric VO module that estimates a coarse relative pose\nwhich is further consumed as a motion prior by a deep-learned VO model, which\nfinally produces a fine relative pose to be used by the navigation policy. This\nstrategy helps our pipeline achieve up to 2x sample efficiency during training\nand demonstrates superior accuracy and robustness in point-goal navigation\ntasks compared to state-of-the-art VO method(s). Realistic indoor environments\nof the Gibson dataset is used in the AI-Habitat simulator to evaluate the\nproposed approach using navigation metrics (like success/SPL) and pose metrics\n(like RPE/ATE). We hope this method further opens a direction of work where\nmotion priors from various sources can be utilized to improve VO estimates and\nachieve better results in embodied navigation tasks.\n","authors":["Sayan Paul","Ruddra dev Roychoudhury","Brojeshwar Bhowmick"],"pdf_url":"https://arxiv.org/pdf/2411.04796v1.pdf","comment":"Accepted in 50SFM Workshop of the 18th European Conference on\n  Computer Vision (ECCV) 2024"},{"id":"http://arxiv.org/abs/2410.16261v3","updated":"2024-11-07T15:35:52Z","published":"2024-10-21T17:58:20Z","title":"Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5%\n  Parameters and 90% Performance","summary":"  Multimodal large language models (MLLMs) have demonstrated impressive\nperformance in vision-language tasks across a broad spectrum of domains.\nHowever, the large model scale and associated high computational costs pose\nsignificant challenges for training and deploying MLLMs on consumer-grade GPUs\nor edge devices, thereby hindering their widespread application. In this work,\nwe introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1B\nto 4B, which achieves 90% of the performance with only 5% of the parameters.\nThis significant improvement in efficiency and effectiveness makes our models\nmore accessible and applicable in various real-world scenarios. To further\npromote the adoption of our models, we develop a unified adaptation framework\nfor Mini-InternVL, which enables our models to transfer and outperform\nspecialized models in downstream tasks, including autonomous driving, medical\nimages, and remote sensing. We believe that our study can provide valuable\ninsights and resources to advance the development of efficient and effective\nMLLMs. Code is available at https://github.com/OpenGVLab/InternVL.\n","authors":["Zhangwei Gao","Zhe Chen","Erfei Cui","Yiming Ren","Weiyun Wang","Jinguo Zhu","Hao Tian","Shenglong Ye","Junjun He","Xizhou Zhu","Lewei Lu","Tong Lu","Yu Qiao","Jifeng Dai","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16261v3.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2406.10395v3","updated":"2024-11-07T15:28:50Z","published":"2024-06-14T19:49:45Z","title":"BrainSegFounder: Towards 3D Foundation Models for Neuroimage\n  Segmentation","summary":"  The burgeoning field of brain health research increasingly leverages\nartificial intelligence (AI) to interpret and analyze neurological data. This\nstudy introduces a novel approach towards the creation of medical foundation\nmodels by integrating a large-scale multi-modal magnetic resonance imaging\n(MRI) dataset derived from 41,400 participants in its own. Our method involves\na novel two-stage pretraining approach using vision transformers. The first\nstage is dedicated to encoding anatomical structures in generally healthy\nbrains, identifying key features such as shapes and sizes of different brain\nregions. The second stage concentrates on spatial information, encompassing\naspects like location and the relative positioning of brain structures. We\nrigorously evaluate our model, BrainFounder, using the Brain Tumor Segmentation\n(BraTS) challenge and Anatomical Tracings of Lesions After Stroke v2.0 (ATLAS\nv2.0) datasets. BrainFounder demonstrates a significant performance gain,\nsurpassing the achievements of the previous winning solutions using fully\nsupervised learning. Our findings underscore the impact of scaling up both the\ncomplexity of the model and the volume of unlabeled training data derived from\ngenerally healthy brains, which enhances the accuracy and predictive\ncapabilities of the model in complex neuroimaging tasks with MRI. The\nimplications of this research provide transformative insights and practical\napplications in healthcare and make substantial steps towards the creation of\nfoundation models for Medical AI. Our pretrained models and training code can\nbe found at https://github.com/lab-smile/GatorBrain.\n","authors":["Joseph Cox","Peng Liu","Skylar E. Stolte","Yunchao Yang","Kang Liu","Kyle B. See","Huiwen Ju","Ruogu Fang"],"pdf_url":"https://arxiv.org/pdf/2406.10395v3.pdf","comment":"19 pages, 5 figures, to be published in Medical Image Analysis"},{"id":"http://arxiv.org/abs/2411.04782v1","updated":"2024-11-07T15:22:32Z","published":"2024-11-07T15:22:32Z","title":"An Effective Pipeline for Whole-Slide Image Glomerulus Segmentation","summary":"  Whole-slide images (WSI) glomerulus segmentation is essential for accurately\ndiagnosing kidney diseases. In this work, we propose a practical pipeline for\nglomerulus segmentation that effectively enhances both patch-level and\nWSI-level segmentation tasks. Our approach leverages stitching on overlapping\npatches, increasing the detection coverage, especially when glomeruli are\nlocated near patch image borders. In addition, we conduct comprehensive\nevaluations from different segmentation models across two large and diverse\ndatasets with over 30K glomerulus annotations. Experimental results demonstrate\nthat models using our pipeline outperform the previous state-of-the-art method,\nachieving superior results across both datasets and setting a new benchmark for\nglomerulus segmentation in WSIs. The code and pre-trained models are available\nat https://github.com/huuquan1994/wsi_glomerulus_seg.\n","authors":["Quan Huu Cap"],"pdf_url":"https://arxiv.org/pdf/2411.04782v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03286v2","updated":"2024-11-07T15:07:59Z","published":"2024-11-05T17:35:41Z","title":"DiT4Edit: Diffusion Transformer for Image Editing","summary":"  Despite recent advances in UNet-based image editing, methods for shape-aware\nobject editing in high-resolution images are still lacking. Compared to UNet,\nDiffusion Transformers (DiT) demonstrate superior capabilities to effectively\ncapture the long-range dependencies among patches, leading to higher-quality\nimage generation. In this paper, we propose DiT4Edit, the first Diffusion\nTransformer-based image editing framework. Specifically, DiT4Edit uses the\nDPM-Solver inversion algorithm to obtain the inverted latents, reducing the\nnumber of steps compared to the DDIM inversion algorithm commonly used in\nUNet-based frameworks. Additionally, we design unified attention control and\npatches merging, tailored for transformer computation streams. This integration\nallows our framework to generate higher-quality edited images faster. Our\ndesign leverages the advantages of DiT, enabling it to surpass UNet structures\nin image editing, especially in high-resolution and arbitrary-size images.\nExtensive experiments demonstrate the strong performance of DiT4Edit across\nvarious editing scenarios, highlighting the potential of Diffusion Transformers\nin supporting image editing.\n","authors":["Kunyu Feng","Yue Ma","Bingyuan Wang","Chenyang Qi","Haozhe Chen","Qifeng Chen","Zeyu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03286v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08673v2","updated":"2024-11-07T14:49:28Z","published":"2024-10-11T09:59:21Z","title":"SpikeBottleNet: Spike-Driven Feature Compression Architecture for\n  Edge-Cloud Co-Inference","summary":"  Edge-cloud co-inference enables efficient deep neural network (DNN)\ndeployment by splitting the architecture between an edge device and cloud\nserver, crucial for resource-constraint edge devices. This approach requires\nbalancing on-device computations and communication costs, often achieved\nthrough compressed intermediate feature transmission. Conventional DNN\narchitectures require continuous data processing and floating point\nactivations, leading to considerable energy consumption and increased feature\nsizes, thus raising transmission costs. This challenge motivates exploring\nbinary, event-driven activations using spiking neural networks (SNNs), known\nfor their extreme energy efficiency. In this research, we propose\nSpikeBottleNet, a novel architecture for edge-cloud co-inference systems that\nintegrates a spiking neuron model to significantly reduce energy consumption on\nedge devices. A key innovation of our study is an intermediate feature\ncompression technique tailored for SNNs for efficient feature transmission.\nThis technique leverages a split computing approach to strategically place\nencoder-decoder bottleneck units within complex deep architectures like ResNet\nand MobileNet. Experimental results demonstrate that SpikeBottleNet achieves up\nto 256x bit compression in the final convolutional layer of ResNet, with\nminimal accuracy loss (0.16%). Additionally, our approach enhances edge device\nenergy efficiency by up to 144x compared to the baseline BottleNet, making it\nideal for resource-limited edge devices.\n","authors":["Maruf Hassan","Steven Davy"],"pdf_url":"https://arxiv.org/pdf/2410.08673v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04746v1","updated":"2024-11-07T14:29:02Z","published":"2024-11-07T14:29:02Z","title":"Taming Rectified Flow for Inversion and Editing","summary":"  Rectified-flow-based diffusion transformers, such as FLUX and OpenSora, have\ndemonstrated exceptional performance in the field of image and video\ngeneration. Despite their robust generative capabilities, these models often\nsuffer from inaccurate inversion, which could further limit their effectiveness\nin downstream tasks such as image and video editing. To address this issue, we\npropose RF-Solver, a novel training-free sampler that enhances inversion\nprecision by reducing errors in the process of solving rectified flow ODEs.\nSpecifically, we derive the exact formulation of the rectified flow ODE and\nperform a high-order Taylor expansion to estimate its nonlinear components,\nsignificantly decreasing the approximation error at each timestep. Building\nupon RF-Solver, we further design RF-Edit, which comprises specialized\nsub-modules for image and video editing. By sharing self-attention layer\nfeatures during the editing process, RF-Edit effectively preserves the\nstructural information of the source image or video while achieving\nhigh-quality editing results. Our approach is compatible with any pre-trained\nrectified-flow-based models for image and video tasks, requiring no additional\ntraining or optimization. Extensive experiments on text-to-image generation,\nimage & video inversion, and image & video editing demonstrate the robust\nperformance and adaptability of our methods. Code is available at\nhttps://github.com/wangjiangshan0725/RF-Solver-Edit.\n","authors":["Jiangshan Wang","Junfu Pu","Zhongang Qi","Jiayi Guo","Yue Ma","Nisha Huang","Yuxin Chen","Xiu Li","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2411.04746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04732v1","updated":"2024-11-07T14:12:00Z","published":"2024-11-07T14:12:00Z","title":"Convolutional Differentiable Logic Gate Networks","summary":"  With the increasing inference cost of machine learning models, there is a\ngrowing interest in models with fast and efficient inference. Recently, an\napproach for learning logic gate networks directly via a differentiable\nrelaxation was proposed. Logic gate networks are faster than conventional\nneural network approaches because their inference only requires logic gate\noperators such as NAND, OR, and XOR, which are the underlying building blocks\nof current hardware and can be efficiently executed. We build on this idea,\nextending it by deep logic gate tree convolutions, logical OR pooling, and\nresidual initializations. This allows scaling logic gate networks up by over\none order of magnitude and utilizing the paradigm of convolution. On CIFAR-10,\nwe achieve an accuracy of 86.29% using only 61 million logic gates, which\nimproves over the SOTA while being 29x smaller.\n","authors":["Felix Petersen","Hilde Kuehne","Christian Borgelt","Julian Welzel","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2411.04732v1.pdf","comment":"Published at NeurIPS 2024 (Oral)"},{"id":"http://arxiv.org/abs/2411.04724v1","updated":"2024-11-07T14:02:41Z","published":"2024-11-07T14:02:41Z","title":"Controlling Human Shape and Pose in Text-to-Image Diffusion Models via\n  Domain Adaptation","summary":"  We present a methodology for conditional control of human shape and pose in\npretrained text-to-image diffusion models using a 3D human parametric model\n(SMPL). Fine-tuning these diffusion models to adhere to new conditions requires\nlarge datasets and high-quality annotations, which can be more cost-effectively\nacquired through synthetic data generation rather than real-world data.\nHowever, the domain gap and low scene diversity of synthetic data can\ncompromise the pretrained model's visual fidelity. We propose a\ndomain-adaptation technique that maintains image quality by isolating\nsynthetically trained conditional information in the classifier-free guidance\nvector and composing it with another control network to adapt the generated\nimages to the input domain. To achieve SMPL control, we fine-tune a\nControlNet-based architecture on the synthetic SURREAL dataset of rendered\nhumans and apply our domain adaptation at generation time. Experiments\ndemonstrate that our model achieves greater shape and pose diversity than the\n2d pose-based ControlNet, while maintaining the visual fidelity and improving\nstability, proving its usefulness for downstream tasks such as human animation.\n","authors":["Benito Buchheim","Max Reimann","Jürgen Döllner"],"pdf_url":"https://arxiv.org/pdf/2411.04724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.02340v5","updated":"2024-11-07T14:00:08Z","published":"2023-09-05T15:57:23Z","title":"Local Padding in Patch-Based GANs for Seamless Infinite-Sized Texture\n  Synthesis","summary":"  Texture models based on Generative Adversarial Networks (GANs) use\nzero-padding to implicitly encode positional information of the image features.\nHowever, when extending the spatial input to generate images at large sizes,\nzero-padding can often lead to degradation in image quality due to the\nincorrect positional information at the center of the image. Moreover,\nzero-padding can limit the diversity within the generated large images. In this\npaper, we propose a novel approach for generating stochastic texture images at\nlarge arbitrary sizes using GANs based on patch-by-patch generation. Instead of\nzero-padding, the model uses \\textit{local padding} in the generator that\nshares border features between the generated patches; providing positional\ncontext and ensuring consistency at the boundaries. The proposed models are\ntrainable on a single texture image and have a constant GPU scalability with\nrespect to the output image size, and hence can generate images of infinite\nsizes. We show in the experiments that our method has a significant advancement\nbeyond existing GANs-based texture models in terms of the quality and diversity\nof the generated textures. Furthermore, the implementation of local padding in\nthe state-of-the-art super-resolution models effectively eliminates tiling\nartifacts enabling large-scale super-resolution. Our code is available at\n\\url{https://github.com/ai4netzero/Infinite_Texture_GANs}.\n","authors":["Alhasan Abdellatif","Ahmed H. Elsheikh","Hannah P. Menke"],"pdf_url":"https://arxiv.org/pdf/2309.02340v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04717v1","updated":"2024-11-07T13:57:53Z","published":"2024-11-07T13:57:53Z","title":"Subspace-Constrained Quadratic Matrix Factorization: Algorithm and\n  Applications","summary":"  Matrix Factorization has emerged as a widely adopted framework for modeling\ndata exhibiting low-rank structures. To address challenges in manifold\nlearning, this paper presents a subspace-constrained quadratic matrix\nfactorization model. The model is designed to jointly learn key low-dimensional\nstructures, including the tangent space, the normal subspace, and the quadratic\nform that links the tangent space to a low-dimensional representation. We solve\nthe proposed factorization model using an alternating minimization method,\ninvolving an in-depth investigation of nonlinear regression and projection\nsubproblems. Theoretical properties of the quadratic projection problem and\nconvergence characteristics of the alternating strategy are also investigated.\nTo validate our approach, we conduct numerical experiments on synthetic and\nreal-world datasets. Results demonstrate that our model outperforms existing\nmethods, highlighting its robustness and efficacy in capturing core\nlow-dimensional structures.\n","authors":["Zheng Zhai","Xiaohui Li"],"pdf_url":"https://arxiv.org/pdf/2411.04717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04715v1","updated":"2024-11-07T13:56:13Z","published":"2024-11-07T13:56:13Z","title":"NeuroFly: A framework for whole-brain single neuron reconstruction","summary":"  Neurons, with their elongated, tree-like dendritic and axonal structures,\nenable efficient signal integration and long-range communication across brain\nregions. By reconstructing individual neurons' morphology, we can gain valuable\ninsights into brain connectivity, revealing the structure basis of cognition,\nmovement, and perception. Despite the accumulation of extensive 3D microscopic\nimaging data, progress has been considerably hindered by the absence of\nautomated tools to streamline this process. Here we introduce NeuroFly, a\nvalidated framework for large-scale automatic single neuron reconstruction.\nThis framework breaks down the process into three distinct stages:\nsegmentation, connection, and proofreading. In the segmentation stage, we\nperform automatic segmentation followed by skeletonization to generate\nover-segmented neuronal fragments without branches. During the connection\nstage, we use a 3D image-based path following approach to extend each fragment\nand connect it with other fragments of the same neuron. Finally, human\nannotators are required only to proofread the few unresolved positions. The\nfirst two stages of our process are clearly defined computer vision problems,\nand we have trained robust baseline models to solve them. We validated\nNeuroFly's efficiency using in-house datasets that include a variety of\nchallenging scenarios, such as dense arborizations, weak axons, images with\ncontamination. We will release the datasets along with a suite of visualization\nand annotation tools for better reproducibility. Our goal is to foster\ncollaboration among researchers to address the neuron reconstruction challenge,\nultimately accelerating advancements in neuroscience research. The dataset and\ncode are available at https://github.com/beanli161514/neurofly\n","authors":["Rubin Zhao","Yang Liu","Shiqi Zhang","Zijian Yi","Yanyang Xiao","Fang Xu","Yi Yang","Pencheng Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.04715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04711v1","updated":"2024-11-07T13:53:13Z","published":"2024-11-07T13:53:13Z","title":"Progressive Multi-Level Alignments for Semi-Supervised Domain Adaptation\n  SAR Target Recognition Using Simulated Data","summary":"  Recently, an intriguing research trend for automatic target recognition (ATR)\nfrom synthetic aperture radar (SAR) imagery has arisen: using simulated data to\ntrain ATR models is a feasible solution to the issue of inadequate measured\ndata. To close the domain gap that exists between the real and simulated data,\nthe unsupervised domain adaptation (UDA) techniques are frequently exploited to\nconstruct ATR models. However, for UDA, the target domain lacks labeled data to\ndirect the model training, posing a great challenge to ATR performance. To\naddress the above problem, a semi-supervised domain adaptation (SSDA) framework\nhas been proposed adopting progressive multi-level alignments for simulated\ndata-aided SAR ATR. First, a progressive wavelet transform data augmentation\n(PWTDA) is presented by analyzing the discrepancies of wavelet decomposition\nsub-bands of two domain images, obtaining the domain-level alignment.\nSpecifically, the domain gap is narrowed by mixing the wavelet transform\nhigh-frequency sub-band components. Second, we develop an asymptotic\ninstance-prototype alignment (AIPA) strategy to push the source domain\ninstances close to the corresponding target prototypes, aiming to achieve\ncategory-level alignment. Moreover, the consistency alignment is implemented by\nexcavating the strong-weak augmentation consistency of both individual samples\nand the multi-sample relationship, enhancing the generalization capability of\nthe model. Extensive experiments on the Synthetic and Measured Paired Labeled\nExperiment (SAMPLE) dataset, indicate that our approach obtains recognition\naccuracies of 99.63% and 98.91% in two common experimental settings with only\none labeled sample per class of the target domain, outperforming the most\nadvanced SSDA techniques.\n","authors":["Xinzheng Zhang","Hui Zhu","Hongqian Zhuang"],"pdf_url":"https://arxiv.org/pdf/2411.04711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04707v1","updated":"2024-11-07T13:45:23Z","published":"2024-11-07T13:45:23Z","title":"From CNN to ConvRNN: Adapting Visualization Techniques for Time-Series\n  Anomaly Detection","summary":"  Nowadays, neural networks are commonly used to solve various problems.\nUnfortunately, despite their effectiveness, they are often perceived as black\nboxes capable of providing answers without explaining their decisions, which\nraises numerous ethical and legal concerns. Fortunately, the field of\nexplainability helps users understand these results. This aspect of machine\nlearning allows users to grasp the decision-making process of a model and\nverify the relevance of its outcomes. In this article, we focus on the learning\nprocess carried out by a ``time distributed`` convRNN, which performs anomaly\ndetection from video data.\n","authors":["Fabien Poirier"],"pdf_url":"https://arxiv.org/pdf/2411.04707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04706v1","updated":"2024-11-07T13:45:04Z","published":"2024-11-07T13:45:04Z","title":"ESC-MISR: Enhancing Spatial Correlations for Multi-Image\n  Super-Resolution in Remote Sensing","summary":"  Multi-Image Super-Resolution (MISR) is a crucial yet challenging research\ntask in the remote sensing community. In this paper, we address the challenging\ntask of Multi-Image Super-Resolution in Remote Sensing (MISR-RS), aiming to\ngenerate a High-Resolution (HR) image from multiple Low-Resolution (LR) images\nobtained by satellites. Recently, the weak temporal correlations among LR\nimages have attracted increasing attention in the MISR-RS task. However,\nexisting MISR methods treat the LR images as sequences with strong temporal\ncorrelations, overlooking spatial correlations and imposing temporal\ndependencies. To address this problem, we propose a novel end-to-end framework\nnamed Enhancing Spatial Correlations in MISR (ESC-MISR), which fully exploits\nthe spatial-temporal relations of multiple images for HR image reconstruction.\nSpecifically, we first introduce a novel fusion module named Multi-Image\nSpatial Transformer (MIST), which emphasizes parts with clearer global spatial\nfeatures and enhances the spatial correlations between LR images. Besides, we\nperform a random shuffle strategy for the sequential inputs of LR images to\nattenuate temporal dependencies and capture weak temporal correlations in the\ntraining stage. Compared with the state-of-the-art methods, our ESC-MISR\nachieves 0.70dB and 0.76dB cPSNR improvements on the two bands of the PROBA-V\ndataset respectively, demonstrating the superiority of our method.\n","authors":["Zhihui Zhang","Jinhui Pang","Jianan Li","Xiaoshuai Hao"],"pdf_url":"https://arxiv.org/pdf/2411.04706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17822v3","updated":"2024-11-07T13:34:24Z","published":"2024-03-26T16:00:31Z","title":"DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing","summary":"  High-fidelity 3D reconstruction of common indoor scenes is crucial for VR and\nAR applications. 3D Gaussian splatting, a novel differentiable rendering\ntechnique, has achieved state-of-the-art novel view synthesis results with high\nrendering speeds and relatively low training times. However, its performance on\nscenes commonly seen in indoor datasets is poor due to the lack of geometric\nconstraints during optimization. In this work, we explore the use of readily\naccessible geometric cues to enhance Gaussian splatting optimization in\nchallenging, ill-posed, and textureless scenes. We extend 3D Gaussian splatting\nwith depth and normal cues to tackle challenging indoor datasets and showcase\ntechniques for efficient mesh extraction. Specifically, we regularize the\noptimization procedure with depth information, enforce local smoothness of\nnearby Gaussians, and use off-the-shelf monocular networks to achieve better\nalignment with the true scene geometry. We propose an adaptive depth loss based\non the gradient of color images, improving depth estimation and novel view\nsynthesis results over various baselines. Our simple yet effective\nregularization technique enables direct mesh extraction from the Gaussian\nrepresentation, yielding more physically accurate reconstructions of indoor\nscenes.\n","authors":["Matias Turkulainen","Xuqian Ren","Iaroslav Melekhov","Otto Seiskari","Esa Rahtu","Juho Kannala"],"pdf_url":"https://arxiv.org/pdf/2403.17822v3.pdf","comment":"To be published in 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2411.04697v1","updated":"2024-11-07T13:31:07Z","published":"2024-11-07T13:31:07Z","title":"Dynamic Brightness Adaptation for Robust Multi-modal Image Fusion","summary":"  Infrared and visible image fusion aim to integrate modality strengths for\nvisually enhanced, informative images. Visible imaging in real-world scenarios\nis susceptible to dynamic environmental brightness fluctuations, leading to\ntexture degradation. Existing fusion methods lack robustness against such\nbrightness perturbations, significantly compromising the visual fidelity of the\nfused imagery. To address this challenge, we propose the Brightness Adaptive\nmultimodal dynamic fusion framework (BA-Fusion), which achieves robust image\nfusion despite dynamic brightness fluctuations. Specifically, we introduce a\nBrightness Adaptive Gate (BAG) module, which is designed to dynamically select\nfeatures from brightness-related channels for normalization, while preserving\nbrightness-independent structural information within the source images.\nFurthermore, we propose a brightness consistency loss function to optimize the\nBAG module. The entire framework is tuned via alternating training strategies.\nExtensive experiments validate that our method surpasses state-of-the-art\nmethods in preserving multi-modal image information and visual fidelity, while\nexhibiting remarkable robustness across varying brightness levels. Our code is\navailable: https://github.com/SunYM2020/BA-Fusion.\n","authors":["Yiming Sun","Bing Cao","Pengfei Zhu","Qinghua Hu"],"pdf_url":"https://arxiv.org/pdf/2411.04697v1.pdf","comment":"Accepted by IJCAI 2024"},{"id":"http://arxiv.org/abs/2411.04693v1","updated":"2024-11-07T13:26:20Z","published":"2024-11-07T13:26:20Z","title":"Reciprocal Point Learning Network with Large Electromagnetic Kernel for\n  SAR Open-Set Recognition","summary":"  The limitations of existing Synthetic Aperture Radar (SAR) Automatic Target\nRecognition (ATR) methods lie in their confinement by the closed-environment\nassumption, hindering their effective and robust handling of unknown target\ncategories in open environments. Open Set Recognition (OSR), a pivotal facet\nfor algorithmic practicality, intends to categorize known classes while\ndenoting unknown ones as \"unknown.\" The chief challenge in OSR involves\nconcurrently mitigating risks associated with generalizing features from a\nrestricted set of known classes to numerous unknown samples and the open space\nexposure to potential unknown data. To enhance open-set SAR classification, a\nmethod called scattering kernel with reciprocal learning network is proposed.\nInitially, a feature learning framework is constructed based on reciprocal\npoint learning (RPL), establishing a bounded space for potential unknown\nclasses. This approach indirectly introduces unknown information into a learner\nconfined to known classes, thereby acquiring more concise and discriminative\nrepresentations. Subsequently, considering the variability in the imaging of\ntargets at different angles and the discreteness of components in SAR images, a\nproposal is made to design convolutional kernels based on large-sized attribute\nscattering center models. This enhances the ability to extract intrinsic\nnon-linear features and specific scattering characteristics in SAR images,\nthereby improving the discriminative features of the model and mitigating the\nimpact of imaging variations on classification performance. Experiments on the\nMSTAR datasets substantiate the superior performance of the proposed approach\ncalled ASC-RPL over mainstream methods.\n","authors":["Xiayang Xiao","Zhuoxuan Li","Ruyi Zhang","Jiacheng Chen","Haipeng Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04692v1","updated":"2024-11-07T13:25:52Z","published":"2024-11-07T13:25:52Z","title":"Personalized Federated Learning for Cross-view Geo-localization","summary":"  In this paper we propose a methodology combining Federated Learning (FL) with\nCross-view Image Geo-localization (CVGL) techniques. We address the challenges\nof data privacy and heterogeneity in autonomous vehicle environments by\nproposing a personalized Federated Learning scenario that allows selective\nsharing of model parameters. Our method implements a coarse-to-fine approach,\nwhere clients share only the coarse feature extractors while keeping\nfine-grained features specific to local environments. We evaluate our approach\nagainst traditional centralized and single-client training schemes using the\nKITTI dataset combined with satellite imagery. Results demonstrate that our\nfederated CVGL method achieves performance close to centralized training while\nmaintaining data privacy. The proposed partial model sharing strategy shows\ncomparable or slightly better performance than classical FL, offering\nsignificant reduced communication overhead without sacrificing accuracy. Our\nwork contributes to more robust and privacy-preserving localization systems for\nautonomous vehicles operating in diverse environments\n","authors":["Christos Anagnostopoulos","Alexandros Gkillas","Nikos Piperigkos","Aris S. Lalos"],"pdf_url":"https://arxiv.org/pdf/2411.04692v1.pdf","comment":"6 pages, 2 figures, Preprint submitted to the IEEE 26th International\n  Workshop on Multimedia Signal Processing (MMSP)"},{"id":"http://arxiv.org/abs/2411.04682v1","updated":"2024-11-07T13:13:23Z","published":"2024-11-07T13:13:23Z","title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging","summary":"  Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.\n","authors":["Tamar Klein","Tom Aizenberg","Roi Ronen"],"pdf_url":"https://arxiv.org/pdf/2411.04682v1.pdf","comment":"4 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.10012v2","updated":"2024-11-07T13:11:02Z","published":"2024-03-15T04:35:25Z","title":"Representing Domain-Mixing Optical Degradation for Real-World\n  Computational Aberration Correction via Vector Quantization","summary":"  Relying on paired synthetic data, existing learning-based Computational\nAberration Correction (CAC) methods are confronted with the intricate and\nmultifaceted synthetic-to-real domain gap, which leads to suboptimal\nperformance in real-world applications. In this paper, in contrast to improving\nthe simulation pipeline, we deliver a novel insight into real-world CAC from\nthe perspective of Unsupervised Domain Adaptation (UDA). By incorporating\nreadily accessible unpaired real-world data into training, we formalize the\nDomain Adaptive CAC (DACAC) task, and then introduce a comprehensive Real-world\naberrated images (Realab) dataset to benchmark it. The setup task presents a\nformidable challenge due to the intricacy of understanding the target optical\ndegradation domain. To this intent, we propose a novel Quantized Domain-Mixing\nRepresentation (QDMR) framework as a potent solution to the issue. Centering\naround representing and quantizing the optical degradation which is consistent\nacross different images, QDMR adapts the CAC model to the target domain from\nthree key aspects: (1) reconstructing aberrated images of both domains by a\nVQGAN to learn a Domain-Mixing Codebook (DMC) characterizing the optical\ndegradation; (2) modulating the deep features in CAC model with DMC to transfer\nthe target domain knowledge; and (3) leveraging the trained VQGAN to generate\npseudo target aberrated images from the source ones for convincing target\ndomain supervision. Extensive experiments on both synthetic and real-world\nbenchmarks reveal that the models with QDMR consistently surpass the\ncompetitive methods in mitigating the synthetic-to-real gap, which produces\nvisually pleasant real-world CAC results with fewer artifacts. Codes and\ndatasets are made publicly available at https://github.com/zju-jiangqi/QDMR.\n","authors":["Qi Jiang","Zhonghua Yi","Shaohua Gao","Yao Gao","Xiaolong Qian","Hao Shi","Lei Sun","JinXing Niu","Kaiwei Wang","Kailun Yang","Jian Bai"],"pdf_url":"https://arxiv.org/pdf/2403.10012v2.pdf","comment":"Accepted to Optics & Laser Technology. Codes and datasets are made\n  publicly available at https://github.com/zju-jiangqi/QDMR"},{"id":"http://arxiv.org/abs/2411.04679v1","updated":"2024-11-07T13:08:04Z","published":"2024-11-07T13:08:04Z","title":"CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent\n  Cooperation","summary":"  In this work, we address the cooperation problem among large language model\n(LLM) based embodied agents, where agents must cooperate to achieve a common\ngoal. Previous methods often execute actions extemporaneously and incoherently,\nwithout long-term strategic and cooperative planning, leading to redundant\nsteps, failures, and even serious repercussions in complex tasks like\nsearch-and-rescue missions where discussion and cooperative plan are crucial.\nTo solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance\nthe cooperation efficiency of LLM-based embodied agents. Inspired by human\ncooperation schemes, CaPo improves cooperation efficiency with two phases: 1)\nmeta-plan generation, and 2) progress-adaptive meta-plan and execution. In the\nfirst phase, all agents analyze the task, discuss, and cooperatively create a\nmeta-plan that decomposes the task into subtasks with detailed steps, ensuring\na long-term strategic and coherent plan for efficient coordination. In the\nsecond phase, agents execute tasks according to the meta-plan and dynamically\nadjust it based on their latest progress (e.g., discovering a target object)\nthrough multi-turn discussions. This progress-based adaptation eliminates\nredundant actions, improving the overall cooperation efficiency of agents.\nExperimental results on the ThreeDworld Multi-Agent Transport and Communicative\nWatch-And-Help tasks demonstrate that CaPo achieves much higher task completion\nrate and efficiency compared with state-of-the-arts.\n","authors":["Jie Liu","Pan Zhou","Yingjun Du","Ah-Hwee Tan","Cees G. M. Snoek","Jan-Jakob Sonke","Efstratios Gavves"],"pdf_url":"https://arxiv.org/pdf/2411.04679v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.04663v1","updated":"2024-11-07T12:48:39Z","published":"2024-11-07T12:48:39Z","title":"Explainable Search and Discovery of Visual Cultural Heritage Collections\n  with Multimodal Large Language Models","summary":"  Many cultural institutions have made large digitized visual collections\navailable online, often under permissible re-use licences. Creating interfaces\nfor exploring and searching these collections is difficult, particularly in the\nabsence of granular metadata. In this paper, we introduce a method for using\nstate-of-the-art multimodal large language models (LLMs) to enable an\nopen-ended, explainable search and discovery interface for visual collections.\nWe show how our approach can create novel clustering and recommendation systems\nthat avoid common pitfalls of methods based directly on visual embeddings. Of\nparticular interest is the ability to offer concrete textual explanations of\neach recommendation without the need to preselect the features of interest.\nTogether, these features can create a digital interface that is more open-ended\nand flexible while also being better suited to addressing privacy and ethical\nconcerns. Through a case study using a collection of documentary photographs,\nwe provide several metrics showing the efficacy and possibilities of our\napproach.\n","authors":["Taylor Arnold","Lauren Tilton"],"pdf_url":"https://arxiv.org/pdf/2411.04663v1.pdf","comment":"16 pages, CHR 2024: Computational Humanities Research Conference,\n  December 4 - 6, 2024, Aarhus University, Denmark"},{"id":"http://arxiv.org/abs/2411.04659v1","updated":"2024-11-07T12:42:48Z","published":"2024-11-07T12:42:48Z","title":"Automated Image Color Mapping for a Historic Photographic Collection","summary":"  In the 1970s, the United States Environmental Protection Agency sponsored\nDocumerica, a large-scale photography initiative to document environmental\nsubjects nation-wide. While over 15,000 digitized public-domain photographs\nfrom the collection are available online, most of the images were scanned from\ndamaged copies of the original prints. We present and evaluate a modified\nhistogram matching technique based on the underlying chemistry of the prints\nfor correcting the damaged images by using training data collected from a small\nset of undamaged prints. The entire set of color-adjusted Documerica images is\nmade available in an open repository.\n","authors":["Taylor Arnold","Lauren Tilton"],"pdf_url":"https://arxiv.org/pdf/2411.04659v1.pdf","comment":"11 pages, CHR 2024: Computational Humanities Research Conference,\n  December 4 - 6, 2024, Aarhus University, Denmark"},{"id":"http://arxiv.org/abs/2411.04656v1","updated":"2024-11-07T12:34:25Z","published":"2024-11-07T12:34:25Z","title":"ICH-SCNet: Intracerebral Hemorrhage Segmentation and Prognosis\n  Classification Network Using CLIP-guided SAM mechanism","summary":"  Intracerebral hemorrhage (ICH) is the most fatal subtype of stroke and is\ncharacterized by a high incidence of disability. Accurate segmentation of the\nICH region and prognosis prediction are critically important for developing and\nrefining treatment plans for post-ICH patients. However, existing approaches\naddress these two tasks independently and predominantly focus on imaging data\nalone, thereby neglecting the intrinsic correlation between the tasks and\nmodalities. This paper introduces a multi-task network, ICH-SCNet, designed for\nboth ICH segmentation and prognosis classification. Specifically, we integrate\na SAM-CLIP cross-modal interaction mechanism that combines medical text and\nsegmentation auxiliary information with neuroimaging data to enhance\ncross-modal feature recognition. Additionally, we develop an effective feature\nfusion module and a multi-task loss function to improve performance further.\nExtensive experiments on an ICH dataset reveal that our approach surpasses\nother state-of-the-art methods. It excels in the overall performance of\nclassification tasks and outperforms competing models in all segmentation task\nmetrics.\n","authors":["Xinlei Yu","Ahmed Elazab","Ruiquan Ge","Hui Jin","Xinchen Jiang","Gangyong Jia","Qing Wu","Qinglei Shi","Changmiao Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04656v1.pdf","comment":"6 pages, 2 figures, 3 tables, published to BIBM 2024"},{"id":"http://arxiv.org/abs/2411.04646v1","updated":"2024-11-07T12:11:11Z","published":"2024-11-07T12:11:11Z","title":"DanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for\n  Audio-Driven Dance Motion Reconstruction","summary":"  This paper introduces DanceFusion, a novel framework for reconstructing and\ngenerating dance movements synchronized to music, utilizing a Spatio-Temporal\nSkeleton Diffusion Transformer. The framework adeptly handles incomplete and\nnoisy skeletal data common in short-form dance videos on social media platforms\nlike TikTok. DanceFusion incorporates a hierarchical Transformer-based\nVariational Autoencoder (VAE) integrated with a diffusion model, significantly\nenhancing motion realism and accuracy. Our approach introduces sophisticated\nmasking techniques and a unique iterative diffusion process that refines the\nmotion sequences, ensuring high fidelity in both motion generation and\nsynchronization with accompanying audio cues. Comprehensive evaluations\ndemonstrate that DanceFusion surpasses existing methods, providing\nstate-of-the-art performance in generating dynamic, realistic, and\nstylistically diverse dance motions. Potential applications of this framework\nextend to content creation, virtual reality, and interactive entertainment,\npromising substantial advancements in automated dance generation. Visit our\nproject page at https://th-mlab.github.io/DanceFusion/.\n","authors":["Li Zhao","Zhengmin Lu"],"pdf_url":"https://arxiv.org/pdf/2411.04646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04642v1","updated":"2024-11-07T11:54:01Z","published":"2024-11-07T11:54:01Z","title":"TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language\n  Models","summary":"  Vision-Language (VL) models have garnered considerable research interest;\nhowever, they still face challenges in effectively handling text within images.\nTo address this limitation, researchers have developed two approaches. The\nfirst method involves utilizing external Optical Character Recognition (OCR)\ntools to extract textual information from images, which is then prepended to\nother textual inputs. The second strategy focuses on employing extremely\nhigh-resolution images to improve text recognition capabilities. In this paper,\nwe focus on enhancing the first strategy by introducing a novel method, named\nTAP-VL, which treats OCR information as a distinct modality and seamlessly\nintegrates it into any VL model. TAP-VL employs a lightweight transformer-based\nOCR module to receive OCR with layout information, compressing it into a short\nfixed-length sequence for input into the LLM. Initially, we conduct\nmodel-agnostic pretraining of the OCR module on unlabeled documents, followed\nby its integration into any VL architecture through brief fine-tuning.\nExtensive experiments demonstrate consistent performance improvements when\napplying TAP-VL to top-performing VL models, across scene-text and\ndocument-based VL benchmarks.\n","authors":["Jonathan Fhima","Elad Ben Avraham","Oren Nuriel","Yair Kittenplon","Roy Ganz","Aviad Aberdam","Ron Litman"],"pdf_url":"https://arxiv.org/pdf/2411.04642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04632v1","updated":"2024-11-07T11:35:31Z","published":"2024-11-07T11:35:31Z","title":"Improved Multi-Task Brain Tumour Segmentation with Synthetic Data\n  Augmentation","summary":"  This paper presents the winning solution of task 1 and the third-placed\nsolution of task 3 of the BraTS challenge. The use of automated tools in\nclinical practice has increased due to the development of more and more\nsophisticated and reliable algorithms. However, achieving clinical standards\nand developing tools for real-life scenarios is a major challenge. To this end,\nBraTS has organised tasks to find the most advanced solutions for specific\npurposes. In this paper, we propose the use of synthetic data to train\nstate-of-the-art frameworks in order to improve the segmentation of adult\ngliomas in a post-treatment scenario, and the segmentation of meningioma for\nradiotherapy planning. Our results suggest that the use of synthetic data leads\nto more robust algorithms, although the synthetic data generation pipeline is\nnot directly suited to the meningioma task. The code for these tasks is\navailable at https://github.com/ShadowTwin41/BraTS_2023_2024_solutions.\n","authors":["André Ferreira","Tiago Jesus","Behrus Puladi","Jens Kleesiek","Victor Alves","Jan Egger"],"pdf_url":"https://arxiv.org/pdf/2411.04632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04630v1","updated":"2024-11-07T11:29:55Z","published":"2024-11-07T11:29:55Z","title":"Brain Tumour Removing and Missing Modality Generation using 3D WDM","summary":"  This paper presents the second-placed solution for task 8 and the\nparticipation solution for task 7 of BraTS 2024. The adoption of automated\nbrain analysis algorithms to support clinical practice is increasing. However,\nmany of these algorithms struggle with the presence of brain lesions or the\nabsence of certain MRI modalities. The alterations in the brain's morphology\nleads to high variability and thus poor performance of predictive models that\nwere trained only on healthy brains. The lack of information that is usually\nprovided by some of the missing MRI modalities also reduces the reliability of\nthe prediction models trained with all modalities. In order to improve the\nperformance of these models, we propose the use of conditional 3D wavelet\ndiffusion models. The wavelet transform enabled full-resolution image training\nand prediction on a GPU with 48 GB VRAM, without patching or downsampling,\npreserving all information for prediction. For the inpainting task of BraTS\n2024, the use of a large and variable number of healthy masks and the stability\nand efficiency of the 3D wavelet diffusion model resulted in 0.007, 22.61 and\n0.842 in the validation set and 0.07 , 22.8 and 0.91 in the testing set (MSE,\nPSNR and SSIM respectively). The code for these tasks is available at\nhttps://github.com/ShadowTwin41/BraTS_2023_2024_solutions.\n","authors":["André Ferreira","Gijs Luijten","Behrus Puladi","Jens Kleesiek","Victor Alves","Jan Egger"],"pdf_url":"https://arxiv.org/pdf/2411.04630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09377v2","updated":"2024-11-07T11:21:56Z","published":"2023-06-15T08:18:29Z","title":"Evaluating alignment between humans and neural network representations\n  in image-based learning tasks","summary":"  Humans represent scenes and objects in rich feature spaces, carrying\ninformation that allows us to generalise about category memberships and\nabstract functions with few examples. What determines whether a neural network\nmodel generalises like a human? We tested how well the representations of $86$\npretrained neural network models mapped to human learning trajectories across\ntwo tasks where humans had to learn continuous relationships and categories of\nnatural images. In these tasks, both human participants and neural networks\nsuccessfully identified the relevant stimulus features within a few trials,\ndemonstrating effective generalisation. We found that while training dataset\nsize was a core determinant of alignment with human choices, contrastive\ntraining with multi-modal data (text and imagery) was a common feature of\ncurrently publicly available models that predicted human generalisation.\nIntrinsic dimensionality of representations had different effects on alignment\nfor different model types. Lastly, we tested three sets of human-aligned\nrepresentations and found no consistent improvements in predictive accuracy\ncompared to the baselines. In conclusion, pretrained neural networks can serve\nto extract representations for cognitive models, as they appear to capture some\nfundamental aspects of cognition that are transferable across tasks. Both our\nparadigms and modelling approach offer a novel way to quantify alignment\nbetween neural networks and humans and extend cognitive science into more\nnaturalistic domains.\n","authors":["Can Demircan","Tankred Saanum","Leonardo Pettini","Marcel Binz","Blazej M Baczkowski","Christian F Doeller","Mona M Garvert","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2306.09377v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04620v1","updated":"2024-11-07T11:09:29Z","published":"2024-11-07T11:09:29Z","title":"Multi-temporal crack segmentation in concrete structure using deep\n  learning approaches","summary":"  Cracks are among the earliest indicators of deterioration in concrete\nstructures. Early automatic detection of these cracks can significantly extend\nthe lifespan of critical infrastructures, such as bridges, buildings, and\ntunnels, while simultaneously reducing maintenance costs and facilitating\nefficient structural health monitoring. This study investigates whether\nleveraging multi-temporal data for crack segmentation can enhance segmentation\nquality. Therefore, we compare a Swin UNETR trained on multi-temporal data with\na U-Net trained on mono-temporal data to assess the effect of temporal\ninformation compared with conventional single-epoch approaches. To this end, a\nmulti-temporal dataset comprising 1356 images, each with 32 sequential crack\npropagation images, was created. After training the models, experiments were\nconducted to analyze their generalization ability, temporal consistency, and\nsegmentation quality. The multi-temporal approach consistently outperformed its\nmono-temporal counterpart, achieving an IoU of $82.72\\%$ and a F1-score of\n$90.54\\%$, representing a significant improvement over the mono-temporal\nmodel's IoU of $76.69\\%$ and F1-score of $86.18\\%$, despite requiring only half\nof the trainable parameters. The multi-temporal model also displayed a more\nconsistent segmentation quality, with reduced noise and fewer errors. These\nresults suggest that temporal information significantly enhances the\nperformance of segmentation models, offering a promising solution for improved\ncrack detection and the long-term monitoring of concrete structures, even with\nlimited sequential data.\n","authors":["Said Harb","Pedro Achanccaray","Mehdi Maboudi","Markus Gerke"],"pdf_url":"https://arxiv.org/pdf/2411.04620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02099v2","updated":"2024-11-07T10:53:14Z","published":"2024-11-04T14:08:26Z","title":"Differentially Private Integrated Decision Gradients (IDG-DP) for\n  Radar-based Human Activity Recognition","summary":"  Human motion analysis offers significant potential for healthcare monitoring\nand early detection of diseases. The advent of radar-based sensing systems has\ncaptured the spotlight for they are able to operate without physical contact\nand they can integrate with pre-existing Wi-Fi networks. They are also seen as\nless privacy-invasive compared to camera-based systems. However, recent\nresearch has shown high accuracy in recognizing subjects or gender from radar\ngait patterns, raising privacy concerns. This study addresses these issues by\ninvestigating privacy vulnerabilities in radar-based Human Activity Recognition\n(HAR) systems and proposing a novel method for privacy preservation using\nDifferential Privacy (DP) driven by attributions derived with Integrated\nDecision Gradient (IDG) algorithm. We investigate Black-box Membership\nInference Attack (MIA) Models in HAR settings across various levels of\nattacker-accessible information. We extensively evaluated the effectiveness of\nthe proposed IDG-DP method by designing a CNN-based HAR model and rigorously\nassessing its resilience against MIAs. Experimental results demonstrate the\npotential of IDG-DP in mitigating privacy attacks while maintaining utility\nacross all settings, particularly excelling against label-only and shadow model\nblack-box MIA attacks. This work represents a crucial step towards balancing\nthe need for effective radar-based HAR with robust privacy protection in\nhealthcare environments.\n","authors":["Idris Zakariyya","Linda Tran","Kaushik Bhargav Sivangi","Paul Henderson","Fani Deligianni"],"pdf_url":"https://arxiv.org/pdf/2411.02099v2.pdf","comment":"Accepted at WACV 2025. 12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.04612v1","updated":"2024-11-07T10:52:57Z","published":"2024-11-07T10:52:57Z","title":"Population estimation using 3D city modelling and Carto2S datasets -- A\n  case study","summary":"  With the launch of Carto2S series of satellites, high resolution images\n(0.6-1.0 meters) are acquired and available for use. High resolution Digital\nElevation Model (DEM) with better accuracies can be generated using C2S\nmulti-view and multi date datasets. DEMs are further used as an input to derive\nDigital terrain models (DTMs) and to extract accurate heights of the objects\n(building and tree) over the surface of the Earth. Extracted building heights\nare validated with ground control points and can be used for generation of city\nmodelling and resource estimation like population estimation, health planning,\nwater and transport resource estimations. In this study, an attempt is made to\nassess the population of a township using high-resolution Indian remote sensing\nsatellite datasets. We used Carto 2S multi-view data and generated a precise\nDEM and DTM over a city area. Using DEM and DTM datasets, accurate heights of\nthe buildings are extracted which are further validated with ground data.\nAccurate building heights and high resolution imagery are used for generating\naccurate virtual 3D city model and assessing the number of floor and carpet\narea of the houses/ flats/ apartments. Population estimation of the area is\nmade using derived information of no of houses/ flats/ apartments from the\nsatellite datasets. Further, information about number of hospital and schools\naround the residential area is extracted from open street maps (OSM).\nPopulation estimation using satellite data and derived information from OSM\ndatasets can prove to be very good tool for local administrator and decision\nmakers.\n","authors":["Jai G Singla"],"pdf_url":"https://arxiv.org/pdf/2411.04612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04610v1","updated":"2024-11-07T10:50:39Z","published":"2024-11-07T10:50:39Z","title":"Solar potential analysis over Indian cities using high-resolution\n  satellite imagery and DEM","summary":"  Most of the research work in the solar potential analysis is performed\nutilizing aerial imagery, LiDAR data, and satellite imagery. However, in the\nexisting studies using satellite data, parameters such as trees/ vegetation\nshadow, adjacent higher architectural structures, and eccentric roof structures\nin urban areas were not considered, and relatively coarser-resolution datasets\nwere used for analysis. In this work, we have implemented a novel approach to\nestimate rooftop solar potential using inputs of high-resolution satellite\nimagery (0.5 cm), a digital elevation model (1m), along with ground station\nradiation data. Solar radiation analysis is performed using the diffusion\nproportion and transmissivity ratio derived from the ground station data hosted\nby IMD. It was observed that due to seasonal variations, environmental effects\nand technical reasons such as solar panel structure etc., there can be a\nsignificant loss of electricity generation up to 50%. Based on the results, it\nis also understood that using 1m DEM and 50cm satellite imagery, more authentic\nresults are produced over the urban areas.\n","authors":["Jai Singla"],"pdf_url":"https://arxiv.org/pdf/2411.04610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04607v1","updated":"2024-11-07T10:46:01Z","published":"2024-11-07T10:46:01Z","title":"Cross- and Intra-image Prototypical Learning for Multi-label Disease\n  Diagnosis and Interpretation","summary":"  Recent advances in prototypical learning have shown remarkable potential to\nprovide useful decision interpretations associating activation maps and\npredictions with class-specific training prototypes. Such prototypical learning\nhas been well-studied for various single-label diseases, but for quite relevant\nand more challenging multi-label diagnosis, where multiple diseases are often\nconcurrent within an image, existing prototypical learning models struggle to\nobtain meaningful activation maps and effective class prototypes due to the\nentanglement of the multiple diseases. In this paper, we present a novel Cross-\nand Intra-image Prototypical Learning (CIPL) framework, for accurate\nmulti-label disease diagnosis and interpretation from medical images. CIPL\ntakes advantage of common cross-image semantics to disentangle the multiple\ndiseases when learning the prototypes, allowing a comprehensive understanding\nof complicated pathological lesions. Furthermore, we propose a new two-level\nalignment-based regularisation strategy that effectively leverages consistent\nintra-image information to enhance interpretation robustness and predictive\nperformance. Extensive experiments show that our CIPL attains the\nstate-of-the-art (SOTA) classification accuracy in two public multi-label\nbenchmarks of disease diagnosis: thoracic radiography and fundus images.\nQuantitative interpretability results show that CIPL also has superiority in\nweakly-supervised thoracic disease localisation over other leading saliency-\nand prototype-based explanation methods.\n","authors":["Chong Wang","Fengbei Liu","Yuanhong Chen","Helen Frazer","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2411.04607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04598v1","updated":"2024-11-07T10:28:49Z","published":"2024-11-07T10:28:49Z","title":"Social EgoMesh Estimation","summary":"  Accurately estimating the 3D pose of the camera wearer in egocentric video\nsequences is crucial to modeling human behavior in virtual and augmented\nreality applications. The task presents unique challenges due to the limited\nvisibility of the user's body caused by the front-facing camera mounted on\ntheir head. Recent research has explored the utilization of the scene and\nego-motion, but it has overlooked humans' interactive nature. We propose a\nnovel framework for Social Egocentric Estimation of body MEshes (SEE-ME). Our\napproach is the first to estimate the wearer's mesh using only a latent\nprobabilistic diffusion model, which we condition on the scene and, for the\nfirst time, on the social wearer-interactee interactions. Our in-depth study\nsheds light on when social interaction matters most for ego-mesh estimation; it\nquantifies the impact of interpersonal distance and gaze direction. Overall,\nSEE-ME surpasses the current best technique, reducing the pose estimation error\n(MPJPE) by 53%. The code is available at https://github.com/L-Scofano/SEEME.\n","authors":["Luca Scofano","Alessio Sampieri","Edoardo De Matteis","Indro Spinelli","Fabio Galasso"],"pdf_url":"https://arxiv.org/pdf/2411.04598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04596v1","updated":"2024-11-07T10:28:11Z","published":"2024-11-07T10:28:11Z","title":"The Impact of Semi-Supervised Learning on Line Segment Detection","summary":"  In this paper we present a method for line segment detection in images, based\non a semi-supervised framework. Leveraging the use of a consistency loss based\non differently augmented and perturbed unlabeled images with a small amount of\nlabeled data, we show comparable results to fully supervised methods. This\nopens up application scenarios where annotation is difficult or expensive, and\nfor domain specific adaptation of models. We are specifically interested in\nreal-time and online applications, and investigate small and efficient learning\nbackbones. Our method is to our knowledge the first to target line detection\nusing modern state-of-the-art methodologies for semi-supervised learning. We\ntest the method on both standard benchmarks and domain specific scenarios for\nforestry applications, showing the tractability of the proposed method.\n","authors":["Johanna Engman","Karl Åström","Magnus Oskarsson"],"pdf_url":"https://arxiv.org/pdf/2411.04596v1.pdf","comment":"9 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2411.04595v1","updated":"2024-11-07T10:26:38Z","published":"2024-11-07T10:26:38Z","title":"TexLiverNet: Leveraging Medical Knowledge and Spatial-Frequency\n  Perception for Enhanced Liver Tumor Segmentation","summary":"  Integrating textual data with imaging in liver tumor segmentation is\nessential for enhancing diagnostic accuracy. However, current multi-modal\nmedical datasets offer only general text annotations, lacking lesion-specific\ndetails critical for extracting nuanced features, especially for fine-grained\nsegmentation of tumor boundaries and small lesions. To address these\nlimitations, we developed datasets with lesion-specific text annotations for\nliver tumors and introduced the TexLiverNet model. TexLiverNet employs an\nagent-based cross-attention module that integrates text features efficiently\nwith visual features, significantly reducing computational costs. Additionally,\nenhanced spatial and adaptive frequency domain perception is proposed to\nprecisely delineate lesion boundaries, reduce background interference, and\nrecover fine details in small lesions. Comprehensive evaluations on public and\nprivate datasets demonstrate that TexLiverNet achieves superior performance\ncompared to current state-of-the-art methods.\n","authors":["Xiaoyan Jiang","Zhi Zhou","Hailing Wang","Guozhong Wang","Zhijun Fang"],"pdf_url":"https://arxiv.org/pdf/2411.04595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04594v1","updated":"2024-11-07T10:25:20Z","published":"2024-11-07T10:25:20Z","title":"Verification of Neural Networks against Convolutional Perturbations via\n  Parameterised Kernels","summary":"  We develop a method for the efficient verification of neural networks against\nconvolutional perturbations such as blurring or sharpening. To define input\nperturbations we use well-known camera shake, box blur and sharpen kernels. We\ndemonstrate that these kernels can be linearly parameterised in a way that\nallows for a variation of the perturbation strength while preserving desired\nkernel properties. To facilitate their use in neural network verification, we\ndevelop an efficient way of convolving a given input with these parameterised\nkernels. The result of this convolution can be used to encode the perturbation\nin a verification setting by prepending a linear layer to a given network. This\nleads to tight bounds and a high effectiveness in the resulting verification\nstep. We add further precision by employing input splitting as a branch and\nbound strategy. We demonstrate that we are able to verify robustness on a\nnumber of standard benchmarks where the baseline is unable to provide any\nsafety certificates. To the best of our knowledge, this is the first solution\nfor verifying robustness against specific convolutional perturbations such as\ncamera shake.\n","authors":["Benedikt Brückner","Alessio Lomuscio"],"pdf_url":"https://arxiv.org/pdf/2411.04594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04586v1","updated":"2024-11-07T10:15:25Z","published":"2024-11-07T10:15:25Z","title":"On the Inherent Robustness of One-Stage Object Detection against\n  Out-of-Distribution Data","summary":"  Robustness is a fundamental aspect for developing safe and trustworthy\nmodels, particularly when they are deployed in the open world. In this work we\nanalyze the inherent capability of one-stage object detectors to robustly\noperate in the presence of out-of-distribution (OoD) data. Specifically, we\npropose a novel detection algorithm for detecting unknown objects in image\ndata, which leverages the features extracted by the model from each sample.\nDifferently from other recent approaches in the literature, our proposal does\nnot require retraining the object detector, thereby allowing for the use of\npretrained models. Our proposed OoD detector exploits the application of\nsupervised dimensionality reduction techniques to mitigate the effects of the\ncurse of dimensionality on the features extracted by the model. Furthermore, it\nutilizes high-resolution feature maps to identify potential unknown objects in\nan unsupervised fashion. Our experiments analyze the Pareto trade-off between\nthe performance detecting known and unknown objects resulting from different\nalgorithmic configurations and inference confidence thresholds. We also compare\nthe performance of our proposed algorithm to that of logits-based post-hoc OoD\nmethods, as well as possible fusion strategies. Finally, we discuss on the\ncompetitiveness of all tested methods against state-of-the-art OoD approaches\nfor object detection models over the recently published Unknown Object\nDetection benchmark. The obtained results verify that the performance of\navant-garde post-hoc OoD detectors can be further improved when combined with\nour proposed algorithm.\n","authors":["Aitor Martinez-Seras","Javier Del Ser","Alain Andres","Pablo Garcia-Bringas"],"pdf_url":"https://arxiv.org/pdf/2411.04586v1.pdf","comment":"12 figures, 4 tables, under review"},{"id":"http://arxiv.org/abs/2411.04584v1","updated":"2024-11-07T10:11:37Z","published":"2024-11-07T10:11:37Z","title":"PASSION for Dermatology: Bridging the Diversity Gap with Pigmented Skin\n  Images from Sub-Saharan Africa","summary":"  Africa faces a huge shortage of dermatologists, with less than one per\nmillion people. This is in stark contrast to the high demand for dermatologic\ncare, with 80% of the paediatric population suffering from largely untreated\nskin conditions. The integration of AI into healthcare sparks significant hope\nfor treatment accessibility, especially through the development of AI-supported\nteledermatology. Current AI models are predominantly trained on white-skinned\npatients and do not generalize well enough to pigmented patients. The PASSION\nproject aims to address this issue by collecting images of skin diseases in\nSub-Saharan countries with the aim of open-sourcing this data. This dataset is\nthe first of its kind, consisting of 1,653 patients for a total of 4,901\nimages. The images are representative of telemedicine settings and encompass\nthe most common paediatric conditions: eczema, fungals, scabies, and impetigo.\nWe also provide a baseline machine learning model trained on the dataset and a\ndetailed performance analysis for the subpopulations represented in the\ndataset. The project website can be found at https://passionderm.github.io/.\n","authors":["Philippe Gottfrois","Fabian Gröger","Faly Herizo Andriambololoniaina","Ludovic Amruthalingam","Alvaro Gonzalez-Jimenez","Christophe Hsu","Agnes Kessy","Simone Lionetti","Daudi Mavura","Wingston Ng'ambi","Dingase Faith Ngongonda","Marc Pouly","Mendrika Fifaliana Rakotoarisaona","Fahafahantsoa Rapelanoro Rabenja","Ibrahima Traoré","Alexander A. Navarini"],"pdf_url":"https://arxiv.org/pdf/2411.04584v1.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2405.09032v4","updated":"2024-11-07T10:06:18Z","published":"2024-05-15T02:03:44Z","title":"ICAL: Implicit Character-Aided Learning for Enhanced Handwritten\n  Mathematical Expression Recognition","summary":"  Significant progress has been made in the field of handwritten mathematical\nexpression recognition, while existing encoder-decoder methods are usually\ndifficult to model global information in $LaTeX$. Therefore, this paper\nintroduces a novel approach, Implicit Character-Aided Learning (ICAL), to mine\nthe global expression information and enhance handwritten mathematical\nexpression recognition. Specifically, we propose the Implicit Character\nConstruction Module (ICCM) to predict implicit character sequences and use a\nFusion Module to merge the outputs of the ICCM and the decoder, thereby\nproducing corrected predictions. By modeling and utilizing implicit character\ninformation, ICAL achieves a more accurate and context-aware interpretation of\nhandwritten mathematical expressions. Experimental results demonstrate that\nICAL notably surpasses the state-of-the-art(SOTA) models, improving the\nexpression recognition rate (ExpRate) by 2.25\\%/1.81\\%/1.39\\% on the CROHME\n2014/2016/2019 datasets respectively, and achieves a remarkable 69.06\\% on the\nchallenging HME100k test set. We make our code available on the GitHub:\nhttps://github.com/qingzhenduyu/ICAL\n","authors":["Jianhua Zhu","Liangcai Gao","Wenqi Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.09032v4.pdf","comment":"ICDAR 2024 Oral Paper"},{"id":"http://arxiv.org/abs/2411.04571v1","updated":"2024-11-07T09:55:36Z","published":"2024-11-07T09:55:36Z","title":"DomainGallery: Few-shot Domain-driven Image Generation by\n  Attribute-centric Finetuning","summary":"  The recent progress in text-to-image models pretrained on large-scale\ndatasets has enabled us to generate various images as long as we provide a text\nprompt describing what we want. Nevertheless, the availability of these models\nis still limited when we expect to generate images that fall into a specific\ndomain either hard to describe or just unseen to the models. In this work, we\npropose DomainGallery, a few-shot domain-driven image generation method which\naims at finetuning pretrained Stable Diffusion on few-shot target datasets in\nan attribute-centric manner. Specifically, DomainGallery features prior\nattribute erasure, attribute disentanglement, regularization and enhancement.\nThese techniques are tailored to few-shot domain-driven generation in order to\nsolve key issues that previous works have failed to settle. Extensive\nexperiments are given to validate the superior performance of DomainGallery on\na variety of domain-driven generation scenarios. Codes are available at\nhttps://github.com/Ldhlwh/DomainGallery.\n","authors":["Yuxuan Duan","Yan Hong","Bo Zhang","Jun Lan","Huijia Zhu","Weiqiang Wang","Jianfu Zhang","Li Niu","Liqing Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.04571v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.16591v2","updated":"2024-11-07T09:33:40Z","published":"2024-05-26T14:50:40Z","title":"CapS-Adapter: Caption-based MultiModal Adapter in Zero-Shot\n  Classification","summary":"  Recent advances in vision-language foundational models, such as CLIP, have\ndemonstrated significant strides in zero-shot classification. However, the\nextensive parameterization of models like CLIP necessitates a\nresource-intensive fine-tuning process. In response, TIP-Adapter and SuS-X have\nintroduced training-free methods aimed at bolstering the efficacy of downstream\ntasks. While these approaches incorporate support sets to maintain data\ndistribution consistency between knowledge cache and test sets, they often fall\nshort in terms of generalization on the test set, particularly when faced with\ntest data exhibiting substantial distributional variations. In this work, we\npresent CapS-Adapter, an innovative method that employs a caption-based support\nset, effectively harnessing both image and caption features to exceed existing\nstate-of-the-art techniques in training-free scenarios. CapS-Adapter adeptly\nconstructs support sets that closely mirror target distributions, utilizing\ninstance-level distribution features extracted from multimodal large models. By\nleveraging CLIP's single and cross-modal strengths, CapS-Adapter enhances\npredictive accuracy through the use of multimodal support sets. Our method\nachieves outstanding zero-shot classification results across 19 benchmark\ndatasets, improving accuracy by 2.19\\% over the previous leading method. Our\ncontributions are substantiated through extensive validation on multiple\nbenchmark datasets, demonstrating superior performance and robust\ngeneralization capabilities. Our code is made publicly available at\nhttps://github.com/WLuLi/CapS-Adapter.\n","authors":["Qijie Wang","Guandu Liu","Bin Wang"],"pdf_url":"https://arxiv.org/pdf/2405.16591v2.pdf","comment":"ACM Multimedia 2024 Poster"},{"id":"http://arxiv.org/abs/2406.01494v2","updated":"2024-11-07T09:23:34Z","published":"2024-06-03T16:21:29Z","title":"Robust Classification by Coupling Data Mollification with Label\n  Smoothing","summary":"  Introducing training-time augmentations is a key technique to enhance\ngeneralization and prepare deep neural networks against test-time corruptions.\nInspired by the success of generative diffusion models, we propose a novel\napproach of coupling data mollification, in the form of image noising and\nblurring, with label smoothing to align predicted label confidences with image\ndegradation. The method is simple to implement, introduces negligible\noverheads, and can be combined with existing augmentations. We demonstrate\nimproved robustness and uncertainty quantification on the corrupted image\nbenchmarks of the CIFAR and TinyImageNet datasets.\n","authors":["Markus Heinonen","Ba-Hien Tran","Michael Kampffmeyer","Maurizio Filippone"],"pdf_url":"https://arxiv.org/pdf/2406.01494v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.04533v1","updated":"2024-11-07T08:43:42Z","published":"2024-11-07T08:43:42Z","title":"Neural Fingerprints for Adversarial Attack Detection","summary":"  Deep learning models for image classification have become standard tools in\nrecent years. A well known vulnerability of these models is their\nsusceptibility to adversarial examples. These are generated by slightly\naltering an image of a certain class in a way that is imperceptible to humans\nbut causes the model to classify it wrongly as another class. Many algorithms\nhave been proposed to address this problem, falling generally into one of two\ncategories: (i) building robust classifiers (ii) directly detecting attacked\nimages. Despite the good performance of these detectors, we argue that in a\nwhite-box setting, where the attacker knows the configuration and weights of\nthe network and the detector, they can overcome the detector by running many\nexamples on a local copy, and sending only those that were not detected to the\nactual model. This problem is common in security applications where even a very\ngood model is not sufficient to ensure safety. In this paper we propose to\novercome this inherent limitation of any static defence with randomization. To\ndo so, one must generate a very large family of detectors with consistent\nperformance, and select one or more of them randomly for each input. For the\nindividual detectors, we suggest the method of neural fingerprints. In the\ntraining phase, for each class we repeatedly sample a tiny random subset of\nneurons from certain layers of the network, and if their average is\nsufficiently different between clean and attacked images of the focal class\nthey are considered a fingerprint and added to the detector bank. During test\ntime, we sample fingerprints from the bank associated with the label predicted\nby the model, and detect attacks using a likelihood ratio test. We evaluate our\ndetectors on ImageNet with different attack methods and model architectures,\nand show near-perfect detection with low rates of false detection.\n","authors":["Haim Fisher","Moni Shahar","Yehezkel S. Resheff"],"pdf_url":"https://arxiv.org/pdf/2411.04533v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2405.14974v2","updated":"2024-11-07T08:41:03Z","published":"2024-05-23T18:21:59Z","title":"LOVA3: Learning to Visual Question Answering, Asking and Assessment","summary":"  Question answering, asking, and assessment are three innate human traits\ncrucial for understanding the world and acquiring knowledge. By enhancing these\ncapabilities, humans can more effectively utilize data, leading to better\ncomprehension and learning outcomes. Current Multimodal Large Language Models\n(MLLMs) primarily focus on question answering, often neglecting the full\npotential of questioning and assessment skills. Inspired by the human learning\nmechanism, we introduce LOVA3, an innovative framework named \"Learning tO\nVisual question Answering, Asking and Assessment,\" designed to equip MLLMs with\nthese additional capabilities. Our approach involves the creation of two\nsupplementary training tasks GenQA and EvalQA, aiming at fostering the skills\nof asking and assessing questions in the context of images. To develop the\nquestioning ability, we compile a comprehensive set of multimodal foundational\ntasks. For assessment, we introduce a new benchmark called EvalQABench,\ncomprising 64,000 training samples (split evenly between positive and negative\nsamples) and 5,000 validation and testing samples. We posit that enhancing\nMLLMs with the capabilities to answer, ask, and assess questions will enhance\ntheir multimodal comprehension, ultimately improving overall performance. To\nvalidate this hypothesis, we train MLLMs using the LOVA3 framework and evaluate\nthem on a range of multimodal datasets and benchmarks. Our results demonstrate\nconsistent performance gains, underscoring the critical role of these\nadditional tasks in fostering comprehensive intelligence in MLLMs. The code is\navailable at https://github.com/showlab/LOVA3.\n","authors":["Henry Hengyuan Zhao","Pan Zhou","Difei Gao","Zechen Bai","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2405.14974v2.pdf","comment":"Accepted by NeurIPS 2024. The code is available at\n  https://github.com/showlab/LOVA3"},{"id":"http://arxiv.org/abs/2409.18694v2","updated":"2024-11-07T08:27:16Z","published":"2024-09-27T12:28:47Z","title":"Learning from Pattern Completion: Self-supervised Controllable\n  Generation","summary":"  The human brain exhibits a strong ability to spontaneously associate\ndifferent visual attributes of the same or similar visual scene, such as\nassociating sketches and graffiti with real-world visual objects, usually\nwithout supervising information. In contrast, in the field of artificial\nintelligence, controllable generation methods like ControlNet heavily rely on\nannotated training datasets such as depth maps, semantic segmentation maps, and\nposes, which limits the method's scalability. Inspired by the neural mechanisms\nthat may contribute to the brain's associative power, specifically the cortical\nmodularization and hippocampal pattern completion, here we propose a\nself-supervised controllable generation (SCG) framework. Firstly, we introduce\nan equivariant constraint to promote inter-module independence and intra-module\ncorrelation in a modular autoencoder network, thereby achieving functional\nspecialization. Subsequently, based on these specialized modules, we employ a\nself-supervised pattern completion approach for controllable generation\ntraining. Experimental results demonstrate that the proposed modular\nautoencoder effectively achieves functional specialization, including the\nmodular processing of color, brightness, and edge detection, and exhibits\nbrain-like features including orientation selectivity, color antagonism, and\ncenter-surround receptive fields. Through self-supervised training, associative\ngeneration capabilities spontaneously emerge in SCG, demonstrating excellent\ngeneralization ability to various tasks such as associative generation on\npainting, sketches, and ancient graffiti. Compared to the previous\nrepresentative method ControlNet, our proposed approach not only demonstrates\nsuperior robustness in more challenging high-noise scenarios but also possesses\nmore promising scalability potential due to its self-supervised manner.Codes\nare released on Github and Gitee.\n","authors":["Zhiqiang Chen","Guofan Fan","Jinying Gao","Lei Ma","Bo Lei","Tiejun Huang","Shan Yu"],"pdf_url":"https://arxiv.org/pdf/2409.18694v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04519v1","updated":"2024-11-07T08:20:29Z","published":"2024-11-07T08:20:29Z","title":"l0-Regularized Sparse Coding-based Interpretable Network for Multi-Modal\n  Image Fusion","summary":"  Multi-modal image fusion (MMIF) enhances the information content of the fused\nimage by combining the unique as well as common features obtained from\ndifferent modality sensor images, improving visualization, object detection,\nand many more tasks. In this work, we introduce an interpretable network for\nthe MMIF task, named FNet, based on an l0-regularized multi-modal convolutional\nsparse coding (MCSC) model. Specifically, for solving the l0-regularized CSC\nproblem, we develop an algorithm unrolling-based l0-regularized sparse coding\n(LZSC) block. Given different modality source images, FNet first separates the\nunique and common features from them using the LZSC block and then these\nfeatures are combined to generate the final fused image. Additionally, we\npropose an l0-regularized MCSC model for the inverse fusion process. Based on\nthis model, we introduce an interpretable inverse fusion network named IFNet,\nwhich is utilized during FNet's training. Extensive experiments show that FNet\nachieves high-quality fusion results across five different MMIF tasks.\nFurthermore, we show that FNet enhances downstream object detection in\nvisible-thermal image pairs. We have also visualized the intermediate results\nof FNet, which demonstrates the good interpretability of our network.\n","authors":["Gargi Panda","Soumitra Kundu","Saumik Bhattacharya","Aurobinda Routray"],"pdf_url":"https://arxiv.org/pdf/2411.04519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04517v1","updated":"2024-11-07T08:19:39Z","published":"2024-11-07T08:19:39Z","title":"Continuous Sign Language Recognition System using Deep Learning with\n  MediaPipe Holistic","summary":"  Sign languages are the language of hearing-impaired people who use visuals\nlike the hand, facial, and body movements for communication. There are\ndifferent signs and gestures representing alphabets, words, and phrases.\nNowadays approximately 300 sign languages are being practiced worldwide such as\nAmerican Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language\n(ISL), and many more. Sign languages are dependent on the vocal language of a\nplace. Unlike vocal or spoken languages, there are no helping words in sign\nlanguage like is, am, are, was, were, will, be, etc. As only a limited\npopulation is well-versed in sign language, this lack of familiarity of sign\nlanguage hinders hearing-impaired people from communicating freely and easily\nwith everyone. This issue can be addressed by a sign language recognition (SLR)\nsystem which has the capability to translate the sign language into vocal\nlanguage. In this paper, a continuous SLR system is proposed using a deep\nlearning model employing Long Short-Term Memory (LSTM), trained and tested on\nan ISL primary dataset. This dataset is created using MediaPipe Holistic\npipeline for tracking face, hand, and body movements and collecting landmarks.\nThe system recognizes the signs and gestures in real-time with 88.23% accuracy.\n","authors":["Sharvani Srivastava","Sudhakar Singh"," Pooja","Shiv Prakash"],"pdf_url":"https://arxiv.org/pdf/2411.04517v1.pdf","comment":"14 pages, 4 figures, Wireless Pers Commun"},{"id":"http://arxiv.org/abs/2411.04509v1","updated":"2024-11-07T08:02:58Z","published":"2024-11-07T08:02:58Z","title":"FedDP: Privacy-preserving method based on federated learning for\n  histopathology image segmentation","summary":"  Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is\nconsidered the gold standard for pathologists and medical practitioners for\ntumor diagnosis, surgical planning, and post-operative assessment. With the\nrapid advancement of deep learning technologies, the development of numerous\nmodels based on convolutional neural networks and transformer-based models has\nbeen applied to the precise segmentation of WSIs. However, due to privacy\nregulations and the need to protect patient confidentiality, centralized\nstorage and processing of image data are impractical. Training a centralized\nmodel directly is challenging to implement in medical settings due to these\nprivacy concerns.This paper addresses the dispersed nature and privacy\nsensitivity of medical image data by employing a federated learning framework,\nallowing medical institutions to collaboratively learn while protecting patient\nprivacy. Additionally, to address the issue of original data reconstruction\nthrough gradient inversion during the federated learning training process,\ndifferential privacy introduces noise into the model updates, preventing\nattackers from inferring the contributions of individual samples, thereby\nprotecting the privacy of the training data.Experimental results show that the\nproposed method, FedDP, minimally impacts model accuracy while effectively\nsafeguarding the privacy of cancer pathology image data, with only a slight\ndecrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,\nrespectively. This approach facilitates cross-institutional collaboration and\nknowledge sharing while protecting sensitive data privacy, providing a viable\nsolution for further research and application in the medical field.\n","authors":["Liangrui Pan","Mao Huang","Lian Wang","Pinle Qin","Shaoliang Peng"],"pdf_url":"https://arxiv.org/pdf/2411.04509v1.pdf","comment":"Accepted in BIBM2024"},{"id":"http://arxiv.org/abs/2401.15613v7","updated":"2024-11-07T07:58:50Z","published":"2024-01-28T10:00:45Z","title":"An efficient dual-branch framework via implicit self-texture enhancement\n  for arbitrary-scale histopathology image super-resolution","summary":"  High-quality whole-slide scanning is expensive, complex, and time-consuming,\nthus limiting the acquisition and utilization of high-resolution histopathology\nimages in daily clinical work. Deep learning-based single-image\nsuper-resolution (SISR) techniques provide an effective way to solve this\nproblem. However, the existing SISR models applied in histopathology images can\nonly work in fixed integer scaling factors, decreasing their applicability.\nThough methods based on implicit neural representation (INR) have shown\npromising results in arbitrary-scale super-resolution (SR) of natural images,\napplying them directly to histopathology images is inadequate because they have\nunique fine-grained image textures different from natural images. Thus, we\npropose an Implicit Self-Texture Enhancement-based dual-branch framework (ISTE)\nfor arbitrary-scale SR of histopathology images to address this challenge. The\nproposed ISTE contains a feature aggregation branch and a texture learning\nbranch. We employ the feature aggregation branch to enhance the learning of the\nlocal details for SR images while utilizing the texture learning branch to\nenhance the learning of high-frequency texture details. Then, we design a\ntwo-stage texture enhancement strategy to fuse the features from the two\nbranches to obtain the SR images. Experiments on publicly available datasets,\nincluding TMA, HistoSR, and the TCGA lung cancer datasets, demonstrate that\nISTE outperforms existing fixed-scale and arbitrary-scale SR algorithms across\nvarious scaling factors. Additionally, extensive experiments have shown that\nthe histopathology images reconstructed by the proposed ISTE are applicable to\ndownstream pathology image analysis tasks.\n","authors":["Minghong Duan","Linhao Qu","Zhiwei Yang","Manning Wang","Chenxi Zhang","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2401.15613v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07269v2","updated":"2024-11-07T07:52:59Z","published":"2024-10-09T04:07:38Z","title":"Deep Learning for Surgical Instrument Recognition and Segmentation in\n  Robotic-Assisted Surgeries: A Systematic Review","summary":"  Applying deep learning (DL) for annotating surgical instruments in\nrobot-assisted minimally invasive surgeries (MIS) represents a significant\nadvancement in surgical technology. This systematic review examines 48 studies\nthat and advanced DL methods and architectures. These sophisticated DL models\nhave shown notable improvements in the precision and efficiency of detecting\nand segmenting surgical tools. The enhanced capabilities of these models\nsupport various clinical applications, including real-time intraoperative\nguidance, comprehensive postoperative evaluations, and objective assessments of\nsurgical skills. By accurately identifying and segmenting surgical instruments\nin video data, DL models provide detailed feedback to surgeons, thereby\nimproving surgical outcomes and reducing complication risks. Furthermore, the\napplication of DL in surgical education is transformative. The review\nunderscores the significant impact of DL on improving the accuracy of skill\nassessments and the overall quality of surgical training programs. However,\nimplementing DL in surgical tool detection and segmentation faces challenges,\nsuch as the need for large, accurately annotated datasets to train these models\neffectively. The manual annotation process is labor-intensive and\ntime-consuming, posing a significant bottleneck. Future research should focus\non automating the detection and segmentation process and enhancing the\nrobustness of DL models against environmental variations. Expanding the\napplication of DL models across various surgical specialties will be essential\nto fully realize this technology's potential. Integrating DL with other\nemerging technologies, such as augmented reality (AR), also offers promising\nopportunities to further enhance the precision and efficacy of surgical\nprocedures.\n","authors":["Fatimaelzahraa Ali Ahmed","Mahmoud Yousef","Mariam Ali Ahmed","Hasan Omar Ali","Anns Mahboob","Hazrat Ali","Zubair Shah","Omar Aboumarzouk","Abdulla Al Ansari","Shidin Balakrishnan"],"pdf_url":"https://arxiv.org/pdf/2410.07269v2.pdf","comment":"57 pages, 9 figures, Published in Artificial Intelligence Reviews\n  journal <https://link.springer.com/journal/10462>"},{"id":"http://arxiv.org/abs/2411.04501v1","updated":"2024-11-07T07:50:58Z","published":"2024-11-07T07:50:58Z","title":"Pose2Trajectory: Using Transformers on Body Pose to Predict Tennis\n  Player's Trajectory","summary":"  Tracking the trajectory of tennis players can help camera operators in\nproduction. Predicting future movement enables cameras to automatically track\nand predict a player's future trajectory without human intervention. Predicting\nfuture human movement in the context of complex physical tasks is also\nintellectually satisfying. Swift advancements in sports analytics and the wide\navailability of videos for tennis have inspired us to propose a novel method\ncalled Pose2Trajectory, which predicts a tennis player's future trajectory as a\nsequence derived from their body joints' data and ball position. Demonstrating\nimpressive accuracy, our approach capitalizes on body joint information to\nprovide a comprehensive understanding of the human body's geometry and motion,\nthereby enhancing the prediction of the player's trajectory. We use\nencoder-decoder Transformer architecture trained on the joints and trajectory\ninformation of the players with ball positions. The predicted sequence can\nprovide information to help close-up cameras to keep tracking the tennis\nplayer, following centroid coordinates. We generate a high-quality dataset from\nmultiple videos to assist tennis player movement prediction using object\ndetection and human pose estimation methods. It contains bounding boxes and\njoint information for tennis players and ball positions in singles tennis\ngames. Our method shows promising results in predicting the tennis player's\nmovement trajectory with different sequence prediction lengths using the joints\nand trajectory information with the ball position.\n","authors":["Ali K. AlShami","Terrance Boult","Jugal Kalita"],"pdf_url":"https://arxiv.org/pdf/2411.04501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05797v2","updated":"2024-11-07T07:47:17Z","published":"2024-02-08T16:37:04Z","title":"TaE: Task-aware Expandable Representation for Long Tail Class\n  Incremental Learning","summary":"  Class-incremental learning is dedicated to the development of deep learning\nmodels that are capable of acquiring new knowledge while retaining previously\nlearned information. Most methods focus on balanced data distribution for each\ntask, overlooking real-world long-tailed distributions. Therefore, Long-Tailed\nClass-Incremental Learning has been introduced, which trains on data where head\nclasses have more samples than tail classes. Existing methods mainly focus on\npreserving representative samples from previous classes to combat catastrophic\nforgetting. Recently, dynamic network algorithms freeze old network structures\nand expand new ones, achieving significant performance. However, with the\nintroduction of the long-tail problem, merely extending Determined blocks can\nlead to miscalibrated predictions, while expanding the entire backbone results\nin an explosion of memory size. To address these issues, we introduce a novel\nTask-aware Expandable (TaE) framework, dynamically allocating and updating\ntask-specific trainable parameters to learn diverse representations from each\nincremental task while resisting forgetting through the majority of frozen\nmodel parameters. To further encourage the class-specific feature\nrepresentation, we develop a Centroid-Enhanced (CEd) method to guide the update\nof these task-aware parameters. This approach is designed to adaptively\nallocate feature space for every class by adjusting the distance between intra-\nand inter-class features, which can extend to all \"training from sketch\"\nalgorithms. Extensive experiments demonstrate that TaE achieves\nstate-of-the-art performance.\n","authors":["Linjie Li","Zhenyu Wu","Jiaming Liu","Yang Ji"],"pdf_url":"https://arxiv.org/pdf/2402.05797v2.pdf","comment":"Accepted to ACCV2024"},{"id":"http://arxiv.org/abs/2411.04493v1","updated":"2024-11-07T07:41:04Z","published":"2024-11-07T07:41:04Z","title":"Synergy-Guided Regional Supervision of Pseudo Labels for Semi-Supervised\n  Medical Image Segmentation","summary":"  Semi-supervised learning has received considerable attention for its\npotential to leverage abundant unlabeled data to enhance model robustness.\nPseudo labeling is a widely used strategy in semi supervised learning. However,\nexisting methods often suffer from noise contamination, which can undermine\nmodel performance. To tackle this challenge, we introduce a novel\nSynergy-Guided Regional Supervision of Pseudo Labels (SGRS-Net) framework.\nBuilt upon the mean teacher network, we employ a Mix Augmentation module to\nenhance the unlabeled data. By evaluating the synergy before and after\naugmentation, we strategically partition the pseudo labels into distinct\nregions. Additionally, we introduce a Region Loss Evaluation module to assess\nthe loss across each delineated area. Extensive experiments conducted on the LA\ndataset have demonstrated superior performance over state-of-the-art\ntechniques, underscoring the efficiency and practicality of our framework.\n","authors":["Tao Wang","Xinlin Zhang","Yuanbin Chen","Yuanbo Zhou","Longxuan Zhao","Tao Tan","Tong Tong"],"pdf_url":"https://arxiv.org/pdf/2411.04493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03807v2","updated":"2024-11-07T07:32:33Z","published":"2024-11-06T10:07:46Z","title":"GS2Pose: Two-stage 6D Object Pose Estimation Guided by Gaussian\n  Splatting","summary":"  This paper proposes a new method for accurate and robust 6D pose estimation\nof novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose\ncan utilize the reconstruction results without requiring a high-quality CAD\nmodel, which means it only requires segmented RGBD images as input.\nSpecifically, GS2Pose employs a two-stage structure consisting of coarse\nestimation followed by refined estimation. In the coarse stage, a lightweight\nU-Net network with a polarization attention mechanism, called Pose-Net, is\ndesigned. By using the 3DGS model for supervised training, Pose-Net can\ngenerate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose\nformulates a pose regression algorithm following the idea of reprojection or\nBundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to\nextend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that\nrefines the coarse pose by comparing the input images with the rendered images.\nGS-Refiner also selectively updates parameters in the 3DGS model to achieve\nenvironmental adaptation, thereby enhancing the algorithm's robustness and\nflexibility to illuminative variation, occlusion, and other challenging\ndisruptive factors. GS2Pose was evaluated through experiments conducted on the\nLineMod dataset, where it was compared with similar algorithms, yielding highly\ncompetitive results. The code for GS2Pose will soon be released on GitHub.\n","authors":["Jilan Mei","Junbo Li","Cai Meng"],"pdf_url":"https://arxiv.org/pdf/2411.03807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04480v1","updated":"2024-11-07T07:19:28Z","published":"2024-11-07T07:19:28Z","title":"CFPNet: Improving Lightweight ToF Depth Completion via Cross-zone\n  Feature Propagation","summary":"  Depth completion using lightweight time-of-flight (ToF) depth sensors is\nattractive due to their low cost. However, lightweight ToF sensors usually have\na limited field of view (FOV) compared with cameras. Thus, only pixels in the\nzone area of the image can be associated with depth signals. Previous methods\nfail to propagate depth features from the zone area to the outside-zone area\neffectively, thus suffering from degraded depth completion performance outside\nthe zone. To this end, this paper proposes the CFPNet to achieve cross-zone\nfeature propagation from the zone area to the outside-zone area with two novel\nmodules. The first is a direct-attention-based propagation module (DAPM), which\nenforces direct cross-zone feature acquisition. The second is a\nlarge-kernel-based propagation module (LKPM), which realizes cross-zone feature\npropagation by utilizing convolution layers with kernel sizes up to 31. CFPNet\nachieves state-of-the-art (SOTA) depth completion performance by combining\nthese two modules properly, as verified by extensive experimental results on\nthe ZJU-L5 dataset. The code will be made public.\n","authors":["Laiyan Ding","Hualie Jiang","Rui Xu","Rui Huang"],"pdf_url":"https://arxiv.org/pdf/2411.04480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04475v1","updated":"2024-11-07T07:03:40Z","published":"2024-11-07T07:03:40Z","title":"Deep Learning Models for UAV-Assisted Bridge Inspection: A YOLO\n  Benchmark Analysis","summary":"  Visual inspections of bridges are critical to ensure their safety and\nidentify potential failures early. This inspection process can be rapidly and\naccurately automated by using unmanned aerial vehicles (UAVs) integrated with\ndeep learning models. However, choosing an appropriate model that is\nlightweight enough to integrate into the UAV and fulfills the strict\nrequirements for inference time and accuracy is challenging. Therefore, our\nwork contributes to the advancement of this model selection process by\nconducting a benchmark of 23 models belonging to the four newest YOLO variants\n(YOLOv5, YOLOv6, YOLOv7, YOLOv8) on COCO-Bridge-2021+, a dataset for bridge\ndetails detection. Through comprehensive benchmarking, we identify YOLOv8n,\nYOLOv7tiny, YOLOv6m, and YOLOv6m6 as the models offering an optimal balance\nbetween accuracy and processing speed, with mAP@50 scores of 0.803, 0.837,\n0.853, and 0.872, and inference times of 5.3ms, 7.5ms, 14.06ms, and 39.33ms,\nrespectively. Our findings accelerate the model selection process for UAVs,\nenabling more efficient and reliable bridge inspections.\n","authors":["Trong-Nhan Phan","Hoang-Hai Nguyen","Thi-Thu-Hien Ha","Huy-Tan Thai","Kim-Hung Le"],"pdf_url":"https://arxiv.org/pdf/2411.04475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04918v4","updated":"2024-11-07T06:58:04Z","published":"2024-09-07T21:52:58Z","title":"Training-free Zero-shot Composed Image Retrieval via Weighted Modality\n  Fusion and Similarity","summary":"  Composed image retrieval (CIR), which formulates the query as a combination\nof a reference image and modified text, has emerged as a new form of image\nsearch due to its enhanced ability to capture user intent. However, training a\nCIR model in a supervised manner typically requires labor-intensive collection\nof (reference image, text modifier, target image) triplets. While existing\nzero-shot CIR (ZS-CIR) methods eliminate the need for training on specific\ndownstream datasets, they still require additional pretraining on large-scale\nimage datasets. In this paper, we introduce a training-free approach for\nZS-CIR. Our approach, Weighted Modality fusion and similarity for CIR\n(WeiMoCIR), operates under the assumption that image and text modalities can be\neffectively combined using a simple weighted average. This allows the query\nrepresentation to be constructed directly from the reference image and text\nmodifier. To further enhance retrieval performance, we employ multimodal large\nlanguage models (MLLMs) to generate image captions for the database images and\nincorporate these textual captions into the similarity computation by combining\nthem with image information using a weighted average. Our approach is simple,\neasy to implement, and its effectiveness is validated through experiments on\nthe FashionIQ and CIRR datasets. Code is available at\nhttps://github.com/whats2000/WeiMoCIR.\n","authors":["Ren-Di Wu","Yu-Yen Lin","Huei-Fang Yang"],"pdf_url":"https://arxiv.org/pdf/2409.04918v4.pdf","comment":"14 pages, 6 figures, International Conference on Technologies and\n  Applications of Artificial Intelligence (TAAI) Camera Ready"},{"id":"http://arxiv.org/abs/2411.04469v1","updated":"2024-11-07T06:39:50Z","published":"2024-11-07T06:39:50Z","title":"FreeCap: Hybrid Calibration-Free Motion Capture in Open Environments","summary":"  We propose a novel hybrid calibration-free method FreeCap to accurately\ncapture global multi-person motions in open environments. Our system combines a\nsingle LiDAR with expandable moving cameras, allowing for flexible and precise\nmotion estimation in a unified world coordinate. In particular, We introduce a\nlocal-to-global pose-aware cross-sensor human-matching module that predicts the\nalignment among each sensor, even in the absence of calibration. Additionally,\nour coarse-to-fine sensor-expandable pose optimizer further optimizes the 3D\nhuman key points and the alignments, it is also capable of incorporating\nadditional cameras to enhance accuracy. Extensive experiments on Human-M3 and\nFreeMotion datasets demonstrate that our method significantly outperforms\nstate-of-the-art single-modal methods, offering an expandable and efficient\nsolution for multi-person motion capture across various applications.\n","authors":["Aoru Xue","Yiming Ren","Zining Song","Mao Ye","Xinge Zhu","Yuexin Ma"],"pdf_url":"https://arxiv.org/pdf/2411.04469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01723v7","updated":"2024-11-07T06:25:25Z","published":"2023-11-03T05:41:25Z","title":"Towards Calibrated Robust Fine-Tuning of Vision-Language Models","summary":"  Improving out-of-distribution (OOD) generalization during in-distribution\n(ID) adaptation is a primary goal of robust fine-tuning of zero-shot models\nbeyond naive fine-tuning. However, despite decent OOD generalization\nperformance from recent robust fine-tuning methods, confidence calibration for\nreliable model output has not been fully addressed. This work proposes a robust\nfine-tuning method that improves both OOD accuracy and confidence calibration\nsimultaneously in vision language models. Firstly, we show that both OOD\nclassification and OOD calibration errors have a shared upper bound consisting\nof two terms of ID data: 1) ID calibration error and 2) the smallest singular\nvalue of the ID input covariance matrix. Based on this insight, we design a\nnovel framework that conducts fine-tuning with a constrained multimodal\ncontrastive loss enforcing a larger smallest singular value, which is further\nguided by the self-distillation of a moving-averaged model to achieve\ncalibrated prediction as well. Starting from empirical evidence supporting our\ntheoretical statements, we provide extensive experimental results on ImageNet\ndistribution shift benchmarks that demonstrate the effectiveness of our theorem\nand its practical implementation.\n","authors":["Changdae Oh","Hyesu Lim","Mijoo Kim","Dongyoon Han","Sangdoo Yun","Jaegul Choo","Alexander Hauptmann","Zhi-Qi Cheng","Kyungwoo Song"],"pdf_url":"https://arxiv.org/pdf/2311.01723v7.pdf","comment":"NeurIPS 2024 (a short version was presented at the NeurIPS 2023\n  Workshop on Distribution Shifts); Major modification of (v7): Fixing the\n  x-axis of Figure 3 and Pearson correlation, accordingly"},{"id":"http://arxiv.org/abs/2411.04457v1","updated":"2024-11-07T06:04:57Z","published":"2024-11-07T06:04:57Z","title":"Efficient single image non-uniformity correction algorithm","summary":"  This paper introduces a new way to correct the non-uniformity (NU) in\nuncooled infrared-type images. The main defect of these uncooled images is the\nlack of a column (resp. line) time-dependent cross-calibration, resulting in a\nstrong column (resp. line) and time dependent noise. This problem can be\nconsidered as a 1D flicker of the columns inside each frame. Thus, classic\nmovie deflickering algorithms can be adapted, to equalize the columns (resp.\nthe lines). The proposed method therefore applies to the series formed by the\ncolumns of an infrared image a movie deflickering algorithm. The obtained\nsingle image method works on static images, and therefore requires no\nregistration, no camera motion compensation, and no closed aperture sensor\nequalization. Thus, the method has only one camera dependent parameter, and is\nlandscape independent. This simple method will be compared to a state of the\nart total variation single image correction on raw real and simulated images.\nThe method is real time, requiring only two operations per pixel. It involves\nno test-pattern calibration and produces no \"ghost artifacts\".\n","authors":["Yohann Tendero","Jerome Gilles","Stephane Landeau","Jean-Michel Morel"],"pdf_url":"https://arxiv.org/pdf/2411.04457v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2411.03615"},{"id":"http://arxiv.org/abs/2411.04456v1","updated":"2024-11-07T06:04:43Z","published":"2024-11-07T06:04:43Z","title":"Properties of BV-G structures + textures decomposition models.\n  Application to road detection in satellite images","summary":"  In this paper we present some theoretical results about a structures-textures\nimage decomposition model which was proposed by the second author. We prove a\ntheorem which gives the behavior of this model in different cases. Finally, as\na consequence of the theorem we derive an algorithm for the detection of long\nand thin objects applied to a road networks detection application in aerial or\nsatellite images.\n","authors":["Jerome Gilles","Yves Meyer"],"pdf_url":"https://arxiv.org/pdf/2411.04456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18057v2","updated":"2024-11-07T04:49:24Z","published":"2024-09-26T17:00:02Z","title":"LightAvatar: Efficient Head Avatar as Dynamic Neural Light Field","summary":"  Recent works have shown that neural radiance fields (NeRFs) on top of\nparametric models have reached SOTA quality to build photorealistic head\navatars from a monocular video. However, one major limitation of the NeRF-based\navatars is the slow rendering speed due to the dense point sampling of NeRF,\npreventing them from broader utility on resource-constrained devices. We\nintroduce LightAvatar, the first head avatar model based on neural light fields\n(NeLFs). LightAvatar renders an image from 3DMM parameters and a camera pose\nvia a single network forward pass, without using mesh or volume rendering. The\nproposed approach, while being conceptually appealing, poses a significant\nchallenge towards real-time efficiency and training stability. To resolve them,\nwe introduce dedicated network designs to obtain proper representations for the\nNeLF model and maintain a low FLOPs budget. Meanwhile, we tap into a\ndistillation-based training strategy that uses a pretrained avatar model as\nteacher to synthesize abundant pseudo data for training. A warping field\nnetwork is introduced to correct the fitting error in the real data so that the\nmodel can learn better. Extensive experiments suggest that our method can\nachieve new SOTA image quality quantitatively or qualitatively, while being\nsignificantly faster than the counterparts, reporting 174.1 FPS (512x512\nresolution) on a consumer-grade GPU (RTX3090) with no customized optimization.\n","authors":["Huan Wang","Feitong Tan","Ziqian Bai","Yinda Zhang","Shichen Liu","Qiangeng Xu","Menglei Chai","Anish Prabhu","Rohit Pandey","Sean Fanello","Zeng Huang","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2409.18057v2.pdf","comment":"ECCV'24 CADL Workshop. Code:\n  https://github.com/MingSun-Tse/LightAvatar-TensorFlow. V2: Corrected speed\n  benchmark with GaussianAvatar"},{"id":"http://arxiv.org/abs/2312.02548v3","updated":"2024-11-07T04:44:38Z","published":"2023-12-05T07:34:30Z","title":"GeNIe: Generative Hard Negative Images Through Diffusion","summary":"  Data augmentation is crucial in training deep models, preventing them from\noverfitting to limited data. Recent advances in generative AI, e.g., diffusion\nmodels, have enabled more sophisticated augmentation techniques that produce\ndata resembling natural images. We introduce GeNIe a novel augmentation method\nwhich leverages a latent diffusion model conditioned on a text prompt to\ncombine two contrasting data points (an image from the source category and a\ntext prompt from the target category) to generate challenging augmentations. To\nachieve this, we adjust the noise level (equivalently, number of diffusion\niterations) to ensure the generated image retains low-level and background\nfeatures from the source image while representing the target category,\nresulting in a hard negative sample for the source category. We further\nautomate and enhance GeNIe by adaptively adjusting the noise level selection on\na per image basis (coined as GeNIe-Ada), leading to further performance\nimprovements. Our extensive experiments, in both few-shot and long-tail\ndistribution settings, demonstrate the effectiveness of our novel augmentation\nmethod and its superior performance over the prior art. Our code is available\nat: https://github.com/UCDvision/GeNIe\n","authors":["Soroush Abbasi Koohpayegani","Anuj Singh","K L Navaneet","Hamed Pirsiavash","Hadi Jamali-Rad"],"pdf_url":"https://arxiv.org/pdf/2312.02548v3.pdf","comment":"Our code is available https://github.com/UCDvision/GeNIe"},{"id":"http://arxiv.org/abs/2411.00172v2","updated":"2024-11-07T04:41:32Z","published":"2024-10-31T19:37:47Z","title":"SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor\n  Geological Survey","summary":"  A major obstacle to the advancements of machine learning models in marine\nscience, particularly in sonar imagery analysis, is the scarcity of AI-ready\ndatasets. While there have been efforts to make AI-ready sonar image dataset\npublicly available, they suffer from limitations in terms of environment\nsetting and scale. To bridge this gap, we introduce SeafloorAI, the first\nextensive AI-ready datasets for seafloor mapping across 5 geological layers\nthat is curated in collaboration with marine scientists. We further extend the\ndataset to SeafloorGenAI by incorporating the language component in order to\nfacilitate the development of both vision- and language-capable machine\nlearning models for sonar imagery. The dataset consists of 62 geo-distributed\ndata surveys spanning 17,300 square kilometers, with 696K sonar images, 827K\nannotated segmentation masks, 696K detailed language descriptions and\napproximately 7M question-answer pairs. By making our data processing source\ncode publicly available, we aim to engage the marine science community to\nenrich the data pool and inspire the machine learning community to develop more\nrobust models. This collaborative approach will enhance the capabilities and\napplications of our datasets within both fields.\n","authors":["Kien X. Nguyen","Fengchun Qiao","Arthur Trembanis","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2411.00172v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04420v1","updated":"2024-11-07T04:16:15Z","published":"2024-11-07T04:16:15Z","title":"BendVLM: Test-Time Debiasing of Vision-Language Embeddings","summary":"  Vision-language model (VLM) embeddings have been shown to encode biases\npresent in their training data, such as societal biases that prescribe negative\ncharacteristics to members of various racial and gender identities. VLMs are\nbeing quickly adopted for a variety of tasks ranging from few-shot\nclassification to text-guided image generation, making debiasing VLM embeddings\ncrucial. Debiasing approaches that fine-tune the VLM often suffer from\ncatastrophic forgetting. On the other hand, fine-tuning-free methods typically\nutilize a \"one-size-fits-all\" approach that assumes that correlation with the\nspurious attribute can be explained using a single linear direction across all\npossible inputs. In this work, we propose Bend-VLM, a nonlinear,\nfine-tuning-free approach for VLM embedding debiasing that tailors the\ndebiasing operation to each unique input. This allows for a more flexible\ndebiasing approach. Additionally, we do not require knowledge of the set of\ninputs a priori to inference time, making our method more appropriate for\nonline, open-set tasks such as retrieval and text guided image generation.\n","authors":["Walter Gerych","Haoran Zhang","Kimia Hamidieh","Eileen Pan","Maanas Sharma","Thomas Hartvigsen","Marzyeh Ghassemi"],"pdf_url":"https://arxiv.org/pdf/2411.04420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01981v2","updated":"2024-11-07T04:10:10Z","published":"2024-11-04T11:09:47Z","title":"Typicalness-Aware Learning for Failure Detection","summary":"  Deep neural networks (DNNs) often suffer from the overconfidence issue, where\nincorrect predictions are made with high confidence scores, hindering the\napplications in critical systems. In this paper, we propose a novel approach\ncalled Typicalness-Aware Learning (TAL) to address this issue and improve\nfailure detection performance. We observe that, with the cross-entropy loss,\nmodel predictions are optimized to align with the corresponding labels via\nincreasing logit magnitude or refining logit direction. However, regarding\natypical samples, the image content and their labels may exhibit disparities.\nThis discrepancy can lead to overfitting on atypical samples, ultimately\nresulting in the overconfidence issue that we aim to address. To tackle the\nproblem, we have devised a metric that quantifies the typicalness of each\nsample, enabling the dynamic adjustment of the logit magnitude during the\ntraining process. By allowing atypical samples to be adequately fitted while\npreserving reliable logit direction, the problem of overconfidence can be\nmitigated. TAL has been extensively evaluated on benchmark datasets, and the\nresults demonstrate its superiority over existing failure detection methods.\nSpecifically, TAL achieves a more than 5% improvement on CIFAR100 in terms of\nthe Area Under the Risk-Coverage Curve (AURC) compared to the state-of-the-art.\nCode is available at https://github.com/liuyijungoon/TAL.\n","authors":["Yijun Liu","Jiequan Cui","Zhuotao Tian","Senqiao Yang","Qingdong He","Xiaoling Wang","Jingyong Su"],"pdf_url":"https://arxiv.org/pdf/2411.01981v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03348v2","updated":"2024-11-07T04:05:58Z","published":"2024-11-03T18:44:28Z","title":"Undermining Image and Text Classification Algorithms Using Adversarial\n  Attacks","summary":"  Machine learning models are prone to adversarial attacks, where inputs can be\nmanipulated in order to cause misclassifications. While previous research has\nfocused on techniques like Generative Adversarial Networks (GANs), there's\nlimited exploration of GANs and Synthetic Minority Oversampling Technique\n(SMOTE) in text and image classification models to perform adversarial attacks.\nOur study addresses this gap by training various machine learning models and\nusing GANs and SMOTE to generate additional data points aimed at attacking text\nclassification models. Furthermore, we extend our investigation to face\nrecognition models, training a Convolutional Neural Network(CNN) and subjecting\nit to adversarial attacks with fast gradient sign perturbations on key features\nidentified by GradCAM, a technique used to highlight key image characteristics\nCNNs use in classification. Our experiments reveal a significant vulnerability\nin classification models. Specifically, we observe a 20 % decrease in accuracy\nfor the top-performing text classification models post-attack, along with a 30\n% decrease in facial recognition accuracy. This highlights the susceptibility\nof these models to manipulation of input data. Adversarial attacks not only\ncompromise the security but also undermine the reliability of machine learning\nsystems. By showcasing the impact of adversarial attacks on both text\nclassification and face recognition models, our study underscores the urgent\nneed for develop robust defenses against such vulnerabilities.\n","authors":["Langalibalele Lunga","Suhas Sreehari"],"pdf_url":"https://arxiv.org/pdf/2411.03348v2.pdf","comment":"Accepted for presentation at Electronic Imaging Conference 2025"},{"id":"http://arxiv.org/abs/2411.04406v1","updated":"2024-11-07T03:55:23Z","published":"2024-11-07T03:55:23Z","title":"Image Understanding Makes for A Good Tokenizer for Image Generation","summary":"  Abstract Modern image generation (IG) models have been shown to capture rich\nsemantics valuable for image understanding (IU) tasks. However, the potential\nof IU models to improve IG performance remains uncharted. We address this issue\nusing a token-based IG framework, which relies on effective tokenizers to\nproject images into token sequences. Currently, pixel reconstruction (e.g.,\nVQGAN) dominates the training objective for image tokenizers. In contrast, our\napproach adopts the feature reconstruction objective, where tokenizers are\ntrained by distilling knowledge from pretrained IU encoders. Comprehensive\ncomparisons indicate that tokenizers with strong IU capabilities achieve\nsuperior IG performance across a variety of metrics, datasets, tasks, and\nproposal networks. Notably, VQ-KD CLIP achieves $4.10$ FID on ImageNet-1k\n(IN-1k). Visualization suggests that the superiority of VQ-KD can be partly\nattributed to the rich semantics within the VQ-KD codebook. We further\nintroduce a straightforward pipeline to directly transform IU encoders into\ntokenizers, demonstrating exceptional effectiveness for IG tasks. These\ndiscoveries may energize further exploration into image tokenizer research and\ninspire the community to reassess the relationship between IU and IG. The code\nis released at https://github.com/magic-research/vector_quantization.\n","authors":["Luting Wang","Yang Zhao","Zijian Zhang","Jiashi Feng","Si Liu","Bingyi Kang"],"pdf_url":"https://arxiv.org/pdf/2411.04406v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2310.03739v5","updated":"2024-11-07T03:54:22Z","published":"2023-10-05T17:59:18Z","title":"Aligning Text-to-Image Diffusion Models with Reward Backpropagation","summary":"  Text-to-image diffusion models have recently emerged at the forefront of\nimage generation, powered by very large-scale unsupervised or weakly supervised\ntext-to-image training datasets. Due to their unsupervised training,\ncontrolling their behavior in downstream tasks, such as maximizing\nhuman-perceived image quality, image-text alignment, or ethical image\ngeneration, is difficult. Recent works finetune diffusion models to downstream\nreward functions using vanilla reinforcement learning, notorious for the high\nvariance of the gradient estimators. In this paper, we propose AlignProp, a\nmethod that aligns diffusion models to downstream reward functions using\nend-to-end backpropagation of the reward gradient through the denoising\nprocess. While naive implementation of such backpropagation would require\nprohibitive memory resources for storing the partial derivatives of modern\ntext-to-image models, AlignProp finetunes low-rank adapter weight modules and\nuses gradient checkpointing, to render its memory usage viable. We test\nAlignProp in finetuning diffusion models to various objectives, such as\nimage-text semantic alignment, aesthetics, compressibility and controllability\nof the number of objects present, as well as their combinations. We show\nAlignProp achieves higher rewards in fewer training steps than alternatives,\nwhile being conceptually simpler, making it a straightforward choice for\noptimizing diffusion models for differentiable reward functions of interest.\nCode and Visualization results are available at https://align-prop.github.io/.\n","authors":["Mihir Prabhudesai","Anirudh Goyal","Deepak Pathak","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2310.03739v5.pdf","comment":"This paper is subsumed by a later paper of ours: arXiv:2407.08737"},{"id":"http://arxiv.org/abs/2411.04404v1","updated":"2024-11-07T03:48:35Z","published":"2024-11-07T03:48:35Z","title":"Enhancing Bronchoscopy Depth Estimation through Synthetic-to-Real Domain\n  Adaptation","summary":"  Monocular depth estimation has shown promise in general imaging tasks, aiding\nin localization and 3D reconstruction. While effective in various domains, its\napplication to bronchoscopic images is hindered by the lack of labeled data,\nchallenging the use of supervised learning methods. In this work, we propose a\ntransfer learning framework that leverages synthetic data with depth labels for\ntraining and adapts domain knowledge for accurate depth estimation in real\nbronchoscope data. Our network demonstrates improved depth prediction on real\nfootage using domain adaptation compared to training solely on synthetic data,\nvalidating our approach.\n","authors":["Qingyao Tian","Huai Liao","Xinyan Huang","Lujie Li","Hongbin Liu"],"pdf_url":"https://arxiv.org/pdf/2411.04404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04399v1","updated":"2024-11-07T03:28:24Z","published":"2024-11-07T03:28:24Z","title":"ProGraph: Temporally-alignable Probability Guided Graph Topological\n  Modeling for 3D Human Reconstruction","summary":"  Current 3D human motion reconstruction methods from monocular videos rely on\nfeatures within the current reconstruction window, leading to distortion and\ndeformations in the human structure under local occlusions or blurriness in\nvideo frames. To estimate realistic 3D human mesh sequences based on incomplete\nfeatures, we propose Temporally-alignable Probability Guided Graph Topological\nModeling for 3D Human Reconstruction (ProGraph). For missing parts recovery, we\nexploit the explicit topological-aware probability distribution across the\nentire motion sequence. To restore the complete human, Graph Topological\nModeling (GTM) learns the underlying topological structure, focusing on the\nrelationships inherent in the individual parts. Next, to generate blurred\nmotion parts, Temporal-alignable Probability Distribution (TPDist) utilizes the\nGTM to predict features based on distribution. This interactive mechanism\nfacilitates motion consistency, allowing the restoration of human parts.\nFurthermore, Hierarchical Human Loss (HHLoss) constrains the probability\ndistribution errors of inter-frame features during topological structure\nvariation. Our Method achieves superior results than other SOTA methods in\naddressing occlusions and blurriness on 3DPW.\n","authors":["Hongsheng Wang","Zehui Feng","Tong Xiao","Genfan Yang","Shengyu Zhang","Fei Wu","Feng Lin"],"pdf_url":"https://arxiv.org/pdf/2411.04399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00132v2","updated":"2024-11-07T03:22:56Z","published":"2024-10-31T18:33:39Z","title":"Beyond Accuracy: Ensuring Correct Predictions With Correct Rationales","summary":"  Large pretrained foundation models demonstrate exceptional performance and,\nin some high-stakes applications, even surpass human experts. However, most of\nthese models are currently evaluated primarily on prediction accuracy,\noverlooking the validity of the rationales behind their accurate predictions.\nFor the safe deployment of foundation models, there is a pressing need to\nensure double-correct predictions, i.e., correct prediction backed by correct\nrationales. To achieve this, we propose a two-phase scheme: First, we curate a\nnew dataset that offers structured rationales for visual recognition tasks.\nSecond, we propose a rationale-informed optimization method to guide the model\nin disentangling and localizing visual evidence for each rationale, without\nrequiring manual annotations. Extensive experiments and ablation studies\ndemonstrate that our model outperforms state-of-the-art models by up to 10.1%\nin prediction accuracy across a wide range of tasks. Furthermore, our method\nsignificantly improves the model's rationale correctness, improving\nlocalization by 7.5% and disentanglement by 36.5%. Our dataset, source code,\nand pretrained weights: https://github.com/deep-real/DCP\n","authors":["Tang Li","Mengmeng Ma","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2411.00132v2.pdf","comment":"In Proceedings of the 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2410.23247v3","updated":"2024-11-07T02:52:47Z","published":"2024-10-30T17:30:35Z","title":"bit2bit: 1-bit quanta video reconstruction via self-supervised photon\n  prediction","summary":"  Quanta image sensors, such as SPAD arrays, are an emerging sensor technology,\nproducing 1-bit arrays representing photon detection events over exposures as\nshort as a few nanoseconds. In practice, raw data are post-processed using\nheavy spatiotemporal binning to create more useful and interpretable images at\nthe cost of degrading spatiotemporal resolution. In this work, we propose\nbit2bit, a new method for reconstructing high-quality image stacks at the\noriginal spatiotemporal resolution from sparse binary quanta image data.\nInspired by recent work on Poisson denoising, we developed an algorithm that\ncreates a dense image sequence from sparse binary photon data by predicting the\nphoton arrival location probability distribution. However, due to the binary\nnature of the data, we show that the assumption of a Poisson distribution is\ninadequate. Instead, we model the process with a Bernoulli lattice process from\nthe truncated Poisson. This leads to the proposal of a novel self-supervised\nsolution based on a masked loss function. We evaluate our method using both\nsimulated and real data. On simulated data from a conventional video, we\nachieve 34.35 mean PSNR with extremely photon-sparse binary input (<0.06\nphotons per pixel per frame). We also present a novel dataset containing a wide\nrange of real SPAD high-speed videos under various challenging imaging\nconditions. The scenes cover strong/weak ambient light, strong motion,\nultra-fast events, etc., which will be made available to the community, on\nwhich we demonstrate the promise of our approach. Both reconstruction quality\nand throughput substantially surpass the state-of-the-art methods (e.g., Quanta\nBurst Photography (QBP)). Our approach significantly enhances the visualization\nand usability of the data, enabling the application of existing analysis\ntechniques.\n","authors":["Yehe Liu","Alexander Krull","Hector Basevi","Ales Leonardis","Michael W. Jenkins"],"pdf_url":"https://arxiv.org/pdf/2410.23247v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.14789v3","updated":"2024-11-07T02:43:03Z","published":"2024-08-27T05:31:30Z","title":"Revisiting Surgical Instrument Segmentation Without Human Intervention:\n  A Graph Partitioning View","summary":"  Surgical instrument segmentation (SIS) on endoscopic images stands as a\nlong-standing and essential task in the context of computer-assisted\ninterventions for boosting minimally invasive surgery. Given the recent surge\nof deep learning methodologies and their data-hungry nature, training a neural\npredictive model based on massive expert-curated annotations has been\ndominating and served as an off-the-shelf approach in the field, which could,\nhowever, impose prohibitive burden to clinicians for preparing fine-grained\npixel-wise labels corresponding to the collected surgical video frames. In this\nwork, we propose an unsupervised method by reframing the video frame\nsegmentation as a graph partitioning problem and regarding image pixels as\ngraph nodes, which is significantly different from the previous efforts. A\nself-supervised pre-trained model is firstly leveraged as a feature extractor\nto capture high-level semantic features. Then, Laplacian matrixs are computed\nfrom the features and are eigendecomposed for graph partitioning. On the \"deep\"\neigenvectors, a surgical video frame is meaningfully segmented into different\nmodules such as tools and tissues, providing distinguishable semantic\ninformation like locations, classes, and relations. The segmentation problem\ncan then be naturally tackled by applying clustering or threshold on the\neigenvectors. Extensive experiments are conducted on various datasets (e.g.,\nEndoVis2017, EndoVis2018, UCL, etc.) for different clinical endpoints. Across\nall the challenging scenarios, our method demonstrates outstanding performance\nand robustness higher than unsupervised state-of-the-art (SOTA) methods. The\ncode is released at https://github.com/MingyuShengSMY/GraphClusteringSIS.git.\n","authors":["Mingyu Sheng","Jianan Fan","Dongnan Liu","Ron Kikinis","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2408.14789v3.pdf","comment":"Accepted by The 32nd ACM International Conference on Multimedia (ACM\n  MM 2024) Workshop on Multimedia Computing for Health and Medicine (MCHM)"},{"id":"http://arxiv.org/abs/2411.03695v2","updated":"2024-11-07T02:40:12Z","published":"2024-11-06T06:33:55Z","title":"AMNCutter: Affinity-Attention-Guided Multi-View Normalized Cutter for\n  Unsupervised Surgical Instrument Segmentation","summary":"  Surgical instrument segmentation (SIS) is pivotal for robotic-assisted\nminimally invasive surgery, assisting surgeons by identifying surgical\ninstruments in endoscopic video frames. Recent unsupervised surgical instrument\nsegmentation (USIS) methods primarily rely on pseudo-labels derived from\nlow-level features such as color and optical flow, but these methods show\nlimited effectiveness and generalizability in complex and unseen endoscopic\nscenarios. In this work, we propose a label-free unsupervised model featuring a\nnovel module named Multi-View Normalized Cutter (m-NCutter). Different from\nprevious USIS works, our model is trained using a graph-cutting loss function\nthat leverages patch affinities for supervision, eliminating the need for\npseudo-labels. The framework adaptively determines which affinities from which\nlevels should be prioritized. Therefore, the low- and high-level features and\ntheir affinities are effectively integrated to train a label-free unsupervised\nmodel, showing superior effectiveness and generalization ability. We conduct\ncomprehensive experiments across multiple SIS datasets to validate our\napproach's state-of-the-art (SOTA) performance, robustness, and exceptional\npotential as a pre-trained model. Our code is released at\nhttps://github.com/MingyuShengSMY/AMNCutter.\n","authors":["Mingyu Sheng","Jianan Fan","Dongnan Liu","Ron Kikinis","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2411.03695v2.pdf","comment":"Accepted by the 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV 2025)"},{"id":"http://arxiv.org/abs/2406.02880v2","updated":"2024-11-07T02:26:49Z","published":"2024-06-05T02:54:46Z","title":"Controllable Talking Face Generation by Implicit Facial Keypoints\n  Editing","summary":"  Audio-driven talking face generation has garnered significant interest within\nthe domain of digital human research. Existing methods are encumbered by\nintricate model architectures that are intricately dependent on each other,\ncomplicating the process of re-editing image or video inputs. In this work, we\npresent ControlTalk, a talking face generation method to control face\nexpression deformation based on driven audio, which can construct the head pose\nand facial expression including lip motion for both single image or sequential\nvideo inputs in a unified manner. By utilizing a pre-trained video synthesis\nrenderer and proposing the lightweight adaptation, ControlTalk achieves precise\nand naturalistic lip synchronization while enabling quantitative control over\nmouth opening shape. Our experiments show that our method is superior to\nstate-of-the-art performance on widely used benchmarks, including HDTF and\nMEAD. The parameterized adaptation demonstrates remarkable generalization\ncapabilities, effectively handling expression deformation across same-ID and\ncross-ID scenarios, and extending its utility to out-of-domain portraits,\nregardless of languages. Code is available at\nhttps://github.com/NetEase-Media/ControlTalk.\n","authors":["Dong Zhao","Jiaying Shi","Wenjun Li","Shudong Wang","Shenghui Xu","Zhaoming Pan"],"pdf_url":"https://arxiv.org/pdf/2406.02880v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18782v2","updated":"2024-11-07T01:31:00Z","published":"2024-05-29T05:42:25Z","title":"Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play\n  Priors","summary":"  Diffusion models (DMs) have recently shown outstanding capabilities in\nmodeling complex image distributions, making them expressive image priors for\nsolving Bayesian inverse problems. However, most existing DM-based methods rely\non approximations in the generative process to be generic to different inverse\nproblems, leading to inaccurate sample distributions that deviate from the\ntarget posterior defined within the Bayesian framework. To harness the\ngenerative power of DMs while avoiding such approximations, we propose a Markov\nchain Monte Carlo algorithm that performs posterior sampling for general\ninverse problems by reducing it to sampling the posterior of a Gaussian\ndenoising problem. Crucially, we leverage a general DM formulation as a unified\ninterface that allows for rigorously solving the denoising problem with a range\nof state-of-the-art DMs. We demonstrate the effectiveness of the proposed\nmethod on six inverse problems (three linear and three nonlinear), including a\nreal-world black hole imaging problem. Experimental results indicate that our\nproposed method offers more accurate reconstructions and posterior estimation\ncompared to existing DM-based imaging inverse methods.\n","authors":["Zihui Wu","Yu Sun","Yifan Chen","Bingliang Zhang","Yisong Yue","Katherine L. Bouman"],"pdf_url":"https://arxiv.org/pdf/2405.18782v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04357v1","updated":"2024-11-07T01:30:30Z","published":"2024-11-07T01:30:30Z","title":"MegaPortrait: Revisiting Diffusion Control for High-fidelity Portrait\n  Generation","summary":"  We propose MegaPortrait. It's an innovative system for creating personalized\nportrait images in computer vision. It has three modules: Identity Net, Shading\nNet, and Harmonization Net. Identity Net generates learned identity using a\ncustomized model fine-tuned with source images. Shading Net re-renders\nportraits using extracted representations. Harmonization Net fuses pasted faces\nand the reference image's body for coherent results. Our approach with\noff-the-shelf Controlnets is better than state-of-the-art AI portrait products\nin identity preservation and image fidelity. MegaPortrait has a simple but\neffective design and we compare it with other methods and products to show its\nsuperiority.\n","authors":["Han Yang","Sotiris Anagnostidis","Enis Simsar","Thomas Hofmann"],"pdf_url":"https://arxiv.org/pdf/2411.04357v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2406.05768v6","updated":"2024-11-07T01:29:26Z","published":"2024-06-09T12:55:50Z","title":"TLCM: Training-efficient Latent Consistency Model for Image Generation\n  with 2-8 Steps","summary":"  Distilling latent diffusion models (LDMs) into ones that are fast to sample\nfrom is attracting growing research interest. However, the majority of existing\nmethods face two critical challenges: (1) They hinge on long training using a\nhuge volume of real data. (2) They routinely lead to quality degradation for\ngeneration, especially in text-image alignment. This paper proposes a novel\ntraining-efficient Latent Consistency Model (TLCM) to overcome these\nchallenges. Our method first accelerates LDMs via data-free multistep latent\nconsistency distillation (MLCD), and then data-free latent consistency\ndistillation is proposed to efficiently guarantee the inter-segment consistency\nin MLCD. Furthermore, we introduce bags of techniques, e.g., distribution\nmatching, adversarial learning, and preference learning, to enhance TLCM's\nperformance at few-step inference without any real data. TLCM demonstrates a\nhigh level of flexibility by enabling adjustment of sampling steps within the\nrange of 2 to 8 while still producing competitive outputs compared to full-step\napproaches. Notably, TLCM enjoys the data-free merit by employing synthetic\ndata from the teacher for distillation. With just 70 training hours on an A100\nGPU, a 3-step TLCM distilled from SDXL achieves an impressive CLIP Score of\n33.68 and an Aesthetic Score of 5.97 on the MSCOCO-2017 5K benchmark,\nsurpassing various accelerated models and even outperforming the teacher model\nin human preference metrics. We also demonstrate the versatility of TLCMs in\napplications including image style transfer, controllable generation, and\nChinese-to-image generation.\n","authors":["Qingsong Xie","Zhenyi Liao","Zhijie Deng","Chen chen","Haonan Lu"],"pdf_url":"https://arxiv.org/pdf/2406.05768v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06633v2","updated":"2024-11-07T01:14:29Z","published":"2024-07-09T07:59:34Z","title":"Variational Zero-shot Multispectral Pansharpening","summary":"  Pansharpening aims to generate a high spatial resolution multispectral image\n(HRMS) by fusing a low spatial resolution multispectral image (LRMS) and a\npanchromatic image (PAN). The most challenging issue for this task is that only\nthe to-be-fused LRMS and PAN are available, and the existing deep\nlearning-based methods are unsuitable since they rely on many training pairs.\nTraditional variational optimization (VO) based methods are well-suited for\naddressing such a problem. They focus on carefully designing explicit fusion\nrules as well as regularizations for an optimization problem, which are based\non the researcher's discovery of the image relationships and image structures.\nUnlike previous VO-based methods, in this work, we explore such complex\nrelationships by a parameterized term rather than a manually designed one.\nSpecifically, we propose a zero-shot pansharpening method by introducing a\nneural network into the optimization objective. This network estimates a\nrepresentation component of HRMS, which mainly describes the relationship\nbetween HRMS and PAN. In this way, the network achieves a similar goal to the\nso-called deep image prior because it implicitly regulates the relationship\nbetween the HRMS and PAN images through its inherent structure. We directly\nminimize this optimization objective via network parameters and the expected\nHRMS image through iterative updating. Extensive experiments on various\nbenchmark datasets demonstrate that our proposed method can achieve better\nperformance compared with other state-of-the-art methods. The codes are\navailable at https://github.com/xyrui/PSDip.\n","authors":["Xiangyu Rui","Xiangyong Cao","Yining Li","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2407.06633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04351v1","updated":"2024-11-07T01:12:01Z","published":"2024-11-07T01:12:01Z","title":"LidaRefer: Outdoor 3D Visual Grounding for Autonomous Driving with\n  Transformers","summary":"  3D visual grounding (VG) aims to locate relevant objects or regions within 3D\nscenes based on natural language descriptions. Although recent methods for\nindoor 3D VG have successfully transformer-based architectures to capture\nglobal contextual information and enable fine-grained cross-modal fusion, they\nare unsuitable for outdoor environments due to differences in the distribution\nof point clouds between indoor and outdoor settings. Specifically, first,\nextensive LiDAR point clouds demand unacceptable computational and memory\nresources within transformers due to the high-dimensional visual features.\nSecond, dominant background points and empty spaces in sparse LiDAR point\nclouds complicate cross-modal fusion owing to their irrelevant visual\ninformation. To address these challenges, we propose LidaRefer, a\ntransformer-based 3D VG framework designed for large-scale outdoor scenes.\nMoreover, during training, we introduce a simple and effective localization\nmethod, which supervises the decoder's queries to localize not only a target\nobject but also ambiguous objects that might be confused as the target due to\nthe exhibition of similar attributes in a scene or the incorrect understanding\nof a language description. This supervision enhances the model's ability to\ndistinguish ambiguous objects from a target by learning the differences in\ntheir spatial relationships and attributes. LidaRefer achieves state-of-the-art\nperformance on Talk2Car-3D, a 3D VG dataset for autonomous driving, with\nsignificant improvements under various evaluation settings.\n","authors":["Yeong-Seung Baek","Heung-Seon Oh"],"pdf_url":"https://arxiv.org/pdf/2411.04351v1.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.04348v1","updated":"2024-11-07T01:10:05Z","published":"2024-11-07T01:10:05Z","title":"UEVAVD: A Dataset for Developing UAV's Eye View Active Object Detection","summary":"  Occlusion is a longstanding difficulty that challenges the UAV-based object\ndetection. Many works address this problem by adapting the detection model.\nHowever, few of them exploit that the UAV could fundamentally improve detection\nperformance by changing its viewpoint. Active Object Detection (AOD) offers an\neffective way to achieve this purpose. Through Deep Reinforcement Learning\n(DRL), AOD endows the UAV with the ability of autonomous path planning to\nsearch for the observation that is more conducive to target identification.\nUnfortunately, there exists no available dataset for developing the UAV AOD\nmethod. To fill this gap, we released a UAV's eye view active vision dataset\nnamed UEVAVD and hope it can facilitate research on the UAV AOD problem.\nAdditionally, we improve the existing DRL-based AOD method by incorporating the\ninductive bias when learning the state representation. First, due to the\npartial observability, we use the gated recurrent unit to extract state\nrepresentations from the observation sequence instead of the single-view\nobservation. Second, we pre-decompose the scene with the Segment Anything Model\n(SAM) and filter out the irrelevant information with the derived masks. With\nthese practices, the agent could learn an active viewing policy with better\ngeneralization capability. The effectiveness of our innovations is validated by\nthe experiments on the UEVAVD dataset. Our dataset will soon be available at\nhttps://github.com/Leo000ooo/UEVAVD_dataset.\n","authors":["Xinhua Jiang","Tianpeng Liu","Li Liu","Zhen Liu","Yongxiang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.04348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21739v2","updated":"2024-11-07T00:37:50Z","published":"2024-10-29T04:54:45Z","title":"SS3DM: Benchmarking Street-View Surface Reconstruction with a Synthetic\n  3D Mesh Dataset","summary":"  Reconstructing accurate 3D surfaces for street-view scenarios is crucial for\napplications such as digital entertainment and autonomous driving simulation.\nHowever, existing street-view datasets, including KITTI, Waymo, and nuScenes,\nonly offer noisy LiDAR points as ground-truth data for geometric evaluation of\nreconstructed surfaces. These geometric ground-truths often lack the necessary\nprecision to evaluate surface positions and do not provide data for assessing\nsurface normals. To overcome these challenges, we introduce the SS3DM dataset,\ncomprising precise \\textbf{S}ynthetic \\textbf{S}treet-view \\textbf{3D}\n\\textbf{M}esh models exported from the CARLA simulator. These mesh models\nfacilitate accurate position evaluation and include normal vectors for\nevaluating surface normal. To simulate the input data in realistic driving\nscenarios for 3D reconstruction, we virtually drive a vehicle equipped with six\nRGB cameras and five LiDAR sensors in diverse outdoor scenes. Leveraging this\ndataset, we establish a benchmark for state-of-the-art surface reconstruction\nmethods, providing a comprehensive evaluation of the associated challenges.\n  For more information, visit our homepage at https://ss3dm.top.\n","authors":["Yubin Hu","Kairui Wen","Heng Zhou","Xiaoyang Guo","Yong-Jin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.21739v2.pdf","comment":"NeurIPS 2024, Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2411.04335v1","updated":"2024-11-07T00:22:38Z","published":"2024-11-07T00:22:38Z","title":"GazeGen: Gaze-Driven User Interaction for Visual Content Generation","summary":"  We present GazeGen, a user interaction system that generates visual content\n(images and videos) for locations indicated by the user's eye gaze. GazeGen\nallows intuitive manipulation of visual content by targeting regions of\ninterest with gaze. Using advanced techniques in object detection and\ngenerative AI, GazeGen performs gaze-controlled image adding/deleting,\nrepositioning, and surface material changes of image objects, and converts\nstatic images into videos. Central to GazeGen is the DFT Gaze (Distilled and\nFine-Tuned Gaze) agent, an ultra-lightweight model with only 281K parameters,\nperforming accurate real-time gaze predictions tailored to individual users'\neyes on small edge devices. GazeGen is the first system to combine visual\ncontent generation with real-time gaze estimation, made possible exclusively by\nDFT Gaze. This real-time gaze estimation enables various visual content\ngeneration tasks, all controlled by the user's gaze. The input for DFT Gaze is\nthe user's eye images, while the inputs for visual content generation are the\nuser's view and the predicted gaze point from DFT Gaze. To achieve efficient\ngaze predictions, we derive the small model from a large model (10x larger) via\nnovel knowledge distillation and personal adaptation techniques. We integrate\nknowledge distillation with a masked autoencoder, developing a compact yet\npowerful gaze estimation model. This model is further fine-tuned with Adapters,\nenabling highly accurate and personalized gaze predictions with minimal user\ninput. DFT Gaze ensures low-latency and precise gaze tracking, supporting a\nwide range of gaze-driven tasks. We validate the performance of DFT Gaze on AEA\nand OpenEDS2020 benchmarks, demonstrating low angular gaze error and low\nlatency on the edge device (Raspberry Pi 4). Furthermore, we describe\napplications of GazeGen, illustrating its versatility and effectiveness in\nvarious usage scenarios.\n","authors":["He-Yen Hsieh","Ziyun Li","Sai Qian Zhang","Wei-Te Mark Ting","Kao-Den Chang","Barbara De Salvo","Chiao Liu","H. T. Kung"],"pdf_url":"https://arxiv.org/pdf/2411.04335v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.04332v1","updated":"2024-11-07T00:14:39Z","published":"2024-11-07T00:14:39Z","title":"HandCraft: Anatomically Correct Restoration of Malformed Hands in\n  Diffusion Generated Images","summary":"  Generative text-to-image models, such as Stable Diffusion, have demonstrated\na remarkable ability to generate diverse, high-quality images. However, they\nare surprisingly inept when it comes to rendering human hands, which are often\nanatomically incorrect or reside in the \"uncanny valley\". In this paper, we\npropose a method HandCraft for restoring such malformed hands. This is achieved\nby automatically constructing masks and depth images for hands as conditioning\nsignals using a parametric model, allowing a diffusion-based image editor to\nfix the hand's anatomy and adjust its pose while seamlessly integrating the\nchanges into the original image, preserving pose, color, and style. Our\nplug-and-play hand restoration solution is compatible with existing pretrained\ndiffusion models, and the restoration process facilitates adoption by eschewing\nany fine-tuning or training requirements for the diffusion models. We also\ncontribute MalHand datasets that contain generated images with a wide variety\nof malformed hands in several styles for hand detector training and hand\nrestoration benchmarking, and demonstrate through qualitative and quantitative\nevaluation that HandCraft not only restores anatomical correctness but also\nmaintains the integrity of the overall image.\n","authors":["Zhenyue Qin","Yiqun Zhang","Yang Liu","Dylan Campbell"],"pdf_url":"https://arxiv.org/pdf/2411.04332v1.pdf","comment":"Accepted by WACV 2025"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.05007v1","updated":"2024-11-07T18:59:58Z","published":"2024-11-07T18:59:58Z","title":"SVDQunat: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion\n  Models","summary":"  Diffusion models have been proven highly effective at generating high-quality\nimages. However, as these models grow larger, they require significantly more\nmemory and suffer from higher latency, posing substantial challenges for\ndeployment. In this work, we aim to accelerate diffusion models by quantizing\ntheir weights and activations to 4 bits. At such an aggressive level, both\nweights and activations are highly sensitive, where conventional post-training\nquantization methods for large language models like smoothing become\ninsufficient. To overcome this limitation, we propose SVDQuant, a new 4-bit\nquantization paradigm. Different from smoothing which redistributes outliers\nbetween weights and activations, our approach absorbs these outliers using a\nlow-rank branch. We first consolidate the outliers by shifting them from\nactivations to weights, then employ a high-precision low-rank branch to take in\nthe weight outliers with Singular Value Decomposition (SVD). This process eases\nthe quantization on both sides. However, na\\\"{\\i}vely running the low-rank\nbranch independently incurs significant overhead due to extra data movement of\nactivations, negating the quantization speedup. To address this, we co-design\nan inference engine Nunchaku that fuses the kernels of the low-rank branch into\nthose of the low-bit branch to cut off redundant memory access. It can also\nseamlessly support off-the-shelf low-rank adapters (LoRAs) without the need for\nre-quantization. Extensive experiments on SDXL, PixArt-$\\Sigma$, and FLUX.1\nvalidate the effectiveness of SVDQuant in preserving image quality. We reduce\nthe memory usage for the 12B FLUX.1 models by 3.5$\\times$, achieving\n3.0$\\times$ speedup over the 4-bit weight-only quantized baseline on the 16GB\nlaptop 4090 GPU, paving the way for more interactive applications on PCs. Our\nquantization library and inference engine are open-sourced.\n","authors":["Muyang Li","Yujun Lin","Zhekai Zhang","Tianle Cai","Xiuyu Li","Junxian Guo","Enze Xie","Chenlin Meng","Jun-Yan Zhu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2411.05007v1.pdf","comment":"Quantization Library: https://github.com/mit-han-lab/deepcompressor\n  Inference Engine: https://github.com/mit-han-lab/nunchaku Website:\n  https://hanlab.mit.edu/projects/svdquant Demo: https://svdquant.mit.edu Blog:\n  https://hanlab.mit.edu/blog/svdquant"},{"id":"http://arxiv.org/abs/2411.05005v1","updated":"2024-11-07T18:59:53Z","published":"2024-11-07T18:59:53Z","title":"Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion\n  Models","summary":"  Beyond high-fidelity image synthesis, diffusion models have recently\nexhibited promising results in dense visual perception tasks. However, most\nexisting work treats diffusion models as a standalone component for perception\ntasks, employing them either solely for off-the-shelf data augmentation or as\nmere feature extractors. In contrast to these isolated and thus sub-optimal\nefforts, we introduce a unified, versatile, diffusion-based framework,\nDiff-2-in-1, that can simultaneously handle both multi-modal data generation\nand dense visual perception, through a unique exploitation of the\ndiffusion-denoising process. Within this framework, we further enhance\ndiscriminative visual perception via multi-modal generation, by utilizing the\ndenoising network to create multi-modal data that mirror the distribution of\nthe original training set. Importantly, Diff-2-in-1 optimizes the utilization\nof the created diverse and faithful data by leveraging a novel self-improving\nlearning mechanism. Comprehensive experimental evaluations validate the\neffectiveness of our framework, showcasing consistent performance improvements\nacross various discriminative backbones and high-quality multi-modal data\ngeneration characterized by both realism and usefulness.\n","authors":["Shuhong Zheng","Zhipeng Bao","Ruoyu Zhao","Martial Hebert","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05005v1.pdf","comment":"26 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.05003v1","updated":"2024-11-07T18:59:45Z","published":"2024-11-07T18:59:45Z","title":"ReCapture: Generative Video Camera Controls for User-Provided Videos\n  using Masked Video Fine-Tuning","summary":"  Recently, breakthroughs in video modeling have allowed for controllable\ncamera trajectories in generated videos. However, these methods cannot be\ndirectly applied to user-provided videos that are not generated by a video\nmodel. In this paper, we present ReCapture, a method for generating new videos\nwith novel camera trajectories from a single user-provided video. Our method\nallows us to re-generate the reference video, with all its existing scene\nmotion, from vastly different angles and with cinematic camera motion. Notably,\nusing our method we can also plausibly hallucinate parts of the scene that were\nnot observable in the reference video. Our method works by (1) generating a\nnoisy anchor video with a new camera trajectory using multiview diffusion\nmodels or depth-based point cloud rendering and then (2) regenerating the\nanchor video into a clean and temporally consistent reangled video using our\nproposed masked video fine-tuning technique.\n","authors":["David Junhao Zhang","Roni Paiss","Shiran Zada","Nikhil Karnad","David E. Jacobs","Yael Pritch","Inbar Mosseri","Mike Zheng Shou","Neal Wadhwa","Nataniel Ruiz"],"pdf_url":"https://arxiv.org/pdf/2411.05003v1.pdf","comment":"project page: https://generative-video-camera-controls.github.io/"},{"id":"http://arxiv.org/abs/2411.05001v1","updated":"2024-11-07T18:59:28Z","published":"2024-11-07T18:59:28Z","title":"Analyzing The Language of Visual Tokens","summary":"  With the introduction of transformer-based models for vision and language\ntasks, such as LLaVA and Chameleon, there has been renewed interest in the\ndiscrete tokenized representation of images. These models often treat image\npatches as discrete tokens, analogous to words in natural language, learning\njoint alignments between visual and human languages. However, little is known\nabout the statistical behavior of these visual languages - whether they follow\nsimilar frequency distributions, grammatical structures, or topologies as\nnatural languages. In this paper, we take a natural-language-centric approach\nto analyzing discrete visual languages and uncover striking similarities and\nfundamental differences. We demonstrate that, although visual languages adhere\nto Zipfian distributions, higher token innovation drives greater entropy and\nlower compression, with tokens predominantly representing object parts,\nindicating intermediate granularity. We also show that visual languages lack\ncohesive grammatical structures, leading to higher perplexity and weaker\nhierarchical organization compared to natural languages. Finally, we\ndemonstrate that, while vision models align more closely with natural languages\nthan other models, this alignment remains significantly weaker than the\ncohesion found within natural languages. Through these experiments, we\ndemonstrate how understanding the statistical properties of discrete visual\nlanguages can inform the design of more effective computer vision models.\n","authors":["David M. Chan","Rodolfo Corona","Joonyong Park","Cheol Jun Cho","Yutong Bai","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2411.05001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04999v1","updated":"2024-11-07T18:59:27Z","published":"2024-11-07T18:59:27Z","title":"DynaMem: Online Dynamic Spatio-Semantic Memory for Open World Mobile\n  Manipulation","summary":"  Significant progress has been made in open-vocabulary mobile manipulation,\nwhere the goal is for a robot to perform tasks in any environment given a\nnatural language description. However, most current systems assume a static\nenvironment, which limits the system's applicability in real-world scenarios\nwhere environments frequently change due to human intervention or the robot's\nown actions. In this work, we present DynaMem, a new approach to open-world\nmobile manipulation that uses a dynamic spatio-semantic memory to represent a\nrobot's environment. DynaMem constructs a 3D data structure to maintain a\ndynamic memory of point clouds, and answers open-vocabulary object localization\nqueries using multimodal LLMs or open-vocabulary features generated by\nstate-of-the-art vision-language models. Powered by DynaMem, our robots can\nexplore novel environments, search for objects not found in memory, and\ncontinuously update the memory as objects move, appear, or disappear in the\nscene. We run extensive experiments on the Stretch SE3 robots in three real and\nnine offline scenes, and achieve an average pick-and-drop success rate of 70%\non non-stationary objects, which is more than a 2x improvement over\nstate-of-the-art static systems. Our code as well as our experiment and\ndeployment videos are open sourced and can be found on our project website:\nhttps://dynamem.github.io/\n","authors":["Peiqi Liu","Zhanqiu Guo","Mohit Warke","Soumith Chintala","Chris Paxton","Nur Muhammad Mahi Shafiullah","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2411.04999v1.pdf","comment":"Website: https://dynamem.github.io"},{"id":"http://arxiv.org/abs/2411.04998v1","updated":"2024-11-07T18:59:16Z","published":"2024-11-07T18:59:16Z","title":"HourVideo: 1-Hour Video-Language Understanding","summary":"  We present HourVideo, a benchmark dataset for hour-long video-language\nunderstanding. Our dataset consists of a novel task suite comprising\nsummarization, perception (recall, tracking), visual reasoning (spatial,\ntemporal, predictive, causal, counterfactual), and navigation (room-to-room,\nobject retrieval) tasks. HourVideo includes 500 manually curated egocentric\nvideos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and\nfeatures 12,976 high-quality, five-way multiple-choice questions. Benchmarking\nresults reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve\nmarginal improvements over random chance. In stark contrast, human experts\nsignificantly outperform the state-of-the-art long-context multimodal model,\nGemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal\ncapabilities. Our benchmark, evaluation toolkit, prompts, and documentation are\navailable at https://hourvideo.stanford.edu\n","authors":["Keshigeyan Chandrasegaran","Agrim Gupta","Lea M. Hadzic","Taran Kota","Jimming He","Cristóbal Eyzaguirre","Zane Durante","Manling Li","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2411.04998v1.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track; 28 pages"},{"id":"http://arxiv.org/abs/2411.04995v1","updated":"2024-11-07T18:58:57Z","published":"2024-11-07T18:58:57Z","title":"LoFi: Scalable Local Image Reconstruction with Implicit Neural\n  Representation","summary":"  Neural fields or implicit neural representations (INRs) have attracted\nsignificant attention in machine learning and signal processing due to their\nefficient continuous representation of images and 3D volumes. In this work, we\nbuild on INRs and introduce a coordinate-based local processing framework for\nsolving imaging inverse problems, termed LoFi (Local Field). Unlike\nconventional methods for image reconstruction, LoFi processes local information\nat each coordinate \\textit{separately} by multi-layer perceptrons (MLPs),\nrecovering the object at that specific coordinate. Similar to INRs, LoFi can\nrecover images at any continuous coordinate, enabling image reconstruction at\nmultiple resolutions. With comparable or better performance than standard CNNs\nfor image reconstruction, LoFi achieves excellent generalization to\nout-of-distribution data and memory usage almost independent of image\nresolution. Remarkably, training on $1024 \\times 1024$ images requires just 3GB\nof memory -- over 20 times less than the memory typically needed by standard\nCNNs. Additionally, LoFi's local design allows it to train on extremely small\ndatasets with less than 10 samples, without overfitting or the need for\nregularization or early stopping. Finally, we use LoFi as a denoising prior in\na plug-and-play framework for solving general inverse problems to benefit from\nits continuous image representation and strong generalization. Although trained\non low-resolution images, LoFi can be used as a low-dimensional prior to solve\ninverse problems at any resolution. We validate our framework across a variety\nof imaging modalities, from low-dose computed tomography to radio\ninterferometric imaging.\n","authors":["AmirEhsan Khorashadizadeh","Tobías I. Liaudat","Tianlin Liu","Jason D. McEwen","Ivan Dokmanić"],"pdf_url":"https://arxiv.org/pdf/2411.04995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04992v1","updated":"2024-11-07T18:57:24Z","published":"2024-11-07T18:57:24Z","title":"Which bits went where? Past and future transfer entropy decomposition\n  with the information bottleneck","summary":"  Whether the system under study is a shoal of fish, a collection of neurons,\nor a set of interacting atmospheric and oceanic processes, transfer entropy\nmeasures the flow of information between time series and can detect possible\ncausal relationships. Much like mutual information, transfer entropy is\ngenerally reported as a single value summarizing an amount of shared variation,\nyet a more fine-grained accounting might illuminate much about the processes\nunder study. Here we propose to decompose transfer entropy and localize the\nbits of variation on both sides of information flow: that of the originating\nprocess's past and that of the receiving process's future. We employ the\ninformation bottleneck (IB) to compress the time series and identify the\ntransferred entropy. We apply our method to decompose the transfer entropy in\nseveral synthetic recurrent processes and an experimental mouse dataset of\nconcurrent behavioral and neural activity. Our approach highlights the nuanced\ndynamics within information flow, laying a foundation for future explorations\ninto the intricate interplay of temporal processes in complex systems.\n","authors":["Kieran A. Murphy","Zhuowen Yin","Dani S. Bassett"],"pdf_url":"https://arxiv.org/pdf/2411.04992v1.pdf","comment":"NeurIPS 2024 workshop \"Machine learning and the physical sciences\"\n  Camera ready"},{"id":"http://arxiv.org/abs/2411.04990v1","updated":"2024-11-07T18:56:37Z","published":"2024-11-07T18:56:37Z","title":"Clustering in Causal Attention Masking","summary":"  This work presents a modification of the self-attention dynamics proposed by\nGeshkovski et al. (arXiv:2312.10794) to better reflect the practically\nrelevant, causally masked attention used in transformer architectures for\ngenerative AI. This modification translates into an interacting particle system\nthat cannot be interpreted as a mean-field gradient flow. Despite this loss of\nstructure, we significantly strengthen the results of Geshkovski et al.\n(arXiv:2312.10794) in this context: While previous rigorous results focused on\ncases where all three matrices (Key, Query, and Value) were scaled identities,\nwe prove asymptotic convergence to a single cluster for arbitrary key-query\nmatrices and a value matrix equal to the identity. Additionally, we establish a\nconnection to the classical R\\'enyi parking problem from combinatorial geometry\nto make initial theoretical steps towards demonstrating the existence of\nmeta-stable states.\n","authors":["Nikita Karagodin","Yury Polyanskiy","Philippe Rigollet"],"pdf_url":"https://arxiv.org/pdf/2411.04990v1.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024), 22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.04989v1","updated":"2024-11-07T18:56:11Z","published":"2024-11-07T18:56:11Z","title":"SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation","summary":"  Methods for image-to-video generation have achieved impressive,\nphoto-realistic quality. However, adjusting specific elements in generated\nvideos, such as object motion or camera movement, is often a tedious process of\ntrial and error, e.g., involving re-generating videos with different random\nseeds. Recent techniques address this issue by fine-tuning a pre-trained model\nto follow conditioning signals, such as bounding boxes or point trajectories.\nYet, this fine-tuning procedure can be computationally expensive, and it\nrequires datasets with annotated object motion, which can be difficult to\nprocure. In this work, we introduce SG-I2V, a framework for controllable\nimage-to-video generation that is self-guided$\\unicode{x2013}$offering\nzero-shot control by relying solely on the knowledge present in a pre-trained\nimage-to-video diffusion model without the need for fine-tuning or external\nknowledge. Our zero-shot method outperforms unsupervised baselines while being\ncompetitive with supervised models in terms of visual quality and motion\nfidelity.\n","authors":["Koichi Namekata","Sherwin Bahmani","Ziyi Wu","Yash Kant","Igor Gilitschenski","David B. Lindell"],"pdf_url":"https://arxiv.org/pdf/2411.04989v1.pdf","comment":"Project page: https://kmcode1.github.io/Projects/SG-I2V/"},{"id":"http://arxiv.org/abs/2411.04987v1","updated":"2024-11-07T18:55:10Z","published":"2024-11-07T18:55:10Z","title":"Few-Shot Task Learning through Inverse Generative Modeling","summary":"  Learning the intents of an agent, defined by its goals or motion style, is\noften extremely challenging from just a few examples. We refer to this problem\nas task concept learning and present our approach, Few-Shot Task Learning\nthrough Inverse Generative Modeling (FTL-IGM), which learns new task concepts\nby leveraging invertible neural generative models. The core idea is to pretrain\na generative model on a set of basic concepts and their demonstrations. Then,\ngiven a few demonstrations of a new concept (such as a new goal or a new\naction), our method learns the underlying concepts through backpropagation\nwithout updating the model weights, thanks to the invertibility of the\ngenerative model. We evaluate our method in five domains -- object\nrearrangement, goal-oriented navigation, motion caption of human actions,\nautonomous driving, and real-world table-top manipulation. Our experimental\nresults demonstrate that via the pretrained generative model, we successfully\nlearn novel concepts and generate agent plans or motion corresponding to these\nconcepts in (1) unseen environments and (2) in composition with training\nconcepts.\n","authors":["Aviv Netanyahu","Yilun Du","Antonia Bronars","Jyothish Pari","Joshua Tenenbaum","Tianmin Shu","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2411.04987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04976v1","updated":"2024-11-07T18:50:14Z","published":"2024-11-07T18:50:14Z","title":"Noisy Zero-Shot Coordination: Breaking The Common Knowledge Assumption\n  In Zero-Shot Coordination Games","summary":"  Zero-shot coordination (ZSC) is a popular setting for studying the ability of\nreinforcement learning (RL) agents to coordinate with novel partners. Prior ZSC\nformulations assume the $\\textit{problem setting}$ is common knowledge: each\nagent knows the underlying Dec-POMDP, knows others have this knowledge, and so\non ad infinitum. However, this assumption rarely holds in complex real-world\nsettings, which are often difficult to fully and correctly specify. Hence, in\nsettings where this common knowledge assumption is invalid, agents trained\nusing ZSC methods may not be able to coordinate well. To address this\nlimitation, we formulate the $\\textit{noisy zero-shot coordination}$ (NZSC)\nproblem. In NZSC, agents observe different noisy versions of the ground truth\nDec-POMDP, which are assumed to be distributed according to a fixed noise\nmodel. Only the distribution of ground truth Dec-POMDPs and the noise model are\ncommon knowledge. We show that a NZSC problem can be reduced to a ZSC problem\nby designing a meta-Dec-POMDP with an augmented state space consisting of all\nthe ground-truth Dec-POMDPs. For solving NZSC problems, we propose a simple and\nflexible meta-learning method called NZSC training, in which the agents are\ntrained across a distribution of coordination problems - which they only get to\nobserve noisy versions of. We show that with NZSC training, RL agents can be\ntrained to coordinate well with novel partners even when the (exact) problem\nsetting of the coordination is not common knowledge.\n","authors":["Usman Anwar","Ashish Pandian","Jia Wan","David Krueger","Jakob Foerster"],"pdf_url":"https://arxiv.org/pdf/2411.04976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04975v1","updated":"2024-11-07T18:49:33Z","published":"2024-11-07T18:49:33Z","title":"SuffixDecoding: A Model-Free Approach to Speeding Up Large Language\n  Model Inference","summary":"  We present SuffixDecoding, a novel model-free approach to accelerating large\nlanguage model (LLM) inference through speculative decoding. Unlike existing\nmethods that rely on draft models or specialized decoding heads, SuffixDecoding\nleverages suffix trees built from previously generated outputs to efficiently\npredict candidate token sequences. Our approach enables flexible\ntree-structured speculation without the overhead of maintaining and\norchestrating additional models. SuffixDecoding builds and dynamically updates\nsuffix trees to capture patterns in the generated text, using them to construct\nspeculation trees through a principled scoring mechanism based on empirical\ntoken frequencies. SuffixDecoding requires only CPU memory which is plentiful\nand underutilized on typical LLM serving nodes. We demonstrate that\nSuffixDecoding achieves competitive speedups compared to model-based approaches\nacross diverse workloads including open-domain chat, code generation, and\ntext-to-SQL tasks. For open-ended chat and code generation tasks,\nSuffixDecoding achieves up to $1.4\\times$ higher output throughput than\nSpecInfer and up to $1.1\\times$ lower time-per-token (TPOT) latency. For a\nproprietary multi-LLM text-to-SQL application, SuffixDecoding achieves up to\n$2.9\\times$ higher output throughput and $3\\times$ lower latency than\nspeculative decoding. Our evaluation shows that SuffixDecoding maintains high\nacceptance rates even with small reference corpora of 256 examples, while\ncontinuing to improve performance as more historical outputs are incorporated.\n","authors":["Gabriele Oliaro","Zhihao Jia","Daniel Campos","Aurick Qiao"],"pdf_url":"https://arxiv.org/pdf/2411.04975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04967v1","updated":"2024-11-07T18:43:17Z","published":"2024-11-07T18:43:17Z","title":"AsCAN: Asymmetric Convolution-Attention Networks for Efficient\n  Recognition and Generation","summary":"  Neural network architecture design requires making many crucial decisions.\nThe common desiderata is that similar decisions, with little modifications, can\nbe reused in a variety of tasks and applications. To satisfy that,\narchitectures must provide promising latency and performance trade-offs,\nsupport a variety of tasks, scale efficiently with respect to the amounts of\ndata and compute, leverage available data from other tasks, and efficiently\nsupport various hardware. To this end, we introduce AsCAN -- a hybrid\narchitecture, combining both convolutional and transformer blocks. We revisit\nthe key design principles of hybrid architectures and propose a simple and\neffective \\emph{asymmetric} architecture, where the distribution of\nconvolutional and transformer blocks is \\emph{asymmetric}, containing more\nconvolutional blocks in the earlier stages, followed by more transformer blocks\nin later stages. AsCAN supports a variety of tasks: recognition, segmentation,\nclass-conditional image generation, and features a superior trade-off between\nperformance and latency. We then scale the same architecture to solve a\nlarge-scale text-to-image task and show state-of-the-art performance compared\nto the most recent public and commercial models. Notably, even without any\ncomputation optimization for transformer blocks, our models still yield faster\ninference speed than existing works featuring efficient attention mechanisms,\nhighlighting the advantages and the value of our approach.\n","authors":["Anil Kag","Huseyin Coskun","Jierun Chen","Junli Cao","Willi Menapace","Aliaksandr Siarohin","Sergey Tulyakov","Jian Ren"],"pdf_url":"https://arxiv.org/pdf/2411.04967v1.pdf","comment":"NeurIPS 2024. Project Page:\n  https://snap-research.github.io/snap_image/"},{"id":"http://arxiv.org/abs/2401.09980v2","updated":"2024-11-07T18:43:06Z","published":"2024-01-18T13:51:20Z","title":"A Comparative Analysis of U-Net-based models for Segmentation of Cardiac\n  MRI","summary":"  Medical imaging refers to the technologies and methods utilized to view the\nhuman body and its inside, in order to diagnose, monitor, or even treat medical\ndisorders. This paper aims to explore the application of deep learning\ntechniques in the semantic segmentation of Cardiac short-axis MRI (Magnetic\nResonance Imaging) images, aiming to enhance the diagnosis, monitoring, and\ntreatment of medical disorders related to the heart. The focus centers on\nimplementing various architectures that are derivatives of U-Net, to\neffectively isolate specific parts of the heart for comprehensive anatomical\nand functional analysis. Through a combination of images, graphs, and\nquantitative metrics, the efficacy of the models and their predictions are\nshowcased. Additionally, this paper addresses encountered challenges and\noutline strategies for future improvements. This abstract provides a concise\noverview of the efforts in utilizing deep learning for cardiac image\nsegmentation, emphasizing both the accomplishments and areas for further\nrefinement.\n","authors":["Ketan Suhaas Saichandran"],"pdf_url":"https://arxiv.org/pdf/2401.09980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04965v1","updated":"2024-11-07T18:41:50Z","published":"2024-11-07T18:41:50Z","title":"BitNet a4.8: 4-bit Activations for 1-bit LLMs","summary":"  Recent research on the 1-bit Large Language Models (LLMs), such as BitNet\nb1.58, presents a promising direction for reducing the inference cost of LLMs\nwhile maintaining their performance. In this work, we introduce BitNet a4.8,\nenabling 4-bit activations for 1-bit LLMs. BitNet a4.8 employs a hybrid\nquantization and sparsification strategy to mitigate the quantization errors\nintroduced by the outlier channels. Specifically, we utilize 4-bit activations\nfor inputs to the attention and feed-forward network layers, while sparsifying\nintermediate states followed with 8-bit quantization. Extensive experiments\ndemonstrate that BitNet a4.8 achieves performance comparable to BitNet b1.58\nwith equivalent training costs, while being faster in inference with enabling\n4-bit (INT4/FP4) kernels. Additionally, BitNet a4.8 activates only 55% of\nparameters and supports 3-bit KV cache, further enhancing the efficiency of\nlarge-scale LLM deployment and inference.\n","authors":["Hongyu Wang","Shuming Ma","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2411.04965v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.02472v3","updated":"2024-11-07T18:30:38Z","published":"2024-10-03T13:25:15Z","title":"Meta-Models: An Architecture for Decoding LLM Behaviors Through\n  Interpreted Embeddings and Natural Language","summary":"  As Large Language Models (LLMs) become increasingly integrated into our daily\nlives, the potential harms from deceptive behavior underlie the need for\nfaithfully interpreting their decision-making. While traditional probing\nmethods have shown some effectiveness, they remain best for narrowly scoped\ntasks while more comprehensive explanations are still necessary. To this end,\nwe investigate meta-models-an architecture using a \"meta-model\" that takes\nactivations from an \"input-model\" and answers natural language questions about\nthe input-model's behaviors. We evaluate the meta-model's ability to generalize\nby training them on selected task types and assessing their out-of-distribution\nperformance in deceptive scenarios. Our findings show that meta-models\ngeneralize well to out-of-distribution tasks and point towards opportunities\nfor future research in this area. Our code is available at\nhttps://github.com/acostarelli/meta-models-public .\n","authors":["Anthony Costarelli","Mat Allen","Severin Field"],"pdf_url":"https://arxiv.org/pdf/2410.02472v3.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.04946v1","updated":"2024-11-07T18:23:30Z","published":"2024-11-07T18:23:30Z","title":"SPGD: Steepest Perturbed Gradient Descent Optimization","summary":"  Optimization algorithms are pivotal in advancing various scientific and\nindustrial fields but often encounter obstacles such as trapping in local\nminima, saddle points, and plateaus (flat regions), which makes the convergence\nto reasonable or near-optimal solutions particularly challenging. This paper\npresents the Steepest Perturbed Gradient Descent (SPGD), a novel algorithm that\ninnovatively combines the principles of the gradient descent method with\nperiodic uniform perturbation sampling to effectively circumvent these\nimpediments and lead to better solutions whenever possible. SPGD is\ndistinctively designed to generate a set of candidate solutions and select the\none exhibiting the steepest loss difference relative to the current solution.\nIt enhances the traditional gradient descent approach by integrating a\nstrategic exploration mechanism that significantly increases the likelihood of\nescaping sub-optimal local minima and navigating complex optimization\nlandscapes effectively. Our approach not only retains the directed efficiency\nof gradient descent but also leverages the exploratory benefits of stochastic\nperturbations, thus enabling a more comprehensive search for global optima\nacross diverse problem spaces. We demonstrate the efficacy of SPGD in solving\nthe 3D component packing problem, an NP-hard challenge. Preliminary results\nshow a substantial improvement over four established methods, particularly on\nresponse surfaces with complex topographies and in multidimensional non-convex\ncontinuous optimization problems. Comparative analyses with established 2D\nbenchmark functions highlight SPGD's superior performance, showcasing its\nability to navigate complex optimization landscapes. These results emphasize\nSPGD's potential as a versatile tool for a wide range of optimization problems.\n","authors":["Amir M. Vahedi","Horea T. Ilies"],"pdf_url":"https://arxiv.org/pdf/2411.04946v1.pdf","comment":"28 pages, 26 figures, submitted to Journal of Mechanical Design"},{"id":"http://arxiv.org/abs/2401.08426v5","updated":"2024-11-07T18:22:41Z","published":"2024-01-16T15:11:29Z","title":"GD doesn't make the cut: Three ways that non-differentiability affects\n  neural network training","summary":"  This paper critically examines the fundamental distinctions between gradient\nmethods applied to non-differentiable functions (NGDMs) and classical gradient\ndescents (GDs) for differentiable functions, revealing significant gaps in\ncurrent deep learning optimization theory. We demonstrate that NGDMs exhibit\nmarkedly different convergence properties compared to GDs, strongly challenging\nthe applicability of extensive neural network convergence literature based on\n$L-smoothness$ to non-smooth neural networks. Our analysis reveals paradoxical\nbehavior of NDGM solutions for $L_{1}$-regularized problems, where increasing\nregularization counterintuitively leads to larger $L_{1}$ norms of optimal\nsolutions. This finding calls into question widely adopted $L_{1}$ penalization\ntechniques for network pruning. We further challenge the common assumption that\noptimization algorithms like RMSProp behave similarly in differentiable and\nnon-differentiable contexts. Expanding on the Edge of Stability phenomenon, we\ndemonstrate its occurrence in a broader class of functions, including Lipschitz\ncontinuous convex differentiable functions. This finding raises important\nquestions about its relevance and interpretation in non-convex,\nnon-differentiable neural networks, particularly those using ReLU activations.\nOur work identifies critical misunderstandings of NDGMs in influential\nliterature, stemming from an overreliance on strong smoothness assumptions.\nThese findings necessitate a reevaluation of optimization dynamics in deep\nlearning, emphasizing the crucial need for more nuanced theoretical foundations\nin analyzing these complex systems.\n","authors":["Siddharth Krishna Kumar"],"pdf_url":"https://arxiv.org/pdf/2401.08426v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04939v1","updated":"2024-11-07T18:15:38Z","published":"2024-11-07T18:15:38Z","title":"Pareto Set Identification With Posterior Sampling","summary":"  The problem of identifying the best answer among a collection of items having\nreal-valued distribution is well-understood.\n  Despite its practical relevance for many applications, fewer works have\nstudied its extension when multiple and potentially conflicting metrics are\navailable to assess an item's quality.\n  Pareto set identification (PSI) aims to identify the set of answers whose\nmeans are not uniformly worse than another.\n  This paper studies PSI in the transductive linear setting with potentially\ncorrelated objectives.\n  Building on posterior sampling in both the stopping and the sampling rules,\nwe propose the PSIPS algorithm that deals simultaneously with structure and\ncorrelation without paying the computational cost of existing oracle-based\nalgorithms.\n  Both from a frequentist and Bayesian perspective, PSIPS is asymptotically\noptimal.\n  We demonstrate its good empirical performance in real-world and synthetic\ninstances.\n","authors":["Cyrille Kone","Marc Jourdan","Emilie Kaufmann"],"pdf_url":"https://arxiv.org/pdf/2411.04939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04936v1","updated":"2024-11-07T18:13:31Z","published":"2024-11-07T18:13:31Z","title":"Fed-LDR: Federated Local Data-infused Graph Creation with Node-centric\n  Model Refinement","summary":"  The rapid acceleration of global urbanization has introduced novel challenges\nin enhancing urban infrastructure and services. Spatio-temporal data,\nintegrating spatial and temporal dimensions, has emerged as a critical tool for\nunderstanding urban phenomena and promoting sustainability. In this context,\nFederated Learning (FL) has gained prominence as a distributed learning\nparadigm aligned with the privacy requirements of urban IoT environments.\nHowever, integrating traditional and deep learning models into the FL framework\nposes significant challenges, particularly in capturing complex spatio-temporal\ndependencies and adapting to diverse urban conditions. To address these\nchallenges, we propose the Federated Local Data-Infused Graph Creation with\nNode-centric Model Refinement (Fed-LDR) algorithm. Fed-LDR leverages FL and\nGraph Convolutional Networks (GCN) to enhance spatio-temporal data analysis in\nurban environments. The algorithm comprises two key modules: (1) the Local\nData-Infused Graph Creation (LDIGC) module, which dynamically reconfigures\nadjacency matrices to reflect evolving spatial relationships within urban\nenvironments, and (2) the Node-centric Model Refinement (NoMoR) module, which\ncustomizes model parameters for individual urban nodes to accommodate\nheterogeneity. Evaluations on the PeMSD4 and PeMSD8 datasets demonstrate\nFed-LDR's superior performance over six baseline methods. Fed-LDR achieved the\nlowest Mean Absolute Error (MAE) values of 20.15 and 17.30, and the lowest Root\nMean Square Error (RMSE) values of 32.30 and 27.15, respectively, while\nmaintaining a high correlation coefficient of 0.96 across both datasets.\nNotably, on the PeMSD4 dataset, Fed-LDR reduced MAE and RMSE by up to 81\\% and\n78\\%, respectively, compared to the best-performing baseline FedMedian.\n","authors":["Jiechao Gao","Yuangang Li","Syeda Faiza Ahmed"],"pdf_url":"https://arxiv.org/pdf/2411.04936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04915v1","updated":"2024-11-07T17:55:07Z","published":"2024-11-07T17:55:07Z","title":"Evaluating Robustness of Reinforcement Learning Algorithms for\n  Autonomous Shipping","summary":"  Recently, there has been growing interest in autonomous shipping due to its\npotential to improve maritime efficiency and safety. The use of advanced\ntechnologies, such as artificial intelligence, can address the current\nnavigational and operational challenges in autonomous shipping. In particular,\ninland waterway transport (IWT) presents a unique set of challenges, such as\ncrowded waterways and variable environmental conditions. In such dynamic\nsettings, the reliability and robustness of autonomous shipping solutions are\ncritical factors for ensuring safe operations. This paper examines the\nrobustness of benchmark deep reinforcement learning (RL) algorithms,\nimplemented for IWT within an autonomous shipping simulator, and their ability\nto generate effective motion planning policies. We demonstrate that a\nmodel-free approach can achieve an adequate policy in the simulator,\nsuccessfully navigating port environments never encountered during training. We\nfocus particularly on Soft-Actor Critic (SAC), which we show to be inherently\nmore robust to environmental disturbances compared to MuZero, a\nstate-of-the-art model-based RL algorithm. In this paper, we take a significant\nstep towards developing robust, applied RL frameworks that can be generalized\nto various vessel types and navigate complex port- and inland environments and\nscenarios.\n","authors":["Bavo Lesy","Ali Anwar","Siegfried Mercelis"],"pdf_url":"https://arxiv.org/pdf/2411.04915v1.pdf","comment":"5 pages, 4 figures. Will be presented at IEEE RAAI 2024"},{"id":"http://arxiv.org/abs/2411.04913v1","updated":"2024-11-07T17:51:55Z","published":"2024-11-07T17:51:55Z","title":"Structure Matters: Dynamic Policy Gradient","summary":"  In this work, we study $\\gamma$-discounted infinite-horizon tabular Markov\ndecision processes (MDPs) and introduce a framework called dynamic policy\ngradient (DynPG). The framework directly integrates dynamic programming with\n(any) policy gradient method, explicitly leveraging the Markovian property of\nthe environment. DynPG dynamically adjusts the problem horizon during training,\ndecomposing the original infinite-horizon MDP into a sequence of contextual\nbandit problems. By iteratively solving these contextual bandits, DynPG\nconverges to the stationary optimal policy of the infinite-horizon MDP. To\ndemonstrate the power of DynPG, we establish its non-asymptotic global\nconvergence rate under the tabular softmax parametrization, focusing on the\ndependencies on salient but essential parameters of the MDP. By combining\nclassical arguments from dynamic programming with more recent convergence\narguments of policy gradient schemes, we prove that softmax DynPG scales\npolynomially in the effective horizon $(1-\\gamma)^{-1}$. Our findings contrast\nrecent exponential lower bound examples for vanilla policy gradient.\n","authors":["Sara Klein","Xiangyuan Zhang","Tamer Başar","Simon Weissmann","Leif Döring"],"pdf_url":"https://arxiv.org/pdf/2411.04913v1.pdf","comment":"46 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.04907v1","updated":"2024-11-07T17:48:37Z","published":"2024-11-07T17:48:37Z","title":"Enhancing Missing Data Imputation through Combined Bipartite Graph and\n  Complete Directed Graph","summary":"  In this paper, we aim to address a significant challenge in the field of\nmissing data imputation: identifying and leveraging the interdependencies among\nfeatures to enhance missing data imputation for tabular data. We introduce a\nnovel framework named the Bipartite and Complete Directed Graph Neural Network\n(BCGNN). Within BCGNN, observations and features are differentiated as two\ndistinct node types, and the values of observed features are converted into\nattributed edges linking them. The bipartite segment of our framework\ninductively learns embedding representations for nodes, efficiently utilizing\nthe comprehensive information encapsulated in the attributed edges. In\nparallel, the complete directed graph segment adeptly outlines and communicates\nthe complex interdependencies among features. When compared to contemporary\nleading imputation methodologies, BCGNN consistently outperforms them,\nachieving a noteworthy average reduction of 15% in mean absolute error for\nfeature imputation tasks under different missing mechanisms. Our extensive\nexperimental investigation confirms that an in-depth grasp of the\ninterdependence structure substantially enhances the model's feature embedding\nability. We also highlight the model's superior performance in label prediction\ntasks involving missing data, and its formidable ability to generalize to\nunseen data points.\n","authors":["Zhaoyang Zhang","Hongtu Zhu","Ziqi Chen","Yingjie Zhang","Hai Shu"],"pdf_url":"https://arxiv.org/pdf/2411.04907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06754v3","updated":"2024-11-07T17:46:23Z","published":"2024-09-10T16:05:02Z","title":"Scaling Law Hypothesis for Multimodal Model","summary":"  We propose a scaling law hypothesis for multimodal models processing text,\naudio, images, and video within a shared token and embedding space. Our\nframework predicts model performance based on modality-specific compression and\ntokenization efficiency, extending established scaling laws from text-based\ndecoder models to mixed-modality systems. We explore whether leveraging more\ntraining data in multiple modalities can reduce the size of the multimodal\nmodel, enabling efficient deployment on resource-constrained devices.\n","authors":["Qingyun Sun","Zhen Guo"],"pdf_url":"https://arxiv.org/pdf/2409.06754v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04899v1","updated":"2024-11-07T17:41:07Z","published":"2024-11-07T17:41:07Z","title":"Sampling-guided Heterogeneous Graph Neural Network with Temporal\n  Smoothing for Scalable Longitudinal Data Imputation","summary":"  In this paper, we propose a novel framework, the Sampling-guided\nHeterogeneous Graph Neural Network (SHT-GNN), to effectively tackle the\nchallenge of missing data imputation in longitudinal studies. Unlike\ntraditional methods, which often require extensive preprocessing to handle\nirregular or inconsistent missing data, our approach accommodates arbitrary\nmissing data patterns while maintaining computational efficiency. SHT-GNN\nmodels both observations and covariates as distinct node types, connecting\nobservation nodes at successive time points through subject-specific\nlongitudinal subnetworks, while covariate-observation interactions are\nrepresented by attributed edges within bipartite graphs. By leveraging\nsubject-wise mini-batch sampling and a multi-layer temporal smoothing\nmechanism, SHT-GNN efficiently scales to large datasets, while effectively\nlearning node representations and imputing missing data. Extensive experiments\non both synthetic and real-world datasets, including the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) dataset, demonstrate that SHT-GNN significantly\noutperforms existing imputation methods, even with high missing data rates. The\nempirical results highlight SHT-GNN's robust imputation capabilities and\nsuperior performance, particularly in the context of complex, large-scale\nlongitudinal data.\n","authors":["Zhaoyang Zhang","Ziqi Chen","Qiao Liu","Jinhan Xie","Hongtu Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.04899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15814v2","updated":"2024-11-07T17:33:37Z","published":"2024-07-22T17:26:12Z","title":"Perceptions of Linguistic Uncertainty by Language Models and Humans","summary":"  _Uncertainty expressions_ such as \"probably\" or \"highly unlikely\" are\npervasive in human language. While prior work has established that there is\npopulation-level agreement in terms of how humans quantitatively interpret\nthese expressions, there has been little inquiry into the abilities of language\nmodels in the same context. In this paper, we investigate how language models\nmap linguistic expressions of uncertainty to numerical responses. Our approach\nassesses whether language models can employ theory of mind in this setting:\nunderstanding the uncertainty of another agent about a particular statement,\nindependently of the model's own certainty about that statement. We find that 7\nout of 10 models are able to map uncertainty expressions to probabilistic\nresponses in a human-like manner. However, we observe systematically different\nbehavior depending on whether a statement is actually true or false. This\nsensitivity indicates that language models are substantially more susceptible\nto bias based on their prior knowledge (as compared to humans). These findings\nraise important questions and have broad implications for human-AI and AI-AI\ncommunication.\n","authors":["Catarina G Belem","Markelle Kelly","Mark Steyvers","Sameer Singh","Padhraic Smyth"],"pdf_url":"https://arxiv.org/pdf/2407.15814v2.pdf","comment":"Accepted at EMNLP 2024 (Main)"},{"id":"http://arxiv.org/abs/2410.03728v2","updated":"2024-11-07T17:19:26Z","published":"2024-09-30T10:50:12Z","title":"Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic\n  Analysis","summary":"  QUIC, a new and increasingly used transport protocol, addresses and resolves\nthe limitations of TCP by offering improved security, performance, and features\nsuch as stream multiplexing and connection migration. These features, however,\nalso present challenges for network operators who need to monitor and analyze\nweb traffic. In this paper, we introduce VisQUIC, a labeled dataset comprising\nover 100,000 QUIC traces from more than 44,000 websites (URLs), collected over\na four-month period. These traces provide the foundation for generating more\nthan seven million images, with configurable parameters of window length, pixel\nresolution, normalization, and labels. These images enable an observer looking\nat the interactions between a client and a server to analyze and gain insights\nabout QUIC encrypted connections. To illustrate the dataset's potential, we\noffer a use-case example of an observer estimating the number of HTTP/3\nresponses/requests pairs in a given QUIC, which can reveal server behavior,\nclient--server interactions, and the load imposed by an observed connection. We\nformulate the problem as a discrete regression problem, train a machine\nlearning (ML) model for it, and then evaluate it using the proposed dataset on\nan example use case.\n","authors":["Barak Gahtan","Robert J. Shahla","Alex M. Bronstein","Reuven Cohen"],"pdf_url":"https://arxiv.org/pdf/2410.03728v2.pdf","comment":"The dataset and the supplementary material can be provided upon\n  request"},{"id":"http://arxiv.org/abs/2310.09254v4","updated":"2024-11-07T17:14:38Z","published":"2023-10-13T17:12:04Z","title":"GENOT: Entropic (Gromov) Wasserstein Flow Matching with Applications to\n  Single-Cell Genomics","summary":"  Single-cell genomics has significantly advanced our understanding of cellular\nbehavior, catalyzing innovations in treatments and precision medicine. However,\nsingle-cell sequencing technologies are inherently destructive and can only\nmeasure a limited array of data modalities simultaneously. This limitation\nunderscores the need for new methods capable of realigning cells. Optimal\ntransport (OT) has emerged as a potent solution, but traditional discrete\nsolvers are hampered by scalability, privacy, and out-of-sample estimation\nissues. These challenges have spurred the development of neural network-based\nsolvers, known as neural OT solvers, that parameterize OT maps. Yet, these\nmodels often lack the flexibility needed for broader life science applications.\nTo address these deficiencies, our approach learns stochastic maps (i.e.\ntransport plans), allows for any cost function, relaxes mass conservation\nconstraints and integrates quadratic solvers to tackle the complex challenges\nposed by the (Fused) Gromov-Wasserstein problem. Utilizing flow matching as a\nbackbone, our method offers a flexible and effective framework. We demonstrate\nits versatility and robustness through applications in cell development\nstudies, cellular drug response modeling, and cross-modality cell translation,\nillustrating significant potential for enhancing therapeutic strategies.\n","authors":["Dominik Klein","Théo Uscidda","Fabian Theis","Marco Cuturi"],"pdf_url":"https://arxiv.org/pdf/2310.09254v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04876v1","updated":"2024-11-07T17:13:16Z","published":"2024-11-07T17:13:16Z","title":"Non-Euclidean Mixture Model for Social Network Embedding","summary":"  It is largely agreed that social network links are formed due to either\nhomophily or social influence. Inspired by this, we aim at understanding the\ngeneration of links via providing a novel embedding-based graph formation\nmodel. Different from existing graph representation learning, where link\ngeneration probabilities are defined as a simple function of the corresponding\nnode embeddings, we model the link generation as a mixture model of the two\nfactors. In addition, we model the homophily factor in spherical space and the\ninfluence factor in hyperbolic space to accommodate the fact that (1) homophily\nresults in cycles and (2) influence results in hierarchies in networks. We also\ndesign a special projection to align these two spaces. We call this model\nNon-Euclidean Mixture Model, i.e., NMM. We further integrate NMM with our\nnon-Euclidean graph variational autoencoder (VAE) framework, NMM-GNN. NMM-GNN\nlearns embeddings through a unified framework which uses non-Euclidean GNN\nencoders, non-Euclidean Gaussian priors, a non-Euclidean decoder, and a novel\nspace unification loss component to unify distinct non-Euclidean geometric\nspaces. Experiments on public datasets show NMM-GNN significantly outperforms\nstate-of-the-art baselines on social network generation and classification\ntasks, demonstrating its ability to better explain how the social network is\nformed.\n","authors":["Roshni G. Iyer","Yewen Wang","Wei Wang","Yizhou Sun"],"pdf_url":"https://arxiv.org/pdf/2411.04876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16803v2","updated":"2024-11-07T17:10:15Z","published":"2024-07-23T19:06:44Z","title":"C3T: Cross-modal Transfer Through Time for Human Action Recognition","summary":"  In order to unlock the potential of diverse sensors, we investigate a method\nto transfer knowledge between modalities using the structure of a unified\nmultimodal representation space for Human Action Recognition (HAR). We\nformalize and explore an understudied cross-modal transfer setting we term\nUnsupervised Modality Adaptation (UMA), where the modality used in testing is\nnot used in supervised training, i.e. zero labeled instances of the test\nmodality are available during training. We develop three methods to perform\nUMA: Student-Teacher (ST), Contrastive Alignment (CA), and Cross-modal Transfer\nThrough Time (C3T). Our extensive experiments on various camera+IMU datasets\ncompare these methods to each other in the UMA setting, and to their empirical\nupper bound in the supervised setting. The results indicate C3T is the most\nrobust and highest performing by at least a margin of 8%, and nears the\nsupervised setting performance even in the presence of temporal noise. This\nmethod introduces a novel mechanism for aligning signals across time-varying\nlatent vectors, extracted from the receptive field of temporal convolutions.\nOur findings suggest that C3T has significant potential for developing\ngeneralizable models for time-series sensor data, opening new avenues for\nmulti-modal learning in various applications.\n","authors":["Abhi Kamboj","Anh Duy Nguyen","Minh Do"],"pdf_url":"https://arxiv.org/pdf/2407.16803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04867v1","updated":"2024-11-07T16:59:32Z","published":"2024-11-07T16:59:32Z","title":"Think Smart, Act SMARL! Analyzing Probabilistic Logic Driven Safety in\n  Multi-Agent Reinforcement Learning","summary":"  An important challenge for enabling the deployment of reinforcement learning\n(RL) algorithms in the real world is safety. This has resulted in the recent\nresearch field of Safe RL, which aims to learn optimal policies that are safe.\nOne successful approach in that direction is probabilistic logic shields (PLS),\na model-based Safe RL technique that uses formal specifications based on\nprobabilistic logic programming, constraining an agent's policy to comply with\nthose specifications in a probabilistic sense. However, safety is inherently a\nmulti-agent concept, since real-world environments often involve multiple\nagents interacting simultaneously, leading to a complex system which is hard to\ncontrol. Moreover, safe multi-agent RL (Safe MARL) is still underexplored. In\norder to address this gap, in this paper we ($i$) introduce Shielded MARL\n(SMARL) by extending PLS to MARL -- in particular, we introduce Probabilistic\nLogic Temporal Difference Learning (PLTD) to enable shielded independent\nQ-learning (SIQL), and introduce shielded independent PPO (SIPPO) using\nprobabilistic logic policy gradients; ($ii$) show its positive effect and use\nas an equilibrium selection mechanism in various game-theoretic environments\nincluding two-player simultaneous games, extensive-form games, stochastic\ngames, and some grid-world extensions in terms of safety, cooperation, and\nalignment with normative behaviors; and ($iii$) look into the asymmetric case\nwhere only one agent is shielded, and show that the shielded agent has a\nsignificant influence on the unshielded one, providing further evidence of\nSMARL's ability to enhance safety and cooperation in diverse multi-agent\nenvironments.\n","authors":["Satchit Chatterji","Erman Acar"],"pdf_url":"https://arxiv.org/pdf/2411.04867v1.pdf","comment":"19 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.13835v2","updated":"2024-11-07T16:57:02Z","published":"2024-10-17T17:54:06Z","title":"Active-Dormant Attention Heads: Mechanistically Demystifying\n  Extreme-Token Phenomena in LLMs","summary":"  Practitioners have consistently observed three puzzling phenomena in\ntransformer-based large language models (LLMs): attention sinks, value-state\ndrains, and residual-state peaks, collectively referred to as extreme-token\nphenomena. These phenomena are characterized by certain so-called \"sink tokens\"\nreceiving disproportionately high attention weights, exhibiting significantly\nsmaller value states, and having much larger residual-state norms than those of\nother tokens. These extreme tokens give rise to various challenges in LLM\ninference, quantization, and interpretability.\n  We elucidate the mechanisms behind extreme-token phenomena. First, we show\nthat these phenomena arise in very simple architectures -- transformers with\none to three layers -- trained on a toy model, the Bigram-Backcopy (BB) task.\nIn this setting, we identify an active-dormant mechanism, where attention heads\nbecome sinks for specific input domains while remaining non-sinks for others.\nOur theoretical analysis of the training dynamics reveals that these phenomena\nare driven by a mutual reinforcement mechanism. Building on these insights, we\npropose strategies to mitigate extreme-token phenomena during pretraining,\nincluding replacing softmax with ReLU and Adam with SGD. Next, we extend our\nanalysis to pretrained LLMs, including Llama and OLMo, showing that many\nattention heads exhibit a similar active-dormant mechanism as in the BB task,\nand that the mutual reinforcement mechanism also governs the emergence of\nextreme-token phenomena during LLM pretraining. Our results reveal that many of\nthe static and dynamic properties of extreme-token phenomena predicted by the\nBB task align with observations in pretrained LLMs.\n","authors":["Tianyu Guo","Druv Pai","Yu Bai","Jiantao Jiao","Michael I. Jordan","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2410.13835v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04863v1","updated":"2024-11-07T16:54:54Z","published":"2024-11-07T16:54:54Z","title":"OneProt: Towards Multi-Modal Protein Foundation Models","summary":"  Recent AI advances have enabled multi-modal systems to model and translate\ndiverse information spaces. Extending beyond text and vision, we introduce\nOneProt, a multi-modal AI for proteins that integrates structural, sequence,\nalignment, and binding site data. Using the ImageBind framework, OneProt aligns\nthe latent spaces of modality encoders along protein sequences. It demonstrates\nstrong performance in retrieval tasks and surpasses state-of-the-art methods in\nvarious downstream tasks, including metal ion binding classification,\ngene-ontology annotation, and enzyme function prediction. This work expands\nmulti-modal capabilities in protein models, paving the way for applications in\ndrug discovery, biocatalytic reaction planning, and protein engineering.\n","authors":["Klemens Flöge","Srisruthi Udayakumar","Johanna Sommer","Marie Piraud","Stefan Kesselheim","Vincent Fortuin","Stephan Günneman","Karel J van der Weg","Holger Gohlke","Alina Bazarova","Erinc Merdivan"],"pdf_url":"https://arxiv.org/pdf/2411.04863v1.pdf","comment":"28 pages, 15 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.12530v3","updated":"2024-11-07T16:52:39Z","published":"2023-11-21T11:21:53Z","title":"An efficient likelihood-free Bayesian inference method based on\n  sequential neural posterior estimation","summary":"  Sequential neural posterior estimation (SNPE) techniques have been recently\nproposed for dealing with simulation-based models with intractable likelihoods.\nUnlike approximate Bayesian computation, SNPE techniques learn the posterior\nfrom sequential simulation using neural network-based conditional density\nestimators by minimizing a specific loss function. The SNPE method proposed by\nLueckmann et al. (2017) used a calibration kernel to boost the sample weights\naround the observed data, resulting in a concentrated loss function. However,\nthe use of calibration kernels may increase the variances of both the empirical\nloss and its gradient, making the training inefficient. To improve the\nstability of SNPE, this paper proposes to use an adaptive calibration kernel\nand several variance reduction techniques. The proposed method greatly speeds\nup the process of training and provides a better approximation of the posterior\nthan the original SNPE method and some existing competitors as confirmed by\nnumerical experiments. We also manage to demonstrate the superiority of the\nproposed method for a high-dimensional model with real-world dataset.\n","authors":["Yifei Xiong","Xiliang Yang","Sanguo Zhang","Zhijian He"],"pdf_url":"https://arxiv.org/pdf/2311.12530v3.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.04855v1","updated":"2024-11-07T16:47:06Z","published":"2024-11-07T16:47:06Z","title":"Clinicians' Voice: Fundamental Considerations for XAI in Healthcare","summary":"  Explainable AI (XAI) holds the promise of advancing the implementation and\nadoption of AI-based tools in practice, especially in high-stakes environments\nlike healthcare. However, most of the current research is disconnected from its\npractical applications and lacks input of end users. To address this, we\nconducted semi-structured interviews with clinicians to discuss their thoughts,\nhopes, and concerns. We find that clinicians generally think positively about\ndeveloping AI-based tools for clinical practice, but they have concerns about\nhow these will fit into their workflow and how it will impact clinician-patient\nrelations. We further identify education of clinicians on AI as a crucial\nfactor for the success of AI in healthcare and highlight aspects clinicians are\nlooking for in (X)AI-based tools. In contrast to other studies, we take on a\nholistic and exploratory perspective to identify general requirements, which is\nnecessary before moving on to testing specific (X)AI products for healthcare.\n","authors":["T. E. Röber","R. Goedhart","S. İ. Birbil"],"pdf_url":"https://arxiv.org/pdf/2411.04855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04852v1","updated":"2024-11-07T16:39:29Z","published":"2024-11-07T16:39:29Z","title":"Conformalized Credal Regions for Classification with Ambiguous Ground\n  Truth","summary":"  An open question in \\emph{Imprecise Probabilistic Machine Learning} is how to\nempirically derive a credal region (i.e., a closed and convex family of\nprobabilities on the output space) from the available data, without any prior\nknowledge or assumption. In classification problems, credal regions are a tool\nthat is able to provide provable guarantees under realistic assumptions by\ncharacterizing the uncertainty about the distribution of the labels. Building\non previous work, we show that credal regions can be directly constructed using\nconformal methods. This allows us to provide a novel extension of classical\nconformal prediction to problems with ambiguous ground truth, that is, when the\nexact labels for given inputs are not exactly known. The resulting construction\nenjoys desirable practical and theoretical properties: (i) conformal coverage\nguarantees, (ii) smaller prediction sets (compared to classical conformal\nprediction regions) and (iii) disentanglement of uncertainty sources\n(epistemic, aleatoric). We empirically verify our findings on both synthetic\nand real datasets.\n","authors":["Michele Caprio","David Stutz","Shuo Li","Arnaud Doucet"],"pdf_url":"https://arxiv.org/pdf/2411.04852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04845v1","updated":"2024-11-07T16:32:50Z","published":"2024-11-07T16:32:50Z","title":"Asymptotic regularity of a generalised stochastic Halpern scheme with\n  applications","summary":"  We provide abstract, general and highly uniform rates of asymptotic\nregularity for a generalized stochastic Halpern-style iteration, which\nincorporates a second mapping in the style of a Krasnoselskii-Mann iteration.\nThis iteration is general in two ways: First, it incorporates stochasticity in\na completely abstract way rather than fixing a sampling method; secondly, it\nincludes as special cases stochastic versions of various schemes from the\noptimization literature, including Halpern's iteration as well as a\nKrasnoselskii-Mann iteration with Tikhonov regularization terms in the sense of\nBo\\c{t}, Csetnek and Meier. For these particular cases, we in particular obtain\nlinear rates of asymptotic regularity, matching (or improving) the currently\nbest known rates for these iterations in stochastic optimization, and quadratic\nrates of asymptotic regularity are obtained in the context of inner product\nspaces for the general iteration. We utilize these rates to give bounds on the\noracle complexity of such iterations under suitable variance assumptions and\nbatching strategies, again presented in an abstract style. Finally, we sketch\nhow the schemes presented here can be instantiated in the context of\nreinforcement learning to yield novel methods for Q-learning.\n","authors":["Nicholas Pischke","Thomas Powell"],"pdf_url":"https://arxiv.org/pdf/2411.04845v1.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2411.04843v1","updated":"2024-11-07T16:31:31Z","published":"2024-11-07T16:31:31Z","title":"Learning in Budgeted Auctions with Spacing Objectives","summary":"  In many repeated auction settings, participants care not only about how\nfrequently they win but also how their winnings are distributed over time. This\nproblem arises in various practical domains where avoiding congested demand is\ncrucial, such as online retail sales and compute services, as well as in\nadvertising campaigns that require sustained visibility over time. We introduce\na simple model of this phenomenon, modeling it as a budgeted auction where the\nvalue of a win is a concave function of the time since the last win. This\nimplies that for a given number of wins, even spacing over time is optimal. We\nalso extend our model and results to the case when not all wins result in\n\"conversions\" (realization of actual gains), and the probability of conversion\ndepends on a context. The goal is to maximize and evenly space conversions\nrather than just wins.\n  We study the optimal policies for this setting in second-price auctions and\noffer learning algorithms for the bidders that achieve low regret against the\noptimal bidding policy in a Bayesian online setting. Our main result is a\ncomputationally efficient online learning algorithm that achieves $\\tilde\nO(\\sqrt T)$ regret. We achieve this by showing that an infinite-horizon Markov\ndecision process (MDP) with the budget constraint in expectation is essentially\nequivalent to our problem, even when limiting that MDP to a very small number\nof states. The algorithm achieves low regret by learning a bidding policy that\nchooses bids as a function of the context and the system's state, which will be\nthe time elapsed since the last win (or conversion). We show that\nstate-independent strategies incur linear regret even without uncertainty of\nconversions. We complement this by showing that there are state-independent\nstrategies that, while still having linear regret, achieve a $(1-\\frac 1 e)$\napproximation to the optimal reward.\n","authors":["Giannis Fikioris","Robert Kleinberg","Yoav Kolumbus","Raunak Kumar","Yishay Mansour","Éva Tardos"],"pdf_url":"https://arxiv.org/pdf/2411.04843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04838v1","updated":"2024-11-07T16:29:03Z","published":"2024-11-07T16:29:03Z","title":"Machine learning and optimization-based approaches to duality in\n  statistical physics","summary":"  The notion of duality -- that a given physical system can have two different\nmathematical descriptions -- is a key idea in modern theoretical physics.\nEstablishing a duality in lattice statistical mechanics models requires the\nconstruction of a dual Hamiltonian and a map from the original to the dual\nobservables. By using simple neural networks to parameterize these maps and\nintroducing a loss function that penalises the difference between correlation\nfunctions in original and dual models, we formulate the process of duality\ndiscovery as an optimization problem. We numerically solve this problem and\nshow that our framework can rediscover the celebrated Kramers-Wannier duality\nfor the 2d Ising model, reconstructing the known mapping of temperatures. We\nalso discuss an alternative approach which uses known features of the mapping\nof topological lines to reduce the problem to optimizing the couplings in a\ndual Hamiltonian, and explore next-to-nearest neighbour deformations of the 2d\nIsing duality. We discuss future directions and prospects for discovering new\ndualities within this framework.\n","authors":["Andrea E. V. Ferrari","Prateek Gupta","Nabil Iqbal"],"pdf_url":"https://arxiv.org/pdf/2411.04838v1.pdf","comment":"27 pages + appendices, lots of plots"},{"id":"http://arxiv.org/abs/2411.04832v1","updated":"2024-11-07T16:13:54Z","published":"2024-11-07T16:13:54Z","title":"Plasticity Loss in Deep Reinforcement Learning: A Survey","summary":"  Akin to neuroplasticity in human brains, the plasticity of deep neural\nnetworks enables their quick adaption to new data. This makes plasticity\nparticularly crucial for deep Reinforcement Learning (RL) agents: Once\nplasticity is lost, an agent's performance will inevitably plateau because it\ncannot improve its policy to account for changes in the data distribution,\nwhich are a necessary consequence of its learning process. Thus, developing\nwell-performing and sample-efficient agents hinges on their ability to remain\nplastic during training. Furthermore, the loss of plasticity can be connected\nto many other issues plaguing deep RL, such as training instabilities, scaling\nfailures, overestimation bias, and insufficient exploration. With this survey,\nwe aim to provide an overview of the emerging research on plasticity loss for\nacademics and practitioners of deep reinforcement learning. First, we propose a\nunified definition of plasticity loss based on recent works, relate it to\ndefinitions from the literature, and discuss metrics for measuring plasticity\nloss. Then, we categorize and discuss numerous possible causes of plasticity\nloss before reviewing currently employed mitigation strategies. Our taxonomy is\nthe first systematic overview of the current state of the field. Lastly, we\ndiscuss prevalent issues within the literature, such as a necessity for broader\nevaluation, and provide recommendations for future research, like gaining a\nbetter understanding of an agent's neural activity and behavior.\n","authors":["Timo Klein","Lukas Miklautz","Kevin Sidak","Claudia Plant","Sebastian Tschiatschek"],"pdf_url":"https://arxiv.org/pdf/2411.04832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14837v2","updated":"2024-11-07T16:13:14Z","published":"2024-10-18T19:17:48Z","title":"Topological obstruction to the training of shallow ReLU neural networks","summary":"  Studying the interplay between the geometry of the loss landscape and the\noptimization trajectories of simple neural networks is a fundamental step for\nunderstanding their behavior in more complex settings. This paper reveals the\npresence of topological obstruction in the loss landscape of shallow ReLU\nneural networks trained using gradient flow. We discuss how the homogeneous\nnature of the ReLU activation function constrains the training trajectories to\nlie on a product of quadric hypersurfaces whose shape depends on the particular\ninitialization of the network's parameters. When the neural network's output is\na single scalar, we prove that these quadrics can have multiple connected\ncomponents, limiting the set of reachable parameters during training. We\nanalytically compute the number of these components and discuss the possibility\nof mapping one to the other through neuron rescaling and permutation. In this\nsimple setting, we find that the non-connectedness results in a topological\nobstruction, which, depending on the initialization, can make the global\noptimum unreachable. We validate this result with numerical experiments.\n","authors":["Marco Nurisso","Pierrick Leroy","Francesco Vaccarino"],"pdf_url":"https://arxiv.org/pdf/2410.14837v2.pdf","comment":"23 pages, 5 figures, Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2409.00220v2","updated":"2024-11-07T16:09:14Z","published":"2024-08-30T19:25:28Z","title":"Learning Latent Space Dynamics with Model-Form Uncertainties: A\n  Stochastic Reduced-Order Modeling Approach","summary":"  This paper presents a probabilistic approach to represent and quantify\nmodel-form uncertainties in the reduced-order modeling of complex systems using\noperator inference techniques. Such uncertainties can arise in the selection of\nan appropriate state-space representation, in the projection step that\nunderlies many reduced-order modeling methods, or as a byproduct of\nconsiderations made during training, to name a few. Following previous works in\nthe literature, the proposed method captures these uncertainties by expanding\nthe approximation space through the randomization of the projection matrix.\nThis is achieved by combining Riemannian projection and retraction operators -\nacting on a subset of the Stiefel manifold - with an information-theoretic\nformulation. The efficacy of the approach is assessed on canonical problems in\nfluid mechanics by identifying and quantifying the impact of model-form\nuncertainties on the inferred operators.\n","authors":["Jin Yi Yong","Rudy Geelen","Johann Guilleminot"],"pdf_url":"https://arxiv.org/pdf/2409.00220v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04826v1","updated":"2024-11-07T16:07:00Z","published":"2024-11-07T16:07:00Z","title":"D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic\n  Scenes","summary":"  Depth estimation is a crucial technology in robotics. Recently,\nself-supervised depth estimation methods have demonstrated great potential as\nthey can efficiently leverage large amounts of unlabelled real-world data.\nHowever, most existing methods are designed under the assumption of static\nscenes, which hinders their adaptability in dynamic environments. To address\nthis issue, we present D$^3$epth, a novel method for self-supervised depth\nestimation in dynamic scenes. It tackles the challenge of dynamic objects from\ntwo key perspectives. First, within the self-supervised framework, we design a\nreprojection constraint to identify regions likely to contain dynamic objects,\nallowing the construction of a dynamic mask that mitigates their impact at the\nloss level. Second, for multi-frame depth estimation, we introduce a cost\nvolume auto-masking strategy that leverages adjacent frames to identify regions\nassociated with dynamic objects and generate corresponding masks. This provides\nguidance for subsequent processes. Furthermore, we propose a spectral entropy\nuncertainty module that incorporates spectral entropy to guide uncertainty\nestimation during depth fusion, effectively addressing issues arising from cost\nvolume computation in dynamic environments. Extensive experiments on KITTI and\nCityscapes datasets demonstrate that the proposed method consistently\noutperforms existing self-supervised monocular depth estimation baselines. Code\nis available at \\url{https://github.com/Csyunling/D3epth}.\n","authors":["Siyu Chen","Hong Liu","Wenhao Li","Ying Zhu","Guoquan Wang","Jianbing Wu"],"pdf_url":"https://arxiv.org/pdf/2411.04826v1.pdf","comment":"Open sourced"},{"id":"http://arxiv.org/abs/2411.04825v1","updated":"2024-11-07T16:06:00Z","published":"2024-11-07T16:06:00Z","title":"VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and\n  Benchmark Models","summary":"  Existing text simplification or paraphrase datasets mainly focus on\nsentence-level text generation in a general domain. These datasets are\ntypically developed without using domain knowledge. In this paper, we release a\nnovel dataset, VTechAGP, which is the first academic-to-general-audience text\nparaphrase dataset consisting of 4,938 document-level these and dissertation\nacademic and general-audience abstract pairs from 8 colleges authored over 25\nyears. We also propose a novel dynamic soft prompt generative language model,\nDSPT5. For training, we leverage a contrastive-generative loss function to\nlearn the keyword vectors in the dynamic prompt. For inference, we adopt a\ncrowd-sampling decoding strategy at both semantic and structural levels to\nfurther select the best output candidate. We evaluate DSPT5 and various\nstate-of-the-art large language models (LLMs) from multiple perspectives.\nResults demonstrate that the SOTA LLMs does not provide satisfactory outcomes,\nwhile the lightweight DSPT5 can achieve competitive results. To the best of our\nknowledge, we are the first to build a benchmark dataset and solutions for\nacademic-to-general-audience text paraphrase dataset.\n","authors":["Ming Cheng","Jiaying Gong","Chenhan Yuan","William A. Ingram","Edward Fox","Hoda Eldardiry"],"pdf_url":"https://arxiv.org/pdf/2411.04825v1.pdf","comment":"21 pages, 3 figures"},{"id":"http://arxiv.org/abs/2110.14427v5","updated":"2024-11-07T15:59:59Z","published":"2021-10-27T13:38:25Z","title":"The ODE Method for Asymptotic Statistics in Stochastic Approximation and\n  Reinforcement Learning","summary":"  The paper concerns the $d$-dimensional stochastic approximation recursion, $$\n\\theta_{n+1}= \\theta_n + \\alpha_{n + 1} f(\\theta_n, \\Phi_{n+1}) $$ where $ \\{\n\\Phi_n \\}$ is a stochastic process on a general state space, satisfying a\nconditional Markov property that allows for parameter-dependent noise. The main\nresults are established under additional conditions on the mean flow and a\nversion of the Donsker-Varadhan Lyapunov drift condition known as (DV3):\n  {(i)} An appropriate Lyapunov function is constructed that implies\nconvergence of the estimates in $L_4$.\n  {(ii)} A functional central limit theorem (CLT) is established, as well as\nthe usual one-dimensional CLT for the normalized error. Moment bounds combined\nwith the CLT imply convergence of the normalized covariance $\\textsf{E} [ z_n\nz_n^T ]$ to the asymptotic covariance in the CLT, where $z_n{=:}\n(\\theta_n-\\theta^*)/\\sqrt{\\alpha_n}$.\n  {(iii)} The CLT holds for the normalized version $z^{\\text{PR}}_n{=:}\n\\sqrt{n} [\\theta^{\\text{PR}}_n -\\theta^*]$, of the averaged parameters\n$\\theta^{\\text{PR}}_n {=:} n^{-1} \\sum_{k=1}^n\\theta_k$, subject to standard\nassumptions on the step-size. Moreover, the covariance in the CLT coincides\nwith the minimal covariance of Polyak and Ruppert.\n  {(iv)} An example is given where $f$ and $\\bar{f}$ are linear in $\\theta$,\nand $\\Phi$ is a geometrically ergodic Markov chain but does not satisfy (DV3).\nWhile the algorithm is convergent, the second moment of $\\theta_n$ is unbounded\nand in fact diverges.\n  {\\bf This arXiv version 3 represents a major extension of the results in\nprior versions.} The main results now allow for parameter-dependent noise, as\nis often the case in applications to reinforcement learning.\n","authors":["Vivek Borkar","Shuhang Chen","Adithya Devraj","Ioannis Kontoyiannis","Sean Meyn"],"pdf_url":"https://arxiv.org/pdf/2110.14427v5.pdf","comment":"2 figures"},{"id":"http://arxiv.org/abs/2311.01968v2","updated":"2024-11-07T15:52:24Z","published":"2023-11-03T15:10:05Z","title":"Latent Diffusion Model for Conditional Reservoir Facies Generation","summary":"  Creating accurate and geologically realistic reservoir facies based on\nlimited measurements is crucial for field development and reservoir management,\nespecially in the oil and gas sector. Traditional two-point geostatistics,\nwhile foundational, often struggle to capture complex geological patterns.\nMulti-point statistics offers more flexibility, but comes with its own\nchallenges related to pattern configurations and storage limits. With the rise\nof Generative Adversarial Networks (GANs) and their success in various fields,\nthere has been a shift towards using them for facies generation. However,\nrecent advances in the computer vision domain have shown the superiority of\ndiffusion models over GANs. Motivated by this, a novel Latent Diffusion Model\nis proposed, which is specifically designed for conditional generation of\nreservoir facies. The proposed model produces high-fidelity facies realizations\nthat rigorously preserve conditioning data. It significantly outperforms a\nGAN-based alternative. Our implementation on GitHub:\n\\url{https://github.com/ML4ITS/Latent-Diffusion-Model-for-Conditional-Reservoir-Facies-Generation}.\n","authors":["Daesoo Lee","Oscar Ovanger","Jo Eidsvik","Erlend Aune","Jacob Skauvold","Ragnar Hauge"],"pdf_url":"https://arxiv.org/pdf/2311.01968v2.pdf","comment":"accepted in Computers & Geosciences"},{"id":"http://arxiv.org/abs/2411.04814v1","updated":"2024-11-07T15:50:42Z","published":"2024-11-07T15:50:42Z","title":"A Simple Packing Algorithm for Optimized Mapping of Artificial Neural\n  Networks onto Non-Volatile Memory Cross-Bar Arrays","summary":"  Neuromorphic computing with crossbar arrays has emerged as a promising\nalternative to improve computing efficiency for machine learning. Previous work\nhas focused on implementing crossbar arrays to perform basic mathematical\noperations. However, in this paper, we explore the impact of mapping the layers\nof an artificial neural network onto physical cross-bar arrays arranged in\ntiles across a chip. We have developed a simplified mapping algorithm to\ndetermine the number of physical tiles, with fixed optimal array dimensions,\nand to estimate the minimum area occupied by these tiles for a given design\nobjective. This simplified algorithm is compared with conventional binary\nlinear optimization, which solves the equivalent bin-packing problem. We have\nfound that the optimum solution is not necessarily related to the minimum\nnumber of tiles; rather, it is shown to be an interaction between tile array\ncapacity and the scaling properties of its peripheral circuits. Additionally,\nwe have discovered that square arrays are not always the best choice for\noptimal mapping, and that performance optimization comes at the cost of total\ntile area\n","authors":["W. Haensch"],"pdf_url":"https://arxiv.org/pdf/2411.04814v1.pdf","comment":"24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.04812v1","updated":"2024-11-07T15:49:53Z","published":"2024-11-07T15:49:53Z","title":"Soft Hoeffding Tree: A Transparent and Differentiable Model on Data\n  Streams","summary":"  We propose soft Hoeffding trees (SoHoT) as a new differentiable and\ntransparent model for possibly infinite and changing data streams. Stream\nmining algorithms such as Hoeffding trees grow based on the incoming data\nstream, but they currently lack the adaptability of end-to-end deep learning\nsystems. End-to-end learning can be desirable if a feature representation is\nlearned by a neural network and used in a tree, or if the outputs of trees are\nfurther processed in a deep learning model or workflow. Different from\nHoeffding trees, soft trees can be integrated into such systems due to their\ndifferentiability, but are neither transparent nor explainable. Our novel model\ncombines the extensibility and transparency of Hoeffding trees with the\ndifferentiability of soft trees. We introduce a new gating function to regulate\nthe balance between univariate and multivariate splits in the tree. Experiments\nare performed on 20 data streams, comparing SoHoT to standard Hoeffding trees,\nHoeffding trees with limited complexity, and soft trees applying a sparse\nactivation function for sample routing. The results show that soft Hoeffding\ntrees outperform Hoeffding trees in estimating class probabilities and, at the\nsame time, maintain transparency compared to soft trees, with relatively small\nlosses in terms of AUROC and cross-entropy. We also demonstrate how to trade\noff transparency against performance using a hyperparameter, obtaining\nunivariate splits at one end of the spectrum and multivariate splits at the\nother.\n","authors":["Kirsten Köbschall","Lisa Hartung","Stefan Kramer"],"pdf_url":"https://arxiv.org/pdf/2411.04812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04811v1","updated":"2024-11-07T15:49:03Z","published":"2024-11-07T15:49:03Z","title":"Defending Deep Regression Models against Backdoor Attacks","summary":"  Deep regression models are used in a wide variety of safety-critical\napplications, but are vulnerable to backdoor attacks. Although many defenses\nhave been proposed for classification models, they are ineffective as they do\nnot consider the uniqueness of regression models. First, the outputs of\nregression models are continuous values instead of discretized labels. Thus,\nthe potential infected target of a backdoored regression model has infinite\npossibilities, which makes it impossible to be determined by existing defenses.\nSecond, the backdoor behavior of backdoored deep regression models is triggered\nby the activation values of all the neurons in the feature space, which makes\nit difficult to be detected and mitigated using existing defenses. To resolve\nthese problems, we propose DRMGuard, the first defense to identify if a deep\nregression model in the image domain is backdoored or not. DRMGuard formulates\nthe optimization problem for reverse engineering based on the unique\noutput-space and feature-space characteristics of backdoored deep regression\nmodels. We conduct extensive evaluations on two regression tasks and four\ndatasets. The results show that DRMGuard can consistently defend against\nvarious backdoor attacks. We also generalize four state-of-the-art defenses\ndesigned for classifiers to regression models, and compare DRMGuard with them.\nThe results show that DRMGuard significantly outperforms all those defenses.\n","authors":["Lingyu Du","Yupei Liu","Jinyuan Jia","Guohao Lan"],"pdf_url":"https://arxiv.org/pdf/2411.04811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12921v3","updated":"2024-11-07T15:44:43Z","published":"2023-02-24T22:38:54Z","title":"Pre-Finetuning for Few-Shot Emotional Speech Recognition","summary":"  Speech models have long been known to overfit individual speakers for many\nclassification tasks. This leads to poor generalization in settings where the\nspeakers are out-of-domain or out-of-distribution, as is common in production\nenvironments. We view speaker adaptation as a few-shot learning problem and\npropose investigating transfer learning approaches inspired by recent success\nwith pre-trained models in natural language tasks. We propose pre-finetuning\nspeech models on difficult tasks to distill knowledge into few-shot downstream\nclassification objectives. We pre-finetune Wav2Vec2.0 on every permutation of\nfour multiclass emotional speech recognition corpora and evaluate our\npre-finetuned models through 33,600 few-shot fine-tuning trials on the\nEmotional Speech Dataset.\n","authors":["Maximillian Chen","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2302.12921v3.pdf","comment":"Published at INTERSPEECH 2023. 5 pages, 4 figures. Code available at\n  https://github.com/maxlchen/Speech-PreFinetuning"},{"id":"http://arxiv.org/abs/2403.00867v3","updated":"2024-11-07T15:41:38Z","published":"2024-03-01T03:29:54Z","title":"Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by\n  Exploring Refusal Loss Landscapes","summary":"  Large Language Models (LLMs) are becoming a prominent generative AI tool,\nwhere the user enters a query and the LLM generates an answer. To reduce harm\nand misuse, efforts have been made to align these LLMs to human values using\nadvanced training techniques such as Reinforcement Learning from Human Feedback\n(RLHF). However, recent studies have highlighted the vulnerability of LLMs to\nadversarial jailbreak attempts aiming at subverting the embedded safety\nguardrails. To address this challenge, this paper defines and investigates the\nRefusal Loss of LLMs and then proposes a method called Gradient Cuff to detect\njailbreak attempts. Gradient Cuff exploits the unique properties observed in\nthe refusal loss landscape, including functional values and its smoothness, to\ndesign an effective two-step detection strategy. Experimental results on two\naligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak\nattacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can\nsignificantly improve the LLM's rejection capability for malicious jailbreak\nqueries, while maintaining the model's performance for benign user queries by\nadjusting the detection threshold.\n","authors":["Xiaomeng Hu","Pin-Yu Chen","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2403.00867v3.pdf","comment":"Accepted by NeurIPS 2024. Project page:\n  https://huggingface.co/spaces/TrustSafeAI/GradientCuff-Jailbreak-Defense"},{"id":"http://arxiv.org/abs/2406.09014v5","updated":"2024-11-07T15:41:04Z","published":"2024-06-13T11:38:58Z","title":"Deep learning empowered sensor fusion boosts infant movement\n  classification","summary":"  To assess the integrity of the developing nervous system, the Prechtl general\nmovement assessment (GMA) is recognized for its clinical value in diagnosing\nneurological impairments in early infancy. GMA has been increasingly augmented\nthrough machine learning approaches intending to scale-up its application,\ncircumvent costs in the training of human assessors and further standardize\nclassification of spontaneous motor patterns. Available deep learning tools,\nall of which are based on single sensor modalities, are however still\nconsiderably inferior to that of well-trained human assessors. These approaches\nare hardly comparable as all models are designed, trained and evaluated on\nproprietary/silo-data sets. With this study we propose a sensor fusion approach\nfor assessing fidgety movements (FMs). FMs were recorded from 51 typically\ndeveloping participants. We compared three different sensor modalities\n(pressure, inertial, and visual sensors). Various combinations and two sensor\nfusion approaches (late and early fusion) for infant movement classification\nwere tested to evaluate whether a multi-sensor system outperforms single\nmodality assessments. Convolutional neural network (CNN) architectures were\nused to classify movement patterns. The performance of the three-sensor fusion\n(classification accuracy of 94.5%) was significantly higher than that of any\nsingle modality evaluated. We show that the sensor fusion approach is a\npromising avenue for automated classification of infant motor patterns. The\ndevelopment of a robust sensor fusion system may significantly enhance AI-based\nearly recognition of neurofunctions, ultimately facilitating automated early\ndetection of neurodevelopmental conditions.\n","authors":["Tomas Kulvicius","Dajie Zhang","Luise Poustka","Sven Bölte","Lennart Jahn","Sarah Flügge","Marc Kraft","Markus Zweckstetter","Karin Nielsen-Saines","Florentin Wörgötter","Peter B Marschik"],"pdf_url":"https://arxiv.org/pdf/2406.09014v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14758v2","updated":"2024-11-07T15:40:25Z","published":"2024-05-23T16:29:29Z","title":"Axioms for AI Alignment from Human Feedback","summary":"  In the context of reinforcement learning from human feedback (RLHF), the\nreward function is generally derived from maximum likelihood estimation of a\nrandom utility model based on pairwise comparisons made by humans. The problem\nof learning a reward function is one of preference aggregation that, we argue,\nlargely falls within the scope of social choice theory. From this perspective,\nwe can evaluate different aggregation methods via established axioms, examining\nwhether these methods meet or fail well-known standards. We demonstrate that\nboth the Bradley-Terry-Luce Model and its broad generalizations fail to meet\nbasic axioms. In response, we develop novel rules for learning reward functions\nwith strong axiomatic guarantees. A key innovation from the standpoint of\nsocial choice is that our problem has a linear structure, which greatly\nrestricts the space of feasible rules and leads to a new paradigm that we call\nlinear social choice.\n","authors":["Luise Ge","Daniel Halpern","Evi Micha","Ariel D. Procaccia","Itai Shapira","Yevgeniy Vorobeychik","Junlin Wu"],"pdf_url":"https://arxiv.org/pdf/2405.14758v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.13040v2","updated":"2024-11-07T15:40:09Z","published":"2023-10-19T17:59:12Z","title":"Interpreting CLIP: Insights on the Robustness to ImageNet Distribution\n  Shifts","summary":"  What distinguishes robust models from non-robust ones? While for ImageNet\ndistribution shifts it has been shown that such differences in robustness can\nbe traced back predominantly to differences in training data, so far it is not\nknown what that translates to in terms of what the model has learned. In this\nwork, we bridge this gap by probing the representation spaces of 16 robust\nzero-shot CLIP vision encoders with various backbones (ResNets and ViTs) and\npretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and {DataComp}),\nand comparing them to the representation spaces of less robust models with\nidentical backbones, but different (pre)training sets or objectives (CLIP\npretraining on ImageNet-Captions, and supervised training or finetuning on\nImageNet).Through this analysis, we generate three novel insights. Firstly, we\ndetect the presence of outlier features in robust zero-shot CLIP vision\nencoders, which to the best of our knowledge is the first time these are\nobserved in non-language and non-transformer models. Secondly, we find the\nexistence of outlier features to be an indication of ImageNet shift robustness\nin models, since we only find them in robust models in our analysis. Lastly, we\nalso investigate the number of unique encoded concepts in the representation\nspace and find zero-shot CLIP models to encode a higher number of unique\nconcepts in their representation space. However, we do not find this to be an\nindicator of ImageNet shift robustness and hypothesize that it is rather\nrelated to the language supervision. Since the presence of outlier features can\nbe detected without access to any data from shifted datasets, we believe that\nthey could be a useful tool for practitioners to get a feeling for the\ndistribution shift robustness of a pretrained model during deployment.\n","authors":["Jonathan Crabbé","Pau Rodríguez","Vaishaal Shankar","Luca Zappella","Arno Blaas"],"pdf_url":"https://arxiv.org/pdf/2310.13040v2.pdf","comment":"Published in TMLR"},{"id":"http://arxiv.org/abs/2411.04794v1","updated":"2024-11-07T15:36:05Z","published":"2024-11-07T15:36:05Z","title":"AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual\n  Alignment","summary":"  Empirical evidence suggests that LLMs exhibit spontaneous cross-lingual\nalignment. Our findings suggest that although LLMs also demonstrate promising\ncross-lingual alignment in Information Extraction, there remains significant\nimbalance across languages, revealing an underlying deficiency in the IE\nalignment. To address this issue, we propose AlignXIE, a powerful code-based\nLLM that significantly enhances cross-lingual IE alignment through two\nstrategies. Firstly, AlignXIE formulates IE across different languages,\nespecially non-English ones, as code generation tasks, standardizing the\nrepresentation of various schemas using Python classes to ensure consistency of\nthe same ontology in different languages and align the schema. Secondly, it\nincorporates an IE cross-lingual alignment phase through a translated instance\nprediction task proposed in this paper to align the extraction process,\nutilizing ParallelNER, an IE bilingual parallel dataset with 257,190 samples,\ngenerated by our proposed LLM-based automatic pipeline for IE parallel data\nconstruction, with manual annotation to ensure quality. Ultimately, we obtain\nAlignXIE through multilingual IE instruction tuning. Although without training\nin 9 unseen languages, AlignXIE surpasses ChatGPT by $30.17\\%$ and SoTA by\n$20.03\\%$, thereby demonstrating superior cross-lingual IE capabilities.\nComprehensive evaluations on 63 IE benchmarks in Chinese and English under\nvarious settings, demonstrate that AlignXIE significantly enhances\ncross-lingual and multilingual IE through boosting the IE alignment.\n","authors":["Yuxin Zuo","Wenxuan Jiang","Wenxuan Liu","Zixuan Li","Long Bai","Hanbin Wang","Yutao Zeng","Xiaolong Jin","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2411.04794v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.04788v1","updated":"2024-11-07T15:28:20Z","published":"2024-11-07T15:28:20Z","title":"Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in\n  Financial Research","summary":"  In recent years, the application of generative artificial intelligence\n(GenAI) in financial analysis and investment decision-making has gained\nsignificant attention. However, most existing approaches rely on single-agent\nsystems, which fail to fully utilize the collaborative potential of multiple AI\nagents. In this paper, we propose a novel multi-agent collaboration system\ndesigned to enhance decision-making in financial investment research. The\nsystem incorporates agent groups with both configurable group sizes and\ncollaboration structures to leverage the strengths of each agent group type. By\nutilizing a sub-optimal combination strategy, the system dynamically adapts to\nvarying market conditions and investment scenarios, optimizing performance\nacross different tasks. We focus on three sub-tasks: fundamentals, market\nsentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30\ncompanies listed on the Dow Jones Index. Our findings reveal significant\nperformance variations based on the configurations of AI agents for different\ntasks. The results demonstrate that our multi-agent collaboration system\noutperforms traditional single-agent models, offering improved accuracy,\nefficiency, and adaptability in complex financial environments. This study\nhighlights the potential of multi-agent systems in transforming financial\nanalysis and investment decision-making by integrating diverse analytical\nperspectives.\n","authors":["Xuewen Han","Neng Wang","Shangkun Che","Hongyang Yang","Kunpeng Zhang","Sean Xin Xu"],"pdf_url":"https://arxiv.org/pdf/2411.04788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04784v1","updated":"2024-11-07T15:26:38Z","published":"2024-11-07T15:26:38Z","title":"Navigating Trade-offs: Policy Summarization for Multi-Objective\n  Reinforcement Learning","summary":"  Multi-objective reinforcement learning (MORL) is used to solve problems\ninvolving multiple objectives. An MORL agent must make decisions based on the\ndiverse signals provided by distinct reward functions. Training an MORL agent\nyields a set of solutions (policies), each presenting distinct trade-offs among\nthe objectives (expected returns). MORL enhances explainability by enabling\nfine-grained comparisons of policies in the solution set based on their\ntrade-offs as opposed to having a single policy. However, the solution set is\ntypically large and multi-dimensional, where each policy (e.g., a neural\nnetwork) is represented by its objective values.\n  We propose an approach for clustering the solution set generated by MORL. By\nconsidering both policy behavior and objective values, our clustering method\ncan reveal the relationship between policy behaviors and regions in the\nobjective space. This approach can enable decision makers (DMs) to identify\noverarching trends and insights in the solution set rather than examining each\npolicy individually. We tested our method in four multi-objective environments\nand found it outperformed traditional k-medoids clustering. Additionally, we\ninclude a case study that demonstrates its real-world application.\n","authors":["Zuzanna Osika","Jazmin Zatarain-Salazar","Frans A. Oliehoek","Pradeep K. Murukannaiah"],"pdf_url":"https://arxiv.org/pdf/2411.04784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16148v3","updated":"2024-11-07T15:23:59Z","published":"2024-06-23T16:04:26Z","title":"Towards Open Respiratory Acoustic Foundation Models: Pretraining and\n  Benchmarking","summary":"  Respiratory audio, such as coughing and breathing sounds, has predictive\npower for a wide range of healthcare applications, yet is currently\nunder-explored. The main problem for those applications arises from the\ndifficulty in collecting large labeled task-specific data for model\ndevelopment. Generalizable respiratory acoustic foundation models pretrained\nwith unlabeled data would offer appealing advantages and possibly unlock this\nimpasse. However, given the safety-critical nature of healthcare applications,\nit is pivotal to also ensure openness and replicability for any proposed\nfoundation model solution. To this end, we introduce OPERA, an OPEn Respiratory\nAcoustic foundation model pretraining and benchmarking system, as the first\napproach answering this need. We curate large-scale respiratory audio datasets\n(~136K samples, over 400 hours), pretrain three pioneering foundation models,\nand build a benchmark consisting of 19 downstream respiratory health tasks for\nevaluation. Our pretrained models demonstrate superior performance (against\nexisting acoustic models pretrained with general audio on 16 out of 19 tasks)\nand generalizability (to unseen datasets and new respiratory audio modalities).\nThis highlights the great promise of respiratory acoustic foundation models and\nencourages more studies using OPERA as an open resource to accelerate research\non respiratory audio for health. The system is accessible from\nhttps://github.com/evelyn0414/OPERA.\n","authors":["Yuwei Zhang","Tong Xia","Jing Han","Yu Wu","Georgios Rizos","Yang Liu","Mohammed Mosuily","Jagmohan Chauhan","Cecilia Mascolo"],"pdf_url":"https://arxiv.org/pdf/2406.16148v3.pdf","comment":"accepted by NeurIPS 2024 Track Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2411.04777v1","updated":"2024-11-07T15:16:36Z","published":"2024-11-07T15:16:36Z","title":"Learn to Solve Vehicle Routing Problems ASAP: A Neural Optimization\n  Approach for Time-Constrained Vehicle Routing Problems with Finite Vehicle\n  Fleet","summary":"  Finding a feasible and prompt solution to the Vehicle Routing Problem (VRP)\nis a prerequisite for efficient freight transportation, seamless logistics, and\nsustainable mobility. Traditional optimization methods reach their limits when\nconfronted with the real-world complexity of VRPs, which involve numerous\nconstraints and objectives. Recently, the ability of generative Artificial\nIntelligence (AI) to solve combinatorial tasks, known as Neural Combinatorial\nOptimization (NCO), demonstrated promising results, offering new perspectives.\nIn this study, we propose an NCO approach to solve a time-constrained\ncapacitated VRP with a finite vehicle fleet size. The approach is based on an\nencoder-decoder architecture, formulated in line with the Policy Optimization\nwith Multiple Optima (POMO) protocol and trained via a Proximal Policy\nOptimization (PPO) algorithm. We successfully trained the policy with multiple\nobjectives (minimizing the total distance while maximizing vehicle utilization)\nand evaluated it on medium and large instances, benchmarking it against\nstate-of-the-art heuristics. The method is able to find adequate and\ncost-efficient solutions, showing both flexibility and robust generalization.\nFinally, we provide a critical analysis of the solution generated by NCO and\ndiscuss the challenges and opportunities of this new branch of intelligent\nlearning algorithms emerging in optimization science, focusing on freight\ntransportation.\n","authors":["Elija Deineko","Carina Kehrt"],"pdf_url":"https://arxiv.org/pdf/2411.04777v1.pdf","comment":"Affiliation: German Aerospace Center (DLR), Institute of Transport\n  Research, Rudower Chaussee 7, 12489 Berlin Correspondence:\n  Elija.deineko@dlr.de"},{"id":"http://arxiv.org/abs/2411.04775v1","updated":"2024-11-07T15:15:27Z","published":"2024-11-07T15:15:27Z","title":"Learning dynamical systems from data: Gradient-based dictionary\n  optimization","summary":"  The Koopman operator plays a crucial role in analyzing the global behavior of\ndynamical systems. Existing data-driven methods for approximating the Koopman\noperator or discovering the governing equations of the underlying system\ntypically require a fixed set of basis functions, also called dictionary. The\noptimal choice of basis functions is highly problem-dependent and often\nrequires domain knowledge. We present a novel gradient descent-based\noptimization framework for learning suitable and interpretable basis functions\nfrom data and show how it can be used in combination with EDMD, SINDy, and\nPDE-FIND. We illustrate the efficacy of the proposed approach with the aid of\nvarious benchmark problems such as the Ornstein-Uhlenbeck process, Chua's\ncircuit, a nonlinear heat equation, as well as protein-folding data.\n","authors":["Mohammad Tabish","Neil K. Chada","Stefan Klus"],"pdf_url":"https://arxiv.org/pdf/2411.04775v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03955v8","updated":"2024-11-07T15:07:22Z","published":"2024-01-08T15:21:21Z","title":"Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced\n  Zero/Few-Shot Forecasting of Multivariate Time Series","summary":"  Large pre-trained models excel in zero/few-shot learning for language and\nvision tasks but face challenges in multivariate time series (TS) forecasting\ndue to diverse data characteristics. Consequently, recent research efforts have\nfocused on developing pre-trained TS forecasting models. These models, whether\nbuilt from scratch or adapted from large language models (LLMs), excel in\nzero/few-shot forecasting tasks. However, they are limited by slow performance,\nhigh computational demands, and neglect of cross-channel and exogenous\ncorrelations. To address this, we introduce Tiny Time Mixers (TTM), a compact\nmodel (starting from 1M parameters) with effective transfer learning\ncapabilities, trained exclusively on public TS datasets. TTM, based on the\nlight-weight TSMixer architecture, incorporates innovations like adaptive\npatching, diverse resolution sampling, and resolution prefix tuning to handle\npre-training on varied dataset resolutions with minimal model capacity.\nAdditionally, it employs multi-level modeling to capture channel correlations\nand infuse exogenous signals during fine-tuning. TTM outperforms existing\npopular benchmarks in zero/few-shot forecasting by (4-40%), while reducing\ncomputational requirements significantly. Moreover, TTMs are lightweight and\ncan be executed even on CPU-only machines, enhancing usability and fostering\nwider adoption in resource-constrained environments. The model weights for\nreproducibility and research use are available at\nhttps://huggingface.co/ibm/ttm-research-r2/, while enterprise-use weights under\nthe Apache license can be accessed as follows: the initial TTM-Q variant at\nhttps://huggingface.co/ibm-granite/granite-timeseries-ttm-r1, and the latest\nvariants (TTM-B, TTM-E, TTM-A) weights are available at\nhttps://huggingface.co/ibm-granite/granite-timeseries-ttm-r2.\n","authors":["Vijay Ekambaram","Arindam Jati","Pankaj Dayama","Sumanta Mukherjee","Nam H. Nguyen","Wesley M. Gifford","Chandra Reddy","Jayant Kalagnanam"],"pdf_url":"https://arxiv.org/pdf/2401.03955v8.pdf","comment":"Accepted at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2411.04761v1","updated":"2024-11-07T14:59:23Z","published":"2024-11-07T14:59:23Z","title":"Mining the Minoria: Unknown, Under-represented, and Under-performing\n  Minority Groups","summary":"  Due to a variety of reasons, such as privacy, data in the wild often misses\nthe grouping information required for identifying minorities. On the other\nhand, it is known that machine learning models are only as good as the data\nthey are trained on and, hence, may underperform for the under-represented\nminority groups. The missing grouping information presents a dilemma for\nresponsible data scientists who find themselves in an unknown-unknown\nsituation, where not only do they not have access to the grouping attributes\nbut do not also know what groups to consider.\n  This paper is an attempt to address this dilemma. Specifically, we propose a\nminority mining problem, where we find vectors in the attribute space that\nreveal potential groups that are under-represented and under-performing.\nTechnically speaking, we propose a geometric transformation of data into a dual\nspace and use notions such as the arrangement of hyperplanes to design an\nefficient algorithm for the problem in lower dimensions. Generalizing our\nsolution to the higher dimensions is cursed by dimensionality. Therefore, we\npropose a solution based on smart exploration of the search space for such\ncases. We conduct comprehensive experiments using real-world and synthetic\ndatasets alongside the theoretical analysis. Our experiment results demonstrate\nthe effectiveness of our proposed solutions in mining the unknown,\nunder-represented, and under-performing minorities.\n","authors":["Mohsen Dehghankar","Abolfazl Asudeh"],"pdf_url":"https://arxiv.org/pdf/2411.04761v1.pdf","comment":"This paper is currently under review at VLDB 2025"},{"id":"http://arxiv.org/abs/2411.04760v1","updated":"2024-11-07T14:58:51Z","published":"2024-11-07T14:58:51Z","title":"Zero-Shot Temporal Resolution Domain Adaptation for Spiking Neural\n  Networks","summary":"  Spiking Neural Networks (SNNs) are biologically-inspired deep neural networks\nthat efficiently extract temporal information while offering promising gains in\nterms of energy efficiency and latency when deployed on neuromorphic devices.\nHowever, SNN model parameters are sensitive to temporal resolution, leading to\nsignificant performance drops when the temporal resolution of target data at\nthe edge is not the same with that of the pre-deployment source data used for\ntraining, especially when fine-tuning is not possible at the edge. To address\nthis challenge, we propose three novel domain adaptation methods for adapting\nneuron parameters to account for the change in time resolution without\nre-training on target time-resolution. The proposed methods are based on a\nmapping between neuron dynamics in SNNs and State Space Models (SSMs); and are\napplicable to general neuron models. We evaluate the proposed methods under\nspatio-temporal data tasks, namely the audio keyword spotting datasets SHD and\nMSWC as well as the image classification NMINST dataset. Our methods provide an\nalternative to - and in majority of the cases significantly outperform - the\nexisting reference method that simply scales the time constant. Moreover, our\nresults show that high accuracy on high temporal resolution data can be\nobtained by time efficient training on lower temporal resolution data and model\nadaptation.\n","authors":["Sanja Karilanova","Maxime Fabre","Emre Neftci","Ayça Özçelikkale"],"pdf_url":"https://arxiv.org/pdf/2411.04760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03883v2","updated":"2024-11-07T14:57:14Z","published":"2024-11-06T12:57:58Z","title":"MEG: Medical Knowledge-Augmented Large Language Models for Question\n  Answering","summary":"  Question answering is a natural language understanding task that involves\nreasoning over both explicit context and unstated, relevant domain knowledge.\nLarge language models (LLMs), which underpin most contemporary question\nanswering systems, struggle to induce how concepts relate in specialized\ndomains such as medicine. Existing medical LLMs are also costly to train. In\nthis work, we present MEG, a parameter-efficient approach for medical\nknowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate\ngraph embeddings into the LLM, enabling it to leverage external knowledge in a\ncost-effective way. We evaluate our method on four popular medical\nmultiple-choice datasets and show that LLMs greatly benefit from the factual\ngrounding provided by knowledge graph embeddings. MEG attains an average of\n+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized\nmodels like BioMistral. We also show results based on Llama-3. Finally, we show\nthat MEG's performance remains robust to the choice of graph encoder.\n","authors":["Laura Cabello","Carmen Martin-Turrero","Uchenna Akujuobi","Anders Søgaard","Carlos Bobed"],"pdf_url":"https://arxiv.org/pdf/2411.03883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01211v2","updated":"2024-11-07T14:51:44Z","published":"2024-11-02T11:04:45Z","title":"Spatial Transformers for Radio Map Estimation","summary":"  Radio map estimation (RME) involves spatial interpolation of radio\nmeasurements to predict metrics such as the received signal strength at\nlocations where no measurements were collected. The most popular estimators\nnowadays project the measurement locations to a regular grid and complete the\nresulting measurement tensor with a convolutional deep neural network.\nUnfortunately, these approaches suffer from poor spatial resolution and require\na great number of parameters. The first contribution of this paper addresses\nthese limitations by means of an attention-based estimator named Spatial\nTransfOrmer for Radio Map estimation (STORM). This scheme not only outperforms\nthe existing estimators, but also exhibits lower computational complexity,\ntranslation equivariance, rotation equivariance, and full spatial resolution.\nThe second contribution is an extended transformer architecture that allows\nSTORM to perform active sensing, by which the next measurement location is\nselected based on the previous measurements. This is particularly useful for\nminimization of drive tests (MDT) in cellular networks, where operators request\nuser equipment to collect measurements. Finally, STORM is extensively validated\nby experiments with one ray-tracing and two real-measurement datasets.\n","authors":["Pham Q. Viet","Daniel Romero"],"pdf_url":"https://arxiv.org/pdf/2411.01211v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13873v2","updated":"2024-11-07T14:50:06Z","published":"2024-10-02T12:54:21Z","title":"On the Robustness of Machine Learning Models in Predicting Thermodynamic\n  Properties: a Case of Searching for New Quasicrystal Approximants","summary":"  Despite an artificial intelligence-assisted modeling of disordered crystals\nis a widely used and well-tried method of new materials design, the issues of\nits robustness, reliability, and stability are still not resolved and even not\ndiscussed enough. To highlight it, in this work we composed a series of nested\nintermetallic approximants of quasicrystals datasets and trained various\nmachine learning models on them correspondingly. Our qualitative and, what is\nmore important, quantitative assessment of the difference in the predictions\nclearly shows that different reasonable changes in the training sample can lead\nto the completely different set of the predicted potentially new materials. We\nalso showed the advantage of pre-training and proposed a simple yet effective\ntrick of sequential training to increase stability.\n","authors":["Fedor S. Avilov","Roman A. Eremin","Semen A. Budennyy","Innokentiy S. Humonen"],"pdf_url":"https://arxiv.org/pdf/2410.13873v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12970v3","updated":"2024-11-07T14:45:25Z","published":"2023-08-24T17:59:54Z","title":"NeuralClothSim: Neural Deformation Fields Meet the Thin Shell Theory","summary":"  Despite existing 3D cloth simulators producing realistic results, they\npredominantly operate on discrete surface representations (e.g. points and\nmeshes) with a fixed spatial resolution, which often leads to large memory\nconsumption and resolution-dependent simulations. Moreover, back-propagating\ngradients through the existing solvers is difficult, and they cannot be easily\nintegrated into modern neural architectures. In response, this paper re-thinks\nphysically plausible cloth simulation: We propose NeuralClothSim, i.e., a new\nquasistatic cloth simulator using thin shells, in which surface deformation is\nencoded in neural network weights in the form of a neural field. Our\nmemory-efficient solver operates on a new continuous coordinate-based surface\nrepresentation called neural deformation fields (NDFs); it supervises NDF\nequilibria with the laws of the non-linear Kirchhoff-Love shell theory with a\nnon-linear anisotropic material model. NDFs are adaptive: They 1) allocate\ntheir capacity to the deformation details and 2) allow surface state queries at\narbitrary spatial resolutions without re-training. We show how to train\nNeuralClothSim while imposing hard boundary conditions and demonstrate multiple\napplications, such as material interpolation and simulation editing. The\nexperimental results highlight the effectiveness of our continuous neural\nformulation. See our project page: https://4dqv.mpi-inf.mpg.de/NeuralClothSim/.\n","authors":["Navami Kairanda","Marc Habermann","Christian Theobalt","Vladislav Golyanik"],"pdf_url":"https://arxiv.org/pdf/2308.12970v3.pdf","comment":"33 pages, 23 figures and 3 tables; project page:\n  https://4dqv.mpi-inf.mpg.de/NeuralClothSim/"},{"id":"http://arxiv.org/abs/2409.18624v2","updated":"2024-11-07T14:36:04Z","published":"2024-09-27T10:50:49Z","title":"Unsupervised Cognition","summary":"  Unsupervised learning methods have a soft inspiration in cognition models. To\nthis day, the most successful unsupervised learning methods revolve around\nclustering samples in a mathematical space. In this paper we propose a\nstate-of-the-art, primitive-based, unsupervised learning approach for\ndecision-making inspired by a novel cognition framework. This\nrepresentation-centric approach models the input space constructively as a\ndistributed hierarchical structure in an input-agnostic way. We compared our\napproach with both current state-of-the-art unsupervised learning\nclassification, and with current state-of-the-art cancer type classification.\nWe show how our proposal outperforms previous state-of-the-art. We also\nevaluate some cognition-like properties of our proposal where it not only\noutperforms the compared algorithms (even supervised learning ones), but it\nalso shows a different, more cognition-like, behaviour.\n","authors":["Alfredo Ibias","Hector Antona","Guillem Ramirez-Miranda","Enric Guinovart","Eduard Alarcon"],"pdf_url":"https://arxiv.org/pdf/2409.18624v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04747v1","updated":"2024-11-07T14:29:05Z","published":"2024-11-07T14:29:05Z","title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations","summary":"  Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https://github.com/WeToTheMoon/EGAT_DrugSynergy.\n","authors":["Zachary Schwehr"],"pdf_url":"https://arxiv.org/pdf/2411.04747v1.pdf","comment":"8 pages, 1 figure, Presented at IEEE CIBCB"},{"id":"http://arxiv.org/abs/2411.04744v1","updated":"2024-11-07T14:27:49Z","published":"2024-11-07T14:27:49Z","title":"Respecting the limit:Bayesian optimization with a bound on the optimal\n  value","summary":"  In many real-world optimization problems, we have prior information about\nwhat objective function values are achievable. In this paper, we study the\nscenario that we have either exact knowledge of the minimum value or a,\npossibly inexact, lower bound on its value. We propose bound-aware Bayesian\noptimization (BABO), a Bayesian optimization method that uses a new surrogate\nmodel and acquisition function to utilize such prior information. We present\nSlogGP, a new surrogate model that incorporates bound information and adapts\nthe Expected Improvement (EI) acquisition function accordingly. Empirical\nresults on a variety of benchmarks demonstrate the benefit of taking prior\ninformation about the optimal value into account, and that the proposed\napproach significantly outperforms existing techniques. Furthermore, we notice\nthat even in the absence of prior information on the bound, the proposed SlogGP\nsurrogate model still performs better than the standard GP model in most cases,\nwhich we explain by its larger expressiveness.\n","authors":["Hanyang Wang","Juergen Branke","Matthias Poloczek"],"pdf_url":"https://arxiv.org/pdf/2411.04744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20194v5","updated":"2024-11-07T14:25:33Z","published":"2024-05-30T15:58:22Z","title":"Occam Gradient Descent","summary":"  Deep learning neural network models must be large enough to adapt to their\nproblem domain, while small enough to avoid overfitting training data during\ngradient descent. To balance these competing demands, overprovisioned deep\nlearning models such as transformers are trained for a single epoch on large\ndata sets, and hence inefficient with both computing resources and training\ndata. In response to these inefficiencies, we exploit learning theory to derive\nOccam Gradient Descent, an algorithm that interleaves adaptive reduction of\nmodel size to minimize generalization error, with gradient descent on model\nweights to minimize fitting error. In contrast, traditional gradient descent\ngreedily minimizes fitting error without regard to generalization error. Our\nalgorithm simultaneously descends the space of weights and topological size of\nany neural network without modification. With respect to loss, compute and\nmodel size, our experiments show (a) on image classification benchmarks, linear\nand convolutional neural networks trained with Occam Gradient Descent\noutperform traditional gradient descent with or without post-train pruning; (b)\non a range of tabular data classification tasks, neural networks trained with\nOccam Gradient Descent outperform traditional gradient descent, as well as\nRandom Forests; (c) on natural language transformers, Occam Gradient Descent\noutperforms traditional gradient descent.\n","authors":["B. N. Kausik"],"pdf_url":"https://arxiv.org/pdf/2405.20194v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16872v2","updated":"2024-11-07T14:19:42Z","published":"2023-11-28T15:24:02Z","title":"A unified weighting framework for evaluating nearest neighbour\n  classification","summary":"  We present the first comprehensive and large-scale evaluation of classical\n(NN), fuzzy (FNN) and fuzzy rough (FRNN) nearest neighbour classification. We\nstandardise existing proposals for nearest neighbour weighting with kernel\nfunctions, applied to the distance values and/or ranks of the nearest\nneighbours of a test instance. In particular, we show that the theoretically\noptimal Samworth weights converge to a kernel. Kernel functions are closely\nrelated to fuzzy negation operators, and we propose a new kernel based on Yager\nnegation. We also consider various distance and scaling measures, which we show\ncan be related to each other. Through a systematic series of experiments on 85\nreal-life classification datasets, we find that NN, FNN and FRNN all perform\nbest with Boscovich distance, and that NN and FRNN perform best with a\ncombination of Samworth rank- and distance-weights and scaling by the mean\nabsolute deviation around the median ($r_1$), the standard deviation ($r_2$) or\nthe semi-interquartile range ($r_{\\infty}^*$), while FNN performs best with\nonly Samworth distance-weights and $r_1$- or $r_2$-scaling. However, NN\nachieves comparable performance with Yager-$\\frac{1}{2}$ distance-weights,\nwhich are simpler to implement than a combination of Samworth distance- and\nrank-weights. Finally, FRNN generally outperforms NN, which in turn performs\nsystematically better than FNN.\n","authors":["Oliver Urs Lenz","Henri Bollaert","Chris Cornelis"],"pdf_url":"https://arxiv.org/pdf/2311.16872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04732v1","updated":"2024-11-07T14:12:00Z","published":"2024-11-07T14:12:00Z","title":"Convolutional Differentiable Logic Gate Networks","summary":"  With the increasing inference cost of machine learning models, there is a\ngrowing interest in models with fast and efficient inference. Recently, an\napproach for learning logic gate networks directly via a differentiable\nrelaxation was proposed. Logic gate networks are faster than conventional\nneural network approaches because their inference only requires logic gate\noperators such as NAND, OR, and XOR, which are the underlying building blocks\nof current hardware and can be efficiently executed. We build on this idea,\nextending it by deep logic gate tree convolutions, logical OR pooling, and\nresidual initializations. This allows scaling logic gate networks up by over\none order of magnitude and utilizing the paradigm of convolution. On CIFAR-10,\nwe achieve an accuracy of 86.29% using only 61 million logic gates, which\nimproves over the SOTA while being 29x smaller.\n","authors":["Felix Petersen","Hilde Kuehne","Christian Borgelt","Julian Welzel","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2411.04732v1.pdf","comment":"Published at NeurIPS 2024 (Oral)"},{"id":"http://arxiv.org/abs/2411.04728v1","updated":"2024-11-07T14:08:35Z","published":"2024-11-07T14:08:35Z","title":"Neuromorphic Wireless Split Computing with Multi-Level Spikes","summary":"  Inspired by biological processes, neuromorphic computing utilizes spiking\nneural networks (SNNs) to perform inference tasks, offering significant\nefficiency gains for workloads involving sequential data. Recent advances in\nhardware and software have demonstrated that embedding a few bits of payload in\neach spike exchanged between the spiking neurons can further enhance inference\naccuracy. In a split computing architecture, where the SNN is divided across\ntwo separate devices, the device storing the first layers must share\ninformation about the spikes generated by the local output neurons with the\nother device. Consequently, the advantages of multi-level spikes must be\nbalanced against the challenges of transmitting additional bits between the two\ndevices.\n  This paper addresses these challenges by investigating a wireless\nneuromorphic split computing architecture employing multi-level SNNs. For this\nsystem, we present the design of digital and analog modulation schemes\noptimized for an orthogonal frequency division multiplexing (OFDM) radio\ninterface. Simulation and experimental results using software-defined radios\nprovide insights into the performance gains of multi-level SNN models and the\noptimal payload size as a function of the quality of the connection between a\ntransmitter and receiver.\n","authors":["Dengyu Wu","Jiechen Chen","Bipin Rajendran","H. Vincent Poor","Osvaldo Simeone"],"pdf_url":"https://arxiv.org/pdf/2411.04728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16103v3","updated":"2024-11-07T14:00:45Z","published":"2024-10-21T15:31:06Z","title":"LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics","summary":"  We introduce LDAdam, a memory-efficient optimizer for training large models,\nthat performs adaptive optimization steps within lower dimensional subspaces,\nwhile consistently exploring the full parameter space during training. This\nstrategy keeps the optimizer's memory footprint to a fraction of the model\nsize. LDAdam relies on a new projection-aware update rule for the optimizer\nstates that allows for transitioning between subspaces, i.e., estimation of the\nstatistics of the projected gradients. To mitigate the errors due to low-rank\nprojection, LDAdam integrates a new generalized error feedback mechanism, which\nexplicitly accounts for both gradient and optimizer state compression. We prove\nthe convergence of LDAdam under standard assumptions, and show that LDAdam\nallows for accurate and efficient fine-tuning and pre-training of language\nmodels.\n","authors":["Thomas Robert","Mher Safaryan","Ionut-Vlad Modoranu","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.16103v3.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2411.04717v1","updated":"2024-11-07T13:57:53Z","published":"2024-11-07T13:57:53Z","title":"Subspace-Constrained Quadratic Matrix Factorization: Algorithm and\n  Applications","summary":"  Matrix Factorization has emerged as a widely adopted framework for modeling\ndata exhibiting low-rank structures. To address challenges in manifold\nlearning, this paper presents a subspace-constrained quadratic matrix\nfactorization model. The model is designed to jointly learn key low-dimensional\nstructures, including the tangent space, the normal subspace, and the quadratic\nform that links the tangent space to a low-dimensional representation. We solve\nthe proposed factorization model using an alternating minimization method,\ninvolving an in-depth investigation of nonlinear regression and projection\nsubproblems. Theoretical properties of the quadratic projection problem and\nconvergence characteristics of the alternating strategy are also investigated.\nTo validate our approach, we conduct numerical experiments on synthetic and\nreal-world datasets. Results demonstrate that our model outperforms existing\nmethods, highlighting its robustness and efficacy in capturing core\nlow-dimensional structures.\n","authors":["Zheng Zhai","Xiaohui Li"],"pdf_url":"https://arxiv.org/pdf/2411.04717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17113v3","updated":"2024-11-07T13:55:50Z","published":"2024-09-25T17:27:02Z","title":"Characterizing stable regions in the residual stream of LLMs","summary":"  We identify stable regions in the residual stream of Transformers, where the\nmodel's output remains insensitive to small activation changes, but exhibits\nhigh sensitivity at region boundaries. These regions emerge during training and\nbecome more defined as training progresses or model size increases. The regions\nappear to be much larger than previously studied polytopes. Our analysis\nsuggests that these stable regions align with semantic distinctions, where\nsimilar prompts cluster within regions, and activations from the same region\nlead to similar next token predictions. This work provides a promising research\ndirection for understanding the complexity of neural networks, shedding light\non training dynamics, and advancing interpretability.\n","authors":["Jett Janiak","Jacek Karwowski","Chatrik Singh Mangat","Giorgi Giglemiani","Nora Petrova","Stefan Heimersheim"],"pdf_url":"https://arxiv.org/pdf/2409.17113v3.pdf","comment":"Published at Scientific Methods for Understanding Deep Learning\n  (SciForDL) workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04708v1","updated":"2024-11-07T13:45:26Z","published":"2024-11-07T13:45:26Z","title":"Exploring Hierarchical Molecular Graph Representation in Multimodal LLMs","summary":"  Following the milestones in large language models (LLMs) and multimodal\nmodels, we have seen a surge in applying LLMs to biochemical tasks. Leveraging\ngraph features and molecular text representations, LLMs can tackle various\ntasks, such as predicting chemical reaction outcomes and describing molecular\nproperties. However, most current work overlooks the multi-level nature of\ngraph features. The impact of different feature levels on LLMs and the\nimportance of each level remain unexplored, and it is possible that different\nchemistry tasks require different feature levels. In this work, we first\ninvestigate the effect of feature granularity by fusing GNN-generated feature\ntokens, discovering that even reducing all tokens to a single token does not\nsignificantly impact performance. We then explore the effect of various feature\nlevels on performance, finding that both the quality of LLM-generated molecules\nand performance on different tasks benefit from different feature levels. We\nconclude with two key insights: (1) current molecular Multimodal LLMs(MLLMs)\nlack a comprehensive understanding of graph features, and (2) static processing\nis not sufficient for hierarchical graph feature. Our code will be publicly\navailable soon.\n","authors":["Chengxin Hu","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2411.04708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17299v2","updated":"2024-11-07T13:44:22Z","published":"2024-05-27T16:00:45Z","title":"Simplicity Bias of Two-Layer Networks beyond Linearly Separable Data","summary":"  Simplicity bias, the propensity of deep models to over-rely on simple\nfeatures, has been identified as a potential reason for limited\nout-of-distribution generalization of neural networks (Shah et al., 2020).\nDespite the important implications, this phenomenon has been theoretically\nconfirmed and characterized only under strong dataset assumptions, such as\nlinear separability (Lyu et al., 2021). In this work, we characterize\nsimplicity bias for general datasets in the context of two-layer neural\nnetworks initialized with small weights and trained with gradient flow.\nSpecifically, we prove that in the early training phases, network features\ncluster around a few directions that do not depend on the size of the hidden\nlayer. Furthermore, for datasets with an XOR-like pattern, we precisely\nidentify the learned features and demonstrate that simplicity bias intensifies\nduring later training stages. These results indicate that features learned in\nthe middle stages of training may be more useful for OOD transfer. We support\nthis hypothesis with experiments on image data.\n","authors":["Nikita Tsoy","Nikola Konstantinov"],"pdf_url":"https://arxiv.org/pdf/2405.17299v2.pdf","comment":"ICML 2024, camera-ready version (expanded related work)"},{"id":"http://arxiv.org/abs/2411.04700v1","updated":"2024-11-07T13:34:37Z","published":"2024-11-07T13:34:37Z","title":"Field Assessment of Force Torque Sensors for Planetary Rover Navigation","summary":"  Proprioceptive sensors on planetary rovers serve for state estimation and for\nunderstanding terrain and locomotion performance. While inertial measurement\nunits (IMUs) are widely used to this effect, force-torque sensors are less\nexplored for planetary navigation despite their potential to directly measure\ninteraction forces and provide insights into traction performance. This paper\npresents an evaluation of the performance and use cases of force-torque sensors\nbased on data collected from a six-wheeled rover during tests over varying\nterrains, speeds, and slopes. We discuss challenges, such as sensor signal\nreliability and terrain response accuracy, and identify opportunities regarding\nthe use of these sensors. The data is openly accessible and includes\nforce-torque measurements from each of the six-wheel assemblies as well as IMU\ndata from within the rover chassis. This paper aims to inform the design of\nfuture studies and rover upgrades, particularly in sensor integration and\ncontrol algorithms, to improve navigation capabilities.\n","authors":["Levin Gerdes","Carlos Pérez del Pulgar","Raúl Castilla Arquillo","Martin Azkarate"],"pdf_url":"https://arxiv.org/pdf/2411.04700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06672v2","updated":"2024-11-07T13:32:58Z","published":"2024-03-11T12:43:44Z","title":"Provable Mutual Benefits from Federated Learning in Privacy-Sensitive\n  Domains","summary":"  Cross-silo federated learning (FL) allows data owners to train accurate\nmachine learning models by benefiting from each others private datasets.\nUnfortunately, the model accuracy benefits of collaboration are often\nundermined by privacy defenses. Therefore, to incentivize client participation\nin privacy-sensitive domains, a FL protocol should strike a delicate balance\nbetween privacy guarantees and end-model accuracy. In this paper, we study the\nquestion of when and how a server could design a FL protocol provably\nbeneficial for all participants. First, we provide necessary and sufficient\nconditions for the existence of mutually beneficial protocols in the context of\nmean estimation and convex stochastic optimization. We also derive protocols\nthat maximize the total clients' utility, given symmetric privacy preferences.\nFinally, we design protocols maximizing end-model accuracy and demonstrate\ntheir benefits in synthetic experiments.\n","authors":["Nikita Tsoy","Anna Mihalkova","Teodora Todorova","Nikola Konstantinov"],"pdf_url":"https://arxiv.org/pdf/2403.06672v2.pdf","comment":"AISTATS 2024; Camera-ready version (updated references)"},{"id":"http://arxiv.org/abs/2411.04696v1","updated":"2024-11-07T13:29:32Z","published":"2024-11-07T13:29:32Z","title":"The Multiple Dimensions of Spuriousness in Machine Learning","summary":"  Learning correlations from data forms the foundation of today's machine\nlearning (ML) and artificial intelligence (AI) research. While such an approach\nenables the automatic discovery of patterned relationships within big data\ncorpora, it is susceptible to failure modes when unintended correlations are\ncaptured. This vulnerability has expanded interest in interrogating\nspuriousness, often critiqued as an impediment to model performance, fairness,\nand robustness. In this article, we trace deviations from the conventional\ndefinition of statistical spuriousness-which denotes a non-causal observation\narising from either coincidence or confounding variables-to articulate how ML\nresearchers make sense of spuriousness in practice. Drawing on a broad survey\nof ML literature, we conceptualize the \"multiple dimensions of spuriousness,\"\nencompassing: relevance (\"Models should only use correlations that are relevant\nto the task.\"), generalizability (\"Models should only use correlations that\ngeneralize to unseen data\"), human-likeness (\"Models should only use\ncorrelations that a human would use to perform the same task\"), and harmfulness\n(\"Models should only use correlations that are not harmful\"). These dimensions\ndemonstrate that ML spuriousness goes beyond the causal/non-causal dichotomy\nand that the disparate interpretative paths researchers choose could\nmeaningfully influence the trajectory of ML development. By underscoring how a\nfundamental problem in ML is contingently negotiated in research contexts, we\ncontribute to ongoing debates about responsible practices in AI development.\n","authors":["Samuel J. Bell","Skyler Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04695v1","updated":"2024-11-07T13:27:37Z","published":"2024-11-07T13:27:37Z","title":"Is network fragmentation a useful complexity measure?","summary":"  It has been observed that the input space of deep neural network classifiers\ncan exhibit `fragmentation', where the model function rapidly changes class as\nthe input space is traversed. The severity of this fragmentation tends to\nfollow the double descent curve, achieving a maximum at the interpolation\nregime. We study this phenomenon in the context of image classification and ask\nwhether fragmentation could be predictive of generalization performance. Using\na fragmentation-based complexity measure, we show this to be possible by\nachieving good performance on the PGDL (Predicting Generalization in Deep\nLearning) benchmark. In addition, we report on new observations related to\nfragmentation, namely (i) fragmentation is not limited to the input space but\noccurs in the hidden representations as well, (ii) fragmentation follows the\ntrends in the validation error throughout training, and (iii) fragmentation is\nnot a direct result of increased weight norms. Together, this indicates that\nfragmentation is a phenomenon worth investigating further when studying the\ngeneralization ability of deep neural networks.\n","authors":["Coenraad Mouton","Randle Rabe","Daniël G. Haasbroek","Marthinus W. Theunissen","Hermanus L. Potgieter","Marelie H. Davel"],"pdf_url":"https://arxiv.org/pdf/2411.04695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15598v4","updated":"2024-11-07T13:26:18Z","published":"2024-05-24T14:30:00Z","title":"MCDFN: Supply Chain Demand Forecasting via an Explainable Multi-Channel\n  Data Fusion Network Model","summary":"  Accurate demand forecasting is crucial for optimizing supply chain\nmanagement. Traditional methods often fail to capture complex patterns from\nseasonal variability and special events. Despite advancements in deep learning,\ninterpretable forecasting models remain a challenge. To address this, we\nintroduce the Multi-Channel Data Fusion Network (MCDFN), a hybrid architecture\nthat integrates Convolutional Neural Networks (CNN), Long Short-Term Memory\nnetworks (LSTM), and Gated Recurrent Units (GRU) to enhance predictive\nperformance by extracting spatial and temporal features from time series data.\nOur comparative benchmarking demonstrates that MCDFN outperforms seven other\ndeep-learning models, achieving superior metrics: MSE (23.5738), RMSE (4.8553),\nMAE (3.9991), and MAPE (20.1575%). Additionally, MCDFN's predictions were\nstatistically indistinguishable from actual values, confirmed by a paired\nt-test with a 5% p-value and a 10-fold cross-validated statistical paired\nt-test. We apply explainable AI techniques like ShapTime and Permutation\nFeature Importance to enhance interpretability. This research advances demand\nforecasting methodologies and offers practical guidelines for integrating MCDFN\ninto supply chain systems, highlighting future research directions for\nscalability and user-friendly deployment.\n","authors":["Md Abrar Jahin","Asef Shahriar","Md Al Amin"],"pdf_url":"https://arxiv.org/pdf/2405.15598v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16598v2","updated":"2024-11-07T13:12:55Z","published":"2024-05-26T15:18:22Z","title":"Regularized Projection Matrix Approximation with Applications to\n  Community Detection","summary":"  This paper introduces a regularized projection matrix approximation framework\ndesigned to recover cluster information from the affinity matrix. The model is\nformulated as a projection approximation problem, incorporating an entry-wise\npenalty function. We investigate three distinct penalty functions, each\nspecifically tailored to address bounded, positive, and sparse scenarios. To\nsolve this problem, we propose direct optimization on the Stiefel manifold,\nutilizing the Cayley transformation along with the Alternating Direction Method\nof Multipliers (ADMM) algorithm. Additionally, we provide a theoretical\nanalysis that establishes the convergence properties of ADMM, demonstrating\nthat the convergence point satisfies the KKT conditions of the original\nproblem. Numerical experiments conducted on both synthetic and real-world\ndatasets reveal that our regularized projection matrix approximation approach\nsignificantly outperforms state-of-the-art methods in clustering performance.\n","authors":["Zheng Zhai","Jialu Xu","Mingxin Wu","Xiaohui Li"],"pdf_url":"https://arxiv.org/pdf/2405.16598v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04680v1","updated":"2024-11-07T13:08:06Z","published":"2024-11-07T13:08:06Z","title":"Differentially Private Continual Learning using Pre-Trained Models","summary":"  This work explores the intersection of continual learning (CL) and\ndifferential privacy (DP). Crucially, continual learning models must retain\nknowledge across tasks, but this conflicts with the differential privacy\nrequirement of restricting individual samples to be memorised in the model. We\npropose using pre-trained models to address the trade-offs between privacy and\nperformance in a continual learning setting.More specifically, we present\nnecessary assumptions to enable privacy-preservation and propose combining\npre-trained models with parameter-free classifiers and parameter-efficient\nadapters that are learned under differential privacy. Our experiments\ndemonstrate their effectiveness and provide insights into balancing the\ncompeting demands of continual learning and privacy.\n","authors":["Marlon Tobaben","Marcus Klasson","Rui Li","Arno Solin","Antti Honkela"],"pdf_url":"https://arxiv.org/pdf/2411.04680v1.pdf","comment":"15 pages, 3 figures, Accepted at Scalable Continual Learning for\n  Lifelong Foundation Models Workshop at 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2411.04672v1","updated":"2024-11-07T12:55:35Z","published":"2024-11-07T12:55:35Z","title":"Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent\n  Reinforcement Learning","summary":"  This paper presents a semantic-aware multi-modal resource allocation (SAMRA)\nfor multi-task using multi-agent reinforcement learning (MARL), termed\nSAMRAMARL, utilizing in platoon systems where cellular vehicle-to-everything\n(C-V2X) communication is employed. The proposed approach leverages the semantic\ninformation to optimize the allocation of communication resources. By\nintegrating a distributed multi-agent reinforcement learning (MARL) algorithm,\nSAMRAMARL enables autonomous decision-making for each vehicle, channel\nassignment optimization, power allocation, and semantic symbol length based on\nthe contextual importance of the transmitted information. This\nsemantic-awareness ensures that both vehicle-to-vehicle (V2V) and\nvehicle-to-infrastructure (V2I) communications prioritize data that is critical\nfor maintaining safe and efficient platoon operations. The framework also\nintroduces a tailored quality of experience (QoE) metric for semantic\ncommunication, aiming to maximize QoE in V2V links while improving the success\nrate of semantic information transmission (SRS). Extensive simulations has\ndemonstrated that SAMRAMARL outperforms existing methods, achieving significant\ngains in QoE and communication efficiency in C-V2X platooning scenarios.\n","authors":["Zhiyu Shao","Qiong Wu","Pingyi Fan","Kezhi Wang","Qiang Fan","Wen Chen","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2411.04672v1.pdf","comment":"This paper has been submitted to IEEE Journal. The source code has\n  been released\n  at:https://github.com/qiongwu86/Semantic-Aware-Resource-Management-for-C-V2X-Platooning-via-Multi-Agent-Reinforcement-Learning"},{"id":"http://arxiv.org/abs/2411.04669v1","updated":"2024-11-07T12:54:42Z","published":"2024-11-07T12:54:42Z","title":"EffiCANet: Efficient Time Series Forecasting with Convolutional\n  Attention","summary":"  The exponential growth of multivariate time series data from sensor networks\nin domains like industrial monitoring and smart cities requires efficient and\naccurate forecasting models. Current deep learning methods often fail to\nadequately capture long-range dependencies and complex inter-variable\nrelationships, especially under real-time processing constraints. These\nlimitations arise as many models are optimized for either short-term\nforecasting with limited receptive fields or long-term accuracy at the cost of\nefficiency. Additionally, dynamic and intricate interactions between variables\nin real-world data further complicate modeling efforts. To address these\nlimitations, we propose EffiCANet, an Efficient Convolutional Attention Network\ndesigned to enhance forecasting accuracy while maintaining computational\nefficiency. EffiCANet integrates three key components: (1) a Temporal\nLarge-kernel Decomposed Convolution (TLDC) module that captures long-term\ntemporal dependencies while reducing computational overhead; (2) an\nInter-Variable Group Convolution (IVGC) module that captures complex and\nevolving relationships among variables; and (3) a Global Temporal-Variable\nAttention (GTVA) mechanism that prioritizes critical temporal and\ninter-variable features. Extensive evaluations across nine benchmark datasets\nshow that EffiCANet achieves the maximum reduction of 10.02% in MAE over\nstate-of-the-art models, while cutting computational costs by 26.2% relative to\nconventional large-kernel convolution methods, thanks to its efficient\ndecomposition strategy.\n","authors":["Xinxing Zhou","Jiaqi Ye","Shubao Zhao","Ming Jin","Chengyi Yang","Yanlong Wen","Xiaojie Yuan"],"pdf_url":"https://arxiv.org/pdf/2411.04669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04662v1","updated":"2024-11-07T12:48:27Z","published":"2024-11-07T12:48:27Z","title":"Enhancing Trust in Clinically Significant Prostate Cancer Prediction\n  with Multiple Magnetic Resonance Imaging Modalities","summary":"  In the United States, prostate cancer is the second leading cause of deaths\nin males with a predicted 35,250 deaths in 2024. However, most diagnoses are\nnon-lethal and deemed clinically insignificant which means that the patient\nwill likely not be impacted by the cancer over their lifetime. As a result,\nnumerous research studies have explored the accuracy of predicting clinical\nsignificance of prostate cancer based on magnetic resonance imaging (MRI)\nmodalities and deep neural networks. Despite their high performance, these\nmodels are not trusted by most clinical scientists as they are trained solely\non a single modality whereas clinical scientists often use multiple magnetic\nresonance imaging modalities during their diagnosis. In this paper, we\ninvestigate combining multiple MRI modalities to train a deep learning model to\nenhance trust in the models for clinically significant prostate cancer\nprediction. The promising performance and proposed training pipeline showcase\nthe benefits of incorporating multiple MRI modalities for enhanced trust and\naccuracy.\n","authors":["Benjamin Ng","Chi-en Amy Tai","E. Zhixuan Zeng","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2411.04662v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 6 pages"},{"id":"http://arxiv.org/abs/2411.04655v1","updated":"2024-11-07T12:32:24Z","published":"2024-11-07T12:32:24Z","title":"Centrality Graph Shift Operators for Graph Neural Networks","summary":"  Graph Shift Operators (GSOs), such as the adjacency and graph Laplacian\nmatrices, play a fundamental role in graph theory and graph representation\nlearning. Traditional GSOs are typically constructed by normalizing the\nadjacency matrix by the degree matrix, a local centrality metric. In this work,\nwe instead propose and study Centrality GSOs (CGSOs), which normalize adjacency\nmatrices by global centrality metrics such as the PageRank, $k$-core or count\nof fixed length walks. We study spectral properties of the CGSOs, allowing us\nto get an understanding of their action on graph signals. We confirm this\nunderstanding by defining and running the spectral clustering algorithm based\non different CGSOs on several synthetic and real-world datasets. We furthermore\noutline how our CGSO can act as the message passing operator in any Graph\nNeural Network and in particular demonstrate strong performance of a variant of\nthe Graph Convolutional Network and Graph Attention Network using our CGSOs on\nseveral real-world benchmark datasets.\n","authors":["Yassine Abbahaddou","Fragkiskos D. Malliaros","Johannes F. Lutzeyer","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2411.04655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04653v1","updated":"2024-11-07T12:28:52Z","published":"2024-11-07T12:28:52Z","title":"IGDrivSim: A Benchmark for the Imitation Gap in Autonomous Driving","summary":"  Developing autonomous vehicles that can navigate complex environments with\nhuman-level safety and efficiency is a central goal in self-driving research. A\ncommon approach to achieving this is imitation learning, where agents are\ntrained to mimic human expert demonstrations collected from real-world driving\nscenarios. However, discrepancies between human perception and the self-driving\ncar's sensors can introduce an \\textit{imitation gap}, leading to imitation\nlearning failures. In this work, we introduce \\textbf{IGDrivSim}, a benchmark\nbuilt on top of the Waymax simulator, designed to investigate the effects of\nthe imitation gap in learning autonomous driving policy from human expert\ndemonstrations. Our experiments show that this perception gap between human\nexperts and self-driving agents can hinder the learning of safe and effective\ndriving behaviors. We further show that combining imitation with reinforcement\nlearning, using a simple penalty reward for prohibited behaviors, effectively\nmitigates these failures. Our code is open-sourced at:\nhttps://github.com/clemgris/IGDrivSim.git.\n","authors":["Clémence Grislain","Risto Vuorio","Cong Lu","Shimon Whiteson"],"pdf_url":"https://arxiv.org/pdf/2411.04653v1.pdf","comment":"8 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2411.04649v1","updated":"2024-11-07T12:12:44Z","published":"2024-11-07T12:12:44Z","title":"DISCO: DISCovering Overfittings as Causal Rules for Text Classification\n  Models","summary":"  With the rapid advancement of neural language models, the deployment of\nover-parameterized models has surged, increasing the need for interpretable\nexplanations comprehensible to human inspectors. Existing post-hoc\ninterpretability methods, which often focus on unigram features of single input\ntextual instances, fail to capture the models' decision-making process fully.\nAdditionally, many methods do not differentiate between decisions based on\nspurious correlations and those based on a holistic understanding of the input.\nOur paper introduces DISCO, a novel method for discovering global, rule-based\nexplanations by identifying causal n-gram associations with model predictions.\nThis method employs a scalable sequence mining technique to extract relevant\ntext spans from training data, associate them with model predictions, and\nconduct causality checks to distill robust rules that elucidate model behavior.\nThese rules expose potential overfitting and provide insights into misleading\nfeature combinations. We validate DISCO through extensive testing,\ndemonstrating its superiority over existing methods in offering comprehensive\ninsights into complex model behaviors. Our approach successfully identifies all\nshortcuts manually introduced into the training data (100% detection rate on\nthe MultiRC dataset), resulting in an 18.8% regression in model performance --\na capability unmatched by any other method. Furthermore, DISCO supports\ninteractive explanations, enabling human inspectors to distinguish spurious\ncauses in the rule-based output. This alleviates the burden of abundant\ninstance-wise explanations and helps assess the model's risk when encountering\nout-of-distribution (OOD) data.\n","authors":["Zijian Zhang","Vinay Setty","Yumeng Wang","Avishek Anand"],"pdf_url":"https://arxiv.org/pdf/2411.04649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04644v1","updated":"2024-11-07T12:01:36Z","published":"2024-11-07T12:01:36Z","title":"wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification\n  from Physiological Signals","summary":"  Accurate classification of sleep stages from less obtrusive sensor\nmeasurements such as the electrocardiogram (ECG) or photoplethysmogram (PPG)\ncould enable important applications in sleep medicine. Existing approaches to\nthis problem have typically used deep learning models designed and trained to\noperate on one or more specific input signals. However, the datasets used to\ndevelop these models often do not contain the same sets of input signals. Some\nsignals, particularly PPG, are much less prevalent than others, and this has\npreviously been addressed with techniques such as transfer learning.\nAdditionally, only training on one or more fixed modalities precludes\ncross-modal information transfer from other sources, which has proved valuable\nin other problem domains. To address this, we introduce wav2sleep, a unified\nmodel designed to operate on variable sets of input signals during training and\ninference. After jointly training on over 10,000 overnight recordings from six\npublicly available polysomnography datasets, including SHHS and MESA, wav2sleep\noutperforms existing sleep stage classification models across test-time input\ncombinations including ECG, PPG, and respiratory signals.\n","authors":["Jonathan F. Carter","Lionel Tarassenko"],"pdf_url":"https://arxiv.org/pdf/2411.04644v1.pdf","comment":"Accepted to Machine Learning for Health (ML4H) 2024"},{"id":"http://arxiv.org/abs/2411.04635v1","updated":"2024-11-07T11:46:48Z","published":"2024-11-07T11:46:48Z","title":"Cybercrime Prediction via Geographically Weighted Learning","summary":"  Inspired by the success of Geographically Weighted Regression and its\naccounting for spatial variations, we propose GeogGNN -- A graph neural network\nmodel that accounts for geographical latitude and longitudinal points. Using a\nsynthetically generated dataset, we apply the algorithm for a 4-class\nclassification problem in cybersecurity with seemingly realistic geographic\ncoordinates centered in the Gulf Cooperation Council region. We demonstrate\nthat it has higher accuracy than standard neural networks and convolutional\nneural networks that treat the coordinates as features. Encouraged by the\nspeed-up in model accuracy by the GeogGNN model, we provide a general\nmathematical result that demonstrates that a geometrically weighted neural\nnetwork will, in principle, always display higher accuracy in the\nclassification of spatially dependent data by making use of spatial continuity\nand local averaging features.\n","authors":["Muhammad Al-Zafar Khan","Jamal Al-Karaki","Emad Mahafzah"],"pdf_url":"https://arxiv.org/pdf/2411.04635v1.pdf","comment":"17 pages, 8 figures, Submitted to the International Jordanian\n  Cybersecurity Conference 2024 (IJCC24)"},{"id":"http://arxiv.org/abs/2411.04632v1","updated":"2024-11-07T11:35:31Z","published":"2024-11-07T11:35:31Z","title":"Improved Multi-Task Brain Tumour Segmentation with Synthetic Data\n  Augmentation","summary":"  This paper presents the winning solution of task 1 and the third-placed\nsolution of task 3 of the BraTS challenge. The use of automated tools in\nclinical practice has increased due to the development of more and more\nsophisticated and reliable algorithms. However, achieving clinical standards\nand developing tools for real-life scenarios is a major challenge. To this end,\nBraTS has organised tasks to find the most advanced solutions for specific\npurposes. In this paper, we propose the use of synthetic data to train\nstate-of-the-art frameworks in order to improve the segmentation of adult\ngliomas in a post-treatment scenario, and the segmentation of meningioma for\nradiotherapy planning. Our results suggest that the use of synthetic data leads\nto more robust algorithms, although the synthetic data generation pipeline is\nnot directly suited to the meningioma task. The code for these tasks is\navailable at https://github.com/ShadowTwin41/BraTS_2023_2024_solutions.\n","authors":["André Ferreira","Tiago Jesus","Behrus Puladi","Jens Kleesiek","Victor Alves","Jan Egger"],"pdf_url":"https://arxiv.org/pdf/2411.04632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04630v1","updated":"2024-11-07T11:29:55Z","published":"2024-11-07T11:29:55Z","title":"Brain Tumour Removing and Missing Modality Generation using 3D WDM","summary":"  This paper presents the second-placed solution for task 8 and the\nparticipation solution for task 7 of BraTS 2024. The adoption of automated\nbrain analysis algorithms to support clinical practice is increasing. However,\nmany of these algorithms struggle with the presence of brain lesions or the\nabsence of certain MRI modalities. The alterations in the brain's morphology\nleads to high variability and thus poor performance of predictive models that\nwere trained only on healthy brains. The lack of information that is usually\nprovided by some of the missing MRI modalities also reduces the reliability of\nthe prediction models trained with all modalities. In order to improve the\nperformance of these models, we propose the use of conditional 3D wavelet\ndiffusion models. The wavelet transform enabled full-resolution image training\nand prediction on a GPU with 48 GB VRAM, without patching or downsampling,\npreserving all information for prediction. For the inpainting task of BraTS\n2024, the use of a large and variable number of healthy masks and the stability\nand efficiency of the 3D wavelet diffusion model resulted in 0.007, 22.61 and\n0.842 in the validation set and 0.07 , 22.8 and 0.91 in the testing set (MSE,\nPSNR and SSIM respectively). The code for these tasks is available at\nhttps://github.com/ShadowTwin41/BraTS_2023_2024_solutions.\n","authors":["André Ferreira","Gijs Luijten","Behrus Puladi","Jens Kleesiek","Victor Alves","Jan Egger"],"pdf_url":"https://arxiv.org/pdf/2411.04630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07712v3","updated":"2024-11-07T11:26:39Z","published":"2024-07-10T14:44:25Z","title":"Deep-Graph-Sprints: Accelerated Representation Learning in\n  Continuous-Time Dynamic Graphs","summary":"  Continuous-time dynamic graphs (CTDGs) are essential for modeling\ninterconnected, evolving systems. Traditional methods for extracting knowledge\nfrom these graphs often depend on feature engineering or deep learning. Feature\nengineering is limited by the manual and time-intensive nature of crafting\nfeatures, while deep learning approaches suffer from high inference latency,\nmaking them impractical for real-time applications. This paper introduces\nDeep-Graph-Sprints (DGS), a novel deep learning architecture designed for\nefficient representation learning on CTDGs with low-latency inference\nrequirements. We benchmark DGS against state-of-the-art (SOTA) feature\nengineering and graph neural network methods using five diverse datasets. The\nresults indicate that DGS achieves competitive performance while inference\nspeed improves between 4x and 12x compared to other deep learning approaches on\nour benchmark datasets. Our method effectively bridges the gap between deep\nrepresentation learning and low-latency application requirements for CTDGs.\n","authors":["Ahmad Naser Eddin","Jacopo Bono","David Aparício","Hugo Ferreira","Pedro Ribeiro","Pedro Bizarro"],"pdf_url":"https://arxiv.org/pdf/2407.07712v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04625v1","updated":"2024-11-07T11:22:46Z","published":"2024-11-07T11:22:46Z","title":"Sharp Analysis for KL-Regularized Contextual Bandits and RLHF","summary":"  Reverse-Kullback-Leibler (KL) regularization has emerged to be a predominant\ntechnique used to enhance policy optimization in reinforcement learning (RL)\nand reinforcement learning from human feedback (RLHF), which forces the learned\npolicy to stay close to a reference policy. While the effectiveness and\nnecessity of KL-regularization have been empirically demonstrated in various\npractical scenarios, current theoretical analysis of KL-regularized RLHF still\nobtains the same $\\mathcal{O}(1 / \\epsilon^2)$ sample complexity as problems\nwithout KL-regularization. To understand the fundamental distinction between\npolicy learning objectives with KL-regularization and ones without\nKL-regularization, we are the first to theoretically demonstrate the power of\nKL-regularization by providing a sharp analysis for KL-regularized contextual\nbandits and RLHF, revealing an $\\mathcal{O}(1 / \\epsilon)$ sample complexity\nwhen $\\epsilon$ is sufficiently small.\n  We further explore the role of data coverage in contextual bandits and RLHF.\nWhile the coverage assumption is commonly employed in offline RLHF to link the\nsamples from the reference policy to the optimal policy, often at the cost of a\nmultiplicative dependence on the coverage coefficient, its impact on the sample\ncomplexity of online RLHF remains unclear. Previous theoretical analyses of\nonline RLHF typically require explicit exploration and additional structural\nassumptions on the reward function class. In contrast, we show that with\nsufficient coverage from the reference policy, a simple two-stage mixed\nsampling strategy can achieve a sample complexity with only an additive\ndependence on the coverage coefficient. Our results provide a comprehensive\nunderstanding of the roles of KL-regularization and data coverage in RLHF,\nshedding light on the design of more efficient RLHF algorithms.\n","authors":["Heyang Zhao","Chenlu Ye","Quanquan Gu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.04625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09377v2","updated":"2024-11-07T11:21:56Z","published":"2023-06-15T08:18:29Z","title":"Evaluating alignment between humans and neural network representations\n  in image-based learning tasks","summary":"  Humans represent scenes and objects in rich feature spaces, carrying\ninformation that allows us to generalise about category memberships and\nabstract functions with few examples. What determines whether a neural network\nmodel generalises like a human? We tested how well the representations of $86$\npretrained neural network models mapped to human learning trajectories across\ntwo tasks where humans had to learn continuous relationships and categories of\nnatural images. In these tasks, both human participants and neural networks\nsuccessfully identified the relevant stimulus features within a few trials,\ndemonstrating effective generalisation. We found that while training dataset\nsize was a core determinant of alignment with human choices, contrastive\ntraining with multi-modal data (text and imagery) was a common feature of\ncurrently publicly available models that predicted human generalisation.\nIntrinsic dimensionality of representations had different effects on alignment\nfor different model types. Lastly, we tested three sets of human-aligned\nrepresentations and found no consistent improvements in predictive accuracy\ncompared to the baselines. In conclusion, pretrained neural networks can serve\nto extract representations for cognitive models, as they appear to capture some\nfundamental aspects of cognition that are transferable across tasks. Both our\nparadigms and modelling approach offer a novel way to quantify alignment\nbetween neural networks and humans and extend cognitive science into more\nnaturalistic domains.\n","authors":["Can Demircan","Tankred Saanum","Leonardo Pettini","Marcel Binz","Blazej M Baczkowski","Christian F Doeller","Mona M Garvert","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2306.09377v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02099v2","updated":"2024-11-07T10:53:14Z","published":"2024-11-04T14:08:26Z","title":"Differentially Private Integrated Decision Gradients (IDG-DP) for\n  Radar-based Human Activity Recognition","summary":"  Human motion analysis offers significant potential for healthcare monitoring\nand early detection of diseases. The advent of radar-based sensing systems has\ncaptured the spotlight for they are able to operate without physical contact\nand they can integrate with pre-existing Wi-Fi networks. They are also seen as\nless privacy-invasive compared to camera-based systems. However, recent\nresearch has shown high accuracy in recognizing subjects or gender from radar\ngait patterns, raising privacy concerns. This study addresses these issues by\ninvestigating privacy vulnerabilities in radar-based Human Activity Recognition\n(HAR) systems and proposing a novel method for privacy preservation using\nDifferential Privacy (DP) driven by attributions derived with Integrated\nDecision Gradient (IDG) algorithm. We investigate Black-box Membership\nInference Attack (MIA) Models in HAR settings across various levels of\nattacker-accessible information. We extensively evaluated the effectiveness of\nthe proposed IDG-DP method by designing a CNN-based HAR model and rigorously\nassessing its resilience against MIAs. Experimental results demonstrate the\npotential of IDG-DP in mitigating privacy attacks while maintaining utility\nacross all settings, particularly excelling against label-only and shadow model\nblack-box MIA attacks. This work represents a crucial step towards balancing\nthe need for effective radar-based HAR with robust privacy protection in\nhealthcare environments.\n","authors":["Idris Zakariyya","Linda Tran","Kaushik Bhargav Sivangi","Paul Henderson","Fani Deligianni"],"pdf_url":"https://arxiv.org/pdf/2411.02099v2.pdf","comment":"Accepted at WACV 2025. 12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.18624v3","updated":"2024-11-07T10:35:32Z","published":"2024-06-26T12:50:55Z","title":"Robust Low-Cost Drone Detection and Classification in Low SNR\n  Environments","summary":"  The proliferation of drones, or unmanned aerial vehicles (UAVs), has raised\nsignificant safety concerns due to their potential misuse in activities such as\nespionage, smuggling, and infrastructure disruption. This paper addresses the\ncritical need for effective drone detection and classification systems that\noperate independently of UAV cooperation. We evaluate various convolutional\nneural networks (CNNs) for their ability to detect and classify drones using\nspectrogram data derived from consecutive Fourier transforms of signal\ncomponents. The focus is on model robustness in low signal-to-noise ratio (SNR)\nenvironments, which is critical for real-world applications. A comprehensive\ndataset is provided to support future model development. In addition, we\ndemonstrate a low-cost drone detection system using a standard computer,\nsoftware-defined radio (SDR) and antenna, validated through real-world field\ntesting. On our development dataset, all models consistently achieved an\naverage balanced classification accuracy of >= 85% at SNR > -12dB. In the field\ntest, these models achieved an average balance accuracy of > 80%, depending on\ntransmitter distance and antenna direction. Our contributions include: a\npublicly available dataset for model development, a comparative analysis of CNN\nfor drone detection under low SNR conditions, and the deployment and field\nevaluation of a practical, low-cost detection system.\n","authors":["Stefan Glüge","Matthias Nyfeler","Ahmad Aghaebrahimian","Nicola Ramagnano","Christof Schüpbach"],"pdf_url":"https://arxiv.org/pdf/2406.18624v3.pdf","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.04596v1","updated":"2024-11-07T10:28:11Z","published":"2024-11-07T10:28:11Z","title":"The Impact of Semi-Supervised Learning on Line Segment Detection","summary":"  In this paper we present a method for line segment detection in images, based\non a semi-supervised framework. Leveraging the use of a consistency loss based\non differently augmented and perturbed unlabeled images with a small amount of\nlabeled data, we show comparable results to fully supervised methods. This\nopens up application scenarios where annotation is difficult or expensive, and\nfor domain specific adaptation of models. We are specifically interested in\nreal-time and online applications, and investigate small and efficient learning\nbackbones. Our method is to our knowledge the first to target line detection\nusing modern state-of-the-art methodologies for semi-supervised learning. We\ntest the method on both standard benchmarks and domain specific scenarios for\nforestry applications, showing the tractability of the proposed method.\n","authors":["Johanna Engman","Karl Åström","Magnus Oskarsson"],"pdf_url":"https://arxiv.org/pdf/2411.04596v1.pdf","comment":"9 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2411.04594v1","updated":"2024-11-07T10:25:20Z","published":"2024-11-07T10:25:20Z","title":"Verification of Neural Networks against Convolutional Perturbations via\n  Parameterised Kernels","summary":"  We develop a method for the efficient verification of neural networks against\nconvolutional perturbations such as blurring or sharpening. To define input\nperturbations we use well-known camera shake, box blur and sharpen kernels. We\ndemonstrate that these kernels can be linearly parameterised in a way that\nallows for a variation of the perturbation strength while preserving desired\nkernel properties. To facilitate their use in neural network verification, we\ndevelop an efficient way of convolving a given input with these parameterised\nkernels. The result of this convolution can be used to encode the perturbation\nin a verification setting by prepending a linear layer to a given network. This\nleads to tight bounds and a high effectiveness in the resulting verification\nstep. We add further precision by employing input splitting as a branch and\nbound strategy. We demonstrate that we are able to verify robustness on a\nnumber of standard benchmarks where the baseline is unable to provide any\nsafety certificates. To the best of our knowledge, this is the first solution\nfor verifying robustness against specific convolutional perturbations such as\ncamera shake.\n","authors":["Benedikt Brückner","Alessio Lomuscio"],"pdf_url":"https://arxiv.org/pdf/2411.04594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04620v4","updated":"2024-11-07T10:16:23Z","published":"2024-02-07T07:07:02Z","title":"CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract\n  Patients","summary":"  The healthcare landscape is evolving, with patients seeking reliable\ninformation about their health conditions and available treatment options.\nDespite the abundance of information sources, the digital age overwhelms\nindividuals with excess, often inaccurate information. Patients primarily trust\nmedical professionals, highlighting the need for expert-endorsed health\ninformation. However, increased patient loads on experts has led to reduced\ncommunication time, impacting information sharing. To address this gap, we\ndeveloped CataractBot, an experts-in-the-loop chatbot powered by LLMs, in\ncollaboration with an eye hospital in India. CataractBot answers cataract\nsurgery related questions instantly by querying a curated knowledge base and\nprovides expert-verified responses asynchronously. It has multimodal and\nmultilingual capabilities. In an in-the-wild deployment study with 55\nparticipants, CataractBot proved valuable, providing anytime accessibility,\nsaving time, accommodating diverse literacy levels, alleviating power\ndifferences, and adding a privacy layer between patients and doctors. Users\nreported that their trust in the system was established through expert\nverification. Broadly, our results could inform future work on designing\nexpert-mediated LLM bots.\n","authors":["Pragnya Ramjee","Bhuvan Sachdeva","Satvik Golechha","Shreyas Kulkarni","Geeta Fulari","Kaushik Murali","Mohit Jain"],"pdf_url":"https://arxiv.org/pdf/2402.04620v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04586v1","updated":"2024-11-07T10:15:25Z","published":"2024-11-07T10:15:25Z","title":"On the Inherent Robustness of One-Stage Object Detection against\n  Out-of-Distribution Data","summary":"  Robustness is a fundamental aspect for developing safe and trustworthy\nmodels, particularly when they are deployed in the open world. In this work we\nanalyze the inherent capability of one-stage object detectors to robustly\noperate in the presence of out-of-distribution (OoD) data. Specifically, we\npropose a novel detection algorithm for detecting unknown objects in image\ndata, which leverages the features extracted by the model from each sample.\nDifferently from other recent approaches in the literature, our proposal does\nnot require retraining the object detector, thereby allowing for the use of\npretrained models. Our proposed OoD detector exploits the application of\nsupervised dimensionality reduction techniques to mitigate the effects of the\ncurse of dimensionality on the features extracted by the model. Furthermore, it\nutilizes high-resolution feature maps to identify potential unknown objects in\nan unsupervised fashion. Our experiments analyze the Pareto trade-off between\nthe performance detecting known and unknown objects resulting from different\nalgorithmic configurations and inference confidence thresholds. We also compare\nthe performance of our proposed algorithm to that of logits-based post-hoc OoD\nmethods, as well as possible fusion strategies. Finally, we discuss on the\ncompetitiveness of all tested methods against state-of-the-art OoD approaches\nfor object detection models over the recently published Unknown Object\nDetection benchmark. The obtained results verify that the performance of\navant-garde post-hoc OoD detectors can be further improved when combined with\nour proposed algorithm.\n","authors":["Aitor Martinez-Seras","Javier Del Ser","Alain Andres","Pablo Garcia-Bringas"],"pdf_url":"https://arxiv.org/pdf/2411.04586v1.pdf","comment":"12 figures, 4 tables, under review"},{"id":"http://arxiv.org/abs/2411.04580v1","updated":"2024-11-07T10:06:23Z","published":"2024-11-07T10:06:23Z","title":"Interpreting the Learned Model in MuZero Planning","summary":"  MuZero has achieved superhuman performance in various games by using a\ndynamics network to predict environment dynamics for planning, without relying\non simulators. However, the latent states learned by the dynamics network make\nits planning process opaque. This paper aims to demystify MuZero's model by\ninterpreting the learned latent states. We incorporate observation\nreconstruction and state consistency into MuZero training and conduct an\nin-depth analysis to evaluate latent states across two board games: 9x9 Go and\nOuter-Open Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our\nfindings reveal that while the dynamics network becomes less accurate over\nlonger simulations, MuZero still performs effectively by using planning to\ncorrect errors. Our experiments also show that the dynamics network learns\nbetter latent states in board games than in Atari games. These insights\ncontribute to a better understanding of MuZero and offer directions for future\nresearch to improve the playing performance, robustness, and interpretability\nof the MuZero algorithm.\n","authors":["Hung Guei","Yan-Ru Ju","Wei-Yu Chen","Ti-Rong Wu"],"pdf_url":"https://arxiv.org/pdf/2411.04580v1.pdf","comment":"Accepted by the 29th International Conference on Technologies and\n  Applications of Artificial Intelligence (TAAI 2024)"},{"id":"http://arxiv.org/abs/2411.04579v1","updated":"2024-11-07T10:03:44Z","published":"2024-11-07T10:03:44Z","title":"Towards Robust Federated Analytics via Differentially Private\n  Measurements of Statistical Heterogeneity","summary":"  Statistical heterogeneity is a measure of how skewed the samples of a dataset\nare. It is a common problem in the study of differential privacy that the usage\nof a statistically heterogeneous dataset results in a significant loss of\naccuracy. In federated scenarios, statistical heterogeneity is more likely to\nhappen, and so the above problem is even more pressing. We explore the three\nmost promising ways to measure statistical heterogeneity and give formulae for\ntheir accuracy, while simultaneously incorporating differential privacy. We\nfind the optimum privacy parameters via an analytic mechanism, which\nincorporates root finding methods. We validate the main theorems and related\nhypotheses experimentally, and test the robustness of the analytic mechanism to\ndifferent heterogeneity levels. The analytic mechanism in a distributed setting\ndelivers superior accuracy to all combinations involving the classic mechanism\nand/or the centralized setting. All measures of statistical heterogeneity do\nnot lose significant accuracy when a heterogeneous sample is used.\n","authors":["Mary Scott","Graham Cormode","Carsten Maple"],"pdf_url":"https://arxiv.org/pdf/2411.04579v1.pdf","comment":"26 pages, 6 tables, 1 figure"},{"id":"http://arxiv.org/abs/2411.04570v1","updated":"2024-11-07T09:53:11Z","published":"2024-11-07T09:53:11Z","title":"Higher-Order GNNs Meet Efficiency: Sparse Sobolev Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) have shown great promise in modeling\nrelationships between nodes in a graph, but capturing higher-order\nrelationships remains a challenge for large-scale networks. Previous studies\nhave primarily attempted to utilize the information from higher-order neighbors\nin the graph, involving the incorporation of powers of the shift operator, such\nas the graph Laplacian or adjacency matrix. This approach comes with a\ntrade-off in terms of increased computational and memory demands. Relying on\ngraph spectral theory, we make a fundamental observation: the regular and the\nHadamard power of the Laplacian matrix behave similarly in the spectrum. This\nobservation has significant implications for capturing higher-order information\nin GNNs for various tasks such as node classification and semi-supervised\nlearning. Consequently, we propose a novel graph convolutional operator based\non the sparse Sobolev norm of graph signals. Our approach, known as Sparse\nSobolev GNN (S2-GNN), employs Hadamard products between matrices to maintain\nthe sparsity level in graph representations. S2-GNN utilizes a cascade of\nfilters with increasing Hadamard powers to generate a diverse set of functions.\nWe theoretically analyze the stability of S2-GNN to show the robustness of the\nmodel against possible graph perturbations. We also conduct a comprehensive\nevaluation of S2-GNN across various graph mining, semi-supervised node\nclassification, and computer vision tasks. In particular use cases, our\nalgorithm demonstrates competitive performance compared to state-of-the-art\nGNNs in terms of performance and running time.\n","authors":["Jhony H. Giraldo","Aref Einizade","Andjela Todorovic","Jhon A. Castro-Correa","Mohsen Badiey","Thierry Bouwmans","Fragkiskos D. Malliaros"],"pdf_url":"https://arxiv.org/pdf/2411.04570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04569v1","updated":"2024-11-07T09:47:18Z","published":"2024-11-07T09:47:18Z","title":"Impact of Label Noise on Learning Complex Features","summary":"  Neural networks trained with stochastic gradient descent exhibit an inductive\nbias towards simpler decision boundaries, typically converging to a narrow\nfamily of functions, and often fail to capture more complex features. This\nphenomenon raises concerns about the capacity of deep models to adequately\nlearn and represent real-world datasets. Traditional approaches such as\nexplicit regularization, data augmentation, architectural modifications, etc.,\nhave largely proven ineffective in encouraging the models to learn diverse\nfeatures. In this work, we investigate the impact of pre-training models with\nnoisy labels on the dynamics of SGD across various architectures and datasets.\nWe show that pretraining promotes learning complex functions and diverse\nfeatures in the presence of noise. Our experiments demonstrate that\npre-training with noisy labels encourages gradient descent to find alternate\nminima that do not solely depend upon simple features, rather learns more\ncomplex and broader set of features, without hurting performance.\n","authors":["Rahul Vashisht","P. Krishna Kumar","Harsha Vardhan Govind","Harish G. Ramaswamy"],"pdf_url":"https://arxiv.org/pdf/2411.04569v1.pdf","comment":"Accepted at Workshop on Scientific Methods for Understanding Deep\n  Learning, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04562v1","updated":"2024-11-07T09:35:22Z","published":"2024-11-07T09:35:22Z","title":"Constrained Latent Action Policies for Model-Based Offline Reinforcement\n  Learning","summary":"  In offline reinforcement learning, a policy is learned using a static dataset\nin the absence of costly feedback from the environment. In contrast to the\nonline setting, only using static datasets poses additional challenges, such as\npolicies generating out-of-distribution samples. Model-based offline\nreinforcement learning methods try to overcome these by learning a model of the\nunderlying dynamics of the environment and using it to guide policy search. It\nis beneficial but, with limited datasets, errors in the model and the issue of\nvalue overestimation among out-of-distribution states can worsen performance.\nCurrent model-based methods apply some notion of conservatism to the Bellman\nupdate, often implemented using uncertainty estimation derived from model\nensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP)\nwhich learns a generative model of the joint distribution of observations and\nactions. We cast policy learning as a constrained objective to always stay\nwithin the support of the latent action distribution, and use the generative\ncapabilities of the model to impose an implicit constraint on the generated\nactions. Thereby eliminating the need to use additional uncertainty penalties\non the Bellman update and significantly decreasing the number of gradient steps\nrequired to learn a policy. We empirically evaluate C-LAP on the D4RL and\nV-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art\nmethods, especially outperforming on datasets with visual observations.\n","authors":["Marvin Alles","Philip Becker-Ehmck","Patrick van der Smagt","Maximilian Karl"],"pdf_url":"https://arxiv.org/pdf/2411.04562v1.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)"},{"id":"http://arxiv.org/abs/2404.12096v3","updated":"2024-11-07T09:29:32Z","published":"2024-04-18T11:29:23Z","title":"LongEmbed: Extending Embedding Models for Long Context Retrieval","summary":"  Embedding models play a pivot role in modern NLP applications such as IR and\nRAG. While the context limit of LLMs has been pushed beyond 1 million tokens,\nembedding models are still confined to a narrow context window not exceeding 8k\ntokens, refrained from application scenarios requiring long inputs such as\nlegal contracts. This paper explores context window extension of existing\nembedding models, pushing the limit to 32k without requiring additional\ntraining. First, we examine the performance of current embedding models for\nlong context retrieval on our newly constructed LongEmbed benchmark. LongEmbed\ncomprises two synthetic tasks and four carefully chosen real-world tasks,\nfeaturing documents of varying length and dispersed target information.\nBenchmarking results underscore huge room for improvement in these models.\nBased on this, comprehensive experiments show that training-free context window\nextension strategies like position interpolation can effectively extend the\ncontext window of existing embedding models by several folds, regardless of\ntheir original context being 512 or beyond 4k. Furthermore, for models\nemploying absolute position encoding (APE), we show the possibility of further\nfine-tuning to harvest notable performance gains while strictly preserving\noriginal behavior for short inputs. For models using rotary position embedding\n(RoPE), significant enhancements are observed when employing RoPE-specific\nmethods, such as NTK and SelfExtend, indicating RoPE's superiority over APE for\ncontext window extension. To facilitate future research, we release E5-Base-4k\nand E5-RoPE-Base, along with the LongEmbed benchmark.\n","authors":["Dawei Zhu","Liang Wang","Nan Yang","Yifan Song","Wenhao Wu","Furu Wei","Sujian Li"],"pdf_url":"https://arxiv.org/pdf/2404.12096v3.pdf","comment":"EMNLP 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2411.04557v1","updated":"2024-11-07T09:28:38Z","published":"2024-11-07T09:28:38Z","title":"Pruning Literals for Highly Efficient Explainability at Word Level","summary":"  Designing an explainable model becomes crucial now for Natural Language\nProcessing(NLP) since most of the state-of-the-art machine learning models\nprovide a limited explanation for the prediction. In the spectrum of an\nexplainable model, Tsetlin Machine(TM) is promising because of its capability\nof providing word-level explanation using proposition logic. However, concern\nrises over the elaborated combination of literals (propositional logic) in the\nclause that makes the model difficult for humans to comprehend, despite having\na transparent learning process. In this paper, we design a post-hoc pruning of\nclauses that eliminate the randomly placed literals in the clause thereby\nmaking the model more efficiently interpretable than the vanilla TM.\nExperiments on the publicly available YELP-HAT Dataset demonstrate that the\nproposed pruned TM's attention map aligns more with the human attention map\nthan the vanilla TM's attention map. In addition, the pairwise similarity\nmeasure also surpasses the attention map-based neural network models. In terms\nof accuracy, the proposed pruning method does not degrade the accuracy\nsignificantly but rather enhances the performance up to 4% to 9% in some test\ndata.\n","authors":["Rohan Kumar Yadav","Bimal Bhattarai","Abhik Jana","Lei Jiao","Seid Muhie Yimam"],"pdf_url":"https://arxiv.org/pdf/2411.04557v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.04556v1","updated":"2024-11-07T09:27:42Z","published":"2024-11-07T09:27:42Z","title":"Uncertainty Prediction Neural Network (UpNet): Embedding Artificial\n  Neural Network in Bayesian Inversion Framework to Quantify the Uncertainty of\n  Remote Sensing Retrieval","summary":"  For the retrieval of large-scale vegetation biophysical parameters, the\ninversion of radiative transfer models (RTMs) is the most commonly used\napproach. In recent years, Artificial Neural Network (ANN)-based methods have\nbecome the mainstream for inverting RTMs due to their high accuracy and\ncomputational efficiency. It has been widely used in the retrieval of\nbiophysical variables (BV). However, due to the lack of the Bayesian inversion\ntheory interpretation, it faces challenges in quantifying the retrieval\nuncertainty, a crucial metric for product quality validation and downstream\napplications such as data assimilation or ecosystem carbon cycling modeling.\nThis study proved that the ANN trained with squared loss outputs the posterior\nmean, providing a rigorous foundation for its uncertainty quantification,\nregularization, and incorporation of prior information. A Bayesian theoretical\nframework was subsequently proposed for ANN-based methods. Using this\nframework, we derived a new algorithm called Uncertainty Prediction Neural\nNetwork (UpNet), which enables the simultaneous training of two ANNs to\nretrieve BV and provide retrieval uncertainty. To validate our method, we\ncompared UpNet with the standard Bayesian inference method, i.e., Markov Chain\nMonte Carlo (MCMC), in the inversion of a widely used RTM called ProSAIL for\nretrieving BVs and estimating uncertainty. The results demonstrated that the\nBVs retrieved and the uncertainties estimated by UpNet were highly consistent\nwith those from MCMC, achieving over a million-fold acceleration. These results\nindicated that UpNet has significant potential for fast retrieval and\nuncertainty quantification of BVs or other parameters with medium and\nhigh-resolution remote sensing data. Our Python implementation is available at:\nhttps://github.com/Dash-RSer/UpNet.\n","authors":["Dasheng Fan","Xihan Mu","Yongkang Lai","Donghui Xie","Guangjian Yan"],"pdf_url":"https://arxiv.org/pdf/2411.04556v1.pdf","comment":"24 pages, f figures"},{"id":"http://arxiv.org/abs/2411.02623v2","updated":"2024-11-07T09:25:28Z","published":"2024-11-04T21:31:04Z","title":"Learning to Assist Humans without Inferring Rewards","summary":"  Assistive agents should make humans' lives easier. Classically, such\nassistance is studied through the lens of inverse reinforcement learning, where\nan assistive agent (e.g., a chatbot, a robot) infers a human's intention and\nthen selects actions to help the human reach that goal. This approach requires\ninferring intentions, which can be difficult in high-dimensional settings. We\nbuild upon prior work that studies assistance through the lens of empowerment:\nan assistive agent aims to maximize the influence of the human's actions such\nthat they exert a greater control over the environmental outcomes and can solve\ntasks in fewer steps. We lift the major limitation of prior work in this\narea--scalability to high-dimensional settings--with contrastive successor\nrepresentations. We formally prove that these representations estimate a\nsimilar notion of empowerment to that studied by prior work and provide a\nready-made mechanism for optimizing it. Empirically, our proposed method\noutperforms prior methods on synthetic benchmarks, and scales to Overcooked, a\ncooperative game setting. Theoretically, our work connects ideas from\ninformation theory, neuroscience, and reinforcement learning, and charts a path\nfor representations to play a critical role in solving assistive problems.\n","authors":["Vivek Myers","Evan Ellis","Sergey Levine","Benjamin Eysenbach","Anca Dragan"],"pdf_url":"https://arxiv.org/pdf/2411.02623v2.pdf","comment":"Conference on Neural Information Processing Systems (NeurIPS), 2024"},{"id":"http://arxiv.org/abs/2411.04554v1","updated":"2024-11-07T09:24:26Z","published":"2024-11-07T09:24:26Z","title":"Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis","summary":"  Time series analysis finds wide applications in fields such as weather\nforecasting, anomaly detection, and behavior recognition. Previous methods\nattempted to model temporal variations directly using 1D time series. However,\nthis has been quite challenging due to the discrete nature of data points in\ntime series and the complexity of periodic variation. In terms of periodicity,\ntaking weather and traffic data as an example, there are multi-periodic\nvariations such as yearly, monthly, weekly, and daily, etc. In order to break\nthrough the limitations of the previous methods, we decouple the implied\ncomplex periodic variations into inclusion and overlap relationships among\ndifferent level periodic components based on the observation of the\nmulti-periodicity therein and its inclusion relationships. This explicitly\nrepresents the naturally occurring pyramid-like properties in time series,\nwhere the top level is the original time series and lower levels consist of\nperiodic components with gradually shorter periods, which we call the periodic\npyramid. To further extract complex temporal variations, we introduce\nself-attention mechanism into the periodic pyramid, capturing complex periodic\nrelationships by computing attention between periodic components based on their\ninclusion, overlap, and adjacency relationships. Our proposed Peri-midFormer\ndemonstrates outstanding performance in five mainstream time series analysis\ntasks, including short- and long-term forecasting, imputation, classification,\nand anomaly detection.\n","authors":["Qiang Wu","Gechang Yao","Zhixi Feng","Shuyuan Yang"],"pdf_url":"https://arxiv.org/pdf/2411.04554v1.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)"},{"id":"http://arxiv.org/abs/2406.01494v2","updated":"2024-11-07T09:23:34Z","published":"2024-06-03T16:21:29Z","title":"Robust Classification by Coupling Data Mollification with Label\n  Smoothing","summary":"  Introducing training-time augmentations is a key technique to enhance\ngeneralization and prepare deep neural networks against test-time corruptions.\nInspired by the success of generative diffusion models, we propose a novel\napproach of coupling data mollification, in the form of image noising and\nblurring, with label smoothing to align predicted label confidences with image\ndegradation. The method is simple to implement, introduces negligible\noverheads, and can be combined with existing augmentations. We demonstrate\nimproved robustness and uncertainty quantification on the corrupted image\nbenchmarks of the CIFAR and TinyImageNet datasets.\n","authors":["Markus Heinonen","Ba-Hien Tran","Michael Kampffmeyer","Maurizio Filippone"],"pdf_url":"https://arxiv.org/pdf/2406.01494v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2404.02545v2","updated":"2024-11-07T09:20:39Z","published":"2024-04-03T08:03:27Z","title":"Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning","summary":"  Offline reinforcement learning learns from a static dataset without\ninteracting with environments, which ensures security and thus owns a good\napplication prospect. However, directly applying naive reinforcement learning\nalgorithm usually fails in an offline environment due to inaccurate Q value\napproximation caused by out-of-distribution (OOD) state-actions. It is an\neffective way to solve this problem by penalizing the Q-value of OOD\nstate-actions. Among the methods of punishing OOD state-actions, count-based\nmethods have achieved good results in discrete domains in a simple form.\nInspired by it, a novel pseudo-count method for continuous domains called\nGrid-Mapping Pseudo-Count method (GPC) is proposed by extending the count-based\nmethod from discrete to continuous domains. Firstly, the continuous state and\naction space are mapped to discrete space using Grid-Mapping, then the Q-values\nof OOD state-actions are constrained through pseudo-count. Secondly, the\ntheoretical proof is given to show that GPC can obtain appropriate uncertainty\nconstraints under fewer assumptions than other pseudo-count methods. Thirdly,\nGPC is combined with Soft Actor-Critic algorithm (SAC) to get a new algorithm\ncalled GPC-SAC. Lastly, experiments on D4RL datasets are given to show that\nGPC-SAC has better performance and less computational cost than other\nalgorithms that constrain the Q-value.\n","authors":["Yi Shen","Hanyan Huang"],"pdf_url":"https://arxiv.org/pdf/2404.02545v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04551v1","updated":"2024-11-07T09:18:39Z","published":"2024-11-07T09:18:39Z","title":"Measure-to-measure interpolation using Transformers","summary":"  Transformers are deep neural network architectures that underpin the recent\nsuccesses of large language models. Unlike more classical architectures that\ncan be viewed as point-to-point maps, a Transformer acts as a\nmeasure-to-measure map implemented as specific interacting particle system on\nthe unit sphere: the input is the empirical measure of tokens in a prompt and\nits evolution is governed by the continuity equation. In fact, Transformers are\nnot limited to empirical measures and can in principle process any input\nmeasure. As the nature of data processed by Transformers is expanding rapidly,\nit is important to investigate their expressive power as maps from an arbitrary\nmeasure to another arbitrary measure. To that end, we provide an explicit\nchoice of parameters that allows a single Transformer to match $N$ arbitrary\ninput measures to $N$ arbitrary target measures, under the minimal assumption\nthat every pair of input-target measures can be matched by some transport map.\n","authors":["Borjan Geshkovski","Philippe Rigollet","Domènec Ruiz-Balet"],"pdf_url":"https://arxiv.org/pdf/2411.04551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04549v1","updated":"2024-11-07T09:17:50Z","published":"2024-11-07T09:17:50Z","title":"Vision Language Models are In-Context Value Learners","summary":"  Predicting temporal progress from visual trajectories is important for\nintelligent robots that can learn, adapt, and improve. However, learning such\nprogress estimator, or temporal value function, across different tasks and\ndomains requires both a large amount of diverse data and methods which can\nscale and generalize. To address these challenges, we present Generative Value\nLearning (\\GVL), a universal value function estimator that leverages the world\nknowledge embedded in vision-language models (VLMs) to predict task progress.\nNaively asking a VLM to predict values for a video sequence performs poorly due\nto the strong temporal correlation between successive frames. Instead, GVL\nposes value estimation as a temporal ordering problem over shuffled video\nframes; this seemingly more challenging task encourages VLMs to more fully\nexploit their underlying semantic and temporal grounding capabilities to\ndifferentiate frames based on their perceived task progress, consequently\nproducing significantly better value predictions. Without any robot or task\nspecific training, GVL can in-context zero-shot and few-shot predict effective\nvalues for more than 300 distinct real-world tasks across diverse robot\nplatforms, including challenging bimanual manipulation tasks. Furthermore, we\ndemonstrate that GVL permits flexible multi-modal in-context learning via\nexamples from heterogeneous tasks and embodiments, such as human videos. The\ngenerality of GVL enables various downstream applications pertinent to\nvisuomotor policy learning, including dataset filtering, success detection, and\nadvantage-weighted regression -- all without any model training or finetuning.\n","authors":["Yecheng Jason Ma","Joey Hejna","Ayzaan Wahid","Chuyuan Fu","Dhruv Shah","Jacky Liang","Zhuo Xu","Sean Kirmani","Peng Xu","Danny Driess","Ted Xiao","Jonathan Tompson","Osbert Bastani","Dinesh Jayaraman","Wenhao Yu","Tingnan Zhang","Dorsa Sadigh","Fei Xia"],"pdf_url":"https://arxiv.org/pdf/2411.04549v1.pdf","comment":"Project website and demo:\n  https://generative-value-learning.github.io/"},{"id":"http://arxiv.org/abs/2307.10869v3","updated":"2024-11-07T09:03:49Z","published":"2023-07-20T13:41:26Z","title":"Identifying Performance Issues in Cloud Service Systems Based on\n  Relational-Temporal Features","summary":"  Cloud systems are susceptible to performance issues, which may cause\nservice-level agreement violations and financial losses. In current practice,\ncrucial metrics are monitored periodically to provide insight into the\noperational status of components. Identifying performance issues is often\nformulated as an anomaly detection problem, which is tackled by analyzing each\nmetric independently. However, this approach overlooks the complex dependencies\nexisting among cloud components. Some graph neural network-based methods take\nboth temporal and relational information into account, however, the correlation\nviolations in the metrics that serve as indicators of underlying performance\nissues are difficult for them to identify. Furthermore, a large volume of\ncomponents in a cloud system results in a vast array of noisy metrics. This\ncomplexity renders it impractical for engineers to fully comprehend the\ncorrelations, making it challenging to identify performance issues accurately.\nTo address these limitations, we propose Identifying Performance Issues based\non Relational-Temporal Features (ISOLATE ), a learning-based approach that\nleverages both the relational and temporal features of metrics to identify\nperformance issues. In particular, it adopts a graph neural network with\nattention to characterizing the relations among metrics and extracts long-term\nand multi-scale temporal patterns using a GRU and a convolution network,\nrespectively. The learned graph attention weights can be further used to\nlocalize the correlation-violated metrics. Moreover, to relieve the impact of\nnoisy data, ISOLATE utilizes a positive unlabeled learning strategy that tags\npseudo-labels based on a small portion of confirmed negative examples.\nExtensive evaluation on both public and industrial datasets shows that ISOLATE\noutperforms all baseline models with 0.945 F1-score and 0.920 Hit rate@3.\n","authors":["Wenwei Gu","Jinyang Liu","Zhuangbin Chen","Jianping Zhang","Yuxin Su","Jiazhen Gu","Cong Feng","Zengyin Yang","Yongqiang Yang","Michael Lyu"],"pdf_url":"https://arxiv.org/pdf/2307.10869v3.pdf","comment":"Accepted in ACM Transactions on Software Engineering and Methodology\n  (TOSEM)"},{"id":"http://arxiv.org/abs/2404.04940v2","updated":"2024-11-07T08:59:23Z","published":"2024-04-07T12:25:03Z","title":"Fuzzy K-Means Clustering without Cluster Centroids","summary":"  Fuzzy K-Means clustering is a critical technique in unsupervised data\nanalysis. Unlike traditional hard clustering algorithms such as K-Means, it\nallows data points to belong to multiple clusters with varying degrees of\nmembership, determined through iterative optimization to establish optimal\ncluster centers and memberships, thereby achieving fuzzy partitioning of data.\nHowever, the performance of popular Fuzzy K-Means algorithms is sensitive to\nthe selection of initial cluster centroids and is also affected by noise when\nupdating mean cluster centroids. To address these challenges, this paper\nproposes a novel Fuzzy \\textit{K}-Means clustering algorithm that entirely\neliminates the reliance on cluster centroids, obtaining membership metrics\nsolely through distance matrix computation. This innovation enhances\nflexibility in distance measurement between sample points, thus improving the\nalgorithm's performance and robustness. The paper also establishes theoretical\nconnections between the proposed model and popular Fuzzy K-Means clustering\ntechniques. Experimental results on several real datasets demonstrate the\neffectiveness of the algorithm.\n","authors":["Yichen Bao","Han Lu","Quanxue Gao"],"pdf_url":"https://arxiv.org/pdf/2404.04940v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03701v4","updated":"2024-11-07T08:50:25Z","published":"2024-04-04T00:49:05Z","title":"Predictive Analytics of Varieties of Potatoes","summary":"  We explore the application of machine learning algorithms specifically to\nenhance the selection process of Russet potato clones in breeding trials by\npredicting their suitability for advancement. This study addresses the\nchallenge of efficiently identifying high-yield, disease-resistant, and\nclimate-resilient potato varieties that meet processing industry standards.\nLeveraging manually collected data from trials in the state of Oregon, we\ninvestigate the potential of a wide variety of state-of-the-art binary\nclassification models. The dataset includes 1086 clones, with data on 38\nattributes recorded for each clone, focusing on yield, size, appearance, and\nfrying characteristics, with several control varieties planted consistently\nacross four Oregon regions from 2013-2021. We conduct a comprehensive analysis\nof the dataset that includes preprocessing, feature engineering, and imputation\nto address missing values. We focus on several key metrics such as accuracy,\nF1-score, and Matthews correlation coefficient (MCC) for model evaluation. The\ntop-performing models, namely a neural network classifier (Neural Net),\nhistogram-based gradient boosting classifier (HGBC), and a support vector\nmachine classifier (SVM), demonstrate consistent and significant results. To\nfurther validate our findings, we conduct a simulation study. By simulating\ndifferent data-generating scenarios, we assess model robustness and performance\nthrough true positive, true negative, false positive, and false negative\ndistributions, area under the receiver operating characteristic curve (AUC-ROC)\nand MCC. The simulation results highlight that non-linear models like SVM and\nHGBC consistently show higher AUC-ROC and MCC than logistic regression (LR),\nthus outperforming the traditional linear model across various distributions,\nand emphasizing the importance of model selection and tuning in agricultural\ntrials.\n","authors":["Fabiana Ferracina","Bala Krishnamoorthy","Mahantesh Halappanavar","Shengwei Hu","Vidyasagar Sathuvalli"],"pdf_url":"https://arxiv.org/pdf/2404.03701v4.pdf","comment":"Minor revision; to appear in Crop Sciences"},{"id":"http://arxiv.org/abs/2411.04534v1","updated":"2024-11-07T08:48:32Z","published":"2024-11-07T08:48:32Z","title":"Hypercube Policy Regularization Framework for Offline Reinforcement\n  Learning","summary":"  Offline reinforcement learning has received extensive attention from scholars\nbecause it avoids the interaction between the agent and the environment by\nlearning a policy through a static dataset. However, general reinforcement\nlearning methods cannot get satisfactory results in offline reinforcement\nlearning due to the out-of-distribution state actions that the dataset cannot\ncover during training. To solve this problem, the policy regularization method\nthat tries to directly clone policies used in static datasets has received\nnumerous studies due to its simplicity and effectiveness. However, policy\nconstraint methods make the agent choose the corresponding actions in the\nstatic dataset. This type of constraint is usually over-conservative, which\nresults in suboptimal policies, especially in low-quality static datasets. In\nthis paper, a hypercube policy regularization framework is proposed, this\nmethod alleviates the constraints of policy constraint methods by allowing the\nagent to explore the actions corresponding to similar states in the static\ndataset, which increases the effectiveness of algorithms in low-quality\ndatasets. It was also theoretically demonstrated that the hypercube policy\nregularization framework can effectively improve the performance of original\nalgorithms. In addition, the hypercube policy regularization framework is\ncombined with TD3-BC and Diffusion-QL for experiments on D4RL datasets which\nare called TD3-BC-C and Diffusion-QL-C. The experimental results of the score\ndemonstrate that TD3-BC-C and Diffusion-QL-C perform better than\nstate-of-the-art algorithms like IQL, CQL, TD3-BC and Diffusion-QL in most D4RL\nenvironments in approximate time.\n","authors":["Yi Shen","Hanyan Huang"],"pdf_url":"https://arxiv.org/pdf/2411.04534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04533v1","updated":"2024-11-07T08:43:42Z","published":"2024-11-07T08:43:42Z","title":"Neural Fingerprints for Adversarial Attack Detection","summary":"  Deep learning models for image classification have become standard tools in\nrecent years. A well known vulnerability of these models is their\nsusceptibility to adversarial examples. These are generated by slightly\naltering an image of a certain class in a way that is imperceptible to humans\nbut causes the model to classify it wrongly as another class. Many algorithms\nhave been proposed to address this problem, falling generally into one of two\ncategories: (i) building robust classifiers (ii) directly detecting attacked\nimages. Despite the good performance of these detectors, we argue that in a\nwhite-box setting, where the attacker knows the configuration and weights of\nthe network and the detector, they can overcome the detector by running many\nexamples on a local copy, and sending only those that were not detected to the\nactual model. This problem is common in security applications where even a very\ngood model is not sufficient to ensure safety. In this paper we propose to\novercome this inherent limitation of any static defence with randomization. To\ndo so, one must generate a very large family of detectors with consistent\nperformance, and select one or more of them randomly for each input. For the\nindividual detectors, we suggest the method of neural fingerprints. In the\ntraining phase, for each class we repeatedly sample a tiny random subset of\nneurons from certain layers of the network, and if their average is\nsufficiently different between clean and attacked images of the focal class\nthey are considered a fingerprint and added to the detector bank. During test\ntime, we sample fingerprints from the bank associated with the label predicted\nby the model, and detect attacks using a likelihood ratio test. We evaluate our\ndetectors on ImageNet with different attack methods and model architectures,\nand show near-perfect detection with low rates of false detection.\n","authors":["Haim Fisher","Moni Shahar","Yehezkel S. Resheff"],"pdf_url":"https://arxiv.org/pdf/2411.04533v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2411.04532v1","updated":"2024-11-07T08:41:13Z","published":"2024-11-07T08:41:13Z","title":"Real-time stress detection on social network posts using big data\n  technology","summary":"  In the context of modern life, particularly in Industry 4.0 within the online\nspace, emotions and moods are frequently conveyed through social media posts.\nThe trend of sharing stories, thoughts, and feelings on these platforms\ngenerates a vast and promising data source for Big Data. This creates both a\nchallenge and an opportunity for research in applying technology to develop\nmore automated and accurate methods for detecting stress in social media users.\nIn this study, we developed a real-time system for stress detection in online\nposts, using the \"Dreaddit: A Reddit Dataset for Stress Analysis in Social\nMedia,\" which comprises 187,444 posts across five different Reddit domains.\nEach domain contains texts with both stressful and non-stressful content,\nshowcasing various expressions of stress. A labeled dataset of 3,553 lines was\ncreated for training. Apache Kafka, PySpark, and AirFlow were utilized to build\nand deploy the model. Logistic Regression yielded the best results for new\nstreaming data, achieving 69,39% for measuring accuracy and 68,97 for measuring\nF1-scores.\n","authors":["Hai-Yen Phan Nguyen","Phi-Lan Ly","Duc-Manh Le","Trong-Hop Do"],"pdf_url":"https://arxiv.org/pdf/2411.04532v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2405.17382v2","updated":"2024-11-07T08:34:27Z","published":"2024-05-27T17:38:33Z","title":"ReMoDetect: Reward Models Recognize Aligned LLM's Generations","summary":"  The remarkable capabilities and easy accessibility of large language models\n(LLMs) have significantly increased societal risks (e.g., fake news\ngeneration), necessitating the development of LLM-generated text (LGT)\ndetection methods for safe usage. However, detecting LGTs is challenging due to\nthe vast number of LLMs, making it impractical to account for each LLM\nindividually; hence, it is crucial to identify the common characteristics\nshared by these models. In this paper, we draw attention to a common feature of\nrecent powerful LLMs, namely the alignment training, i.e., training LLMs to\ngenerate human-preferable texts. Our key finding is that as these aligned LLMs\nare trained to maximize the human preferences, they generate texts with higher\nestimated preferences even than human-written texts; thus, such texts are\neasily detected by using the reward model (i.e., an LLM trained to model human\npreference distribution). Based on this finding, we propose two training\nschemes to further improve the detection ability of the reward model, namely\n(i) continual preference fine-tuning to make the reward model prefer aligned\nLGTs even further and (ii) reward modeling of Human/LLM mixed texts (a\nrephrased texts from human-written texts using aligned LLMs), which serves as a\nmedian preference text corpus between LGTs and human-written texts to learn the\ndecision boundary better. We provide an extensive evaluation by considering six\ntext domains across twelve aligned LLMs, where our method demonstrates\nstate-of-the-art results. Code is available at\nhttps://github.com/hyunseoklee-ai/ReMoDetect.\n","authors":["Hyunseok Lee","Jihoon Tack","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2405.17382v2.pdf","comment":"Published as a conference proceeding for NeurIPS 2024"},{"id":"http://arxiv.org/abs/2401.00828v4","updated":"2024-11-07T08:29:41Z","published":"2024-01-01T17:56:24Z","title":"Multi-Lattice Sampling of Quantum Field Theories via Neural\n  Operator-based Flows","summary":"  We consider the problem of sampling lattice field configurations on a lattice\nfrom the Boltzmann distribution corresponding to some action. Since such\ndensities arise as approximationw of an underlying functional density, we frame\nthe task as an instance of operator learning. We propose to approximate a\ntime-dependent neural operator whose time integral provides a mapping between\nthe functional distributions of the free and target theories. Once a particular\nlattice is chosen, the neural operator can be discretized to a\nfinite-dimensional, time-dependent vector field which in turn induces a\ncontinuous normalizing flow between finite dimensional distributions over the\nchosen lattice. This flow can then be trained to be a diffeormorphism between\nthe discretized free and target theories on the chosen lattice, and, by\nconstruction, can be evaluated on different discretizations of spacetime. We\nexperimentally validate the proposal on the 2-dimensional $\\phi^4$-theory to\nexplore to what extent such operator-based flow architectures generalize to\nlattice sizes they were not trained on, and show that pretraining on smaller\nlattices can lead to a speedup over training directly on the target lattice\nsize.\n","authors":["Bálint Máté","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2401.00828v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04517v1","updated":"2024-11-07T08:19:39Z","published":"2024-11-07T08:19:39Z","title":"Continuous Sign Language Recognition System using Deep Learning with\n  MediaPipe Holistic","summary":"  Sign languages are the language of hearing-impaired people who use visuals\nlike the hand, facial, and body movements for communication. There are\ndifferent signs and gestures representing alphabets, words, and phrases.\nNowadays approximately 300 sign languages are being practiced worldwide such as\nAmerican Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language\n(ISL), and many more. Sign languages are dependent on the vocal language of a\nplace. Unlike vocal or spoken languages, there are no helping words in sign\nlanguage like is, am, are, was, were, will, be, etc. As only a limited\npopulation is well-versed in sign language, this lack of familiarity of sign\nlanguage hinders hearing-impaired people from communicating freely and easily\nwith everyone. This issue can be addressed by a sign language recognition (SLR)\nsystem which has the capability to translate the sign language into vocal\nlanguage. In this paper, a continuous SLR system is proposed using a deep\nlearning model employing Long Short-Term Memory (LSTM), trained and tested on\nan ISL primary dataset. This dataset is created using MediaPipe Holistic\npipeline for tracking face, hand, and body movements and collecting landmarks.\nThe system recognizes the signs and gestures in real-time with 88.23% accuracy.\n","authors":["Sharvani Srivastava","Sudhakar Singh"," Pooja","Shiv Prakash"],"pdf_url":"https://arxiv.org/pdf/2411.04517v1.pdf","comment":"14 pages, 4 figures, Wireless Pers Commun"},{"id":"http://arxiv.org/abs/2411.03450v2","updated":"2024-11-07T08:10:41Z","published":"2024-11-05T19:07:26Z","title":"Fourier Analysis of Variational Quantum Circuits for Supervised Learning","summary":"  VQC can be understood through the lens of Fourier analysis. It is already\nwell-known that the function space represented by any circuit architecture can\nbe described through a truncated Fourier sum. We show that the spectrum\navailable to that truncated Fourier sum is not entirely determined by the\nencoding gates of the circuit, since the variational part of the circuit can\nconstrain certain coefficients to zero, effectively removing that frequency\nfrom the spectrum. To the best of our knowledge, we give the first description\nof the functional dependence of the Fourier coefficients on the variational\nparameters as trigonometric polynomials. This allows us to provide an algorithm\nwhich computes the exact spectrum of any given circuit and the corresponding\nFourier coefficients. Finally, we demonstrate that by comparing the Fourier\ntransform of the dataset to the available spectra, it is possible to predict\nwhich VQC out of a given list of choices will be able to best fit the data.\n","authors":["Marco Wiedmann","Maniraman Periyasamy","Daniel D. Scherer"],"pdf_url":"https://arxiv.org/pdf/2411.03450v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04512v1","updated":"2024-11-07T08:10:28Z","published":"2024-11-07T08:10:28Z","title":"Normalized Space Alignment: A Versatile Metric for Representation\n  Analysis","summary":"  We introduce a manifold analysis technique for neural network\nrepresentations. Normalized Space Alignment (NSA) compares pairwise distances\nbetween two point clouds derived from the same source and having the same size,\nwhile potentially possessing differing dimensionalities. NSA can act as both an\nanalytical tool and a differentiable loss function, providing a robust means of\ncomparing and aligning representations across different layers and models. It\nsatisfies the criteria necessary for both a similarity metric and a neural\nnetwork loss function. We showcase NSA's versatility by illustrating its\nutility as a representation space analysis metric, a structure-preserving loss\nfunction, and a robustness analysis tool. NSA is not only computationally\nefficient but it can also approximate the global structural discrepancy during\nmini-batching, facilitating its use in a wide variety of neural network\ntraining paradigms.\n","authors":["Danish Ebadulla","Aditya Gulati","Ambuj Singh"],"pdf_url":"https://arxiv.org/pdf/2411.04512v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2411.04511v1","updated":"2024-11-07T08:08:12Z","published":"2024-11-07T08:08:12Z","title":"Improve the Fitting Accuracy of Deep Learning for the Nonlinear\n  Schrödinger Equation Using Linear Feature Decoupling Method","summary":"  We utilize the Feature Decoupling Distributed (FDD) method to enhance the\ncapability of deep learning to fit the Nonlinear Schrodinger Equation (NLSE),\nsignificantly reducing the NLSE loss compared to non decoupling model.\n","authors":["Yunfan Zhang","Zekun Niu","Minghui Shi","Weisheng Hu","Lilin Yi"],"pdf_url":"https://arxiv.org/pdf/2411.04511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01635v4","updated":"2024-11-07T07:52:35Z","published":"2024-06-30T10:53:40Z","title":"Commute Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) have shown remarkable success in learning from\ngraph-structured data. However, their application to directed graphs (digraphs)\npresents unique challenges, primarily due to the inherent asymmetry in node\nrelationships. Traditional GNNs are adept at capturing unidirectional relations\nbut fall short in encoding the mutual path dependencies between nodes, such as\nasymmetrical shortest paths typically found in digraphs. Recognizing this gap,\nwe introduce Commute Graph Neural Networks (CGNN), an approach that seamlessly\nintegrates node-wise commute time into the message passing scheme. The\ncornerstone of CGNN is an efficient method for computing commute time using a\nnewly formulated digraph Laplacian. Commute time is then integrated into the\nneighborhood aggregation process, with neighbor contributions weighted\naccording to their respective commute time to the central node in each layer.\nIt enables CGNN to directly capture the mutual, asymmetric relationships in\ndigraphs. Extensive experiments confirm the superior performance of CGNN.\n","authors":["Wei Zhuo","Guang Tan"],"pdf_url":"https://arxiv.org/pdf/2407.01635v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04493v1","updated":"2024-11-07T07:41:04Z","published":"2024-11-07T07:41:04Z","title":"Synergy-Guided Regional Supervision of Pseudo Labels for Semi-Supervised\n  Medical Image Segmentation","summary":"  Semi-supervised learning has received considerable attention for its\npotential to leverage abundant unlabeled data to enhance model robustness.\nPseudo labeling is a widely used strategy in semi supervised learning. However,\nexisting methods often suffer from noise contamination, which can undermine\nmodel performance. To tackle this challenge, we introduce a novel\nSynergy-Guided Regional Supervision of Pseudo Labels (SGRS-Net) framework.\nBuilt upon the mean teacher network, we employ a Mix Augmentation module to\nenhance the unlabeled data. By evaluating the synergy before and after\naugmentation, we strategically partition the pseudo labels into distinct\nregions. Additionally, we introduce a Region Loss Evaluation module to assess\nthe loss across each delineated area. Extensive experiments conducted on the LA\ndataset have demonstrated superior performance over state-of-the-art\ntechniques, underscoring the efficiency and practicality of our framework.\n","authors":["Tao Wang","Xinlin Zhang","Yuanbin Chen","Yuanbo Zhou","Longxuan Zhao","Tao Tan","Tong Tong"],"pdf_url":"https://arxiv.org/pdf/2411.04493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04491v1","updated":"2024-11-07T07:37:34Z","published":"2024-11-07T07:37:34Z","title":"Series-to-Series Diffusion Bridge Model","summary":"  Diffusion models have risen to prominence in time series forecasting,\nshowcasing their robust capability to model complex data distributions.\nHowever, their effectiveness in deterministic predictions is often constrained\nby instability arising from their inherent stochasticity. In this paper, we\nrevisit time series diffusion models and present a comprehensive framework that\nencompasses most existing diffusion-based methods. Building on this theoretical\nfoundation, we propose a novel diffusion-based time series forecasting model,\nthe Series-to-Series Diffusion Bridge Model ($\\mathrm{S^2DBM}$), which\nleverages the Brownian Bridge process to reduce randomness in reverse\nestimations and improves accuracy by incorporating informative priors and\nconditions derived from historical time series data. Experimental results\ndemonstrate that $\\mathrm{S^2DBM}$ delivers superior performance in\npoint-to-point forecasting and competes effectively with other diffusion-based\nmodels in probabilistic forecasting.\n","authors":["Hao Yang","Zhanbo Feng","Feng Zhou","Robert C Qiu","Zenan Ling"],"pdf_url":"https://arxiv.org/pdf/2411.04491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14979v3","updated":"2024-11-07T07:25:04Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration From A Psychological Perspective","summary":"  Despite their proficiency in math tasks, the mechanisms underlying LLMs'\nmathematical reasoning abilities remain a subject of debate. Recent studies\nsuggest that chain-of-thought (CoT) prompts can bolster mathematical reasoning\nby encouraging LLMs to employ human-like logical reasoning (System 2), enabling\nthem to excel on the Cognitive Reflection Test (CRT). To assess whether LLMs\ngenuinely possess System 2-like logical reasoning, we introduced targeted\nmodifications to CRT problems. Our findings reveal that, despite the use of CoT\nprompts, mainstream LLMs, including the latest o1-preview model, continue to\nexhibit a significant error rate. Further analysis indicates that they\npredominantly rely on System 1-like intuitive reasoning and pattern matching\nderived from training data, rather than demonstrating mastery of mathematical\nthinking. This discovery challenges the prevailing notion that LLMs possess\ngenuine logical reasoning abilities and that CoT can enhance them.\nConsequently, this work may temper overly optimistic projections regarding\nLLMs' advancement toward artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Kai Chen","Xiaobing Sun","Baosheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14979v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04476v1","updated":"2024-11-07T07:07:34Z","published":"2024-11-07T07:07:34Z","title":"LLM-R: A Framework for Domain-Adaptive Maintenance Scheme Generation\n  Combining Hierarchical Agents and RAG","summary":"  The increasing use of smart devices has emphasized the critical role of\nmaintenance in production activities. Interactive Electronic Technical Manuals\n(IETMs) are vital tools that support the maintenance of smart equipment.\nHowever, traditional IETMs face challenges such as transitioning from Graphical\nUser Interfaces (GUIs) to natural Language User Interfaces (LUIs) and managing\ncomplex logical relationships. Additionally, they must meet the current demands\nfor higher intelligence. This paper proposes a Maintenance Scheme Generation\nMethod based on Large Language Models (LLM-R). The proposed method includes\nseveral key innovations: We propose the Low Rank Adaptation-Knowledge Retention\n(LORA-KR) loss technology to proportionally adjust mixed maintenance data for\nfine-tuning the LLM. This method prevents knowledge conflicts caused by mixed\ndata, improving the model's adaptability and reasoning ability in specific\nmaintenance domains, Besides, Hierarchical Task-Based Agent and\nInstruction-level Retrieval-Augmented Generation (RAG) technologies are adopted\nto optimize the generation steps and mitigate the phenomenon of hallucination\ncaused by the model's Inability to access contextual information. This\nenhancement improves the model's flexibility and accuracy in handling known or\nunknown maintenance objects and maintenance scheme scenarios. To validate the\nproposed method's effectiveness in maintenance tasks, a maintenance scheme\ndataset was constructed using objects from different fields. The experimental\nresults show that the accuracy of the maintenance schemes generated by the\nproposed method reached 91.59%, indicating which improvement enhances the\nintelligence of maintenance schemes and introduces novel technical approaches\nfor equipment maintenance.\n","authors":["Laifa Tao","Qixuan Huang","Xianjun Wu","Weiwei Zhang","Yunlong Wu","Bin Li","Chen Lu","Xingshuo Hai"],"pdf_url":"https://arxiv.org/pdf/2411.04476v1.pdf","comment":"30 pages, 7 figures"},{"id":"http://arxiv.org/abs/2405.12452v2","updated":"2024-11-07T06:41:07Z","published":"2024-05-21T02:06:40Z","title":"Prompt-Based Spatio-Temporal Graph Transfer Learning","summary":"  Spatio-temporal graph neural networks have proven efficacy in capturing\ncomplex dependencies for urban computing tasks such as forecasting and kriging.\nYet, their performance is constrained by the reliance on extensive data for\ntraining on a specific task, thereby limiting their adaptability to new urban\ndomains with varied task demands. Although transfer learning has been proposed\nto remedy this problem by leveraging knowledge across domains, the cross-task\ngeneralization still remains under-explored in spatio-temporal graph transfer\nlearning due to the lack of a unified framework. To bridge the gap, we propose\nSpatio-Temporal Graph Prompting (STGP), a prompt-based framework capable of\nadapting to multi-diverse tasks in a data-scarce domain. Specifically, we first\nunify different tasks into a single template and introduce a task-agnostic\nnetwork architecture that aligns with this template. This approach enables\ncapturing dependencies shared across tasks. Furthermore, we employ learnable\nprompts to achieve domain and task transfer in a two-stage prompting pipeline,\nfacilitating the prompts to effectively capture domain knowledge and\ntask-specific properties. Our extensive experiments demonstrate that STGP\noutperforms state-of-the-art baselines in three tasks-forecasting, kriging, and\nextrapolation-achieving an improvement of up to 10.7%.\n","authors":["Junfeng Hu","Xu Liu","Zhencheng Fan","Yifang Yin","Shili Xiang","Savitha Ramasamy","Roger Zimmermann"],"pdf_url":"https://arxiv.org/pdf/2405.12452v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04466v1","updated":"2024-11-07T06:27:12Z","published":"2024-11-07T06:27:12Z","title":"Enabling Adaptive Agent Training in Open-Ended Simulators by Targeting\n  Diversity","summary":"  The wider application of end-to-end learning methods to embodied\ndecision-making domains remains bottlenecked by their reliance on a\nsuperabundance of training data representative of the target domain.\nMeta-reinforcement learning (meta-RL) approaches abandon the aim of zero-shot\ngeneralization--the goal of standard reinforcement learning (RL)--in favor of\nfew-shot adaptation, and thus hold promise for bridging larger generalization\ngaps. While learning this meta-level adaptive behavior still requires\nsubstantial data, efficient environment simulators approaching real-world\ncomplexity are growing in prevalence. Even so, hand-designing sufficiently\ndiverse and numerous simulated training tasks for these complex domains is\nprohibitively labor-intensive. Domain randomization (DR) and procedural\ngeneration (PG), offered as solutions to this problem, require simulators to\npossess carefully-defined parameters which directly translate to meaningful\ntask diversity--a similarly prohibitive assumption. In this work, we present\nDIVA, an evolutionary approach for generating diverse training tasks in such\ncomplex, open-ended simulators. Like unsupervised environment design (UED)\nmethods, DIVA can be applied to arbitrary parameterizations, but can\nadditionally incorporate realistically-available domain knowledge--thus\ninheriting the flexibility and generality of UED, and the supervised structure\nembedded in well-designed simulators exploited by DR and PG. Our empirical\nresults showcase DIVA's unique ability to overcome complex parameterizations\nand successfully train adaptive agent behavior, far outperforming competitive\nbaselines from prior literature. These findings highlight the potential of such\nsemi-supervised environment design (SSED) approaches, of which DIVA is the\nfirst humble constituent, to enable training in realistic simulated domains,\nand produce more robust and capable adaptive agents.\n","authors":["Robby Costales","Stefanos Nikolaidis"],"pdf_url":"https://arxiv.org/pdf/2411.04466v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04459v1","updated":"2024-11-07T06:12:38Z","published":"2024-11-07T06:12:38Z","title":"GPT-Guided Monte Carlo Tree Search for Symbolic Regression in Financial\n  Fraud Detection","summary":"  With the increasing number of financial services available online, the rate\nof financial fraud has also been increasing. The traffic and transaction rates\non the internet have increased considerably, leading to a need for fast\ndecision-making. Financial institutions also have stringent regulations that\noften require transparency and explainability of the decision-making process.\nHowever, most state-of-the-art algorithms currently used in the industry are\nhighly parameterized black-box models that rely on complex computations to\ngenerate a score. These algorithms are inherently slow and lack the\nexplainability and speed of traditional rule-based learners. This work\nintroduces SR-MCTS (Symbolic Regression MCTS), which utilizes a foundational\nGPT model to guide the MCTS, significantly enhancing its convergence speed and\nthe quality of the generated expressions which are further extracted to rules.\nOur experiments show that SR-MCTS can detect fraud more efficiently than widely\nused methods in the industry while providing substantial insights into the\ndecision-making process.\n","authors":["Prashank Kadam"],"pdf_url":"https://arxiv.org/pdf/2411.04459v1.pdf","comment":"ACM International Conference on Information and Knowledge Management\n  2024 RAG - Enterprise"},{"id":"http://arxiv.org/abs/2411.04453v1","updated":"2024-11-07T06:01:12Z","published":"2024-11-07T06:01:12Z","title":"Comparing Fairness of Generative Mobility Models","summary":"  This work examines the fairness of generative mobility models, addressing the\noften overlooked dimension of equity in model performance across geographic\nregions. Predictive models built on crowd flow data are instrumental in\nunderstanding urban structures and movement patterns; however, they risk\nembedding biases, particularly in spatiotemporal contexts where model\nperformance may reflect and reinforce existing inequities tied to geographic\ndistribution. We propose a novel framework for assessing fairness by measuring\nthe utility and equity of generated traces. Utility is assessed via the Common\nPart of Commuters (CPC), a similarity metric comparing generated and real\nmobility flows, while fairness is evaluated using demographic parity. By\nreformulating demographic parity to reflect the difference in CPC distribution\nbetween two groups, our analysis reveals disparities in how various models\nencode biases present in the underlying data. We utilized four models (Gravity,\nRadiation, Deep Gravity, and Non-linear Gravity) and our results indicate that\ntraditional gravity and radiation models produce fairer outcomes, although Deep\nGravity achieves higher CPC. This disparity underscores a trade-off between\nmodel accuracy and equity, with the feature-rich Deep Gravity model amplifying\npre-existing biases in community representations. Our findings emphasize the\nimportance of integrating fairness metrics in mobility modeling to avoid\nperpetuating inequities.\n","authors":["Daniel Wang","Jack McFarland","Afra Mashhadi","Ekin Ugurel"],"pdf_url":"https://arxiv.org/pdf/2411.04453v1.pdf","comment":"2 pages, Accepted at the Network Mobility (NetMob) 2024 conference"},{"id":"http://arxiv.org/abs/2409.00588v2","updated":"2024-11-07T05:58:27Z","published":"2024-09-01T02:47:50Z","title":"Diffusion Policy Policy Optimization","summary":"  We introduce Diffusion Policy Policy Optimization, DPPO, an algorithmic\nframework including best practices for fine-tuning diffusion-based policies\n(e.g. Diffusion Policy) in continuous control and robot learning tasks using\nthe policy gradient (PG) method from reinforcement learning (RL). PG methods\nare ubiquitous in training RL policies with other policy parameterizations;\nnevertheless, they had been conjectured to be less efficient for\ndiffusion-based policies. Surprisingly, we show that DPPO achieves the\nstrongest overall performance and efficiency for fine-tuning in common\nbenchmarks compared to other RL methods for diffusion-based policies and also\ncompared to PG fine-tuning of other policy parameterizations. Through\nexperimental investigation, we find that DPPO takes advantage of unique\nsynergies between RL fine-tuning and the diffusion parameterization, leading to\nstructured and on-manifold exploration, stable training, and strong policy\nrobustness. We further demonstrate the strengths of DPPO in a range of\nrealistic settings, including simulated robotic tasks with pixel observations,\nand via zero-shot deployment of simulation-trained policies on robot hardware\nin a long-horizon, multi-stage manipulation task. Website with code:\ndiffusion-ppo.github.io\n","authors":["Allen Z. Ren","Justin Lidard","Lars L. Ankile","Anthony Simeonov","Pulkit Agrawal","Anirudha Majumdar","Benjamin Burchfiel","Hongkai Dai","Max Simchowitz"],"pdf_url":"https://arxiv.org/pdf/2409.00588v2.pdf","comment":"Website: diffusion-ppo.github.io"},{"id":"http://arxiv.org/abs/2411.01442v2","updated":"2024-11-07T05:54:07Z","published":"2024-11-03T05:43:55Z","title":"Online Relational Inference for Evolving Multi-agent Interacting Systems","summary":"  We introduce a novel framework, Online Relational Inference (ORI), designed\nto efficiently identify hidden interaction graphs in evolving multi-agent\ninteracting systems using streaming data. Unlike traditional offline methods\nthat rely on a fixed training set, ORI employs online backpropagation, updating\nthe model with each new data point, thereby allowing it to adapt to changing\nenvironments in real-time. A key innovation is the use of an adjacency matrix\nas a trainable parameter, optimized through a new adaptive learning rate\ntechnique called AdaRelation, which adjusts based on the historical sensitivity\nof the decoder to changes in the interaction graph. Additionally, a data\naugmentation method named Trajectory Mirror (TM) is introduced to improve\ngeneralization by exposing the model to varied trajectory patterns.\nExperimental results on both synthetic datasets and real-world data (CMU MoCap\nfor human motion) demonstrate that ORI significantly improves the accuracy and\nadaptability of relational inference in dynamic settings compared to existing\nmethods. This approach is model-agnostic, enabling seamless integration with\nvarious neural relational inference (NRI) architectures, and offers a robust\nsolution for real-time applications in complex, evolving systems.\n","authors":["Beomseok Kang","Priyabrata Saha","Sudarshan Sharma","Biswadeep Chakraborty","Saibal Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2411.01442v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04434v1","updated":"2024-11-07T04:57:40Z","published":"2024-11-07T04:57:40Z","title":"Scaling Laws for Pre-training Agents and World Models","summary":"  The performance of embodied agents has been shown to improve by increasing\nmodel parameters, dataset size, and compute. This has been demonstrated in\ndomains from robotics to video games, when generative learning objectives on\noffline datasets (pre-training) are used to model an agent's behavior\n(imitation learning) or their environment (world modeling). This paper\ncharacterizes the role of scale in these tasks more precisely. Going beyond the\nsimple intuition that `bigger is better', we show that the same types of power\nlaws found in language modeling (e.g. between loss and optimal model size),\nalso arise in world modeling and imitation learning. However, the coefficients\nof these laws are heavily influenced by the tokenizer, task \\& architecture --\nthis has important implications on the optimal sizing of models and data.\n","authors":["Tim Pearce","Tabish Rashid","Dave Bignell","Raluca Georgescu","Sam Devlin","Katja Hofmann"],"pdf_url":"https://arxiv.org/pdf/2411.04434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04430v1","updated":"2024-11-07T04:52:18Z","published":"2024-11-07T04:52:18Z","title":"Towards Unifying Interpretability and Control: Evaluation via\n  Intervention","summary":"  With the growing complexity and capability of large language models, a need\nto understand model reasoning has emerged, often motivated by an underlying\ngoal of controlling and aligning models. While numerous interpretability and\nsteering methods have been proposed as solutions, they are typically designed\neither for understanding or for control, seldom addressing both, with the\nconnection between interpretation and control more broadly remaining tenuous.\nAdditionally, the lack of standardized applications, motivations, and\nevaluation metrics makes it difficult to assess these methods' practical\nutility and efficacy. To address this, we propose intervention as a fundamental\ngoal of interpretability and introduce success criteria to evaluate how well\nmethods are able to control model behavior through interventions. We unify and\nextend four popular interpretability methods--sparse autoencoders, logit lens,\ntuned lens, and probing--into an abstract encoder-decoder framework. This\nframework maps intermediate latent representations to human-interpretable\nfeature spaces, enabling interventions on these interpretable features, which\ncan then be mapped back to latent representations to control model outputs. We\nintroduce two new evaluation metrics: intervention success rate and the\ncoherence-intervention tradeoff, designed to measure the accuracy of\nexplanations and their utility in controlling model behavior. Our findings\nreveal that (1) although current methods allow for intervention, they are\ninconsistent across models and features, (2) lens-based methods outperform\nothers in achieving simple, concrete interventions, and (3) interventions often\ncompromise model performance and coherence, underperforming simpler\nalternatives, such as prompting, for steering model behavior and highlighting a\ncritical shortcoming of current interpretability approaches in real-world\napplications requiring control.\n","authors":["Usha Bhalla","Suraj Srinivas","Asma Ghandeharioun","Himabindu Lakkaraju"],"pdf_url":"https://arxiv.org/pdf/2411.04430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00172v2","updated":"2024-11-07T04:41:32Z","published":"2024-10-31T19:37:47Z","title":"SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor\n  Geological Survey","summary":"  A major obstacle to the advancements of machine learning models in marine\nscience, particularly in sonar imagery analysis, is the scarcity of AI-ready\ndatasets. While there have been efforts to make AI-ready sonar image dataset\npublicly available, they suffer from limitations in terms of environment\nsetting and scale. To bridge this gap, we introduce SeafloorAI, the first\nextensive AI-ready datasets for seafloor mapping across 5 geological layers\nthat is curated in collaboration with marine scientists. We further extend the\ndataset to SeafloorGenAI by incorporating the language component in order to\nfacilitate the development of both vision- and language-capable machine\nlearning models for sonar imagery. The dataset consists of 62 geo-distributed\ndata surveys spanning 17,300 square kilometers, with 696K sonar images, 827K\nannotated segmentation masks, 696K detailed language descriptions and\napproximately 7M question-answer pairs. By making our data processing source\ncode publicly available, we aim to engage the marine science community to\nenrich the data pool and inspire the machine learning community to develop more\nrobust models. This collaborative approach will enhance the capabilities and\napplications of our datasets within both fields.\n","authors":["Kien X. Nguyen","Fengchun Qiao","Arthur Trembanis","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2411.00172v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15265v4","updated":"2024-11-07T04:38:33Z","published":"2023-05-24T15:52:08Z","title":"Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of\n  Language Model","summary":"  With the rapid growth in model size, fine-tuning the large pre-trained\nlanguage model has become increasingly difficult due to its extensive memory\nusage. Previous works usually focus on reducing the number of trainable\nparameters in the network. While the model parameters do contribute to memory\nusage, the primary memory bottleneck during training arises from storing\nfeature maps, also known as activations, as they are crucial for gradient\ncalculation. Notably, neural networks are usually trained using stochastic\ngradient descent. We argue that in stochastic optimization, models can handle\nnoisy gradients as long as the gradient estimator is unbiased with reasonable\nvariance. Following this motivation, we propose a new family of unbiased\nestimators called WTA-CRS, for matrix production with reduced variance, which\nonly requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the\ncontext of tuning transformers, our proposed estimators exhibit lower variance\ncompared to existing ones. By replacing the linear operation with our\napproximated one in transformers, we can achieve up to 2.7$\\times$ peak memory\nreduction with almost no accuracy drop and enables up to $6.4\\times$ larger\nbatch size. Under the same hardware, WTA-CRS enables better down-streaming task\nperformance by applying larger models and/or faster training speed with larger\nbatch sizes.\n","authors":["Zirui Liu","Guanchu Wang","Shaochen Zhong","Zhaozhuo Xu","Daochen Zha","Ruixiang Tang","Zhimeng Jiang","Kaixiong Zhou","Vipin Chaudhary","Shuai Xu","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2305.15265v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04422v1","updated":"2024-11-07T04:21:26Z","published":"2024-11-07T04:21:26Z","title":"Unsupervised Abnormal Stop Detection for Long Distance Coaches with\n  Low-Frequency GPS","summary":"  In our urban life, long distance coaches supply a convenient yet economic\napproach to the transportation of the public. One notable problem is to\ndiscover the abnormal stop of the coaches due to the important reason, i.e.,\nillegal pick up on the way which possibly endangers the safety of passengers.\nIt has become a pressing issue to detect the coach abnormal stop with\nlow-quality GPS. In this paper, we propose an unsupervised method that helps\ntransportation managers to efficiently discover the Abnormal Stop Detection\n(ASD) for long distance coaches. Concretely, our method converts the ASD\nproblem into an unsupervised clustering framework in which both the normal stop\nand the abnormal one are decomposed. Firstly, we propose a stop duration model\nfor the low frequency GPS based on the assumption that a coach changes speed\napproximately in a linear approach. Secondly, we strip the abnormal stops from\nthe normal stop points by the low rank assumption. The proposed method is\nconceptually simple yet efficient, by leveraging low rank assumption to handle\nnormal stop points, our approach enables domain experts to discover the ASD for\ncoaches, from a case study motivated by traffic managers. Datset and code are\npublicly available at: https://github.com/pangjunbiao/IPPs.\n","authors":["Jiaxin Deng","Junbiao Pang","Jiayu Xu","Haitao Yu"],"pdf_url":"https://arxiv.org/pdf/2411.04422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04421v1","updated":"2024-11-07T04:17:30Z","published":"2024-11-07T04:17:30Z","title":"Variational Low-Rank Adaptation Using IVON","summary":"  We show that variational learning can significantly improve the accuracy and\ncalibration of Low-Rank Adaptation (LoRA) without a substantial increase in the\ncost. We replace AdamW by the Improved Variational Online Newton (IVON)\nalgorithm to finetune large language models. For Llama-2 with 7 billion\nparameters, IVON improves the accuracy over AdamW by 2.8% and expected\ncalibration error by 4.6%. The accuracy is also better than the other Bayesian\nalternatives, yet the cost is lower and the implementation is easier. Our work\nprovides additional evidence for the effectiveness of IVON for large language\nmodels. The code is available at\nhttps://github.com/team-approx-bayes/ivon-lora.\n","authors":["Bai Cong","Nico Daheim","Yuesong Shen","Daniel Cremers","Rio Yokota","Mohammad Emtiyaz Khan","Thomas Möllenhoff"],"pdf_url":"https://arxiv.org/pdf/2411.04421v1.pdf","comment":"Published at 38th Workshop on Fine-Tuning in Machine Learning\n  (NeurIPS 2024). Code available at\n  https://github.com/team-approx-bayes/ivon-lora"},{"id":"http://arxiv.org/abs/2411.04420v1","updated":"2024-11-07T04:16:15Z","published":"2024-11-07T04:16:15Z","title":"BendVLM: Test-Time Debiasing of Vision-Language Embeddings","summary":"  Vision-language model (VLM) embeddings have been shown to encode biases\npresent in their training data, such as societal biases that prescribe negative\ncharacteristics to members of various racial and gender identities. VLMs are\nbeing quickly adopted for a variety of tasks ranging from few-shot\nclassification to text-guided image generation, making debiasing VLM embeddings\ncrucial. Debiasing approaches that fine-tune the VLM often suffer from\ncatastrophic forgetting. On the other hand, fine-tuning-free methods typically\nutilize a \"one-size-fits-all\" approach that assumes that correlation with the\nspurious attribute can be explained using a single linear direction across all\npossible inputs. In this work, we propose Bend-VLM, a nonlinear,\nfine-tuning-free approach for VLM embedding debiasing that tailors the\ndebiasing operation to each unique input. This allows for a more flexible\ndebiasing approach. Additionally, we do not require knowledge of the set of\ninputs a priori to inference time, making our method more appropriate for\nonline, open-set tasks such as retrieval and text guided image generation.\n","authors":["Walter Gerych","Haoran Zhang","Kimia Hamidieh","Eileen Pan","Maanas Sharma","Thomas Hartvigsen","Marzyeh Ghassemi"],"pdf_url":"https://arxiv.org/pdf/2411.04420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03348v2","updated":"2024-11-07T04:05:58Z","published":"2024-11-03T18:44:28Z","title":"Undermining Image and Text Classification Algorithms Using Adversarial\n  Attacks","summary":"  Machine learning models are prone to adversarial attacks, where inputs can be\nmanipulated in order to cause misclassifications. While previous research has\nfocused on techniques like Generative Adversarial Networks (GANs), there's\nlimited exploration of GANs and Synthetic Minority Oversampling Technique\n(SMOTE) in text and image classification models to perform adversarial attacks.\nOur study addresses this gap by training various machine learning models and\nusing GANs and SMOTE to generate additional data points aimed at attacking text\nclassification models. Furthermore, we extend our investigation to face\nrecognition models, training a Convolutional Neural Network(CNN) and subjecting\nit to adversarial attacks with fast gradient sign perturbations on key features\nidentified by GradCAM, a technique used to highlight key image characteristics\nCNNs use in classification. Our experiments reveal a significant vulnerability\nin classification models. Specifically, we observe a 20 % decrease in accuracy\nfor the top-performing text classification models post-attack, along with a 30\n% decrease in facial recognition accuracy. This highlights the susceptibility\nof these models to manipulation of input data. Adversarial attacks not only\ncompromise the security but also undermine the reliability of machine learning\nsystems. By showcasing the impact of adversarial attacks on both text\nclassification and face recognition models, our study underscores the urgent\nneed for develop robust defenses against such vulnerabilities.\n","authors":["Langalibalele Lunga","Suhas Sreehari"],"pdf_url":"https://arxiv.org/pdf/2411.03348v2.pdf","comment":"Accepted for presentation at Electronic Imaging Conference 2025"},{"id":"http://arxiv.org/abs/2310.03739v5","updated":"2024-11-07T03:54:22Z","published":"2023-10-05T17:59:18Z","title":"Aligning Text-to-Image Diffusion Models with Reward Backpropagation","summary":"  Text-to-image diffusion models have recently emerged at the forefront of\nimage generation, powered by very large-scale unsupervised or weakly supervised\ntext-to-image training datasets. Due to their unsupervised training,\ncontrolling their behavior in downstream tasks, such as maximizing\nhuman-perceived image quality, image-text alignment, or ethical image\ngeneration, is difficult. Recent works finetune diffusion models to downstream\nreward functions using vanilla reinforcement learning, notorious for the high\nvariance of the gradient estimators. In this paper, we propose AlignProp, a\nmethod that aligns diffusion models to downstream reward functions using\nend-to-end backpropagation of the reward gradient through the denoising\nprocess. While naive implementation of such backpropagation would require\nprohibitive memory resources for storing the partial derivatives of modern\ntext-to-image models, AlignProp finetunes low-rank adapter weight modules and\nuses gradient checkpointing, to render its memory usage viable. We test\nAlignProp in finetuning diffusion models to various objectives, such as\nimage-text semantic alignment, aesthetics, compressibility and controllability\nof the number of objects present, as well as their combinations. We show\nAlignProp achieves higher rewards in fewer training steps than alternatives,\nwhile being conceptually simpler, making it a straightforward choice for\noptimizing diffusion models for differentiable reward functions of interest.\nCode and Visualization results are available at https://align-prop.github.io/.\n","authors":["Mihir Prabhudesai","Anirudh Goyal","Deepak Pathak","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2310.03739v5.pdf","comment":"This paper is subsumed by a later paper of ours: arXiv:2407.08737"},{"id":"http://arxiv.org/abs/2408.07941v2","updated":"2024-11-07T03:54:22Z","published":"2024-08-15T05:31:26Z","title":"Robust Offline Active Learning on Graphs","summary":"  We consider the problem of active learning on graphs, which has crucial\napplications in many real-world networks where labeling node responses is\nexpensive. In this paper, we propose an offline active learning method that\nselects nodes to query by explicitly incorporating information from both the\nnetwork structure and node covariates. Building on graph signal recovery\ntheories and the random spectral sparsification technique, the proposed method\nadopts a two-stage biased sampling strategy that takes both informativeness and\nrepresentativeness into consideration for node querying. Informativeness refers\nto the complexity of graph signals that are learnable from the responses of\nqueried nodes, while representativeness refers to the capacity of queried nodes\nto control generalization errors given noisy node-level information. We\nestablish a theoretical relationship between generalization error and the\nnumber of nodes selected by the proposed method. Our theoretical results\ndemonstrate the trade-off between informativeness and representativeness in\nactive learning. Extensive numerical experiments show that the proposed method\nis competitive with existing graph-based active learning methods, especially\nwhen node covariates and responses contain noises. Additionally, the proposed\nmethod is applicable to both regression and classification tasks on graphs.\n","authors":["Yuanchen Wu","Yubai Yuan"],"pdf_url":"https://arxiv.org/pdf/2408.07941v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04105v2","updated":"2024-11-07T03:50:19Z","published":"2024-11-06T18:35:32Z","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic\n  Analysis","summary":"  Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve, but we can train a small\ntransformer to achieve perfect accuracy. Building on our set-up, we then pursue\nan understanding of precisely how a three-layer transformer, trained from\nscratch, solves this problem. We are able to identify certain \"planning\" and\n\"reasoning\" circuits in the network that necessitate cooperation between the\nattention blocks to implement the desired logic. To expand our findings, we\nthen study a larger model, Mistral 7B. Using activation patching, we\ncharacterize internal components that are critical in solving our logic\nproblem. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.\n","authors":["Guan Zhe Hong","Nishanth Dikkala","Enming Luo","Cyrus Rashtchian","Xin Wang","Rina Panigrahy"],"pdf_url":"https://arxiv.org/pdf/2411.04105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06508v2","updated":"2024-11-07T03:40:37Z","published":"2023-12-11T16:33:38Z","title":"Asynchronous Distributed Optimization with Delay-free Parameters","summary":"  Existing asynchronous distributed optimization algorithms often use\ndiminishing step-sizes that cause slow practical convergence, or use fixed\nstep-sizes that depend on and decrease with an upper bound of the delays. Not\nonly are such delay bounds hard to obtain in advance, but they also tend to be\nlarge and rarely attained, resulting in unnecessarily slow convergence. This\npaper develops asynchronous versions of two distributed algorithms, Prox-DGD\nand DGD-ATC, for solving consensus optimization problems over undirected\nnetworks. In contrast to alternatives, our algorithms can converge to the fixed\npoint set of their synchronous counterparts using step-sizes that are\nindependent of the delays. We establish convergence guarantees for convex and\nstrongly convex problems under both partial and total asynchrony. We also show\nthat the convergence speed of the two asynchronous methods adjusts to the\nactual level of asynchrony rather than being constrained by the worst-case.\nNumerical experiments demonstrate a strong practical performance of our\nasynchronous algorithms.\n","authors":["Xuyang Wu","Changxin Liu","Sindri Magnusson","Mikael Johansson"],"pdf_url":"https://arxiv.org/pdf/2312.06508v2.pdf","comment":"18 pages. arXiv admin note: text overlap with arXiv:2303.18034"},{"id":"http://arxiv.org/abs/2411.01350v2","updated":"2024-11-07T03:39:06Z","published":"2024-11-02T19:39:21Z","title":"The Implicit Bias of Gradient Descent on Separable Multiclass Data","summary":"  Implicit bias describes the phenomenon where optimization-based training\nalgorithms, without explicit regularization, show a preference for simple\nestimators even when more complex estimators have equal objective values.\nMultiple works have developed the theory of implicit bias for binary\nclassification under the assumption that the loss satisfies an exponential tail\nproperty. However, there is a noticeable gap in analysis for multiclass\nclassification, with only a handful of results which themselves are restricted\nto the cross-entropy loss. In this work, we employ the framework of Permutation\nEquivariant and Relative Margin-based (PERM) losses [Wang and Scott, 2024] to\nintroduce a multiclass extension of the exponential tail property. This class\nof losses includes not only cross-entropy but also other losses. Using this\nframework, we extend the implicit bias result of Soudry et al. [2018] to\nmulticlass classification. Furthermore, our proof techniques closely mirror\nthose of the binary case, thus illustrating the power of the PERM framework for\nbridging the binary-multiclass gap.\n","authors":["Hrithik Ravi","Clayton Scott","Daniel Soudry","Yutong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.01350v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02059v3","updated":"2024-11-07T03:32:44Z","published":"2024-11-04T13:03:13Z","title":"TableGPT2: A Large Multimodal Model with Tabular Data Integration","summary":"  The emergence of models like GPTs, Claude, LLaMA, and Qwen has reshaped AI\napplications, presenting vast new opportunities across industries. Yet, the\nintegration of tabular data remains notably underdeveloped, despite its\nfoundational role in numerous real-world domains.\n  This gap is critical for three main reasons. First, database or data\nwarehouse data integration is essential for advanced applications; second, the\nvast and largely untapped resource of tabular data offers immense potential for\nanalysis; and third, the business intelligence domain specifically demands\nadaptable, precise solutions that many current LLMs may struggle to provide.\n  In response, we introduce TableGPT2, a model rigorously pre-trained and\nfine-tuned with over 593.8K tables and 2.36M high-quality query-table-output\ntuples, a scale of table-related data unprecedented in prior research. This\nextensive training enables TableGPT2 to excel in table-centric tasks while\nmaintaining strong general language and coding abilities.\n  One of TableGPT2's key innovations is its novel table encoder, specifically\ndesigned to capture schema-level and cell-level information. This encoder\nstrengthens the model's ability to handle ambiguous queries, missing column\nnames, and irregular tables commonly encountered in real-world applications.\nSimilar to visual language models, this pioneering approach integrates with the\ndecoder to form a robust large multimodal model.\n  We believe the results are compelling: over 23 benchmarking metrics,\nTableGPT2 achieves an average performance improvement of 35.20% in the 7B model\nand 49.32% in the 72B model over prior benchmark-neutral LLMs, with robust\ngeneral-purpose capabilities intact.\n","authors":["Aofeng Su","Aowen Wang","Chao Ye","Chen Zhou","Ga Zhang","Gang Chen","Guangcheng Zhu","Haobo Wang","Haokai Xu","Hao Chen","Haoze Li","Haoxuan Lan","Jiaming Tian","Jing Yuan","Junbo Zhao","Junlin Zhou","Kaizhe Shou","Liangyu Zha","Lin Long","Liyao Li","Pengzuo Wu","Qi Zhang","Qingyi Huang","Saisai Yang","Tao Zhang","Wentao Ye","Wufang Zhu","Xiaomeng Hu","Xijun Gu","Xinjie Sun","Xiang Li","Yuhang Yang","Zhiqing Xiao"],"pdf_url":"https://arxiv.org/pdf/2411.02059v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03622v2","updated":"2024-11-07T03:26:58Z","published":"2024-11-06T02:41:26Z","title":"Fully Hyperbolic Rotation for Knowledge Graph Embedding","summary":"  Hyperbolic rotation is commonly used to effectively model knowledge graphs\nand their inherent hierarchies. However, existing hyperbolic rotation models\nrely on logarithmic and exponential mappings for feature transformation. These\nmodels only project data features into hyperbolic space for rotation, limiting\ntheir ability to fully exploit the hyperbolic space. To address this problem,\nwe propose a novel fully hyperbolic model designed for knowledge graph\nembedding. Instead of feature mappings, we define the model directly in\nhyperbolic space with the Lorentz model. Our model considers each relation in\nknowledge graphs as a Lorentz rotation from the head entity to the tail entity.\nWe adopt the Lorentzian version distance as the scoring function for measuring\nthe plausibility of triplets. Extensive results on standard knowledge graph\ncompletion benchmarks demonstrated that our model achieves competitive results\nwith fewer parameters. In addition, our model get the state-of-the-art\nperformance on datasets of CoDEx-s and CoDEx-m, which are more diverse and\nchallenging than before. Our code is available at\nhttps://github.com/llqy123/FHRE.\n","authors":["Qiuyu Liang","Weihua Wang","Feilong Bao","Guanglai Gao"],"pdf_url":"https://arxiv.org/pdf/2411.03622v2.pdf","comment":"Accepted by ECAI 2024"},{"id":"http://arxiv.org/abs/2411.00132v2","updated":"2024-11-07T03:22:56Z","published":"2024-10-31T18:33:39Z","title":"Beyond Accuracy: Ensuring Correct Predictions With Correct Rationales","summary":"  Large pretrained foundation models demonstrate exceptional performance and,\nin some high-stakes applications, even surpass human experts. However, most of\nthese models are currently evaluated primarily on prediction accuracy,\noverlooking the validity of the rationales behind their accurate predictions.\nFor the safe deployment of foundation models, there is a pressing need to\nensure double-correct predictions, i.e., correct prediction backed by correct\nrationales. To achieve this, we propose a two-phase scheme: First, we curate a\nnew dataset that offers structured rationales for visual recognition tasks.\nSecond, we propose a rationale-informed optimization method to guide the model\nin disentangling and localizing visual evidence for each rationale, without\nrequiring manual annotations. Extensive experiments and ablation studies\ndemonstrate that our model outperforms state-of-the-art models by up to 10.1%\nin prediction accuracy across a wide range of tasks. Furthermore, our method\nsignificantly improves the model's rationale correctness, improving\nlocalization by 7.5% and disentanglement by 36.5%. Our dataset, source code,\nand pretrained weights: https://github.com/deep-real/DCP\n","authors":["Tang Li","Mengmeng Ma","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2411.00132v2.pdf","comment":"In Proceedings of the 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2411.04397v1","updated":"2024-11-07T03:21:30Z","published":"2024-11-07T03:21:30Z","title":"A Bayesian Mixture Model of Temporal Point Processes with Determinantal\n  Point Process Prior","summary":"  Asynchronous event sequence clustering aims to group similar event sequences\nin an unsupervised manner. Mixture models of temporal point processes have been\nproposed to solve this problem, but they often suffer from overfitting, leading\nto excessive cluster generation with a lack of diversity. To overcome these\nlimitations, we propose a Bayesian mixture model of Temporal Point Processes\nwith Determinantal Point Process prior (TP$^2$DP$^2$) and accordingly an\nefficient posterior inference algorithm based on conditional Gibbs sampling.\nOur work provides a flexible learning framework for event sequence clustering,\nenabling automatic identification of the potential number of clusters and\naccurate grouping of sequences with similar features. It is applicable to a\nwide range of parametric temporal point processes, including neural\nnetwork-based models. Experimental results on both synthetic and real-world\ndata suggest that our framework could produce moderately fewer yet more diverse\nmixture components, and achieve outstanding results across multiple evaluation\nmetrics.\n","authors":["Yiwei Dong","Shaoxin Ye","Yuwen Cao","Qiyu Han","Hongteng Xu","Hanfang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.04397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04396v1","updated":"2024-11-07T03:18:34Z","published":"2024-11-07T03:18:34Z","title":"Remote Sensing-Based Assessment of Economic Development","summary":"  The goal of our project is to use satellite data (including nighttime light\ndata and remote sensing images) to give us some statistical estimation of the\neconomic development level of a selected area (Singapore). Findings from the\nproject could inform policymakers about areas needing intervention or support\nfor economic development initiatives. Insights gained might aid in targeted\npolicy formulation for infrastructure, agriculture, urban planning, or resource\nmanagement.\n","authors":["Yijian Pan","Yongchang Ma","Bolin Shen","Linyang He"],"pdf_url":"https://arxiv.org/pdf/2411.04396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17767v2","updated":"2024-11-07T03:16:02Z","published":"2024-05-28T02:46:11Z","title":"Linguistic Collapse: Neural Collapse in (Large) Language Models","summary":"  Neural collapse ($\\mathcal{NC}$) is a phenomenon observed in classification\ntasks where top-layer representations collapse into their class means, which\nbecome equinorm, equiangular and aligned with the classifiers. These behaviors\n-- associated with generalization and robustness -- would manifest under\nspecific conditions: models are trained towards zero loss, with noise-free\nlabels belonging to balanced classes, which do not outnumber the model's hidden\ndimension. Recent studies have explored $\\mathcal{NC}$ in the absence of one or\nmore of these conditions to extend and capitalize on the associated benefits of\nideal geometries. Language modeling presents a curious frontier, as\n\\textit{training by token prediction} constitutes a classification task where\nnone of the conditions exist: the vocabulary is imbalanced and exceeds the\nembedding dimension; different tokens might correspond to similar contextual\nembeddings; and large language models (LLMs) in particular are typically only\ntrained for a few epochs. This paper empirically investigates the impact of\nscaling the architectures and training of causal language models (CLMs) on\ntheir progression towards $\\mathcal{NC}$. We find that $\\mathcal{NC}$\nproperties that develop with scale (and regularization) are linked to\ngeneralization. Moreover, there is evidence of some relationship between\n$\\mathcal{NC}$ and generalization independent of scale. Our work thereby\nunderscores the generality of $\\mathcal{NC}$ as it extends to the novel and\nmore challenging setting of language modeling. Downstream, we seek to inspire\nfurther research on the phenomenon to deepen our understanding of LLMs -- and\nneural networks at large -- and improve existing architectures based on\n$\\mathcal{NC}$-related properties. Our code is hosted on GitHub at\nhttps://github.com/rhubarbwu/linguistic-collapse .\n","authors":["Robert Wu","Vardan Papyan"],"pdf_url":"https://arxiv.org/pdf/2405.17767v2.pdf","comment":"NeurIPS 2024; 36 pages; 30 figures"},{"id":"http://arxiv.org/abs/2403.18802v4","updated":"2024-11-07T03:14:38Z","published":"2024-03-27T17:48:55Z","title":"Long-form factuality in large language models","summary":"  Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can outperform crowdsourced human\nannotators - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.\n","authors":["Jerry Wei","Chengrun Yang","Xinying Song","Yifeng Lu","Nathan Hu","Jie Huang","Dustin Tran","Daiyi Peng","Ruibo Liu","Da Huang","Cosmo Du","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2403.18802v4.pdf","comment":"NeurIPS 2024; 72 pages, 18 figures, 30 tables. Code at\n  https://github.com/google-deepmind/long-form-factuality"},{"id":"http://arxiv.org/abs/2411.04394v1","updated":"2024-11-07T03:11:53Z","published":"2024-11-07T03:11:53Z","title":"Statistical-Computational Trade-offs for Greedy Recursive Partitioning\n  Estimators","summary":"  Models based on recursive partitioning such as decision trees and their\nensembles are popular for high-dimensional regression as they can potentially\navoid the curse of dimensionality. Because empirical risk minimization (ERM) is\ncomputationally infeasible, these models are typically trained using greedy\nalgorithms. Although effective in many cases, these algorithms have been\nempirically observed to get stuck at local optima. We explore this phenomenon\nin the context of learning sparse regression functions over $d$ binary\nfeatures, showing that when the true regression function $f^*$ does not satisfy\nthe so-called Merged Staircase Property (MSP), greedy training requires\n$\\exp(\\Omega(d))$ to achieve low estimation error. Conversely, when $f^*$ does\nsatisfy MSP, greedy training can attain small estimation error with only\n$O(\\log d)$ samples. This performance mirrors that of two-layer neural networks\ntrained with stochastic gradient descent (SGD) in the mean-field regime,\nthereby establishing a head-to-head comparison between SGD-trained neural\nnetworks and greedy recursive partitioning estimators. Furthermore, ERM-trained\nrecursive partitioning estimators achieve low estimation error with $O(\\log d)$\nsamples irrespective of whether $f^*$ satisfies MSP, thereby demonstrating a\nstatistical-computational trade-off for greedy training. Our proofs are based\non a novel interpretation of greedy recursive partitioning using stochastic\nprocess theory and a coupling technique that may be of independent interest.\n","authors":["Yan Shuo Tan","Jason M. Klusowski","Krishnakumar Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2411.04394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04393v1","updated":"2024-11-07T03:10:44Z","published":"2024-11-07T03:10:44Z","title":"Bridging the Gap: Representation Spaces in Neuro-Symbolic AI","summary":"  Neuro-symbolic AI is an effective method for improving the overall\nperformance of AI models by combining the advantages of neural networks and\nsymbolic learning. However, there are differences between the two in terms of\nhow they process data, primarily because they often use different data\nrepresentation methods, which is often an important factor limiting the overall\nperformance of the two. From this perspective, we analyzed 191 studies from\n2013 by constructing a four-level classification framework. The first level\ndefines five types of representation spaces, and the second level focuses on\nfive types of information modalities that the representation space can\nrepresent. Then, the third level describes four symbolic logic methods.\nFinally, the fourth-level categories propose three collaboration strategies\nbetween neural networks and symbolic learning. Furthermore, we conducted a\ndetailed analysis of 46 research based on their representation space.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.04393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19487v3","updated":"2024-11-07T03:05:18Z","published":"2024-09-28T23:59:46Z","title":"HealthQ: Unveiling Questioning Capabilities of LLM Chains in Healthcare\n  Conversations","summary":"  In digital healthcare, large language models (LLMs) have primarily been\nutilized to enhance question-answering capabilities and improve patient\ninteractions. However, effective patient care necessitates LLM chains that can\nactively gather information by posing relevant questions. This paper presents\nHealthQ, a novel framework designed to evaluate the questioning capabilities of\nLLM healthcare chains. We implemented several LLM chains, including\nRetrieval-Augmented Generation (RAG), Chain of Thought (CoT), and reflective\nchains, and introduced an LLM judge to assess the relevance and informativeness\nof the generated questions. To validate HealthQ, we employed traditional\nNatural Language Processing (NLP) metrics such as Recall-Oriented Understudy\nfor Gisting Evaluation (ROUGE) and Named Entity Recognition (NER)-based set\ncomparison, and constructed two custom datasets from public medical note\ndatasets, ChatDoctor and MTS-Dialog. Our contributions are threefold: we\nprovide the first comprehensive study on the questioning capabilities of LLMs\nin healthcare conversations, develop a novel dataset generation pipeline, and\npropose a detailed evaluation methodology.\n","authors":["Ziyu Wang","Hao Li","Di Huang","Amir M. Rahmani"],"pdf_url":"https://arxiv.org/pdf/2409.19487v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04389v1","updated":"2024-11-07T03:04:58Z","published":"2024-11-07T03:04:58Z","title":"Approximate Frank-Wolfe Algorithm over Graph-structured Support Set","summary":"  In this project, we reviewed a paper that deals graph-structured convex\noptimization (GSCO) problem with the approximate Frank-Wolfe (FW) algorithm. We\nanalyzed and implemented the original algorithm and introduced some extensions\nbased on that. Then we conducted experiments to compare the results and\nconcluded that our backtracking line-search method effectively reduced the\nnumber of iterations, while our new DMO method (Top-g+ optimal visiting) did\nnot make satisfying enough improvements.\n","authors":["Yijian Pan"],"pdf_url":"https://arxiv.org/pdf/2411.04389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04388v1","updated":"2024-11-07T03:02:09Z","published":"2024-11-07T03:02:09Z","title":"Unlearning in- vs. out-of-distribution data in LLMs under gradient-based\n  method","summary":"  Machine unlearning aims to solve the problem of removing the influence of\nselected training examples from a learned model. Despite the increasing\nattention to this problem, it remains an open research question how to evaluate\nunlearning in large language models (LLMs), and what are the critical\nproperties of the data to be unlearned that affect the quality and efficiency\nof unlearning. This work formalizes a metric to evaluate unlearning quality in\ngenerative models, and uses it to assess the trade-offs between unlearning\nquality and performance. We demonstrate that unlearning out-of-distribution\nexamples requires more unlearning steps but overall presents a better trade-off\noverall. For in-distribution examples, however, we observe a rapid decay in\nperformance as unlearning progresses. We further evaluate how example's\nmemorization and difficulty affect unlearning under a classical gradient\nascent-based approach.\n","authors":["Teodora Baluta","Pascal Lamblin","Daniel Tarlow","Fabian Pedregosa","Gintare Karolina Dziugaite"],"pdf_url":"https://arxiv.org/pdf/2411.04388v1.pdf","comment":"Accepted at Safe Generative AI Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04383v1","updated":"2024-11-07T02:54:35Z","published":"2024-11-07T02:54:35Z","title":"Neuro-Symbolic AI: Explainability, Challenges, and Future Trends","summary":"  Explainability is an essential reason limiting the application of neural\nnetworks in many vital fields. Although neuro-symbolic AI hopes to enhance the\noverall explainability by leveraging the transparency of symbolic learning, the\nresults are less evident than imagined. This article proposes a classification\nfor explainability by considering both model design and behavior of 191 studies\nfrom 2013, focusing on neuro-symbolic AI, hoping to inspire scholars who want\nto understand the explainability of neuro-symbolic AI. Precisely, we classify\nthem into five categories by considering whether the form of bridging the\nrepresentation differences is readable as their design factor, if there are\nrepresentation differences between neural networks and symbolic logic learning,\nand whether a model decision or prediction process is understandable as their\nbehavior factor: implicit intermediate representations and implicit prediction,\npartially explicit intermediate representations and partially explicit\nprediction, explicit intermediate representations or explicit prediction,\nexplicit intermediate representation and explicit prediction, unified\nrepresentation and explicit prediction. We also analyzed the research trends\nand three significant challenges: unified representations, explainability and\ntransparency, and sufficient cooperation from neural networks and symbolic\nlearning. Finally, we put forward suggestions for future research in three\naspects: unified representations, enhancing model explainability, ethical\nconsiderations, and social impact.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.04383v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23247v3","updated":"2024-11-07T02:52:47Z","published":"2024-10-30T17:30:35Z","title":"bit2bit: 1-bit quanta video reconstruction via self-supervised photon\n  prediction","summary":"  Quanta image sensors, such as SPAD arrays, are an emerging sensor technology,\nproducing 1-bit arrays representing photon detection events over exposures as\nshort as a few nanoseconds. In practice, raw data are post-processed using\nheavy spatiotemporal binning to create more useful and interpretable images at\nthe cost of degrading spatiotemporal resolution. In this work, we propose\nbit2bit, a new method for reconstructing high-quality image stacks at the\noriginal spatiotemporal resolution from sparse binary quanta image data.\nInspired by recent work on Poisson denoising, we developed an algorithm that\ncreates a dense image sequence from sparse binary photon data by predicting the\nphoton arrival location probability distribution. However, due to the binary\nnature of the data, we show that the assumption of a Poisson distribution is\ninadequate. Instead, we model the process with a Bernoulli lattice process from\nthe truncated Poisson. This leads to the proposal of a novel self-supervised\nsolution based on a masked loss function. We evaluate our method using both\nsimulated and real data. On simulated data from a conventional video, we\nachieve 34.35 mean PSNR with extremely photon-sparse binary input (<0.06\nphotons per pixel per frame). We also present a novel dataset containing a wide\nrange of real SPAD high-speed videos under various challenging imaging\nconditions. The scenes cover strong/weak ambient light, strong motion,\nultra-fast events, etc., which will be made available to the community, on\nwhich we demonstrate the promise of our approach. Both reconstruction quality\nand throughput substantially surpass the state-of-the-art methods (e.g., Quanta\nBurst Photography (QBP)). Our approach significantly enhances the visualization\nand usability of the data, enabling the application of existing analysis\ntechniques.\n","authors":["Yehe Liu","Alexander Krull","Hector Basevi","Ales Leonardis","Michael W. Jenkins"],"pdf_url":"https://arxiv.org/pdf/2410.23247v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04381v1","updated":"2024-11-07T02:47:50Z","published":"2024-11-07T02:47:50Z","title":"TrajGPT: Controlled Synthetic Trajectory Generation Using a Multitask\n  Transformer-Based Spatiotemporal Model","summary":"  Human mobility modeling from GPS-trajectories and synthetic trajectory\ngeneration are crucial for various applications, such as urban planning,\ndisaster management and epidemiology. Both of these tasks often require filling\ngaps in a partially specified sequence of visits - a new problem that we call\n\"controlled\" synthetic trajectory generation. Existing methods for\nnext-location prediction or synthetic trajectory generation cannot solve this\nproblem as they lack the mechanisms needed to constrain the generated sequences\nof visits. Moreover, existing approaches (1) frequently treat space and time as\nindependent factors, an assumption that fails to hold true in real-world\nscenarios, and (2) suffer from challenges in accuracy of temporal prediction as\nthey fail to deal with mixed distributions and the inter-relationships of\ndifferent modes with latent variables (e.g., day-of-the-week). These\nlimitations become even more pronounced when the task involves filling gaps\nwithin sequences instead of solely predicting the next visit.\n  We introduce TrajGPT, a transformer-based, multi-task, joint spatiotemporal\ngenerative model to address these issues. Taking inspiration from large\nlanguage models, TrajGPT poses the problem of controlled trajectory generation\nas that of text infilling in natural language. TrajGPT integrates the spatial\nand temporal models in a transformer architecture through a Bayesian\nprobability model that ensures that the gaps in a visit sequence are filled in\na spatiotemporally consistent manner. Our experiments on public and private\ndatasets demonstrate that TrajGPT not only excels in controlled synthetic visit\ngeneration but also outperforms competing models in next-location prediction\ntasks - Relatively, TrajGPT achieves a 26-fold improvement in temporal accuracy\nwhile retaining more than 98% of spatial accuracy on average.\n","authors":["Shang-Ling Hsu","Emmanuel Tung","John Krumm","Cyrus Shahabi","Khurram Shafique"],"pdf_url":"https://arxiv.org/pdf/2411.04381v1.pdf","comment":"10 pages, 3 figures, 32nd ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems (ACM SIGSPATIAL 2024)"},{"id":"http://arxiv.org/abs/2402.07193v3","updated":"2024-11-07T02:39:30Z","published":"2024-02-11T13:00:04Z","title":"Parameter Symmetry and Noise Equilibrium of Stochastic Gradient Descent","summary":"  Symmetries are prevalent in deep learning and can significantly influence the\nlearning dynamics of neural networks. In this paper, we examine how exponential\nsymmetries -- a broad subclass of continuous symmetries present in the model\narchitecture or loss function -- interplay with stochastic gradient descent\n(SGD). We first prove that gradient noise creates a systematic motion (a\n``Noether flow\") of the parameters $\\theta$ along the degenerate direction to a\nunique initialization-independent fixed point $\\theta^*$. These points are\nreferred to as the {\\it noise equilibria} because, at these points, noise\ncontributions from different directions are balanced and aligned. Then, we show\nthat the balance and alignment of gradient noise can serve as a novel\nalternative mechanism for explaining important phenomena such as progressive\nsharpening/flattening and representation formation within neural networks and\nhave practical implications for understanding techniques like representation\nnormalization and warmup.\n","authors":["Liu Ziyin","Mingze Wang","Hongchao Li","Lei Wu"],"pdf_url":"https://arxiv.org/pdf/2402.07193v3.pdf","comment":"NeurIPS camera ready"},{"id":"http://arxiv.org/abs/2405.16907v5","updated":"2024-11-07T02:24:18Z","published":"2024-05-27T07:55:45Z","title":"GTA: Generative Trajectory Augmentation with Guidance for Offline\n  Reinforcement Learning","summary":"  Offline Reinforcement Learning (Offline RL) presents challenges of learning\neffective decision-making policies from static datasets without any online\ninteractions. Data augmentation techniques, such as noise injection and data\nsynthesizing, aim to improve Q-function approximation by smoothing the learned\nstate-action region. However, these methods often fall short of directly\nimproving the quality of offline datasets, leading to suboptimal results. In\nresponse, we introduce GTA, Generative Trajectory Augmentation, a novel\ngenerative data augmentation approach designed to enrich offline data by\naugmenting trajectories to be both high-rewarding and dynamically plausible.\nGTA applies a diffusion model within the data augmentation framework. GTA\npartially noises original trajectories and then denoises them with\nclassifier-free guidance via conditioning on amplified return value. Our\nresults show that GTA, as a general data augmentation strategy, enhances the\nperformance of widely used offline RL algorithms across various tasks with\nunique challenges. Furthermore, we conduct a quality analysis of data augmented\nby GTA and demonstrate that GTA improves the quality of the data. Our code is\navailable at https://github.com/Jaewoopudding/GTA\n","authors":["Jaewoo Lee","Sujin Yun","Taeyoung Yun","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2405.16907v5.pdf","comment":"NeurIPS 2024. Previously accepted (Spotlight) to ICLR 2024 Workshop\n  on Generative Models for Decision Making. Jaewoo Lee and Sujin Yun are equal\n  contribution authors"},{"id":"http://arxiv.org/abs/2411.04376v1","updated":"2024-11-07T02:20:04Z","published":"2024-11-07T02:20:04Z","title":"Game-Theoretic Defenses for Robust Conformal Prediction Against\n  Adversarial Attacks in Medical Imaging","summary":"  Adversarial attacks pose significant threats to the reliability and safety of\ndeep learning models, especially in critical domains such as medical imaging.\nThis paper introduces a novel framework that integrates conformal prediction\nwith game-theoretic defensive strategies to enhance model robustness against\nboth known and unknown adversarial perturbations. We address three primary\nresearch questions: constructing valid and efficient conformal prediction sets\nunder known attacks (RQ1), ensuring coverage under unknown attacks through\nconservative thresholding (RQ2), and determining optimal defensive strategies\nwithin a zero-sum game framework (RQ3). Our methodology involves training\nspecialized defensive models against specific attack types and employing\nmaximum and minimum classifiers to aggregate defenses effectively. Extensive\nexperiments conducted on the MedMNIST datasets, including PathMNIST,\nOrganAMNIST, and TissueMNIST, demonstrate that our approach maintains high\ncoverage guarantees while minimizing prediction set sizes. The game-theoretic\nanalysis reveals that the optimal defensive strategy often converges to a\nsingular robust model, outperforming uniform and simple strategies across all\nevaluated datasets. This work advances the state-of-the-art in uncertainty\nquantification and adversarial robustness, providing a reliable mechanism for\ndeploying deep learning models in adversarial environments.\n","authors":["Rui Luo","Jie Bao","Zhixin Zhou","Chuangyin Dang"],"pdf_url":"https://arxiv.org/pdf/2411.04376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04372v1","updated":"2024-11-07T02:05:43Z","published":"2024-11-07T02:05:43Z","title":"Benchmarking Large Language Models with Integer Sequence Generation\n  Tasks","summary":"  This paper presents a novel benchmark where the large language model (LLM)\nmust write code that computes integer sequences from the Online Encyclopedia of\nInteger Sequences (OEIS), a widely-used resource for mathematical sequences.\nThe benchmark is designed to evaluate both the correctness of the generated\ncode and its computational efficiency. Our benchmark reveals that the o1 series\nof models outperform other frontier models from OpenAI, Anthropic, Meta, and\nGoogle in accuracy and cheating rates across both easy and hard integer\nsequences. In order to ensure models do not exploit memorized sequence values,\nwe introduce an automated cheating detection mechanism that flags the use of\nlookup tables and validated this automation against human cheating evaluations.\nThis benchmark provides a meaningful challenge for current LLMs, offering\ninsights into their mathematical reasoning and code writing capabilities, which\ncan guide future research directions and model development in mathematical\nreasoning and code synthesis.\n","authors":["Daniel O'Malley","Manish Bhattarai","Javier Santos"],"pdf_url":"https://arxiv.org/pdf/2411.04372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04371v1","updated":"2024-11-07T02:04:34Z","published":"2024-11-07T02:04:34Z","title":"ComFairGNN: Community Fair Graph Neural Network","summary":"  Graph Neural Networks (GNNs) have become the leading approach for addressing\ngraph analytical problems in various real-world scenarios. However, GNNs may\nproduce biased predictions against certain demographic subgroups due to node\nattributes and neighbors surrounding a node. Most current research on GNN\nfairness focuses predominantly on debiasing GNNs using oversimplified fairness\nevaluation metrics, which can give a misleading impression of fairness.\nUnderstanding the potential evaluation paradoxes due to the complicated nature\nof the graph structure is crucial for developing effective GNN debiasing\nmechanisms. In this paper, we examine the effectiveness of current GNN\ndebiasing methods in terms of unfairness evaluation. Specifically, we introduce\na community-level strategy to measure bias in GNNs and evaluate debiasing\nmethods at this level. Further, We introduce ComFairGNN, a novel framework\ndesigned to mitigate community-level bias in GNNs. Our approach employs a\nlearnable coreset-based debiasing function that addresses bias arising from\ndiverse local neighborhood distributions during GNNs neighborhood aggregation.\nComprehensive evaluations on three benchmark datasets demonstrate our model's\neffectiveness in both accuracy and fairness metrics.\n","authors":["Yonas Sium","Qi Li"],"pdf_url":"https://arxiv.org/pdf/2411.04371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15520v2","updated":"2024-11-07T01:52:17Z","published":"2024-09-23T20:14:09Z","title":"Enabling Efficient On-Device Fine-Tuning of LLMs Using Only Inference\n  Engines","summary":"  Large Language Models (LLMs) are currently pre-trained and fine-tuned on\nlarge cloud servers. The next frontier is LLM personalization, where a\nfoundation model can be fine-tuned with user/task-specific data. Given the\nsensitive nature of such private data, it is desirable to fine-tune these\nmodels on edge devices to improve user trust. However, fine-tuning on\nresource-constrained edge devices presents significant challenges due to\nsubstantial memory and computational demands, as well as limited infrastructure\nsupport. We observe that inference engines (e.g., ExecuTorch) can be repurposed\nfor fine-tuning by leveraging zeroth-order (ZO) optimization, which uses\nmultiple forward passes to approximate gradients. However, directly applying ZO\nmethods on edge devices is impractical due to the high computational cost of\nmultiple model perturbations required to achieve accuracy improvements. Based\non these observations, we propose a memory- and computation-efficient LLM\nfine-tuning method for edge devices. Our approach has three key innovations:\n(1) We introduce a parallelized randomized gradient estimation (P-RGE)\ntechnique that achieves high parallel efficiency by leveraging outer-loop and\ninner-loop parallelization. This enables multiple function queries and forward\npasses to be executed in parallel, reducing training time. (2) We integrate\nP-RGE with parameter-efficient fine-tuning methods (e.g. LoRA) to further\nreduce computational and memory overhead. (3) We implement a P-RGE LoRA-FA\nmodule that fully supports fine-tuning with ExecuTorch. Our approach requires\nno modifications to ExecuTorch's runtime code, as it can be implemented with\nserver-side code changes only. Experiments demonstrate that P-RGE achieves\nsubstantial runtime speedups and memory savings while improving fine-tuning\naccuracy, paving the way for practical deployment of LLMs in real-time,\non-device applications.\n","authors":["Lei Gao","Amir Ziashahabi","Yue Niu","Salman Avestimehr","Murali Annavaram"],"pdf_url":"https://arxiv.org/pdf/2409.15520v2.pdf","comment":"Accepted at NeurIPS 2024 ENLSP-IV workshop"},{"id":"http://arxiv.org/abs/2411.04358v1","updated":"2024-11-07T01:31:48Z","published":"2024-11-07T01:31:48Z","title":"Robust and Efficient Fine-tuning of LLMs with Bayesian\n  Reparameterization of Low-Rank Adaptation","summary":"  Large Language Models (LLMs) are highly resource-intensive to fine-tune due\nto their enormous size. While low-rank adaptation is a prominent\nparameter-efficient fine-tuning approach, it suffers from sensitivity to\nhyperparameter choices, leading to instability in model performance on\nfine-tuning downstream tasks. This paper highlights the importance of effective\nparameterization in low-rank fine-tuning to reduce estimator variance and\nenhance the stability of final model outputs. We propose MonteCLoRA, an\nefficient fine-tuning technique, employing Monte Carlo estimation to learn an\nunbiased posterior estimation of low-rank parameters with low expected\nvariance, which stabilizes fine-tuned LLMs with only O(1) additional\nparameters. MonteCLoRA shows significant improvements in accuracy and\nrobustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness\nthan existing efficient fine-tuning methods on natural language understanding\ntasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with\npre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance\nwith 50% lower variance than the contemporary efficient fine-tuning methods.\nThe theoretical and empirical results presented in the paper underscore how\nparameterization and hyperpriors balance exploration-exploitation in the\nlow-rank parametric space, therefore leading to more optimal and robust\nparameter estimation during efficient fine-tuning.\n","authors":["Vaibhav Seth","Arinjay Pathak","Ayan Sengupta","Natraj Raman","Sriram Gopalakrishnan","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2411.04358v1.pdf","comment":"48 pages, 10 figures, 10 tables, Code:\n  https://github.com/LCS2-IIITD/MonteCLoRA"},{"id":"http://arxiv.org/abs/2401.02561v2","updated":"2024-11-07T01:28:54Z","published":"2024-01-04T22:23:56Z","title":"CONTRAST: Continual Multi-source Adaptation to Dynamic Distributions","summary":"  Adapting to dynamic data distributions is a practical yet challenging task.\nOne effective strategy is to use a model ensemble, which leverages the diverse\nexpertise of different models to transfer knowledge to evolving data\ndistributions. However, this approach faces difficulties when the dynamic test\ndistribution is available only in small batches and without access to the\noriginal source data. To address the challenge of adapting to dynamic\ndistributions in such practical settings, we propose Continual Multi-source\nAdaptation to Dynamic Distributions (CONTRAST), a novel method that optimally\ncombines multiple source models to adapt to the dynamic test data. CONTRAST has\ntwo distinguishing features. First, it efficiently computes the optimal\ncombination weights to combine the source models to adapt to the test data\ndistribution continuously as a function of time. Second, it identifies which of\nthe source model parameters to update so that only the model which is most\ncorrelated to the target data is adapted, leaving the less correlated ones\nuntouched; this mitigates the issue of ``forgetting\" the source model\nparameters by focusing only on the source model that exhibits the strongest\ncorrelation with the test batch distribution. Through theoretical analysis we\nshow that the proposed method is able to optimally combine the source models\nand prioritize updates to the model least prone to forgetting. Experimental\nanalysis on diverse datasets demonstrates that the combination of multiple\nsource models does at least as well as the best source (with hindsight\nknowledge), and performance does not degrade as the test data distribution\nchanges over time (robust to forgetting).\n","authors":["Sk Miraj Ahmed","Fahim Faisal Niloy","Xiangyu Chang","Dripta S. Raychaudhuri","Samet Oymak","Amit K. Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2401.02561v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04356v1","updated":"2024-11-07T01:23:48Z","published":"2024-11-07T01:23:48Z","title":"GaGSL: Global-augmented Graph Structure Learning via Graph Information\n  Bottleneck","summary":"  Graph neural networks (GNNs) are prominent for their effectiveness in\nprocessing graph data for semi-supervised node classification tasks. Most works\nof GNNs assume that the observed structure accurately represents the underlying\nnode relationships. However, the graph structure is inevitably noisy or\nincomplete in reality, which can degrade the quality of graph representations.\nTherefore, it is imperative to learn a clean graph structure that balances\nperformance and robustness. In this paper, we propose a novel method named\n\\textit{Global-augmented Graph Structure Learning} (GaGSL), guided by the Graph\nInformation Bottleneck (GIB) principle. The key idea behind GaGSL is to learn a\ncompact and informative graph structure for node classification tasks.\nSpecifically, to mitigate the bias caused by relying solely on the original\nstructure, we first obtain augmented features and augmented structure through\nglobal feature augmentation and global structure augmentation. We then input\nthe augmented features and augmented structure into a structure estimator with\ndifferent parameters for optimization and re-definition of the graph structure,\nrespectively. The redefined structures are combined to form the final graph\nstructure. Finally, we employ GIB based on mutual information to guide the\noptimization of the graph structure to obtain the minimum sufficient graph\nstructure. Comprehensive evaluations across a range of datasets reveal the\noutstanding performance and robustness of GaGSL compared with the\nstate-of-the-art methods.\n","authors":["Shuangjie Li","Jiangqing Song","Baoming Zhang","Gaoli Ruan","Junyuan Xie","Chongjun Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04354v1","updated":"2024-11-07T01:21:12Z","published":"2024-11-07T01:21:12Z","title":"Impact of white noise in artificial neural networks trained for\n  classification: performance and noise mitigation strategies","summary":"  In recent years, the hardware implementation of neural networks, leveraging\nphysical coupling and analog neurons has substantially increased in relevance.\nSuch nonlinear and complex physical networks provide significant advantages in\nspeed and energy efficiency, but are potentially susceptible to internal noise\nwhen compared to digital emulations of such networks. In this work, we consider\nhow additive and multiplicative Gaussian white noise on the neuronal level can\naffect the accuracy of the network when applied for specific tasks and\nincluding a softmax function in the readout layer. We adapt several noise\nreduction techniques to the essential setting of classification tasks, which\nrepresent a large fraction of neural network computing. We find that these\nadjusted concepts are highly effective in mitigating the detrimental impact of\nnoise.\n","authors":["Nadezhda Semenova","Daniel Brunner"],"pdf_url":"https://arxiv.org/pdf/2411.04354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04342v1","updated":"2024-11-07T00:41:11Z","published":"2024-11-07T00:41:11Z","title":"Classification with Conceptual Safeguards","summary":"  We propose a new approach to promote safety in classification tasks with\nestablished concepts. Our approach -- called a conceptual safeguard -- acts as\na verification layer for models that predict a target outcome by first\npredicting the presence of intermediate concepts. Given this architecture, a\nsafeguard ensures that a model meets a minimal level of accuracy by abstaining\nfrom uncertain predictions. In contrast to a standard selective classifier, a\nsafeguard provides an avenue to improve coverage by allowing a human to confirm\nthe presence of uncertain concepts on instances on which it abstains. We\ndevelop methods to build safeguards that maximize coverage without compromising\nsafety, namely techniques to propagate the uncertainty in concept predictions\nand to flag salient concepts for human review. We benchmark our approach on a\ncollection of real-world and synthetic datasets, showing that it can improve\nperformance and coverage in deep learning tasks.\n","authors":["Hailey Joren","Charles Marx","Berk Ustun"],"pdf_url":"https://arxiv.org/pdf/2411.04342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04341v1","updated":"2024-11-07T00:39:34Z","published":"2024-11-07T00:39:34Z","title":"Enhancing classroom teaching with LLMs and RAG","summary":"  Large Language Models have become a valuable source of information for our\ndaily inquiries. However, after training, its data source quickly becomes\nout-of-date, making RAG a useful tool for providing even more recent or\npertinent data. In this work, we investigate how RAG pipelines, with the course\nmaterials serving as a data source, might help students in K-12 education. The\ninitial research utilizes Reddit as a data source for up-to-date cybersecurity\ninformation. Chunk size is evaluated to determine the optimal amount of context\nneeded to generate accurate answers. After running the experiment for different\nchunk sizes, answer correctness was evaluated using RAGAs with average answer\ncorrectness not exceeding 50 percent for any chunk size. This suggests that\nReddit is not a good source to mine for data for questions about cybersecurity\nthreats. The methodology was successful in evaluating the data source, which\nhas implications for its use to evaluate educational resources for\neffectiveness.\n","authors":["Elizabeth A Mullins","Adrian Portillo","Kristalys Ruiz-Rohena","Aritran Piplai"],"pdf_url":"https://arxiv.org/pdf/2411.04341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01030v3","updated":"2024-11-07T00:23:14Z","published":"2024-11-01T21:01:13Z","title":"Birdie: Advancing State Space Models with Reward-Driven Objectives and\n  Curricula","summary":"  Efficient state space models (SSMs), such as linear recurrent neural networks\nand linear attention variants, offer computational advantages over Transformers\nbut struggle with tasks requiring long-range in-context retrieval-like text\ncopying, associative recall, and question answering over long contexts.\nPrevious efforts to address these challenges have focused on architectural\nmodifications, often reintroducing computational inefficiencies. In this paper,\nwe propose a novel training procedure, Birdie, that significantly enhances the\nin-context retrieval capabilities of SSMs without altering their architecture.\nOur approach combines bidirectional input processing with dynamic mixtures of\nspecialized pre-training objectives, optimized via reinforcement learning. We\nintroduce a new bidirectional SSM architecture that seamlessly transitions from\nbidirectional context processing to causal generation. Experimental evaluations\ndemonstrate that Birdie markedly improves performance on retrieval-intensive\ntasks such as multi-number phone book lookup, long paragraph\nquestion-answering, and infilling. This narrows the performance gap with\nTransformers, while retaining computational efficiency. Our findings highlight\nthe importance of training procedures in leveraging the fixed-state capacity of\nSSMs, offering a new direction to advance their capabilities. All code and\npre-trained models are available at https://www.github.com/samblouir/birdie,\nwith support for JAX and PyTorch.\n","authors":["Sam Blouir","Jimmy T. H. Smith","Antonios Anastasopoulos","Amarda Shehu"],"pdf_url":"https://arxiv.org/pdf/2411.01030v3.pdf","comment":"Accepted to EMNLP 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2411.04330v1","updated":"2024-11-07T00:10:10Z","published":"2024-11-07T00:10:10Z","title":"Scaling Laws for Precision","summary":"  Low precision training and inference affect both the quality and cost of\nlanguage models, but current scaling laws do not account for this. In this\nwork, we devise \"precision-aware\" scaling laws for both training and inference.\nWe propose that training in lower precision reduces the model's \"effective\nparameter count,\" allowing us to predict the additional loss incurred from\ntraining in low precision and post-train quantization. For inference, we find\nthat the degradation introduced by post-training quantization increases as\nmodels are trained on more data, eventually making additional pretraining data\nactively harmful. For training, our scaling laws allow us to predict the loss\nof a model with different parts in different precisions, and suggest that\ntraining larger models in lower precision may be compute optimal. We unify the\nscaling laws for post and pretraining quantization to arrive at a single\nfunctional form that predicts degradation from training and inference in varied\nprecisions. We fit on over 465 pretraining runs and validate our predictions on\nmodel sizes up to 1.7B parameters trained on up to 26B tokens.\n","authors":["Tanishq Kumar","Zachary Ankner","Benjamin F. Spector","Blake Bordelon","Niklas Muennighoff","Mansheej Paul","Cengiz Pehlevan","Christopher Ré","Aditi Raghunathan"],"pdf_url":"https://arxiv.org/pdf/2411.04330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01006v2","updated":"2024-11-07T00:07:17Z","published":"2024-11-01T20:04:59Z","title":"Abstracted Shapes as Tokens -- A Generalizable and Interpretable Model\n  for Time-series Classification","summary":"  In time-series analysis, many recent works seek to provide a unified view and\nrepresentation for time-series across multiple domains, leading to the\ndevelopment of foundation models for time-series data. Despite diverse modeling\ntechniques, existing models are black boxes and fail to provide insights and\nexplanations about their representations. In this paper, we present VQShape, a\npre-trained, generalizable, and interpretable model for time-series\nrepresentation learning and classification. By introducing a novel\nrepresentation for time-series data, we forge a connection between the latent\nspace of VQShape and shape-level features. Using vector quantization, we show\nthat time-series from different domains can be described using a unified set of\nlow-dimensional codes, where each code can be represented as an abstracted\nshape in the time domain. On classification tasks, we show that the\nrepresentations of VQShape can be utilized to build interpretable classifiers,\nachieving comparable performance to specialist models. Additionally, in\nzero-shot learning, VQShape and its codebook can generalize to previously\nunseen datasets and domains that are not included in the pre-training process.\nThe code and pre-trained weights are available at\nhttps://github.com/YunshiWen/VQShape.\n","authors":["Yunshi Wen","Tengfei Ma","Tsui-Wei Weng","Lam M. Nguyen","Anak Agung Julius"],"pdf_url":"https://arxiv.org/pdf/2411.01006v2.pdf","comment":"Accepted by Neural Information Processing Systems (NeurIPS) 2024"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.04859v1","updated":"2024-11-07T16:49:25Z","published":"2024-11-07T16:49:25Z","title":"A multi-purpose automatic editing system based on lecture semantics for\n  remote education","summary":"  Remote teaching has become popular recently due to its convenience and\nsafety, especially under extreme circumstances like a pandemic. However, online\nstudents usually have a poor experience since the information acquired from the\nviews provided by the broadcast platforms is limited. One potential solution is\nto show more camera views simultaneously, but it is technically challenging and\ndistracting for the viewers. Therefore, an automatic multi-camera\ndirecting/editing system, which aims at selecting the most concerned view at\neach time instance to guide the attention of online students, is in urgent\ndemand. However, existing systems mostly make simple assumptions and focus on\ntracking the position of the speaker instead of the real lecture semantics, and\ntherefore have limited capacities to deliver optimal information flow. To this\nend, this paper proposes an automatic multi-purpose editing system based on the\nlecture semantics, which can both direct the multiple video streams for\nreal-time broadcasting and edit the optimal video offline for review purposes.\nOur system directs the views by semantically analyzing the class events while\nfollowing the professional directing rules, mimicking a human director to\ncapture the regions of interest from the viewpoint of the onsite students. We\nconduct both qualitative and quantitative analyses to verify the effectiveness\nof the proposed system and its components.\n","authors":["Panwen Hu","Rui Huang"],"pdf_url":"https://arxiv.org/pdf/2411.04859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04517v1","updated":"2024-11-07T08:19:39Z","published":"2024-11-07T08:19:39Z","title":"Continuous Sign Language Recognition System using Deep Learning with\n  MediaPipe Holistic","summary":"  Sign languages are the language of hearing-impaired people who use visuals\nlike the hand, facial, and body movements for communication. There are\ndifferent signs and gestures representing alphabets, words, and phrases.\nNowadays approximately 300 sign languages are being practiced worldwide such as\nAmerican Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language\n(ISL), and many more. Sign languages are dependent on the vocal language of a\nplace. Unlike vocal or spoken languages, there are no helping words in sign\nlanguage like is, am, are, was, were, will, be, etc. As only a limited\npopulation is well-versed in sign language, this lack of familiarity of sign\nlanguage hinders hearing-impaired people from communicating freely and easily\nwith everyone. This issue can be addressed by a sign language recognition (SLR)\nsystem which has the capability to translate the sign language into vocal\nlanguage. In this paper, a continuous SLR system is proposed using a deep\nlearning model employing Long Short-Term Memory (LSTM), trained and tested on\nan ISL primary dataset. This dataset is created using MediaPipe Holistic\npipeline for tracking face, hand, and body movements and collecting landmarks.\nThe system recognizes the signs and gestures in real-time with 88.23% accuracy.\n","authors":["Sharvani Srivastava","Sudhakar Singh"," Pooja","Shiv Prakash"],"pdf_url":"https://arxiv.org/pdf/2411.04517v1.pdf","comment":"14 pages, 4 figures, Wireless Pers Commun"},{"id":"http://arxiv.org/abs/2411.02551v2","updated":"2024-11-07T07:18:51Z","published":"2024-11-04T19:34:13Z","title":"PIAST: A Multimodal Piano Dataset with Audio, Symbolic and Text","summary":"  While piano music has become a significant area of study in Music Information\nRetrieval (MIR), there is a notable lack of datasets for piano solo music with\ntext labels. To address this gap, we present PIAST (PIano dataset with Audio,\nSymbolic, and Text), a piano music dataset. Utilizing a piano-specific taxonomy\nof semantic tags, we collected 9,673 tracks from YouTube and added human\nannotations for 2,023 tracks by music experts, resulting in two subsets:\nPIAST-YT and PIAST-AT. Both include audio, text, tag annotations, and\ntranscribed MIDI utilizing state-of-the-art piano transcription and beat\ntracking models. Among many possible tasks with the multi-modal dataset, we\nconduct music tagging and retrieval using both audio and MIDI data and report\nbaseline performances to demonstrate its potential as a valuable resource for\nMIR research.\n","authors":["Hayeon Bang","Eunjin Choi","Megan Finch","Seungheon Doh","Seolhee Lee","Gyeong-Hoon Lee","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2411.02551v2.pdf","comment":"Accepted for publication at the 3rd Workshop on NLP for Music and\n  Audio (NLP4MusA 2024)"},{"id":"http://arxiv.org/abs/2411.04366v1","updated":"2024-11-07T01:52:46Z","published":"2024-11-07T01:52:46Z","title":"The Concatenator: A Bayesian Approach To Real Time Concatenative\n  Musaicing","summary":"  We present ``The Concatenator,'' a real time system for audio-guided\nconcatenative synthesis. Similarly to Driedger et al.'s ``musaicing'' (or\n``audio mosaicing'') technique, we concatenate a set number of windows within a\ncorpus of audio to re-create the harmonic and percussive aspects of a target\naudio stream. Unlike Driedger's NMF-based technique, however, we instead use an\nexplicitly Bayesian point of view, where corpus window indices are hidden\nstates and the target audio stream is an observation. We use a particle filter\nto infer the best hidden corpus states in real-time. Our transition model\nincludes a tunable parameter to control the time-continuity of corpus grains,\nand our observation model allows users to prioritize how quickly windows change\nto match the target. Because the computational complexity of the system is\nindependent of the corpus size, our system scales to corpora that are hours\nlong, which is an important feature in the age of vast audio data collections.\nWithin The Concatenator module itself, composers can vary grain length, fit to\ntarget, and pitch shift in real time while reacting to the sounds they hear,\nenabling them to rapidly iterate ideas. To conclude our work, we evaluate our\nsystem with extensive quantitative tests of the effects of parameters, as well\nas a qualitative evaluation with artistic insights. Based on the quality of the\nresults, we believe the real-time capability unlocks new avenues for musical\nexpression and control, suitable for live performance and modular synthesis\nintegration, which furthermore represents an essential breakthrough in\nconcatenative synthesis technology.\n","authors":["Christopher Tralie","Ben Cantil"],"pdf_url":"https://arxiv.org/pdf/2411.04366v1.pdf","comment":"12 pages, 6 figures, Accepted for Publication in The International\n  Society for Music Information Retrieval Proceedings, 2024"}],"Computation and Language":[{"id":"http://arxiv.org/abs/2406.00922v3","updated":"2024-11-07T18:59:30Z","published":"2024-06-03T01:32:52Z","title":"MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive\n  Clinical Reasoning","summary":"  Users typically engage with LLMs interactively, yet most existing benchmarks\nevaluate them in a static, single-turn format, posing reliability concerns in\ninteractive scenarios. We identify a key obstacle towards reliability: LLMs are\ntrained to answer any question, even with incomplete context or insufficient\nknowledge. In this paper, we propose to change the static paradigm to an\ninteractive one, develop systems that proactively ask questions to gather more\ninformation and respond reliably, and introduce an benchmark - MediQ - to\nevaluate question-asking ability in LLMs. MediQ simulates clinical interactions\nconsisting of a Patient System and an adaptive Expert System; with potentially\nincomplete initial information, the Expert refrains from making diagnostic\ndecisions when unconfident, and instead elicits missing details via follow-up\nquestions. We provide a pipeline to convert single-turn medical benchmarks into\nan interactive format. Our results show that directly prompting\nstate-of-the-art LLMs to ask questions degrades performance, indicating that\nadapting LLMs to proactive information-seeking settings is nontrivial. We\nexperiment with abstention strategies to better estimate model confidence and\ndecide when to ask questions, improving diagnostic accuracy by 22.3%; however,\nperformance still lags compared to an (unrealistic in practice) upper bound\nwith complete information upfront. Further analyses show improved interactive\nperformance with filtering irrelevant contexts and reformatting conversations.\nOverall, we introduce a novel problem towards LLM reliability, an interactive\nMediQ benchmark and a novel question-asking system, and highlight directions to\nextend LLMs' information-seeking abilities in critical domains.\n","authors":["Shuyue Stella Li","Vidhisha Balachandran","Shangbin Feng","Jonathan S. Ilgen","Emma Pierson","Pang Wei Koh","Yulia Tsvetkov"],"pdf_url":"https://arxiv.org/pdf/2406.00922v3.pdf","comment":"29 pages, 12 figures"},{"id":"http://arxiv.org/abs/2411.05001v1","updated":"2024-11-07T18:59:28Z","published":"2024-11-07T18:59:28Z","title":"Analyzing The Language of Visual Tokens","summary":"  With the introduction of transformer-based models for vision and language\ntasks, such as LLaVA and Chameleon, there has been renewed interest in the\ndiscrete tokenized representation of images. These models often treat image\npatches as discrete tokens, analogous to words in natural language, learning\njoint alignments between visual and human languages. However, little is known\nabout the statistical behavior of these visual languages - whether they follow\nsimilar frequency distributions, grammatical structures, or topologies as\nnatural languages. In this paper, we take a natural-language-centric approach\nto analyzing discrete visual languages and uncover striking similarities and\nfundamental differences. We demonstrate that, although visual languages adhere\nto Zipfian distributions, higher token innovation drives greater entropy and\nlower compression, with tokens predominantly representing object parts,\nindicating intermediate granularity. We also show that visual languages lack\ncohesive grammatical structures, leading to higher perplexity and weaker\nhierarchical organization compared to natural languages. Finally, we\ndemonstrate that, while vision models align more closely with natural languages\nthan other models, this alignment remains significantly weaker than the\ncohesion found within natural languages. Through these experiments, we\ndemonstrate how understanding the statistical properties of discrete visual\nlanguages can inform the design of more effective computer vision models.\n","authors":["David M. Chan","Rodolfo Corona","Joonyong Park","Cheol Jun Cho","Yutong Bai","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2411.05001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05000v1","updated":"2024-11-07T18:59:27Z","published":"2024-11-07T18:59:27Z","title":"Needle Threading: Can LLMs Follow Threads through Near-Million-Scale\n  Haystacks?","summary":"  As the context limits of Large Language Models (LLMs) increase, the range of\npossible applications and downstream functions broadens. In many real-world\ntasks, decisions depend on details scattered across collections of often\ndisparate documents containing mostly irrelevant information. Long-context LLMs\nappear well-suited to this form of complex information retrieval and reasoning,\nwhich has traditionally proven costly and time-consuming. However, although the\ndevelopment of longer context models has seen rapid gains in recent years, our\nunderstanding of how effectively LLMs use their context has not kept pace. To\naddress this, we conduct a set of retrieval experiments designed to evaluate\nthe capabilities of 17 leading LLMs, such as their ability to follow threads of\ninformation through the context window. Strikingly, we find that many models\nare remarkably threadsafe: capable of simultaneously following multiple threads\nwithout significant loss in performance. Still, for many models, we find the\neffective context limit is significantly shorter than the supported context\nlength, with accuracy decreasing as the context window grows. Our study also\nhighlights the important point that token counts from different tokenizers\nshould not be directly compared -- they often correspond to substantially\ndifferent numbers of written characters. We release our code and long-context\nexperimental data.\n","authors":["Jonathan Roberts","Kai Han","Samuel Albanie"],"pdf_url":"https://arxiv.org/pdf/2411.05000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04997v1","updated":"2024-11-07T18:59:16Z","published":"2024-11-07T18:59:16Z","title":"LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation","summary":"  CLIP is one of the most important multimodal foundational models today. What\npowers CLIP's capabilities? The rich supervision signals provided by natural\nlanguage, the carrier of human knowledge, shape a powerful cross-modal\nrepresentation space. However, with the rapid advancements in large language\nmodels LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and\ngeneration are continually being pushed. This raises an intriguing question:\ncan the capabilities of LLMs be harnessed to further improve multimodal\nrepresentation learning? The potential benefits of incorporating LLMs into CLIP\nare clear. LLMs' strong textual understanding can fundamentally improve CLIP's\nability to handle image captions, drastically enhancing its ability to process\nlong and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs\nare trained on a vast corpus of text, possessing open-world knowledge. This\nallows them to expand on caption information during training, increasing the\nefficiency of the learning process. In this paper, we propose LLM2CLIP, a novel\napproach that embraces the power of LLMs to unlock CLIP's potential. By\nfine-tuning the LLM in the caption space with contrastive learning, we extract\nits textual capabilities into the output embeddings, significantly improving\nthe output layer's textual discriminability. We then design an efficient\ntraining process where the fine-tuned LLM acts as a powerful teacher for CLIP's\nvisual encoder. Thanks to the LLM's presence, we can now incorporate longer and\nmore complex captions without being restricted by vanilla CLIP's text encoder's\ncontext window and ability limitations. Our experiments demonstrate that this\napproach brings substantial improvements in cross-modal tasks.\n","authors":["Weiquan Huang","Aoqi Wu","Yifan Yang","Xufang Luo","Yuqing Yang","Liang Hu","Qi Dai","Xiyang Dai","Dongdong Chen","Chong Luo","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2411.04997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04996v1","updated":"2024-11-07T18:59:06Z","published":"2024-11-07T18:59:06Z","title":"Mixture-of-Transformers: A Sparse and Scalable Architecture for\n  Multi-Modal Foundation Models","summary":"  The development of large language models (LLMs) has expanded to multi-modal\nsystems capable of processing text, images, and speech within a unified\nframework. Training these models demands significantly larger datasets and\ncomputational resources compared to text-only LLMs. To address the scaling\nchallenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal\ntransformer architecture that significantly reduces pretraining computational\ncosts. MoT decouples non-embedding parameters of the model by modality --\nincluding feed-forward networks, attention matrices, and layer normalization --\nenabling modality-specific processing with global self-attention over the full\ninput sequence. We evaluate MoT across multiple settings and model scales. In\nthe Chameleon 7B setting (autoregressive text-and-image generation), MoT\nmatches the dense baseline's performance using only 55.8\\% of the FLOPs. When\nextended to include speech, MoT reaches speech performance comparable to the\ndense baseline with only 37.2\\% of the FLOPs. In the Transfusion setting, where\ntext and image are trained with different objectives, a 7B MoT model matches\nthe image modality performance of the dense baseline with one third of the\nFLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image\ngeneration metrics. System profiling further highlights MoT's practical\nbenefits, achieving dense baseline image quality in 47.2\\% of the wall-clock\ntime and text quality in 75.6\\% of the wall-clock time (measured on AWS\np4de.24xlarge instances with NVIDIA A100 GPUs).\n","authors":["Weixin Liang","Lili Yu","Liang Luo","Srinivasan Iyer","Ning Dong","Chunting Zhou","Gargi Ghosh","Mike Lewis","Wen-tau Yih","Luke Zettlemoyer","Xi Victoria Lin"],"pdf_url":"https://arxiv.org/pdf/2411.04996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04986v1","updated":"2024-11-07T18:55:09Z","published":"2024-11-07T18:55:09Z","title":"The Semantic Hub Hypothesis: Language Models Share Semantic\n  Representations Across Languages and Modalities","summary":"  Modern language models can process inputs across diverse languages and\nmodalities. We hypothesize that models acquire this capability through learning\na shared representation space across heterogeneous data types (e.g., different\nlanguages and modalities), which places semantically similar inputs near one\nanother, even if they are from different modalities/languages. We term this the\nsemantic hub hypothesis, following the hub-and-spoke model from neuroscience\n(Patterson et al., 2007) which posits that semantic knowledge in the human\nbrain is organized through a transmodal semantic \"hub\" which integrates\ninformation from various modality-specific \"spokes\" regions. We first show that\nmodel representations for semantically equivalent inputs in different languages\nare similar in the intermediate layers, and that this space can be interpreted\nusing the model's dominant pretraining language via the logit lens. This\ntendency extends to other data types, including arithmetic expressions, code,\nand visual/audio inputs. Interventions in the shared representation space in\none data type also predictably affect model outputs in other data types,\nsuggesting that this shared representations space is not simply a vestigial\nbyproduct of large-scale training on broad data, but something that is actively\nutilized by the model during input processing.\n","authors":["Zhaofeng Wu","Xinyan Velocity Yu","Dani Yogatama","Jiasen Lu","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2411.04986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04975v1","updated":"2024-11-07T18:49:33Z","published":"2024-11-07T18:49:33Z","title":"SuffixDecoding: A Model-Free Approach to Speeding Up Large Language\n  Model Inference","summary":"  We present SuffixDecoding, a novel model-free approach to accelerating large\nlanguage model (LLM) inference through speculative decoding. Unlike existing\nmethods that rely on draft models or specialized decoding heads, SuffixDecoding\nleverages suffix trees built from previously generated outputs to efficiently\npredict candidate token sequences. Our approach enables flexible\ntree-structured speculation without the overhead of maintaining and\norchestrating additional models. SuffixDecoding builds and dynamically updates\nsuffix trees to capture patterns in the generated text, using them to construct\nspeculation trees through a principled scoring mechanism based on empirical\ntoken frequencies. SuffixDecoding requires only CPU memory which is plentiful\nand underutilized on typical LLM serving nodes. We demonstrate that\nSuffixDecoding achieves competitive speedups compared to model-based approaches\nacross diverse workloads including open-domain chat, code generation, and\ntext-to-SQL tasks. For open-ended chat and code generation tasks,\nSuffixDecoding achieves up to $1.4\\times$ higher output throughput than\nSpecInfer and up to $1.1\\times$ lower time-per-token (TPOT) latency. For a\nproprietary multi-LLM text-to-SQL application, SuffixDecoding achieves up to\n$2.9\\times$ higher output throughput and $3\\times$ lower latency than\nspeculative decoding. Our evaluation shows that SuffixDecoding maintains high\nacceptance rates even with small reference corpora of 256 examples, while\ncontinuing to improve performance as more historical outputs are incorporated.\n","authors":["Gabriele Oliaro","Zhihao Jia","Daniel Campos","Aurick Qiao"],"pdf_url":"https://arxiv.org/pdf/2411.04975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04965v1","updated":"2024-11-07T18:41:50Z","published":"2024-11-07T18:41:50Z","title":"BitNet a4.8: 4-bit Activations for 1-bit LLMs","summary":"  Recent research on the 1-bit Large Language Models (LLMs), such as BitNet\nb1.58, presents a promising direction for reducing the inference cost of LLMs\nwhile maintaining their performance. In this work, we introduce BitNet a4.8,\nenabling 4-bit activations for 1-bit LLMs. BitNet a4.8 employs a hybrid\nquantization and sparsification strategy to mitigate the quantization errors\nintroduced by the outlier channels. Specifically, we utilize 4-bit activations\nfor inputs to the attention and feed-forward network layers, while sparsifying\nintermediate states followed with 8-bit quantization. Extensive experiments\ndemonstrate that BitNet a4.8 achieves performance comparable to BitNet b1.58\nwith equivalent training costs, while being faster in inference with enabling\n4-bit (INT4/FP4) kernels. Additionally, BitNet a4.8 activates only 55% of\nparameters and supports 3-bit KV cache, further enhancing the efficiency of\nlarge-scale LLM deployment and inference.\n","authors":["Hongyu Wang","Shuming Ma","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2411.04965v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.04962v1","updated":"2024-11-07T18:39:04Z","published":"2024-11-07T18:39:04Z","title":"Position Paper On Diagnostic Uncertainty Estimation from Large Language\n  Models: Next-Word Probability Is Not Pre-test Probability","summary":"  Large language models (LLMs) are being explored for diagnostic decision\nsupport, yet their ability to estimate pre-test probabilities, vital for\nclinical decision-making, remains limited. This study evaluates two LLMs,\nMistral-7B and Llama3-70B, using structured electronic health record data on\nthree diagnosis tasks. We examined three current methods of extracting LLM\nprobability estimations and revealed their limitations. We aim to highlight the\nneed for improved techniques in LLM confidence estimation.\n","authors":["Yanjun Gao","Skatje Myers","Shan Chen","Dmitriy Dligach","Timothy A Miller","Danielle Bitterman","Guanhua Chen","Anoop Mayampurath","Matthew Churpek","Majid Afshar"],"pdf_url":"https://arxiv.org/pdf/2411.04962v1.pdf","comment":"Accepted to GenAI4Health Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04952v1","updated":"2024-11-07T18:29:38Z","published":"2024-11-07T18:29:38Z","title":"M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page\n  Multi-document Understanding","summary":"  Document visual question answering (DocVQA) pipelines that answer questions\nfrom documents have broad applications. Existing methods focus on handling\nsingle-page documents with multi-modal language models (MLMs), or rely on\ntext-based retrieval-augmented generation (RAG) that uses text extraction tools\nsuch as optical character recognition (OCR). However, there are difficulties in\napplying these methods in real-world scenarios: (a) questions often require\ninformation across different pages or documents, where MLMs cannot handle many\nlong documents; (b) documents often have important information in visual\nelements such as figures, but text extraction tools ignore them. We introduce\nM3DocRAG, a novel multi-modal RAG framework that flexibly accommodates various\ndocument contexts (closed-domain and open-domain), question hops (single-hop\nand multi-hop), and evidence modalities (text, chart, figure, etc.). M3DocRAG\nfinds relevant documents and answers questions using a multi-modal retriever\nand an MLM, so that it can efficiently handle single or many documents while\npreserving visual information. Since previous DocVQA datasets ask questions in\nthe context of a specific document, we also present M3DocVQA, a new benchmark\nfor evaluating open-domain DocVQA over 3,000+ PDF documents with 40,000+ pages.\nIn three benchmarks (M3DocVQA/MMLongBench-Doc/MP-DocVQA), empirical results\nshow that M3DocRAG with ColPali and Qwen2-VL 7B achieves superior performance\nthan many strong baselines, including state-of-the-art performance in\nMP-DocVQA. We provide comprehensive analyses of different indexing, MLMs, and\nretrieval models. Lastly, we qualitatively show that M3DocRAG can successfully\nhandle various scenarios, such as when relevant information exists across\nmultiple pages and when answer evidence only exists in images.\n","authors":["Jaemin Cho","Debanjan Mahata","Ozan Irsoy","Yujie He","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2411.04952v1.pdf","comment":"Project webpage: https://m3docrag.github.io"},{"id":"http://arxiv.org/abs/2411.04950v1","updated":"2024-11-07T18:28:40Z","published":"2024-11-07T18:28:40Z","title":"Estimating the Influence of Sequentially Correlated Literary Properties\n  in Textual Classification: A Data-Centric Hypothesis-Testing Approach","summary":"  Stylometry aims to distinguish authors by analyzing literary traits assumed\nto reflect semi-conscious choices distinct from elements like genre or theme.\nHowever, these components often overlap, complicating text classification based\nsolely on feature distributions. While some literary properties, such as\nthematic content, are likely to manifest as correlations between adjacent text\nunits, others, like authorial style, may be independent thereof. We introduce a\nhypothesis-testing approach to evaluate the influence of sequentially\ncorrelated literary properties on text classification, aiming to determine when\nthese correlations drive classification. Using a multivariate binary\ndistribution, our method models sequential correlations between text units as a\nstochastic process, assessing the likelihood of clustering across varying\nadjacency scales. This enables us to examine whether classification is\ndominated by sequentially correlated properties or remains independent. In\nexperiments on a diverse English prose corpus, our analysis integrates\ntraditional and neural embeddings within supervised and unsupervised\nframeworks. Results demonstrate that our approach effectively identifies when\ntextual classification is not primarily influenced by sequentially correlated\nliterary properties, particularly in cases where texts differ in authorial\nstyle or genre rather than by a single author within a similar genre.\n","authors":["Gideon Yoffe","Nachum Dershowitz","Ariel Vishne","Barak Sober"],"pdf_url":"https://arxiv.org/pdf/2411.04950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14894v2","updated":"2024-11-07T18:15:23Z","published":"2024-06-21T06:30:16Z","title":"Talking the Talk Does Not Entail Walking the Walk: On the Limits of\n  Large Language Models in Lexical Entailment Recognition","summary":"  Verbs form the backbone of language, providing the structure and meaning to\nsentences. Yet, their intricate semantic nuances pose a longstanding challenge.\nUnderstanding verb relations through the concept of lexical entailment is\ncrucial for comprehending sentence meanings and grasping verb dynamics. This\nwork investigates the capabilities of eight Large Language Models in\nrecognizing lexical entailment relations among verbs through differently\ndevised prompting strategies and zero-/few-shot settings over verb pairs from\ntwo lexical databases, namely WordNet and HyperLex. Our findings unveil that\nthe models can tackle the lexical entailment recognition task with moderately\ngood performance, although at varying degree of effectiveness and under\ndifferent conditions. Also, utilizing few-shot prompting can enhance the\nmodels' performance. However, perfectly solving the task arises as an unmet\nchallenge for all examined LLMs, which raises an emergence for further research\ndevelopments on this topic.\n","authors":["Candida M. Greco","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2406.14894v2.pdf","comment":"Accepted for publication at The 2024 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP-2024) - Findings"},{"id":"http://arxiv.org/abs/2411.04920v1","updated":"2024-11-07T17:57:03Z","published":"2024-11-07T17:57:03Z","title":"GPTKB: Building Very Large Knowledge Bases from Language Models","summary":"  General-domain knowledge bases (KB), in particular the \"big three\" --\nWikidata, Yago and DBpedia -- are the backbone of many intelligent\napplications. While these three have seen steady development, comprehensive KB\nconstruction at large has seen few fresh attempts. In this work, we propose to\nbuild a large general-domain KB entirely from a large language model (LLM). We\ndemonstrate the feasibility of large-scale KB construction from LLMs, while\nhighlighting specific challenges arising around entity recognition, entity and\nproperty canonicalization, and taxonomy construction. As a prototype, we use\nGPT-4o-mini to construct GPTKB, which contains 105 million triples for more\nthan 2.9 million entities, at a cost 100x less than previous KBC projects. Our\nwork is a landmark for two fields: For NLP, for the first time, it provides\n\\textit{constructive} insights into the knowledge (or beliefs) of LLMs. For the\nSemantic Web, it shows novel ways forward for the long-standing challenge of\ngeneral-domain KB construction. GPTKB is accessible at https://gptkb.org.\n","authors":["Yujia Hu","Shrestha Ghosh","Tuan-Phong Nugyen","Simon Razniewski"],"pdf_url":"https://arxiv.org/pdf/2411.04920v1.pdf","comment":"11 pages, 4 tables"},{"id":"http://arxiv.org/abs/2406.15586v2","updated":"2024-11-07T17:56:19Z","published":"2024-06-21T18:41:22Z","title":"TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship\n  Embeddings","summary":"  The goal of text style transfer is to transform the style of texts while\npreserving their original meaning, often with only a few examples of the target\nstyle. Existing style transfer methods generally rely on the few-shot\ncapabilities of large language models or on complex controllable text\ngeneration approaches that are inefficient and underperform on fluency metrics.\nWe introduce TinyStyler, a lightweight but effective approach, which leverages\na small language model (800M params) and pre-trained authorship embeddings to\nperform efficient, few-shot text style transfer. We evaluate on the challenging\ntask of authorship style transfer and find TinyStyler outperforms strong\napproaches such as GPT-4. We also evaluate TinyStyler's ability to perform text\nattribute style transfer (formal $\\leftrightarrow$ informal) with automatic and\nhuman evaluations and find that the approach outperforms recent controllable\ntext generation methods. Our model has been made publicly available at\nhttps://huggingface.co/tinystyler/tinystyler .\n","authors":["Zachary Horvitz","Ajay Patel","Kanishk Singh","Chris Callison-Burch","Kathleen McKeown","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2406.15586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04914v1","updated":"2024-11-07T17:53:47Z","published":"2024-11-07T17:53:47Z","title":"GASE: Generatively Augmented Sentence Encoding","summary":"  We propose an approach to enhance sentence embeddings by applying generative\ntext models for data augmentation at inference time. Unlike conventional data\naugmentation that utilises synthetic training data, our approach does not\nrequire access to model parameters or the computational resources typically\nrequired for fine-tuning state-of-the-art models. Generatively Augmented\nSentence Encoding uses diverse linguistic synthetic variants of input texts\ngenerated by paraphrasing, summarising, or extracting keywords, followed by\npooling the original and synthetic embeddings. Experimental results on the\nMassive Text Embedding Benchmark for Semantic Textual Similarity (STS)\ndemonstrate performance improvements across a range of embedding models using\ndifferent generative models for augmentation. We find that generative\naugmentation leads to larger performance improvements for embedding models with\nlower baseline performance. These findings suggest that integrating generative\naugmentation at inference time adds semantic diversity and can enhance the\nrobustness and generalizability of sentence embeddings for embedding models.\nOur results show that the degree to which generative augmentation can improve\nSTS performance depends not only on the embedding model but also on the\ndataset. From a broader perspective, the approach allows trading training for\ninference compute.\n","authors":["Manuel Frank","Haithem Afli"],"pdf_url":"https://arxiv.org/pdf/2411.04914v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.04905v1","updated":"2024-11-07T17:47:25Z","published":"2024-11-07T17:47:25Z","title":"OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models","summary":"  Large language models (LLMs) for code have become indispensable in various\ndomains, including code generation, reasoning tasks and agent systems.While\nopen-access code LLMs are increasingly approaching the performance levels of\nproprietary models, high-quality code LLMs suitable for rigorous scientific\ninvestigation, particularly those with reproducible data processing pipelines\nand transparent training protocols, remain limited. The scarcity is due to\nvarious challenges, including resource constraints, ethical considerations, and\nthe competitive advantages of keeping models advanced. To address the gap, we\nintroduce OpenCoder, a top-tier code LLM that not only achieves performance\ncomparable to leading models but also serves as an ``open cookbook'' for the\nresearch community. Unlike most prior efforts, we release not only model\nweights and inference code, but also the reproducible training data, complete\ndata processing pipeline, rigorous experimental ablation results, and detailed\ntraining protocols for open scientific research. Through this comprehensive\nrelease, we identify the key ingredients for building a top-tier code LLM: (1)\ncode optimized heuristic rules for data cleaning and methods for data\ndeduplication, (2) recall of text corpus related to code and (3) high-quality\nsynthetic data in both annealing and supervised fine-tuning stages. By offering\nthis level of openness, we aim to broaden access to all aspects of a top-tier\ncode LLM, with OpenCoder serving as both a powerful model and an open\nfoundation to accelerate research, and enable reproducible advancements in code\nAI.\n","authors":["Siming Huang","Tianhao Cheng","Jason Klein Liu","Jiaran Hao","Liuyihan Song","Yang Xu","J. Yang","J. H. Liu","Chenchen Zhang","Linzheng Chai","Ruifeng Yuan","Zhaoxiang Zhang","Jie Fu","Qian Liu","Ge Zhang","Zili Wang","Yuan Qi","Yinghui Xu","Wei Chu"],"pdf_url":"https://arxiv.org/pdf/2411.04905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15814v2","updated":"2024-11-07T17:33:37Z","published":"2024-07-22T17:26:12Z","title":"Perceptions of Linguistic Uncertainty by Language Models and Humans","summary":"  _Uncertainty expressions_ such as \"probably\" or \"highly unlikely\" are\npervasive in human language. While prior work has established that there is\npopulation-level agreement in terms of how humans quantitatively interpret\nthese expressions, there has been little inquiry into the abilities of language\nmodels in the same context. In this paper, we investigate how language models\nmap linguistic expressions of uncertainty to numerical responses. Our approach\nassesses whether language models can employ theory of mind in this setting:\nunderstanding the uncertainty of another agent about a particular statement,\nindependently of the model's own certainty about that statement. We find that 7\nout of 10 models are able to map uncertainty expressions to probabilistic\nresponses in a human-like manner. However, we observe systematically different\nbehavior depending on whether a statement is actually true or false. This\nsensitivity indicates that language models are substantially more susceptible\nto bias based on their prior knowledge (as compared to humans). These findings\nraise important questions and have broad implications for human-AI and AI-AI\ncommunication.\n","authors":["Catarina G Belem","Markelle Kelly","Mark Steyvers","Sameer Singh","Padhraic Smyth"],"pdf_url":"https://arxiv.org/pdf/2407.15814v2.pdf","comment":"Accepted at EMNLP 2024 (Main)"},{"id":"http://arxiv.org/abs/2410.04981v2","updated":"2024-11-07T17:25:45Z","published":"2024-10-07T12:22:06Z","title":"On the Rigour of Scientific Writing: Criteria, Analysis, and Insights","summary":"  Rigour is crucial for scientific research as it ensures the reproducibility\nand validity of results and findings. Despite its importance, little work\nexists on modelling rigour computationally, and there is a lack of analysis on\nwhether these criteria can effectively signal or measure the rigour of\nscientific papers in practice. In this paper, we introduce a bottom-up,\ndata-driven framework to automatically identify and define rigour criteria and\nassess their relevance in scientific writing. Our framework includes rigour\nkeyword extraction, detailed rigour definition generation, and salient criteria\nidentification. Furthermore, our framework is domain-agnostic and can be\ntailored to the evaluation of scientific rigour for different areas,\naccommodating the distinct salient criteria across fields. We conducted\ncomprehensive experiments based on datasets collected from two high impact\nvenues for Machine Learning and NLP (i.e., ICLR and ACL) to demonstrate the\neffectiveness of our framework in modelling rigour. In addition, we analyse\nlinguistic patterns of rigour, revealing that framing certainty is crucial for\nenhancing the perception of scientific rigour, while suggestion certainty and\nprobability uncertainty diminish it.\n","authors":["Joseph James","Chenghao Xiao","Yucheng Li","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.04981v2.pdf","comment":"Accepted Findings at EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.04862v1","updated":"2024-11-07T16:53:09Z","published":"2024-11-07T16:53:09Z","title":"Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained\n  Language Models","summary":"  Title: Sentiment Analysis of Spanish Political Party Communications on\nTwitter Using Pre-trained Language Models\n  Authors: Chuqiao Song, Shunzhang Chen, Xinyi Cai, Hao Chen\n  Comments: 21 pages, 6 figures\n  Abstract: This study investigates sentiment patterns within Spanish political\nparty communications on Twitter by leveraging BETO and RoBERTuito, two\npre-trained language models optimized for Spanish text. Using a dataset of\ntweets from major Spanish political parties: PSOE, PP, Vox, Podemos, and\nCiudadanos, spanning 2019 to 2024, this research analyzes sentiment\ndistributions and explores the relationship between sentiment expression and\nparty ideology. The findings indicate that both models consistently identify a\npredominant Neutral sentiment across all parties, with significant variations\nin Negative and Positive sentiments that align with ideological distinctions.\nSpecifically, Vox exhibits higher levels of Negative sentiment, while PSOE\ndemonstrates relatively high Positive sentiment, supporting the hypothesis that\nemotional appeals in political messaging reflect ideological stances. This\nstudy underscores the potential of pre-trained language models for non-English\nsentiment analysis on social media, providing insights into sentiment dynamics\nthat shape public discourse within Spain's multi-party political system.\n  Keywords: Spanish politics, sentiment analysis, pre-trained language models,\nTwitter, BETO, RoBERTuito, political ideology, multi-party system\n","authors":["Chuqiao Song","Shunzhang Chen","Xinyi Cai","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2411.04862v1.pdf","comment":"21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.09269v2","updated":"2024-11-07T16:43:01Z","published":"2024-02-14T15:55:30Z","title":"Personalized Large Language Models","summary":"  Large language models (LLMs) have significantly advanced Natural Language\nProcessing (NLP) tasks in recent years. However, their universal nature poses\nlimitations in scenarios requiring personalized responses, such as\nrecommendation systems and chatbots. This paper investigates methods to\npersonalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on\nsubjective tasks. Results demonstrate that personalized fine-tuning improves\nmodel reasoning compared to non-personalized models. Experiments on datasets\nfor emotion recognition and hate speech detection show consistent performance\ngains with personalized methods across different LLM architectures. These\nfindings underscore the importance of personalization for enhancing LLM\ncapabilities in subjective text perception tasks.\n","authors":["Stanisław Woźniak","Bartłomiej Koptyra","Arkadiusz Janz","Przemysław Kazienko","Jan Kocoń"],"pdf_url":"https://arxiv.org/pdf/2402.09269v2.pdf","comment":"Accepted to SENTIRE 2024 (ICDM Workshops):\n  https://sentic.net/sentire2024wozniak.pdf"},{"id":"http://arxiv.org/abs/2411.04847v1","updated":"2024-11-07T16:33:48Z","published":"2024-11-07T16:33:48Z","title":"Prompt-Guided Internal States for Hallucination Detection of Large\n  Language Models","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\na variety of tasks in different domains. However, they sometimes generate\nresponses that are logically coherent but factually incorrect or misleading,\nwhich is known as LLM hallucinations. Data-driven supervised methods train\nhallucination detectors by leveraging the internal states of LLMs, but\ndetectors trained on specific domains often struggle to generalize well to\nother domains. In this paper, we aim to enhance the cross-domain performance of\nsupervised detectors with only in-domain data. We propose a novel framework,\nprompt-guided internal states for hallucination detection of LLMs, namely\nPRISM. By utilizing appropriate prompts to guide changes in the structure\nrelated to text truthfulness within the LLM's internal states, we make this\nstructure more salient and consistent across texts from different domains. We\nintegrated our framework with existing hallucination detection methods and\nconducted experiments on datasets from different domains. The experimental\nresults indicate that our framework significantly enhances the cross-domain\ngeneralization of existing hallucination detection methods.\n","authors":["Fujie Zhang","Peiqi Yu","Biao Yi","Baolei Zhang","Tong Li","Zheli Liu"],"pdf_url":"https://arxiv.org/pdf/2411.04847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04825v1","updated":"2024-11-07T16:06:00Z","published":"2024-11-07T16:06:00Z","title":"VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and\n  Benchmark Models","summary":"  Existing text simplification or paraphrase datasets mainly focus on\nsentence-level text generation in a general domain. These datasets are\ntypically developed without using domain knowledge. In this paper, we release a\nnovel dataset, VTechAGP, which is the first academic-to-general-audience text\nparaphrase dataset consisting of 4,938 document-level these and dissertation\nacademic and general-audience abstract pairs from 8 colleges authored over 25\nyears. We also propose a novel dynamic soft prompt generative language model,\nDSPT5. For training, we leverage a contrastive-generative loss function to\nlearn the keyword vectors in the dynamic prompt. For inference, we adopt a\ncrowd-sampling decoding strategy at both semantic and structural levels to\nfurther select the best output candidate. We evaluate DSPT5 and various\nstate-of-the-art large language models (LLMs) from multiple perspectives.\nResults demonstrate that the SOTA LLMs does not provide satisfactory outcomes,\nwhile the lightweight DSPT5 can achieve competitive results. To the best of our\nknowledge, we are the first to build a benchmark dataset and solutions for\nacademic-to-general-audience text paraphrase dataset.\n","authors":["Ming Cheng","Jiaying Gong","Chenhan Yuan","William A. Ingram","Edward Fox","Hoda Eldardiry"],"pdf_url":"https://arxiv.org/pdf/2411.04825v1.pdf","comment":"21 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.04822v1","updated":"2024-11-07T15:59:54Z","published":"2024-11-07T15:59:54Z","title":"When Does Classical Chinese Help? Quantifying Cross-Lingual Transfer in\n  Hanja and Kanbun","summary":"  Historical and linguistic connections within the Sinosphere have led\nresearchers to use Classical Chinese resources for cross-lingual transfer when\nprocessing historical documents from Korea and Japan. In this paper, we\nquestion the assumption of cross-lingual transferability from Classical Chinese\nto Hanja and Kanbun, the ancient written languages of Korea and Japan,\nrespectively. Our experiments across machine translation, named entity\nrecognition, and punctuation restoration tasks show minimal impact of Classical\nChinese datasets on language model performance for ancient Korean documents\nwritten in Hanja, with performance differences within $\\pm{}0.0068$ F1-score\nfor sequence labeling tasks and up to $+0.84$ BLEU score for translation. These\nlimitations persist consistently across various model sizes, architectures, and\ndomain-specific datasets. Our analysis reveals that the benefits of Classical\nChinese resources diminish rapidly as local language data increases for Hanja,\nwhile showing substantial improvements only in extremely low-resource scenarios\nfor both Korean and Japanese historical documents. These mixed results\nemphasize the need for careful empirical validation rather than assuming\nbenefits from indiscriminate cross-lingual transfer.\n","authors":["Seyoung Song","Haneul Yoo","Jiho Jin","Kyunghyun Cho","Alice Oh"],"pdf_url":"https://arxiv.org/pdf/2411.04822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04813v1","updated":"2024-11-07T15:50:40Z","published":"2024-11-07T15:50:40Z","title":"LuxBank: The First Universal Dependency Treebank for Luxembourgish","summary":"  The Universal Dependencies (UD) project has significantly expanded linguistic\ncoverage across 161 languages, yet Luxembourgish, a West Germanic language\nspoken by approximately 400,000 people, has remained absent until now. In this\npaper, we introduce LuxBank, the first UD Treebank for Luxembourgish,\naddressing the gap in syntactic annotation and analysis for this `low-research'\nlanguage. We establish formal guidelines for Luxembourgish language annotation,\nproviding the foundation for the first large-scale quantitative analysis of its\nsyntax. LuxBank serves not only as a resource for linguists and language\nlearners but also as a tool for developing spell checkers and grammar checkers,\norganising existing text archives and even training large language models. By\nincorporating Luxembourgish into the UD framework, we aim to enhance the\nunderstanding of syntactic variation within West Germanic languages and offer a\nmodel for documenting smaller, semi-standardised languages. This work positions\nLuxembourgish as a valuable resource in the broader linguistic and NLP\ncommunities, contributing to the study of languages with limited research and\nresources.\n","authors":["Alistair Plum","Caroline Döhmer","Emilia Milano","Anne-Marie Lutgen","Christoph Purschke"],"pdf_url":"https://arxiv.org/pdf/2411.04813v1.pdf","comment":"Accepted at 22nd Workshop on Treebanks and Linguistic Theories (TLT\n  2024)"},{"id":"http://arxiv.org/abs/2408.16163v2","updated":"2024-11-07T15:48:11Z","published":"2024-08-28T22:51:29Z","title":"FRACTURED-SORRY-Bench: Framework for Revealing Attacks in Conversational\n  Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench (Automated\n  Multi-shot Jailbreaks)","summary":"  This paper introduces FRACTURED-SORRY-Bench, a framework for evaluating the\nsafety of Large Language Models (LLMs) against multi-turn conversational\nattacks. Building upon the SORRY-Bench dataset, we propose a simple yet\neffective method for generating adversarial prompts by breaking down harmful\nqueries into seemingly innocuous sub-questions. Our approach achieves a maximum\nincrease of +46.22\\% in Attack Success Rates (ASRs) across GPT-4, GPT-4o,\nGPT-4o-mini, and GPT-3.5-Turbo models compared to baseline methods. We\ndemonstrate that this technique poses a challenge to current LLM safety\nmeasures and highlights the need for more robust defenses against subtle,\nmulti-turn attacks.\n","authors":["Aman Priyanshu","Supriti Vijay"],"pdf_url":"https://arxiv.org/pdf/2408.16163v2.pdf","comment":"4 pages, 2 tables"},{"id":"http://arxiv.org/abs/2302.12921v3","updated":"2024-11-07T15:44:43Z","published":"2023-02-24T22:38:54Z","title":"Pre-Finetuning for Few-Shot Emotional Speech Recognition","summary":"  Speech models have long been known to overfit individual speakers for many\nclassification tasks. This leads to poor generalization in settings where the\nspeakers are out-of-domain or out-of-distribution, as is common in production\nenvironments. We view speaker adaptation as a few-shot learning problem and\npropose investigating transfer learning approaches inspired by recent success\nwith pre-trained models in natural language tasks. We propose pre-finetuning\nspeech models on difficult tasks to distill knowledge into few-shot downstream\nclassification objectives. We pre-finetune Wav2Vec2.0 on every permutation of\nfour multiclass emotional speech recognition corpora and evaluate our\npre-finetuned models through 33,600 few-shot fine-tuning trials on the\nEmotional Speech Dataset.\n","authors":["Maximillian Chen","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2302.12921v3.pdf","comment":"Published at INTERSPEECH 2023. 5 pages, 4 figures. Code available at\n  https://github.com/maxlchen/Speech-PreFinetuning"},{"id":"http://arxiv.org/abs/2403.00867v3","updated":"2024-11-07T15:41:38Z","published":"2024-03-01T03:29:54Z","title":"Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by\n  Exploring Refusal Loss Landscapes","summary":"  Large Language Models (LLMs) are becoming a prominent generative AI tool,\nwhere the user enters a query and the LLM generates an answer. To reduce harm\nand misuse, efforts have been made to align these LLMs to human values using\nadvanced training techniques such as Reinforcement Learning from Human Feedback\n(RLHF). However, recent studies have highlighted the vulnerability of LLMs to\nadversarial jailbreak attempts aiming at subverting the embedded safety\nguardrails. To address this challenge, this paper defines and investigates the\nRefusal Loss of LLMs and then proposes a method called Gradient Cuff to detect\njailbreak attempts. Gradient Cuff exploits the unique properties observed in\nthe refusal loss landscape, including functional values and its smoothness, to\ndesign an effective two-step detection strategy. Experimental results on two\naligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak\nattacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can\nsignificantly improve the LLM's rejection capability for malicious jailbreak\nqueries, while maintaining the model's performance for benign user queries by\nadjusting the detection threshold.\n","authors":["Xiaomeng Hu","Pin-Yu Chen","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2403.00867v3.pdf","comment":"Accepted by NeurIPS 2024. Project page:\n  https://huggingface.co/spaces/TrustSafeAI/GradientCuff-Jailbreak-Defense"},{"id":"http://arxiv.org/abs/2411.04799v1","updated":"2024-11-07T15:38:25Z","published":"2024-11-07T15:38:25Z","title":"Kwai-STaR: Transform LLMs into State-Transition Reasoners","summary":"  Mathematical reasoning presents a significant challenge to the cognitive\ncapabilities of LLMs. Various methods have been proposed to enhance the\nmathematical ability of LLMs. However, few recognize the value of state\ntransition for LLM reasoning. In this work, we define mathematical\nproblem-solving as a process of transiting from an initial unsolved state to\nthe final resolved state, and propose Kwai-STaR framework, which transforms\nLLMs into State-Transition Reasoners to improve their intuitive reasoning\ncapabilities. Our approach comprises three main steps: (1) Define the state\nspace tailored to the mathematical reasoning. (2) Generate state-transition\ndata based on the state space. (3) Convert original LLMs into State-Transition\nReasoners via a curricular training strategy. Our experiments validate the\neffectiveness of Kwai-STaR in enhancing mathematical reasoning: After training\non the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and\nLLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard\ndataset. Additionally, the state transition-based design endows Kwai-STaR with\nremarkable training and inference efficiency. Further experiments are underway\nto establish the generality of Kwai-STaR.\n","authors":["Xingyu Lu","Yuhang Hu","Changyi Liu","Tianke Zhang","Zhenyu Yang","Zhixiang Ding","Shengsheng Qian","Meng Du","Ruiwen Kang","Kaiyu Tang","Fan Yang","Tingting Gao","Di Zhang","Hai-Tao Zheng","Bin Wen"],"pdf_url":"https://arxiv.org/pdf/2411.04799v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.04794v1","updated":"2024-11-07T15:36:05Z","published":"2024-11-07T15:36:05Z","title":"AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual\n  Alignment","summary":"  Empirical evidence suggests that LLMs exhibit spontaneous cross-lingual\nalignment. Our findings suggest that although LLMs also demonstrate promising\ncross-lingual alignment in Information Extraction, there remains significant\nimbalance across languages, revealing an underlying deficiency in the IE\nalignment. To address this issue, we propose AlignXIE, a powerful code-based\nLLM that significantly enhances cross-lingual IE alignment through two\nstrategies. Firstly, AlignXIE formulates IE across different languages,\nespecially non-English ones, as code generation tasks, standardizing the\nrepresentation of various schemas using Python classes to ensure consistency of\nthe same ontology in different languages and align the schema. Secondly, it\nincorporates an IE cross-lingual alignment phase through a translated instance\nprediction task proposed in this paper to align the extraction process,\nutilizing ParallelNER, an IE bilingual parallel dataset with 257,190 samples,\ngenerated by our proposed LLM-based automatic pipeline for IE parallel data\nconstruction, with manual annotation to ensure quality. Ultimately, we obtain\nAlignXIE through multilingual IE instruction tuning. Although without training\nin 9 unseen languages, AlignXIE surpasses ChatGPT by $30.17\\%$ and SoTA by\n$20.03\\%$, thereby demonstrating superior cross-lingual IE capabilities.\nComprehensive evaluations on 63 IE benchmarks in Chinese and English under\nvarious settings, demonstrate that AlignXIE significantly enhances\ncross-lingual and multilingual IE through boosting the IE alignment.\n","authors":["Yuxin Zuo","Wenxuan Jiang","Wenxuan Liu","Zixuan Li","Long Bai","Hanbin Wang","Yutao Zeng","Xiaolong Jin","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2411.04794v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.04788v1","updated":"2024-11-07T15:28:20Z","published":"2024-11-07T15:28:20Z","title":"Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in\n  Financial Research","summary":"  In recent years, the application of generative artificial intelligence\n(GenAI) in financial analysis and investment decision-making has gained\nsignificant attention. However, most existing approaches rely on single-agent\nsystems, which fail to fully utilize the collaborative potential of multiple AI\nagents. In this paper, we propose a novel multi-agent collaboration system\ndesigned to enhance decision-making in financial investment research. The\nsystem incorporates agent groups with both configurable group sizes and\ncollaboration structures to leverage the strengths of each agent group type. By\nutilizing a sub-optimal combination strategy, the system dynamically adapts to\nvarying market conditions and investment scenarios, optimizing performance\nacross different tasks. We focus on three sub-tasks: fundamentals, market\nsentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30\ncompanies listed on the Dow Jones Index. Our findings reveal significant\nperformance variations based on the configurations of AI agents for different\ntasks. The results demonstrate that our multi-agent collaboration system\noutperforms traditional single-agent models, offering improved accuracy,\nefficiency, and adaptability in complex financial environments. This study\nhighlights the potential of multi-agent systems in transforming financial\nanalysis and investment decision-making by integrating diverse analytical\nperspectives.\n","authors":["Xuewen Han","Neng Wang","Shangkun Che","Hongyang Yang","Kunpeng Zhang","Sean Xin Xu"],"pdf_url":"https://arxiv.org/pdf/2411.04788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17437v2","updated":"2024-11-07T15:00:00Z","published":"2024-08-30T17:41:30Z","title":"SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic\n  CheckLists","summary":"  Traditional benchmarking in NLP typically involves using static held-out test\nsets. However, this approach often results in an overestimation of performance\nand lacks the ability to offer comprehensive, interpretable, and dynamic\nassessments of NLP models. Recently, works like DynaBench (Kiela et al., 2021)\nand CheckList (Ribeiro et al., 2020) have addressed these limitations through\nbehavioral testing of NLP models with test types generated by a multistep\nhuman-annotated pipeline. Unfortunately, manually creating a variety of test\ntypes requires much human labor, often at prohibitive cost. In this work, we\npropose SYNTHEVAL, a hybrid behavioral testing framework that leverages large\nlanguage models (LLMs) to generate a wide range of test types for a\ncomprehensive evaluation of NLP models. SYNTHEVAL first generates sentences via\nLLMs using controlled generation, and then identifies challenging examples by\ncomparing the predictions made by LLMs with task-specific NLP models. In the\nlast stage, human experts investigate the challenging examples, manually design\ntemplates, and identify the types of failures the taskspecific models\nconsistently exhibit. We apply SYNTHEVAL to two classification tasks, sentiment\nanalysis and toxic language detection, and show that our framework is effective\nin identifying weaknesses of strong models on these tasks. We share our code in\nhttps://github.com/Loreley99/SynthEval_CheckList.\n","authors":["Raoyuan Zhao","Abdullatif Köksal","Yihong Liu","Leonie Weissweiler","Anna Korhonen","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2408.17437v2.pdf","comment":"EMNLP 2024 - Findings"},{"id":"http://arxiv.org/abs/2411.03883v2","updated":"2024-11-07T14:57:14Z","published":"2024-11-06T12:57:58Z","title":"MEG: Medical Knowledge-Augmented Large Language Models for Question\n  Answering","summary":"  Question answering is a natural language understanding task that involves\nreasoning over both explicit context and unstated, relevant domain knowledge.\nLarge language models (LLMs), which underpin most contemporary question\nanswering systems, struggle to induce how concepts relate in specialized\ndomains such as medicine. Existing medical LLMs are also costly to train. In\nthis work, we present MEG, a parameter-efficient approach for medical\nknowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate\ngraph embeddings into the LLM, enabling it to leverage external knowledge in a\ncost-effective way. We evaluate our method on four popular medical\nmultiple-choice datasets and show that LLMs greatly benefit from the factual\ngrounding provided by knowledge graph embeddings. MEG attains an average of\n+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized\nmodels like BioMistral. We also show results based on Llama-3. Finally, we show\nthat MEG's performance remains robust to the choice of graph encoder.\n","authors":["Laura Cabello","Carmen Martin-Turrero","Uchenna Akujuobi","Anders Søgaard","Carlos Bobed"],"pdf_url":"https://arxiv.org/pdf/2411.03883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04756v1","updated":"2024-11-07T14:54:42Z","published":"2024-11-07T14:54:42Z","title":"A study of Vietnamese readability assessing through semantic and\n  statistical features","summary":"  Determining the difficulty of a text involves assessing various textual\nfeatures that may impact the reader's text comprehension, yet current research\nin Vietnamese has only focused on statistical features. This paper introduces a\nnew approach that integrates statistical and semantic approaches to assessing\ntext readability. Our research utilized three distinct datasets: the Vietnamese\nText Readability Dataset (ViRead), OneStopEnglish, and RACE, with the latter\ntwo translated into Vietnamese. Advanced semantic analysis methods were\nemployed for the semantic aspect using state-of-the-art language models such as\nPhoBERT, ViDeBERTa, and ViBERT. In addition, statistical methods were\nincorporated to extract syntactic and lexical features of the text. We\nconducted experiments using various machine learning models, including Support\nVector Machine (SVM), Random Forest, and Extra Trees and evaluated their\nperformance using accuracy and F1 score metrics. Our results indicate that a\njoint approach that combines semantic and statistical features significantly\nenhances the accuracy of readability classification compared to using each\nmethod in isolation. The current study emphasizes the importance of considering\nboth statistical and semantic aspects for a more accurate assessment of text\ndifficulty in Vietnamese. This contribution to the field provides insights into\nthe adaptability of advanced language models in the context of Vietnamese text\nreadability. It lays the groundwork for future research in this area.\n","authors":["Hung Tuan Le","Long Truong To","Manh Trong Nguyen","Quyen Nguyen","Trong-Hop Do"],"pdf_url":"https://arxiv.org/pdf/2411.04756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04752v1","updated":"2024-11-07T14:41:01Z","published":"2024-11-07T14:41:01Z","title":"RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced\n  Code-Mixed Information Retrieval","summary":"  Code-mixing, the integration of lexical and grammatical elements from\nmultiple languages within a single sentence, is a widespread linguistic\nphenomenon, particularly prevalent in multilingual societies. In India, social\nmedia users frequently engage in code-mixed conversations using the Roman\nscript, especially among migrant communities who form online groups to share\nrelevant local information. This paper focuses on the challenges of extracting\nrelevant information from code-mixed conversations, specifically within Roman\ntransliterated Bengali mixed with English. This study presents a novel approach\nto address these challenges by developing a mechanism to automatically identify\nthe most relevant answers from code-mixed conversations. We have experimented\nwith a dataset comprising of queries and documents from Facebook, and Query\nRelevance files (QRels) to aid in this task. Our results demonstrate the\neffectiveness of our approach in extracting pertinent information from complex,\ncode-mixed digital conversations, contributing to the broader field of natural\nlanguage processing in multilingual and informal text environments. We use\nGPT-3.5 Turbo via prompting alongwith using the sequential nature of relevant\ndocuments to frame a mathematical model which helps to detect relevant\ndocuments corresponding to a query.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.04752v1.pdf","comment":"Accepted at FIRE 2024 (Track: Code-Mixed Information Retrieval from\n  Social Media Data)"},{"id":"http://arxiv.org/abs/2310.09765v2","updated":"2024-11-07T13:56:58Z","published":"2023-10-15T07:49:56Z","title":"MILPaC: A Novel Benchmark for Evaluating Translation of Legal Text to\n  Indian Languages","summary":"  Most legal text in the Indian judiciary is written in complex English due to\nhistorical reasons. However, only a small fraction of the Indian population is\ncomfortable in reading English. Hence legal text needs to be made available in\nvarious Indian languages, possibly by translating the available legal text from\nEnglish. Though there has been a lot of research on translation to and between\nIndian languages, to our knowledge, there has not been much prior work on such\ntranslation in the legal domain. In this work, we construct the first\nhigh-quality legal parallel corpus containing aligned text units in English and\nnine Indian languages, that includes several low-resource languages. We also\nbenchmark the performance of a wide variety of Machine Translation (MT) systems\nover this corpus, including commercial MT systems, open-source MT systems and\nLarge Language Models. Through a comprehensive survey by Law practitioners, we\ncheck how satisfied they are with the translations by some of these MT systems,\nand how well automatic MT evaluation metrics agree with the opinions of Law\npractitioners.\n","authors":["Sayan Mahapatra","Debtanu Datta","Shubham Soni","Adrijit Goswami","Saptarshi Ghosh"],"pdf_url":"https://arxiv.org/pdf/2310.09765v2.pdf","comment":"To be published in ACM Transactions on Asian and Low-Resource\n  Language Information Processing (TALLIP)"},{"id":"http://arxiv.org/abs/2411.04699v1","updated":"2024-11-07T13:33:34Z","published":"2024-11-07T13:33:34Z","title":"BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages","summary":"  Automatic Speech Translation (AST) datasets for Indian languages remain\ncritically scarce, with public resources covering fewer than 10 of the 22\nofficial languages. This scarcity has resulted in AST systems for Indian\nlanguages lagging far behind those available for high-resource languages like\nEnglish. In this paper, we first evaluate the performance of widely-used AST\nsystems on Indian languages, identifying notable performance gaps and\nchallenges. Our findings show that while these systems perform adequately on\nread speech, they struggle significantly with spontaneous speech, including\ndisfluencies like pauses and hesitations. Additionally, there is a striking\nabsence of systems capable of accurately translating colloquial and informal\nlanguage, a key aspect of everyday communication. To this end, we introduce\nBhasaAnuvaad, the largest publicly available dataset for AST involving 14\nscheduled Indian languages spanning over 44,400 hours and 17M text segments.\nBhasaAnuvaad contains data for English speech to Indic text, as well as Indic\nspeech to English text. This dataset comprises three key categories: (1)\nCurated datasets from existing resources, (2) Large-scale web mining, and (3)\nSynthetic data generation. By offering this diverse and expansive dataset, we\naim to bridge the resource gap and promote advancements in AST for low-resource\nIndian languages, especially in handling spontaneous and informal speech\npatterns.\n","authors":["Sparsh Jain","Ashwin Sankar","Devilal Choudhary","Dhairya Suman","Nikhil Narasimhan","Mohammed Safi Ur Rahman Khan","Anoop Kunchukuttan","Mitesh M Khapra","Raj Dabre"],"pdf_url":"https://arxiv.org/pdf/2411.04699v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2405.04304v5","updated":"2024-11-07T12:59:39Z","published":"2024-05-07T13:27:52Z","title":"Dynamic Speculation Lookahead Accelerates Speculative Decoding of Large\n  Language Models","summary":"  Speculative decoding is commonly used for reducing the inference latency of\nlarge language models. Its effectiveness depends highly on the speculation\nlookahead (SL)-the number of tokens generated by the draft model at each\niteration. In this work we show that the common practice of using the same SL\nfor all iterations (static SL) is suboptimal. We introduce DISCO (DynamIc\nSpeCulation lookahead Optimization), a novel method for dynamically selecting\nthe SL. Our experiments with four datasets show that DISCO reaches an average\nspeedup of 10% compared to the best static SL baseline, while generating the\nexact same text.\n","authors":["Jonathan Mamou","Oren Pereg","Daniel Korat","Moshe Berchansky","Nadav Timor","Moshe Wasserblat","Roy Schwartz"],"pdf_url":"https://arxiv.org/pdf/2405.04304v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02674v3","updated":"2024-11-07T12:38:41Z","published":"2024-11-04T23:21:12Z","title":"Wave Network: An Ultra-Small Language Model","summary":"  We propose an innovative token representation and update method in a new\nultra-small language model: the Wave network. Specifically, we use a complex\nvector to represent each token, encoding both global and local semantics of the\ninput text. A complex vector consists of two components: a magnitude vector\nrepresenting the global semantics of the input text, and a phase vector\ncapturing the relationships between individual tokens and global semantics.\nExperiments on the AG News text classification task demonstrate that, when\ngenerating complex vectors from randomly initialized token embeddings, our\nsingle-layer Wave Network achieves 90.91% accuracy with wave interference and\n91.66% with wave modulation - outperforming a single Transformer layer using\nBERT pre-trained embeddings by 19.23% and 19.98%, respectively, and approaching\nthe accuracy of the pre-trained and fine-tuned BERT base model (94.64%).\nAdditionally, compared to BERT base, the Wave Network reduces video memory\nusage and training time by 77.34% and 85.62% during wave modulation. In\nsummary, we used a 2.4-million-parameter small language model to achieve\naccuracy comparable to a 100-million-parameter BERT model in text\nclassification.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.02674v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04649v1","updated":"2024-11-07T12:12:44Z","published":"2024-11-07T12:12:44Z","title":"DISCO: DISCovering Overfittings as Causal Rules for Text Classification\n  Models","summary":"  With the rapid advancement of neural language models, the deployment of\nover-parameterized models has surged, increasing the need for interpretable\nexplanations comprehensible to human inspectors. Existing post-hoc\ninterpretability methods, which often focus on unigram features of single input\ntextual instances, fail to capture the models' decision-making process fully.\nAdditionally, many methods do not differentiate between decisions based on\nspurious correlations and those based on a holistic understanding of the input.\nOur paper introduces DISCO, a novel method for discovering global, rule-based\nexplanations by identifying causal n-gram associations with model predictions.\nThis method employs a scalable sequence mining technique to extract relevant\ntext spans from training data, associate them with model predictions, and\nconduct causality checks to distill robust rules that elucidate model behavior.\nThese rules expose potential overfitting and provide insights into misleading\nfeature combinations. We validate DISCO through extensive testing,\ndemonstrating its superiority over existing methods in offering comprehensive\ninsights into complex model behaviors. Our approach successfully identifies all\nshortcuts manually introduced into the training data (100% detection rate on\nthe MultiRC dataset), resulting in an 18.8% regression in model performance --\na capability unmatched by any other method. Furthermore, DISCO supports\ninteractive explanations, enabling human inspectors to distinguish spurious\ncauses in the rule-based output. This alleviates the burden of abundant\ninstance-wise explanations and helps assess the model's risk when encountering\nout-of-distribution (OOD) data.\n","authors":["Zijian Zhang","Vinay Setty","Yumeng Wang","Avishek Anand"],"pdf_url":"https://arxiv.org/pdf/2411.04649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14125v3","updated":"2024-11-07T12:07:07Z","published":"2024-05-23T02:57:42Z","title":"ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based\n  Evaluation","summary":"  Large Language Models (LLMs) can elicit unintended and even harmful content\nwhen misaligned with human values, posing severe risks to users and society. To\nmitigate these risks, current evaluation benchmarks predominantly employ\nexpert-designed contextual scenarios to assess how well LLMs align with human\nvalues. However, the labor-intensive nature of these benchmarks limits their\ntest scope, hindering their ability to generalize to the extensive variety of\nopen-world use cases and identify rare but crucial long-tail risks.\nAdditionally, these static tests fail to adapt to the rapid evolution of LLMs,\nmaking it hard to evaluate timely alignment issues. To address these\nchallenges, we propose ALI-Agent, an evaluation framework that leverages the\nautonomous abilities of LLM-powered agents to conduct in-depth and adaptive\nalignment assessments. ALI-Agent operates through two principal stages:\nEmulation and Refinement. During the Emulation stage, ALI-Agent automates the\ngeneration of realistic test scenarios. In the Refinement stage, it iteratively\nrefines the scenarios to probe long-tail risks. Specifically, ALI-Agent\nincorporates a memory module to guide test scenario generation, a tool-using\nmodule to reduce human labor in tasks such as evaluating feedback from target\nLLMs, and an action module to refine tests. Extensive experiments across three\naspects of human values--stereotypes, morality, and legality--demonstrate that\nALI-Agent, as a general evaluation framework, effectively identifies model\nmisalignment. Systematic analysis also validates that the generated test\nscenarios represent meaningful use cases, as well as integrate enhanced\nmeasures to probe long-tail risks. Our code is available at\nhttps://github.com/SophieZheng998/ALI-Agent.git\n","authors":["Jingnan Zheng","Han Wang","An Zhang","Tai D. Nguyen","Jun Sun","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2405.14125v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04637v1","updated":"2024-11-07T11:51:14Z","published":"2024-11-07T11:51:14Z","title":"Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop","summary":"  Training and deploying machine learning models relies on a large amount of\nhuman-annotated data. As human labeling becomes increasingly expensive and\ntime-consuming, recent research has developed multiple strategies to speed up\nannotation and reduce costs and human workload: generating synthetic training\ndata, active learning, and hybrid labeling. This tutorial is oriented toward\npractical applications: we will present the basics of each strategy, highlight\ntheir benefits and limitations, and discuss in detail real-life case studies.\nAdditionally, we will walk through best practices for managing human annotators\nand controlling the quality of the final dataset. The tutorial includes a\nhands-on workshop, where attendees will be guided in implementing a hybrid\nannotation setup. This tutorial is designed for NLP practitioners from both\nresearch and industry backgrounds who are involved in or interested in\noptimizing data labeling projects.\n","authors":["Ekaterina Artemova","Akim Tsvigun","Dominik Schlechtweg","Natalia Fedorova","Sergei Tilga","Boris Obmoroshev"],"pdf_url":"https://arxiv.org/pdf/2411.04637v1.pdf","comment":"To be presented at COLING 2025"},{"id":"http://arxiv.org/abs/2411.04604v1","updated":"2024-11-07T10:39:10Z","published":"2024-11-07T10:39:10Z","title":"FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment\n  Analysis","summary":"  In the context of low-resource languages, the Algerian dialect (AD) faces\nchallenges due to the absence of annotated corpora, hindering its effective\nprocessing, notably in Machine Learning (ML) applications reliant on corpora\nfor training and assessment. This study outlines the development process of a\nspecialized corpus for Fake News (FN) detection and sentiment analysis (SA) in\nAD called FASSILA. This corpus comprises 10,087 sentences, encompassing over\n19,497 unique words in AD, and addresses the significant lack of linguistic\nresources in the language and covers seven distinct domains. We propose an\nannotation scheme for FN detection and SA, detailing the data collection,\ncleaning, and labelling process. Remarkable Inter-Annotator Agreement indicates\nthat the annotation scheme produces consistent annotations of high quality.\nSubsequent classification experiments using BERT-based models and ML models are\npresented, demonstrate promising results and highlight avenues for further\nresearch. The dataset is made freely available on GitHub\n(https://github.com/amincoding/FASSILA) to facilitate future advancements in\nthe field.\n","authors":["Amin Abdedaiem","Abdelhalim Hafedh Dahou","Mohamed Amine Cheragui","Brigitte Mathiak"],"pdf_url":"https://arxiv.org/pdf/2411.04604v1.pdf","comment":"16 pages, 6 Figuers"},{"id":"http://arxiv.org/abs/2411.04602v1","updated":"2024-11-07T10:31:31Z","published":"2024-11-07T10:31:31Z","title":"Self-Calibrated Listwise Reranking with Large Language Models","summary":"  Large language models (LLMs), with advanced linguistic capabilities, have\nbeen employed in reranking tasks through a sequence-to-sequence approach. In\nthis paradigm, multiple passages are reranked in a listwise manner and a\ntextual reranked permutation is generated. However, due to the limited context\nwindow of LLMs, this reranking paradigm requires a sliding window strategy to\niteratively handle larger candidate sets. This not only increases computational\ncosts but also restricts the LLM from fully capturing all the comparison\ninformation for all candidates. To address these challenges, we propose a novel\nself-calibrated listwise reranking method, which aims to leverage LLMs to\nproduce global relevance scores for ranking. To achieve it, we first propose\nthe relevance-aware listwise reranking framework, which incorporates explicit\nlist-view relevance scores to improve reranking efficiency and enable global\ncomparison across the entire candidate set. Second, to ensure the comparability\nof the computed scores, we propose self-calibrated training that uses\npoint-view relevance assessments generated internally by the LLM itself to\ncalibrate the list-view relevance assessments. Extensive experiments and\ncomprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks\ndemonstrate the effectiveness and efficiency of our proposed method.\n","authors":["Ruiyang Ren","Yuhao Wang","Kun Zhou","Wayne Xin Zhao","Wenjie Wang","Jing Liu","Ji-Rong Wen","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2411.04602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04588v1","updated":"2024-11-07T10:17:40Z","published":"2024-11-07T10:17:40Z","title":"Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using\n  ChatGPT for Arabic Grammatical Error Correction","summary":"  Natural language processing (NLP) utilizes text data augmentation to overcome\nsample size constraints. Increasing the sample size is a natural and widely\nused strategy for alleviating these challenges. In this study, we chose Arabic\nto increase the sample size and correct grammatical errors. Arabic is\nconsidered one of the languages with limited resources for grammatical error\ncorrection (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used\nin most Arabic grammatical error correction research, with approximately 20,500\nparallel examples, which is considered low compared with other languages.\nTherefore, this study aims to develop an Arabic corpus called \"Tibyan\" for\ngrammatical error correction using ChatGPT. ChatGPT is used as a data augmenter\ntool based on a pair of Arabic sentences containing grammatical errors matched\nwith a sentence free of errors extracted from Arabic books, called guide\nsentences. Multiple steps were involved in establishing our corpus, including\nthe collection and pre-processing of a pair of Arabic texts from various\nsources, such as books and open-access corpora. We then used ChatGPT to\ngenerate a parallel corpus based on the text collected previously, as a guide\nfor generating sentences with multiple types of errors. By engaging linguistic\nexperts to review and validate the automatically generated sentences, we\nensured that they were correct and error-free. The corpus was validated and\nrefined iteratively based on feedback provided by linguistic experts to improve\nits accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to\nanalyze the types of errors in the Tibyan corpus. Our corpus contained 49 of\nerrors, including seven types: orthography, morphology, syntax, semantics,\npunctuation, merge, and split. The Tibyan corpus contains approximately 600 K\ntokens.\n","authors":["Ahlam Alrehili","Areej Alhothali"],"pdf_url":"https://arxiv.org/pdf/2411.04588v1.pdf","comment":"17 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.04585v1","updated":"2024-11-07T10:11:38Z","published":"2024-11-07T10:11:38Z","title":"The State and Fate of Summarization Datasets","summary":"  Automatic summarization has consistently attracted attention, due to its\nversatility and wide application in various downstream tasks. Despite its\npopularity, we find that annotation efforts have largely been disjointed, and\nhave lacked common terminology. Consequently, it is challenging to discover\nexisting resources or identify coherent research directions. To address this,\nwe survey a large body of work spanning 133 datasets in over 100 languages,\ncreating a novel ontology covering sample properties, collection methods and\ndistribution. With this ontology we make key observations, including the lack\nin accessible high-quality datasets for low-resource languages, and the field's\nover-reliance on the news domain and on automatically collected distant\nsupervision. Finally, we make available a web interface that allows users to\ninteract and explore our ontology and dataset collection, as well as a template\nfor a summarization data card, which can be used to streamline future research\ninto a more coherent body of work.\n","authors":["Noam Dahan","Gabriel Stanovsky"],"pdf_url":"https://arxiv.org/pdf/2411.04585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04573v1","updated":"2024-11-07T09:57:57Z","published":"2024-11-07T09:57:57Z","title":"Multistage Fine-tuning Strategies for Automatic Speech Recognition in\n  Low-resource Languages","summary":"  This paper presents a novel multistage fine-tuning strategy designed to\nenhance automatic speech recognition (ASR) performance in low-resource\nlanguages using OpenAI's Whisper model. In this approach we aim to build ASR\nmodel for languages with limited digital resources by sequentially adapting the\nmodel across linguistically similar languages. We experimented this on the\nMalasar language, a Dravidian language spoken by approximately ten thousand\npeople in the Western Ghats of South India. Malasar language faces critical\nchallenges for technological intervention due to its lack of a native script\nand absence of digital or spoken data resources. Working in collaboration with\nWycliffe India and Malasar community members, we created a spoken Malasar\ncorpus paired with transcription in Tamil script, a closely related major\nlanguage. In our approach to build ASR model for Malasar, we first build an\nintermediate Tamil ASR, leveraging higher data availability for Tamil annotated\nspeech. This intermediate model is subsequently fine-tuned on Malasar data,\nallowing for more effective ASR adaptation despite limited resources. The\nmultistage fine-tuning strategy demonstrated significant improvements over\ndirect fine-tuning on Malasar data alone, achieving a word error rate (WER) of\n51.9%, which is 4.5% absolute reduction when compared to the direct fine-tuning\nmethod. Further a WER reduction to 47.3% was achieved through punctuation\nremoval in post-processing, which addresses formatting inconsistencies that\nimpact evaluation. Our results underscore the effectiveness of sequential\nmultistage fine-tuning combined with targeted post-processing as a scalable\nstrategy for ASR system development in low-resource languages, especially where\nlinguistic similarities can be leveraged to bridge gaps in training data.\n","authors":["Leena G Pillai","Kavya Manohar","Basil K Raju","Elizabeth Sherly"],"pdf_url":"https://arxiv.org/pdf/2411.04573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12096v3","updated":"2024-11-07T09:29:32Z","published":"2024-04-18T11:29:23Z","title":"LongEmbed: Extending Embedding Models for Long Context Retrieval","summary":"  Embedding models play a pivot role in modern NLP applications such as IR and\nRAG. While the context limit of LLMs has been pushed beyond 1 million tokens,\nembedding models are still confined to a narrow context window not exceeding 8k\ntokens, refrained from application scenarios requiring long inputs such as\nlegal contracts. This paper explores context window extension of existing\nembedding models, pushing the limit to 32k without requiring additional\ntraining. First, we examine the performance of current embedding models for\nlong context retrieval on our newly constructed LongEmbed benchmark. LongEmbed\ncomprises two synthetic tasks and four carefully chosen real-world tasks,\nfeaturing documents of varying length and dispersed target information.\nBenchmarking results underscore huge room for improvement in these models.\nBased on this, comprehensive experiments show that training-free context window\nextension strategies like position interpolation can effectively extend the\ncontext window of existing embedding models by several folds, regardless of\ntheir original context being 512 or beyond 4k. Furthermore, for models\nemploying absolute position encoding (APE), we show the possibility of further\nfine-tuning to harvest notable performance gains while strictly preserving\noriginal behavior for short inputs. For models using rotary position embedding\n(RoPE), significant enhancements are observed when employing RoPE-specific\nmethods, such as NTK and SelfExtend, indicating RoPE's superiority over APE for\ncontext window extension. To facilitate future research, we release E5-Base-4k\nand E5-RoPE-Base, along with the LongEmbed benchmark.\n","authors":["Dawei Zhu","Liang Wang","Nan Yang","Yifan Song","Wenhao Wu","Furu Wei","Sujian Li"],"pdf_url":"https://arxiv.org/pdf/2404.12096v3.pdf","comment":"EMNLP 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2411.04557v1","updated":"2024-11-07T09:28:38Z","published":"2024-11-07T09:28:38Z","title":"Pruning Literals for Highly Efficient Explainability at Word Level","summary":"  Designing an explainable model becomes crucial now for Natural Language\nProcessing(NLP) since most of the state-of-the-art machine learning models\nprovide a limited explanation for the prediction. In the spectrum of an\nexplainable model, Tsetlin Machine(TM) is promising because of its capability\nof providing word-level explanation using proposition logic. However, concern\nrises over the elaborated combination of literals (propositional logic) in the\nclause that makes the model difficult for humans to comprehend, despite having\na transparent learning process. In this paper, we design a post-hoc pruning of\nclauses that eliminate the randomly placed literals in the clause thereby\nmaking the model more efficiently interpretable than the vanilla TM.\nExperiments on the publicly available YELP-HAT Dataset demonstrate that the\nproposed pruned TM's attention map aligns more with the human attention map\nthan the vanilla TM's attention map. In addition, the pairwise similarity\nmeasure also surpasses the attention map-based neural network models. In terms\nof accuracy, the proposed pruning method does not degrade the accuracy\nsignificantly but rather enhances the performance up to 4% to 9% in some test\ndata.\n","authors":["Rohan Kumar Yadav","Bimal Bhattarai","Abhik Jana","Lei Jiao","Seid Muhie Yimam"],"pdf_url":"https://arxiv.org/pdf/2411.04557v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.04539v1","updated":"2024-11-07T08:54:46Z","published":"2024-11-07T08:54:46Z","title":"Best Practices for Distilling Large Language Models into BERT for Web\n  Search Ranking","summary":"  Recent studies have highlighted the significant potential of Large Language\nModels (LLMs) as zero-shot relevance rankers. These methods predominantly\nutilize prompt learning to assess the relevance between queries and documents\nby generating a ranked list of potential documents. Despite their promise, the\nsubstantial costs associated with LLMs pose a significant challenge for their\ndirect implementation in commercial search systems. To overcome this barrier\nand fully exploit the capabilities of LLMs for text ranking, we explore\ntechniques to transfer the ranking expertise of LLMs to a more compact model\nsimilar to BERT, using a ranking loss to enable the deployment of less\nresource-intensive models. Specifically, we enhance the training of LLMs\nthrough Continued Pre-Training, taking the query as input and the clicked title\nand summary as output. We then proceed with supervised fine-tuning of the LLM\nusing a rank loss, assigning the final token as a representative of the entire\nsentence. Given the inherent characteristics of autoregressive language models,\nonly the final token </s> can encapsulate all preceding tokens. Additionally,\nwe introduce a hybrid point-wise and margin MSE loss to transfer the ranking\nknowledge from LLMs to smaller models like BERT. This method creates a viable\nsolution for environments with strict resource constraints. Both offline and\nonline evaluations have confirmed the efficacy of our approach, and our model\nhas been successfully integrated into a commercial web search engine as of\nFebruary 2024.\n","authors":["Dezhi Ye","Junwei Hu","Jiabin Fan","Bowen Tian","Jie Liu","Haijin Liang","Jin Ma"],"pdf_url":"https://arxiv.org/pdf/2411.04539v1.pdf","comment":"Arxiv Version"},{"id":"http://arxiv.org/abs/2411.04535v1","updated":"2024-11-07T08:48:33Z","published":"2024-11-07T08:48:33Z","title":"Meta-Reasoning Improves Tool Use in Large Language Models","summary":"  External tools help large language models (LLMs) succeed at tasks where they\nwould otherwise typically fail. In existing frameworks, LLMs learn tool use\neither by in-context demonstrations or via full model fine-tuning on annotated\ndata. As these approaches do not easily scale, a recent trend is to abandon\nthem in favor of lightweight, parameter-efficient tuning paradigms. These\nmethods allow quickly alternating between the frozen LLM and its specialised\nfine-tuned version, by switching on or off a handful of additional custom\nparameters. Hence, we postulate that the generalization ability of the frozen\nmodel can be leveraged to improve tool selection. We present Tool selECTion via\nmeta-reasONing (TECTON), a two-phase system that first reasons over a task\nusing a custom fine-tuned LM head and outputs candidate tools. Then, with the\ncustom head disabled, it meta-reasons (i.e., it reasons over the previous\nreasoning process) to make a final choice. We show that TECTON results in\nsubstantial gains - both in-distribution and out-of-distribution - on a range\nof math reasoning datasets.\n","authors":["Lisa Alazraki","Marek Rei"],"pdf_url":"https://arxiv.org/pdf/2411.04535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14974v2","updated":"2024-11-07T08:41:03Z","published":"2024-05-23T18:21:59Z","title":"LOVA3: Learning to Visual Question Answering, Asking and Assessment","summary":"  Question answering, asking, and assessment are three innate human traits\ncrucial for understanding the world and acquiring knowledge. By enhancing these\ncapabilities, humans can more effectively utilize data, leading to better\ncomprehension and learning outcomes. Current Multimodal Large Language Models\n(MLLMs) primarily focus on question answering, often neglecting the full\npotential of questioning and assessment skills. Inspired by the human learning\nmechanism, we introduce LOVA3, an innovative framework named \"Learning tO\nVisual question Answering, Asking and Assessment,\" designed to equip MLLMs with\nthese additional capabilities. Our approach involves the creation of two\nsupplementary training tasks GenQA and EvalQA, aiming at fostering the skills\nof asking and assessing questions in the context of images. To develop the\nquestioning ability, we compile a comprehensive set of multimodal foundational\ntasks. For assessment, we introduce a new benchmark called EvalQABench,\ncomprising 64,000 training samples (split evenly between positive and negative\nsamples) and 5,000 validation and testing samples. We posit that enhancing\nMLLMs with the capabilities to answer, ask, and assess questions will enhance\ntheir multimodal comprehension, ultimately improving overall performance. To\nvalidate this hypothesis, we train MLLMs using the LOVA3 framework and evaluate\nthem on a range of multimodal datasets and benchmarks. Our results demonstrate\nconsistent performance gains, underscoring the critical role of these\nadditional tasks in fostering comprehensive intelligence in MLLMs. The code is\navailable at https://github.com/showlab/LOVA3.\n","authors":["Henry Hengyuan Zhao","Pan Zhou","Difei Gao","Zechen Bai","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2405.14974v2.pdf","comment":"Accepted by NeurIPS 2024. The code is available at\n  https://github.com/showlab/LOVA3"},{"id":"http://arxiv.org/abs/2411.04530v1","updated":"2024-11-07T08:38:32Z","published":"2024-11-07T08:38:32Z","title":"Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among\n  Subwords in Multilingual Language Models","summary":"  Human understanding of language is robust to different word choices as far as\nthey represent similar semantic concepts. To what extent does our human\nintuition transfer to language models, which represent all subwords as distinct\nembeddings? In this work, we take an initial step on measuring the role of\nshared semantics among subwords in the encoder-only multilingual language\nmodels (mLMs). To this end, we form \"semantic tokens\" by merging the\nsemantically similar subwords and their embeddings, and evaluate the updated\nmLMs on 5 heterogeneous multilingual downstream tasks. Results show that the\ngeneral shared semantics could get the models a long way in making the\npredictions on mLMs with different tokenizers and model sizes. Inspections on\nthe grouped subwords show that they exhibit a wide range of semantic\nsimilarities, including synonyms and translations across many languages and\nscripts. Lastly, we found the zero-shot results with semantic tokens are on par\nor even better than the original models on certain classification tasks,\nsuggesting that the shared subword-level semantics may serve as the anchors for\ncross-lingual transferring.\n","authors":["Xinyu Zhang","Jing Lu","Vinh Q. Tran","Tal Schuster","Donald Metzler","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.04530v1.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2405.17382v2","updated":"2024-11-07T08:34:27Z","published":"2024-05-27T17:38:33Z","title":"ReMoDetect: Reward Models Recognize Aligned LLM's Generations","summary":"  The remarkable capabilities and easy accessibility of large language models\n(LLMs) have significantly increased societal risks (e.g., fake news\ngeneration), necessitating the development of LLM-generated text (LGT)\ndetection methods for safe usage. However, detecting LGTs is challenging due to\nthe vast number of LLMs, making it impractical to account for each LLM\nindividually; hence, it is crucial to identify the common characteristics\nshared by these models. In this paper, we draw attention to a common feature of\nrecent powerful LLMs, namely the alignment training, i.e., training LLMs to\ngenerate human-preferable texts. Our key finding is that as these aligned LLMs\nare trained to maximize the human preferences, they generate texts with higher\nestimated preferences even than human-written texts; thus, such texts are\neasily detected by using the reward model (i.e., an LLM trained to model human\npreference distribution). Based on this finding, we propose two training\nschemes to further improve the detection ability of the reward model, namely\n(i) continual preference fine-tuning to make the reward model prefer aligned\nLGTs even further and (ii) reward modeling of Human/LLM mixed texts (a\nrephrased texts from human-written texts using aligned LLMs), which serves as a\nmedian preference text corpus between LGTs and human-written texts to learn the\ndecision boundary better. We provide an extensive evaluation by considering six\ntext domains across twelve aligned LLMs, where our method demonstrates\nstate-of-the-art results. Code is available at\nhttps://github.com/hyunseoklee-ai/ReMoDetect.\n","authors":["Hyunseok Lee","Jihoon Tack","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2405.17382v2.pdf","comment":"Published as a conference proceeding for NeurIPS 2024"},{"id":"http://arxiv.org/abs/2308.13149v2","updated":"2024-11-07T08:20:46Z","published":"2023-08-25T03:05:33Z","title":"SciEval: A Multi-Level Large Language Model Evaluation Benchmark for\n  Scientific Research","summary":"  Recently, there has been growing interest in using Large Language Models\n(LLMs) for scientific research. Numerous benchmarks have been proposed to\nevaluate the ability of LLMs for scientific research. However, current\nbenchmarks are mostly based on pre-collected objective questions. This design\nsuffers from data leakage problem and lacks the evaluation of subjective Q/A\nability. In this paper, we propose SciEval, a comprehensive and\nmulti-disciplinary evaluation benchmark to address these issues. Based on\nBloom's taxonomy, SciEval covers four dimensions to systematically evaluate\nscientific research ability. In particular, we design a \"dynamic\" subset based\non scientific principles to prevent evaluation from potential data leakage.\nBoth objective and subjective questions are included in SciEval. These\ncharacteristics make SciEval a more effective benchmark for scientific research\nability evaluation of LLMs. Comprehensive experiments on most advanced LLMs\nshow that, although GPT-4 achieves SOTA performance compared to other LLMs,\nthere is still substantial room for improvement, especially for dynamic\nquestions. The codes and data are publicly available on\nhttps://github.com/OpenDFM/SciEval.\n","authors":["Liangtai Sun","Yang Han","Zihan Zhao","Da Ma","Zhennan Shen","Baocai Chen","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2308.13149v2.pdf","comment":"12 pages, 17 figures, 12 tables. Accepted by AAAI 2024"},{"id":"http://arxiv.org/abs/2411.04496v1","updated":"2024-11-07T07:46:06Z","published":"2024-11-07T07:46:06Z","title":"Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large\n  Language Model","summary":"  To increase social bonding with interlocutors, humans naturally acquire the\nability to respond appropriately in a given situation by considering which\nconversational skill is most suitable for the response - a process we call\nskill-of-mind. For large language model (LLM)-based conversational agents,\nplanning appropriate conversational skills, as humans do, is challenging due to\nthe complexity of social dialogue, especially in interactive scenarios. To\naddress this, we propose a skill-of-mind-annotated conversation dataset, named\nMultifaceted Skill-of-Mind, which includes multi-turn and multifaceted\nconversational skills across various interactive scenarios (e.g., long-term,\ncounseling, task-oriented), grounded in diverse social contexts (e.g.,\ndemographics, persona, rules of thumb). This dataset consists of roughly 100K\nconversations. Using this dataset, we introduce a new family of\nskill-of-mind-infused LLMs, named Thanos, with model sizes of 1B, 3B, and 8B\nparameters. With extensive experiments, these models successfully demonstrate\nthe skill-of-mind process and exhibit strong generalizability in inferring\nmultifaceted skills across a variety of domains. Moreover, we show that Thanos\nsignificantly enhances the quality of responses generated by LLM-based\nconversational agents and promotes prosocial behavior in human evaluations.\n","authors":["Young-Jun Lee","Dokyong Lee","Junyoung Youn","Kyeongjin Oh","Ho-Jin Choi"],"pdf_url":"https://arxiv.org/pdf/2411.04496v1.pdf","comment":"Code: https://github.com/passing2961/Thanos"},{"id":"http://arxiv.org/abs/2410.14979v3","updated":"2024-11-07T07:25:04Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration From A Psychological Perspective","summary":"  Despite their proficiency in math tasks, the mechanisms underlying LLMs'\nmathematical reasoning abilities remain a subject of debate. Recent studies\nsuggest that chain-of-thought (CoT) prompts can bolster mathematical reasoning\nby encouraging LLMs to employ human-like logical reasoning (System 2), enabling\nthem to excel on the Cognitive Reflection Test (CRT). To assess whether LLMs\ngenuinely possess System 2-like logical reasoning, we introduced targeted\nmodifications to CRT problems. Our findings reveal that, despite the use of CoT\nprompts, mainstream LLMs, including the latest o1-preview model, continue to\nexhibit a significant error rate. Further analysis indicates that they\npredominantly rely on System 1-like intuitive reasoning and pattern matching\nderived from training data, rather than demonstrating mastery of mathematical\nthinking. This discovery challenges the prevailing notion that LLMs possess\ngenuine logical reasoning abilities and that CoT can enhance them.\nConsequently, this work may temper overly optimistic projections regarding\nLLMs' advancement toward artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Kai Chen","Xiaobing Sun","Baosheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14979v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04090v2","updated":"2024-11-07T07:12:45Z","published":"2024-11-06T18:08:57Z","title":"A Collaborative Content Moderation Framework for Toxicity Detection\n  based on Conformalized Estimates of Annotation Disagreement","summary":"  Content moderation typically combines the efforts of human moderators and\nmachine learning models. However, these systems often rely on data where\nsignificant disagreement occurs during moderation, reflecting the subjective\nnature of toxicity perception. Rather than dismissing this disagreement as\nnoise, we interpret it as a valuable signal that highlights the inherent\nambiguity of the content,an insight missed when only the majority label is\nconsidered. In this work, we introduce a novel content moderation framework\nthat emphasizes the importance of capturing annotation disagreement. Our\napproach uses multitask learning, where toxicity classification serves as the\nprimary task and annotation disagreement is addressed as an auxiliary task.\nAdditionally, we leverage uncertainty estimation techniques, specifically\nConformal Prediction, to account for both the ambiguity in comment annotations\nand the model's inherent uncertainty in predicting toxicity and\ndisagreement.The framework also allows moderators to adjust thresholds for\nannotation disagreement, offering flexibility in determining when ambiguity\nshould trigger a review. We demonstrate that our joint approach enhances model\nperformance, calibration, and uncertainty estimation, while offering greater\nparameter efficiency and improving the review process in comparison to\nsingle-task methods.\n","authors":["Guillermo Villate-Castillo","Javier Del Ser","Borja Sanz"],"pdf_url":"https://arxiv.org/pdf/2411.04090v2.pdf","comment":"35 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.11709v4","updated":"2024-11-07T07:00:14Z","published":"2024-06-17T16:28:21Z","title":"Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical\n  Questioning for Socratic Code Debugging","summary":"  Socratic questioning is an effective teaching strategy, encouraging critical\nthinking and problem-solving. The conversational capabilities of large language\nmodels (LLMs) show great potential for providing scalable, real-time student\nguidance. However, current LLMs often give away solutions directly, making them\nineffective instructors. We tackle this issue in the code debugging domain with\nTreeInstruct, an Instructor agent guided by a novel state space-based planning\nalgorithm. TreeInstruct asks probing questions to help students independently\nidentify and resolve errors. It estimates a student's conceptual and\nsyntactical knowledge to dynamically construct a question tree based on their\nresponses and current knowledge state, effectively addressing both independent\nand dependent mistakes concurrently in a multi-turn interaction setting. In\naddition to using an existing single-bug debugging benchmark, we construct a\nmore challenging multi-bug dataset of 150 coding problems, incorrect solutions,\nand bug fixes -- all carefully constructed and annotated by experts. Extensive\nevaluation shows TreeInstruct's state-of-the-art performance on both datasets,\nproving it to be a more effective instructor than baselines. Furthermore, a\nreal-world case study with five students of varying skill levels further\ndemonstrates TreeInstruct's ability to guide students to debug their code\nefficiently with minimal turns and highly Socratic questioning.\n","authors":["Priyanka Kargupta","Ishika Agarwal","Dilek Hakkani-Tur","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2406.11709v4.pdf","comment":"Code available at: https://github.com/agarwalishika/TreeInstruct\n  Accepted at EMNLP'24 Findings"},{"id":"http://arxiv.org/abs/2411.04473v1","updated":"2024-11-07T06:51:24Z","published":"2024-11-07T06:51:24Z","title":"ML-Promise: A Multilingual Dataset for Corporate Promise Verification","summary":"  Promises made by politicians, corporate leaders, and public figures have a\nsignificant impact on public perception, trust, and institutional reputation.\nHowever, the complexity and volume of such commitments, coupled with\ndifficulties in verifying their fulfillment, necessitate innovative methods for\nassessing their credibility. This paper introduces the concept of Promise\nVerification, a systematic approach involving steps such as promise\nidentification, evidence assessment, and the evaluation of timing for\nverification. We propose the first multilingual dataset, ML-Promise, which\nincludes English, French, Chinese, Japanese, and Korean, aimed at facilitating\nin-depth verification of promises, particularly in the context of\nEnvironmental, Social, and Governance (ESG) reports. Given the growing emphasis\non corporate environmental contributions, this dataset addresses the challenge\nof evaluating corporate promises, especially in light of practices like\ngreenwashing. Our findings also explore textual and image-based baselines, with\npromising results from retrieval-augmented generation (RAG) approaches. This\nwork aims to foster further discourse on the accountability of public\ncommitments across multiple languages and domains.\n","authors":["Yohei Seki","Hakusen Shu","Anaïs Lhuissier","Hanwool Lee","Juyeon Kang","Min-Yuh Day","Chung-Chi Chen"],"pdf_url":"https://arxiv.org/pdf/2411.04473v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2410.04070v5","updated":"2024-11-07T06:21:14Z","published":"2024-10-05T08:00:55Z","title":"PAD: Personalized Alignment of LLMs at Decoding-Time","summary":"  Aligning with personalized preferences, which vary significantly across\ncultural, educational, and political differences, poses a significant challenge\ndue to the computational costs and data demands of traditional alignment\nmethods. In response, this paper presents Personalized Alignment at\nDecoding-time (PAD), a novel framework designed to align LLM outputs with\ndiverse personalized preferences during the inference phase, eliminating the\nneed for additional training. By introducing a unique personalized reward\nmodeling strategy, this framework decouples the text generation process from\npersonalized preferences, facilitating the generation of generalizable\ntoken-level personalized rewards. The PAD algorithm leverages these rewards to\nguide the decoding process, dynamically tailoring the base model's predictions\nto personalized preferences. Extensive experimental results demonstrate that\nPAD not only outperforms existing training-based alignment methods in terms of\naligning with diverse preferences but also shows significant generalizability\nto preferences unseen during training and scalability across different base\nmodels. This work advances the capability of LLMs to meet user needs in\nreal-time applications, presenting a substantial step forward in personalized\nLLM alignment.\n","authors":["Ruizhe Chen","Xiaotian Zhang","Meng Luo","Wenhao Chai","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.04070v5.pdf","comment":"This paper presents Personalized Alignment at Decoding-time (PAD), a\n  novel framework designed to align LLM outputs with diverse personalized\n  preferences during the inference phase"},{"id":"http://arxiv.org/abs/2411.02887v2","updated":"2024-11-07T05:46:42Z","published":"2024-11-05T07:59:22Z","title":"The Translation of Circumlocution in Arabic Short Stories into English","summary":"  This study investigates the translation of circumlocution from Arabic to\nEnglish in a corpus of short stories by renowned Arabic authors. By analyzing\nthe source and target texts, the study aims to identify and categorize\ncircumlocution instances in Arabic and their corresponding renditions in\nEnglish. The study employs Nida's (1964) translation theory as a framework to\nassess the appropriateness of the translation strategies employed. It examines\nthe extent to which translators successfully rendered Arabic circumlocution\ninto English, identifying potential challenges and limitations in the\ntranslation process. The findings reveal significant similarities between\nArabic circumlocution categories and English metadiscourse categories,\nparticularly in terms of textual and interpersonal functions. However, the\nstudy also highlights instances where translators encountered difficulties in\naccurately conveying the nuances of circumlocution, often resorting to\nstrategies like addition, subtraction, and alteration.https://ntu.edu.iq/\n","authors":["Dalal Waadallah Shehab"],"pdf_url":"https://arxiv.org/pdf/2411.02887v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04448v1","updated":"2024-11-07T05:43:50Z","published":"2024-11-07T05:43:50Z","title":"Gradient Localization Improves Lifelong Pretraining of Language Models","summary":"  Large Language Models (LLMs) trained on web-scale text corpora have been\nshown to capture world knowledge in their parameters. However, the mechanism by\nwhich language models store different types of knowledge is poorly understood.\nIn this work, we examine two types of knowledge relating to temporally\nsensitive entities and demonstrate that each type is localized to different\nsets of parameters within the LLMs. We hypothesize that the lack of\nconsideration of the locality of knowledge in existing continual learning\nmethods contributes to both: the failed uptake of new information, and\ncatastrophic forgetting of previously learned information. We observe that\nsequences containing references to updated and newly mentioned entities exhibit\nlarger gradient norms in a subset of layers. We demonstrate that targeting\nparameter updates to these relevant layers can improve the performance of\ncontinually pretraining on language containing temporal drift.\n","authors":["Jared Fernandez","Yonatan Bisk","Emma Strubell"],"pdf_url":"https://arxiv.org/pdf/2411.04448v1.pdf","comment":"EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2409.18412v2","updated":"2024-11-07T05:38:31Z","published":"2024-09-27T03:00:29Z","title":"SciDFM: A Large Language Model with Mixture-of-Experts for Science","summary":"  Recently, there has been a significant upsurge of interest in leveraging\nlarge language models (LLMs) to assist scientific discovery. However, most LLMs\nonly focus on general science, while they lack domain-specific knowledge, such\nas chemical molecules and amino acid sequences. To bridge these gaps, we\nintroduce SciDFM, a mixture-of-experts LLM, which is trained from scratch and\nis able to conduct college-level scientific reasoning and understand molecules\nand amino acid sequences. We collect a large-scale training corpus containing\nnumerous scientific papers and books from different disciplines as well as data\nfrom domain-specific databases. We further fine-tune the pre-trained model on\nlots of instruction data to improve performances on downstream benchmarks. From\nexperiment results, we show that SciDFM achieves strong performance on general\nscientific benchmarks such as SciEval and SciQ, and it reaches a SOTA\nperformance on domain-specific benchmarks among models of similar size. We\nfurther analyze the expert layers and show that the results of expert selection\nvary with data from different disciplines. To benefit the broader research\ncommunity, we open-source SciDFM at\nhttps://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0.\n","authors":["Liangtai Sun","Danyu Luo","Da Ma","Zihan Zhao","Baocai Chen","Zhennan Shen","Su Zhu","Lu Chen","Xin Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2409.18412v2.pdf","comment":"12 pages, 1 figure, 9 tables. Technical Report, accepted by NeurIPS\n  2024 Workshop FM4Science"},{"id":"http://arxiv.org/abs/2411.04443v1","updated":"2024-11-07T05:35:39Z","published":"2024-11-07T05:35:39Z","title":"ACCIO: Table Understanding Enhanced via Contrastive Learning with\n  Aggregations","summary":"  The attention to table understanding using recent natural language models has\nbeen growing. However, most related works tend to focus on learning the\nstructure of the table directly. Just as humans improve their understanding of\nsentences by comparing them, they can also enhance their understanding by\ncomparing tables. With this idea, in this paper, we introduce ACCIO, tAble\nunderstanding enhanCed via Contrastive learnIng with aggregatiOns, a novel\napproach to enhancing table understanding by contrasting original tables with\ntheir pivot summaries through contrastive learning. ACCIO trains an encoder to\nbring these table pairs closer together. Through validation via column type\nannotation, ACCIO achieves competitive performance with a macro F1 score of\n91.1 compared to state-of-the-art methods. This work represents the first\nattempt to utilize pairs of tables for table embedding, promising significant\nadvancements in table comprehension. Our code is available at\nhttps://github.com/whnhch/ACCIO/.\n","authors":["Whanhee Cho"],"pdf_url":"https://arxiv.org/pdf/2411.04443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18032v2","updated":"2024-11-07T05:10:20Z","published":"2024-10-23T17:02:59Z","title":"GraphTeam: Facilitating Large Language Model-based Graph Analysis via\n  Multi-Agent Collaboration","summary":"  Graphs are widely used for modeling relational data in real-world scenarios,\nsuch as social networks and urban computing. Existing LLM-based graph analysis\napproaches either integrate graph neural networks (GNNs) for specific machine\nlearning tasks, limiting their transferability, or rely solely on LLMs'\ninternal reasoning ability, resulting in suboptimal performance. To address\nthese limitations, we take advantage of recent advances in LLM-based agents,\nwhich have shown capabilities of utilizing external knowledge or tools for\nproblem solving. By simulating human problem-solving strategies such as analogy\nand collaboration, we propose a multi-agent system based on LLMs named\nGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from\nthree modules, and the agents with different specialities can collaborate with\neach other to address complex problems. Specifically, (1) input-output\nnormalization module: the question agent extracts and refines four key\narguments from the original question, facilitating the problem understanding,\nand the answer agent organizes the results to meet the output requirement; (2)\nexternal knowledge retrieval module: we first build a knowledge base consisting\nof relevant documentation and experience information, and then the search agent\nretrieves the most relevant entries for each question. (3) problem-solving\nmodule: given the retrieved information from search agent, the coding agent\nuses established algorithms via programming to generate solutions, and in case\nthe coding agent does not work, the reasoning agent will directly compute the\nresults without programming. Extensive experiments on six graph analysis\nbenchmarks demonstrate that GraphTeam achieves state-of-the-art performance\nwith an average 25.85% improvement over the best baseline in terms of accuracy.\nThe code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.\n","authors":["Xin Li","Qizhi Chu","Yubin Chen","Yang Liu","Yaoqi Liu","Zekai Yu","Weize Chen","Chen Qian","Chuan Shi","Cheng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.18032v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02449v3","updated":"2024-11-07T04:55:29Z","published":"2024-09-04T05:08:23Z","title":"What is lost in Normalization? Exploring Pitfalls in Multilingual ASR\n  Model Evaluations","summary":"  This paper explores the pitfalls in evaluating multilingual automatic speech\nrecognition (ASR) models, with a particular focus on Indic language scripts. We\ninvestigate the text normalization routine employed by leading ASR models,\nincluding OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,\nand their unintended consequences on performance metrics. Our research reveals\nthat current text normalization practices, while aiming to standardize ASR\noutputs for fair comparison, by removing inconsistencies such as variations in\nspelling, punctuation, and special characters, are fundamentally flawed when\napplied to Indic scripts. Through empirical analysis using text similarity\nscores and in-depth linguistic examination, we demonstrate that these flaws\nlead to artificially improved performance metrics for Indic languages. We\nconclude by proposing a shift towards developing text normalization routines\nthat leverage native linguistic expertise, ensuring more robust and accurate\nevaluations of multilingual ASR models.\n","authors":["Kavya Manohar","Leena G Pillai","Elizabeth Sherly"],"pdf_url":"https://arxiv.org/pdf/2409.02449v3.pdf","comment":"Accepted to EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2411.04427v1","updated":"2024-11-07T04:38:58Z","published":"2024-11-07T04:38:58Z","title":"One fish, two fish, but not the whole sea: Alignment reduces language\n  models' conceptual diversity","summary":"  Researchers in social science and psychology have recently proposed using\nlarge language models (LLMs) as replacements for humans in behavioral research.\nIn addition to arguments about whether LLMs accurately capture population-level\npatterns, this has raised questions about whether LLMs capture human-like\nconceptual diversity. Separately, it is debated whether post-training alignment\n(RLHF or RLAIF) affects models' internal diversity. Inspired by human studies,\nwe use a new way of measuring the conceptual diversity of\nsynthetically-generated LLM \"populations\" by relating the internal variability\nof simulated individuals to the population-level variability. We use this\napproach to evaluate non-aligned and aligned LLMs on two domains with rich\nhuman behavioral data. While no model reaches human-like diversity, aligned\nmodels generally display less diversity than their instruction fine-tuned\ncounterparts. Our findings highlight potential trade-offs between increasing\nmodels' value alignment and decreasing the diversity of their conceptual\nrepresentations.\n","authors":["Sonia K. Murthy","Tomer Ullman","Jennifer Hu"],"pdf_url":"https://arxiv.org/pdf/2411.04427v1.pdf","comment":"17 pages, 10 figures"},{"id":"http://arxiv.org/abs/2305.15265v4","updated":"2024-11-07T04:38:33Z","published":"2023-05-24T15:52:08Z","title":"Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of\n  Language Model","summary":"  With the rapid growth in model size, fine-tuning the large pre-trained\nlanguage model has become increasingly difficult due to its extensive memory\nusage. Previous works usually focus on reducing the number of trainable\nparameters in the network. While the model parameters do contribute to memory\nusage, the primary memory bottleneck during training arises from storing\nfeature maps, also known as activations, as they are crucial for gradient\ncalculation. Notably, neural networks are usually trained using stochastic\ngradient descent. We argue that in stochastic optimization, models can handle\nnoisy gradients as long as the gradient estimator is unbiased with reasonable\nvariance. Following this motivation, we propose a new family of unbiased\nestimators called WTA-CRS, for matrix production with reduced variance, which\nonly requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the\ncontext of tuning transformers, our proposed estimators exhibit lower variance\ncompared to existing ones. By replacing the linear operation with our\napproximated one in transformers, we can achieve up to 2.7$\\times$ peak memory\nreduction with almost no accuracy drop and enables up to $6.4\\times$ larger\nbatch size. Under the same hardware, WTA-CRS enables better down-streaming task\nperformance by applying larger models and/or faster training speed with larger\nbatch sizes.\n","authors":["Zirui Liu","Guanchu Wang","Shaochen Zhong","Zhaozhuo Xu","Daochen Zha","Ruixiang Tang","Zhimeng Jiang","Kaixiong Zhou","Vipin Chaudhary","Shuai Xu","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2305.15265v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04425v1","updated":"2024-11-07T04:38:29Z","published":"2024-11-07T04:38:29Z","title":"DELIFT: Data Efficient Language model Instruction Fine Tuning","summary":"  Fine-tuning large language models (LLMs) is essential for enhancing their\nperformance on specific tasks but is often resource-intensive due to redundant\nor uninformative data. To address this inefficiency, we introduce DELIFT (Data\nEfficient Language model Instruction Fine-Tuning), a novel algorithm that\nsystematically optimizes data selection across the three key stages of\nfine-tuning: (1) instruction tuning, (2) task-specific fine-tuning (e.g.,\nreasoning, question-answering), and (3) continual fine-tuning (e.g.,\nincorporating new data versions). Unlike existing methods that focus on\nsingle-stage optimization or rely on computationally intensive gradient\ncalculations, DELIFT operates efficiently across all stages. Central to our\napproach is a pairwise utility metric that quantifies how beneficial a data\nsample is for improving the model's responses to other samples, effectively\nmeasuring the informational value relative to the model's current capabilities.\nBy leveraging different submodular functions applied to this metric, DELIFT\nselects diverse and optimal subsets that are useful across all stages of\nfine-tuning. Experiments across various tasks and model scales demonstrate that\nDELIFT can reduce the fine-tuning data size by up to 70% without compromising\nperformance, offering significant computational savings and outperforming\nexisting methods in both efficiency and efficacy.\n","authors":["Ishika Agarwal","Krishna Killamsetty","Lucian Popa","Marina Danilevksy"],"pdf_url":"https://arxiv.org/pdf/2411.04425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04424v1","updated":"2024-11-07T04:32:40Z","published":"2024-11-07T04:32:40Z","title":"Bayesian Calibration of Win Rate Estimation with LLM Evaluators","summary":"  Recent advances in large language models (LLMs) show the potential of using\nLLMs as evaluators for assessing the quality of text generations from LLMs.\nHowever, applying LLM evaluators naively to compare or judge between different\nsystems can lead to unreliable results due to the intrinsic win rate estimation\nbias of LLM evaluators. In order to mitigate this problem, we propose two\ncalibration methods, Bayesian Win Rate Sampling (BWRS) and Bayesian\nDawid-Skene, both of which leverage Bayesian inference to more accurately infer\nthe true win rate of generative language models. We empirically validate our\nmethods on six datasets covering story generation, summarization, and\ninstruction following tasks. We show that both our methods are effective in\nimproving the accuracy of win rate estimation using LLMs as evaluators,\noffering a promising direction for reliable automatic text quality evaluation.\n","authors":["Yicheng Gao","Gonghan Xu","Zhe Wang","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.04424v1.pdf","comment":"Accepted by EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.04421v1","updated":"2024-11-07T04:17:30Z","published":"2024-11-07T04:17:30Z","title":"Variational Low-Rank Adaptation Using IVON","summary":"  We show that variational learning can significantly improve the accuracy and\ncalibration of Low-Rank Adaptation (LoRA) without a substantial increase in the\ncost. We replace AdamW by the Improved Variational Online Newton (IVON)\nalgorithm to finetune large language models. For Llama-2 with 7 billion\nparameters, IVON improves the accuracy over AdamW by 2.8% and expected\ncalibration error by 4.6%. The accuracy is also better than the other Bayesian\nalternatives, yet the cost is lower and the implementation is easier. Our work\nprovides additional evidence for the effectiveness of IVON for large language\nmodels. The code is available at\nhttps://github.com/team-approx-bayes/ivon-lora.\n","authors":["Bai Cong","Nico Daheim","Yuesong Shen","Daniel Cremers","Rio Yokota","Mohammad Emtiyaz Khan","Thomas Möllenhoff"],"pdf_url":"https://arxiv.org/pdf/2411.04421v1.pdf","comment":"Published at 38th Workshop on Fine-Tuning in Machine Learning\n  (NeurIPS 2024). Code available at\n  https://github.com/team-approx-bayes/ivon-lora"},{"id":"http://arxiv.org/abs/2406.18064v3","updated":"2024-11-07T04:03:04Z","published":"2024-06-26T04:49:41Z","title":"Evaluating Quality of Answers for Retrieval-Augmented Generation: A\n  Strong LLM Is All You Need","summary":"  We present a comprehensive study of answer quality evaluation in\nRetrieval-Augmented Generation (RAG) applications using vRAG-Eval, a novel\ngrading system that is designed to assess correctness, completeness, and\nhonesty. We further map the grading of quality aspects aforementioned into a\nbinary score, indicating an accept or reject decision, mirroring the intuitive\n\"thumbs-up\" or \"thumbs-down\" gesture commonly used in chat applications. This\napproach suits factual business contexts where a clear decision opinion is\nessential. Our assessment applies vRAG-Eval to two Large Language Models\n(LLMs), evaluating the quality of answers generated by a vanilla RAG\napplication. We compare these evaluations with human expert judgments and find\na substantial alignment between GPT-4's assessments and those of human experts,\nreaching 83% agreement on accept or reject decisions. This study highlights the\npotential of LLMs as reliable evaluators in closed-domain, closed-ended\nsettings, particularly when human evaluations require significant resources.\n","authors":["Yang Wang","Alberto Garcia Hernandez","Roman Kyslyi","Nicholas Kersting"],"pdf_url":"https://arxiv.org/pdf/2406.18064v3.pdf","comment":"13 pages, 8 figures, 12 tables"},{"id":"http://arxiv.org/abs/2411.04105v2","updated":"2024-11-07T03:50:19Z","published":"2024-11-06T18:35:32Z","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic\n  Analysis","summary":"  Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve, but we can train a small\ntransformer to achieve perfect accuracy. Building on our set-up, we then pursue\nan understanding of precisely how a three-layer transformer, trained from\nscratch, solves this problem. We are able to identify certain \"planning\" and\n\"reasoning\" circuits in the network that necessitate cooperation between the\nattention blocks to implement the desired logic. To expand our findings, we\nthen study a larger model, Mistral 7B. Using activation patching, we\ncharacterize internal components that are critical in solving our logic\nproblem. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.\n","authors":["Guan Zhe Hong","Nishanth Dikkala","Enming Luo","Cyrus Rashtchian","Xin Wang","Rina Panigrahy"],"pdf_url":"https://arxiv.org/pdf/2411.04105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07930v4","updated":"2024-11-07T03:37:51Z","published":"2024-08-15T04:57:55Z","title":"MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and\n  Iterative Sub-SQL Refinement for Text-to-SQL","summary":"  Recent In-Context Learning based methods have achieved remarkable success in\nText-to-SQL task. However, there is still a large gap between the performance\nof these models and human performance on datasets with complex database schema\nand difficult questions, such as BIRD. Besides, existing work has neglected to\nsupervise intermediate steps when solving questions iteratively with question\ndecomposition methods, and the schema linking methods used in these works are\nvery rudimentary. To address these issues, we propose MAG-SQL, a multi-agent\ngenerative approach with soft schema linking and iterative Sub-SQL refinement.\nIn our framework, an entity-based method with tables' summary is used to select\nthe columns in database, and a novel targets-conditions decomposition method is\nintroduced to decompose those complex questions. Additionally, we build a\niterative generating module which includes a Sub-SQL Generator and Sub-SQL\nRefiner, introducing external oversight for each step of generation. Through a\nseries of ablation studies, the effectiveness of each agent in our framework\nhas been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL\nachieves an execution accuracy of 61.08%, compared to the baseline accuracy of\n46.35% for vanilla GPT-4 and the baseline accuracy of 57.56% for MAC-SQL.\nBesides, our approach makes similar progress on Spider. The codes are available\nat https://github.com/LancelotXWX/MAG-SQL.\n","authors":["Wenxuan Xie","Gaochen Wu","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.07930v4.pdf","comment":"22 pages, 14 figures"},{"id":"http://arxiv.org/abs/2407.15186v4","updated":"2024-11-07T03:26:58Z","published":"2024-07-21T14:48:23Z","title":"A Survey on Employing Large Language Models for Text-to-SQL Tasks","summary":"  The increasing volume of data in relational databases and the expertise\nneeded for writing SQL queries pose challenges for users to access and analyze\ndata. Text-to-SQL (Text2SQL) solves the issues by utilizing natural language\nprocessing (NLP) techniques to convert natural language into SQL queries. With\nthe development of Large Language Models (LLMs), a range of LLM-based Text2SQL\nmethods have emerged. This survey provides a comprehensive review of LLMs in\nText2SQL tasks. We review benchmark datasets, prompt engineering methods,\nfine-tuning methods, and base models in LLM-based Text2SQL methods. We provide\ninsights in each part and discuss future directions in this field.\n","authors":["Liang Shi","Zhengju Tang","Nan Zhang","Xiaotong Zhang","Zhi Yang"],"pdf_url":"https://arxiv.org/pdf/2407.15186v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11484v8","updated":"2024-11-07T03:23:16Z","published":"2024-07-16T08:20:39Z","title":"The Oscars of AI Theater: A Survey on Role-Playing with Language Models","summary":"  This survey explores the burgeoning field of role-playing with language\nmodels, focusing on their development from early persona-based models to\nadvanced character-driven simulations facilitated by Large Language Models\n(LLMs). Initially confined to simple persona consistency due to limited model\ncapabilities, role-playing tasks have now expanded to embrace complex character\nportrayals involving character consistency, behavioral alignment, and overall\nattractiveness. We provide a comprehensive taxonomy of the critical components\nin designing these systems, including data, models and alignment, agent\narchitecture and evaluation. This survey not only outlines the current\nmethodologies and challenges, such as managing dynamic personal profiles and\nachieving high-level persona consistency but also suggests avenues for future\nresearch in improving the depth and realism of role-playing applications. The\ngoal is to guide future research by offering a structured overview of current\nmethodologies and identifying potential areas for improvement. Related\nresources and papers are available at\nhttps://github.com/nuochenpku/Awesome-Role-Play-Papers.\n","authors":["Nuo Chen","Yan Wang","Yang Deng","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2407.11484v8.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2411.02603v3","updated":"2024-11-07T03:17:42Z","published":"2024-11-04T20:53:04Z","title":"FactTest: Factuality Testing in Large Language Models with Finite-Sample\n  and Distribution-Free Guarantees","summary":"  The propensity of Large Language Models (LLMs) to generate hallucinations and\nnon-factual content undermines their reliability in high-stakes domains, where\nrigorous control over Type I errors (the conditional probability of incorrectly\nclassifying hallucinations as truthful content) is essential. Despite its\nimportance, formal verification of LLM factuality with such guarantees remains\nlargely unexplored. In this paper, we introduce FactTest, a novel framework\nthat statistically assesses whether a LLM can confidently provide correct\nanswers to given questions with high-probability correctness guarantees. We\nformulate factuality testing as hypothesis testing problem to enforce an upper\nbound of Type I errors at user-specified significance levels. Notably, we prove\nthat our framework also ensures strong Type II error control under mild\nconditions and can be extended to maintain its effectiveness when covariate\nshifts exist. Our approach is distribution-free and works for any number of\nhuman-annotated samples. It is model-agnostic and applies to any black-box or\nwhite-box LM. Extensive experiments on question-answering (QA) and\nmultiple-choice benchmarks demonstrate that FactTest effectively detects\nhallucinations and improves the model's ability to abstain from answering\nunknown questions, leading to an over 40% accuracy improvement.\n","authors":["Fan Nie","Xiaotian Hou","Shuhang Lin","James Zou","Huaxiu Yao","Linjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.02603v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17767v2","updated":"2024-11-07T03:16:02Z","published":"2024-05-28T02:46:11Z","title":"Linguistic Collapse: Neural Collapse in (Large) Language Models","summary":"  Neural collapse ($\\mathcal{NC}$) is a phenomenon observed in classification\ntasks where top-layer representations collapse into their class means, which\nbecome equinorm, equiangular and aligned with the classifiers. These behaviors\n-- associated with generalization and robustness -- would manifest under\nspecific conditions: models are trained towards zero loss, with noise-free\nlabels belonging to balanced classes, which do not outnumber the model's hidden\ndimension. Recent studies have explored $\\mathcal{NC}$ in the absence of one or\nmore of these conditions to extend and capitalize on the associated benefits of\nideal geometries. Language modeling presents a curious frontier, as\n\\textit{training by token prediction} constitutes a classification task where\nnone of the conditions exist: the vocabulary is imbalanced and exceeds the\nembedding dimension; different tokens might correspond to similar contextual\nembeddings; and large language models (LLMs) in particular are typically only\ntrained for a few epochs. This paper empirically investigates the impact of\nscaling the architectures and training of causal language models (CLMs) on\ntheir progression towards $\\mathcal{NC}$. We find that $\\mathcal{NC}$\nproperties that develop with scale (and regularization) are linked to\ngeneralization. Moreover, there is evidence of some relationship between\n$\\mathcal{NC}$ and generalization independent of scale. Our work thereby\nunderscores the generality of $\\mathcal{NC}$ as it extends to the novel and\nmore challenging setting of language modeling. Downstream, we seek to inspire\nfurther research on the phenomenon to deepen our understanding of LLMs -- and\nneural networks at large -- and improve existing architectures based on\n$\\mathcal{NC}$-related properties. Our code is hosted on GitHub at\nhttps://github.com/rhubarbwu/linguistic-collapse .\n","authors":["Robert Wu","Vardan Papyan"],"pdf_url":"https://arxiv.org/pdf/2405.17767v2.pdf","comment":"NeurIPS 2024; 36 pages; 30 figures"},{"id":"http://arxiv.org/abs/2403.18802v4","updated":"2024-11-07T03:14:38Z","published":"2024-03-27T17:48:55Z","title":"Long-form factuality in large language models","summary":"  Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can outperform crowdsourced human\nannotators - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.\n","authors":["Jerry Wei","Chengrun Yang","Xinying Song","Yifeng Lu","Nathan Hu","Jie Huang","Dustin Tran","Daiyi Peng","Ruibo Liu","Da Huang","Cosmo Du","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2403.18802v4.pdf","comment":"NeurIPS 2024; 72 pages, 18 figures, 30 tables. Code at\n  https://github.com/google-deepmind/long-form-factuality"},{"id":"http://arxiv.org/abs/2409.19487v3","updated":"2024-11-07T03:05:18Z","published":"2024-09-28T23:59:46Z","title":"HealthQ: Unveiling Questioning Capabilities of LLM Chains in Healthcare\n  Conversations","summary":"  In digital healthcare, large language models (LLMs) have primarily been\nutilized to enhance question-answering capabilities and improve patient\ninteractions. However, effective patient care necessitates LLM chains that can\nactively gather information by posing relevant questions. This paper presents\nHealthQ, a novel framework designed to evaluate the questioning capabilities of\nLLM healthcare chains. We implemented several LLM chains, including\nRetrieval-Augmented Generation (RAG), Chain of Thought (CoT), and reflective\nchains, and introduced an LLM judge to assess the relevance and informativeness\nof the generated questions. To validate HealthQ, we employed traditional\nNatural Language Processing (NLP) metrics such as Recall-Oriented Understudy\nfor Gisting Evaluation (ROUGE) and Named Entity Recognition (NER)-based set\ncomparison, and constructed two custom datasets from public medical note\ndatasets, ChatDoctor and MTS-Dialog. Our contributions are threefold: we\nprovide the first comprehensive study on the questioning capabilities of LLMs\nin healthcare conversations, develop a novel dataset generation pipeline, and\npropose a detailed evaluation methodology.\n","authors":["Ziyu Wang","Hao Li","Di Huang","Amir M. Rahmani"],"pdf_url":"https://arxiv.org/pdf/2409.19487v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03644v2","updated":"2024-11-07T02:44:34Z","published":"2024-11-06T03:48:41Z","title":"Deploying Multi-task Online Server with Large Language Model","summary":"  In the industry, numerous tasks are deployed online. Traditional approaches\noften tackle each task separately by its own network, which leads to excessive\ncosts for developing and scaling models, especially in the context of large\nlanguage models. Although multi-task methods can save costs through parameter\nsharing, they often struggle to outperform single-task methods in real-world\napplications. To tackle these challenges, we present a three-stage multi-task\nlearning framework for large language models. It involves task filtering,\nfollowed by fine-tuning on high-resource tasks, and finally fine-tuning on all\ntasks. We conducted comprehensive experiments in single-task and multi-task\nsettings. Our approach, exemplified on different benchmarks, demonstrates that\nit is able to achieve performance comparable to the single-task method while\nreducing up to 90.9\\% of its overhead.\n","authors":["Yincen Qu","Chao Ma","Xiangying Dai","Hui Zhou","Yiting Wu","Hengyue Liu"],"pdf_url":"https://arxiv.org/pdf/2411.03644v2.pdf","comment":"Accepted by COLING 2025 Industry Track"},{"id":"http://arxiv.org/abs/2411.04368v1","updated":"2024-11-07T01:58:42Z","published":"2024-11-07T01:58:42Z","title":"Measuring short-form factuality in large language models","summary":"  We present SimpleQA, a benchmark that evaluates the ability of language\nmodels to answer short, fact-seeking questions. We prioritized two properties\nin designing this eval. First, SimpleQA is challenging, as it is adversarially\ncollected against GPT-4 responses. Second, responses are easy to grade, because\nquestions are created such that there exists only a single, indisputable\nanswer. Each answer in SimpleQA is graded as either correct, incorrect, or not\nattempted. A model with ideal behavior would get as many questions correct as\npossible while not attempting the questions for which it is not confident it\nknows the correct answer. SimpleQA is a simple, targeted evaluation for whether\nmodels \"know what they know,\" and our hope is that this benchmark will remain\nrelevant for the next few generations of frontier models. SimpleQA can be found\nat https://github.com/openai/simple-evals.\n","authors":["Jason Wei","Nguyen Karina","Hyung Won Chung","Yunxin Joy Jiao","Spencer Papay","Amelia Glaese","John Schulman","William Fedus"],"pdf_url":"https://arxiv.org/pdf/2411.04368v1.pdf","comment":"Blog post: https://openai.com/index/introducing-simpleqa/"},{"id":"http://arxiv.org/abs/2411.04358v1","updated":"2024-11-07T01:31:48Z","published":"2024-11-07T01:31:48Z","title":"Robust and Efficient Fine-tuning of LLMs with Bayesian\n  Reparameterization of Low-Rank Adaptation","summary":"  Large Language Models (LLMs) are highly resource-intensive to fine-tune due\nto their enormous size. While low-rank adaptation is a prominent\nparameter-efficient fine-tuning approach, it suffers from sensitivity to\nhyperparameter choices, leading to instability in model performance on\nfine-tuning downstream tasks. This paper highlights the importance of effective\nparameterization in low-rank fine-tuning to reduce estimator variance and\nenhance the stability of final model outputs. We propose MonteCLoRA, an\nefficient fine-tuning technique, employing Monte Carlo estimation to learn an\nunbiased posterior estimation of low-rank parameters with low expected\nvariance, which stabilizes fine-tuned LLMs with only O(1) additional\nparameters. MonteCLoRA shows significant improvements in accuracy and\nrobustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness\nthan existing efficient fine-tuning methods on natural language understanding\ntasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with\npre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance\nwith 50% lower variance than the contemporary efficient fine-tuning methods.\nThe theoretical and empirical results presented in the paper underscore how\nparameterization and hyperpriors balance exploration-exploitation in the\nlow-rank parametric space, therefore leading to more optimal and robust\nparameter estimation during efficient fine-tuning.\n","authors":["Vaibhav Seth","Arinjay Pathak","Ayan Sengupta","Natraj Raman","Sriram Gopalakrishnan","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2411.04358v1.pdf","comment":"48 pages, 10 figures, 10 tables, Code:\n  https://github.com/LCS2-IIITD/MonteCLoRA"},{"id":"http://arxiv.org/abs/2411.01222v3","updated":"2024-11-07T01:26:43Z","published":"2024-11-02T12:01:44Z","title":"$B^4$: A Black-Box Scrubbing Attack on LLM Watermarks","summary":"  Watermarking has emerged as a prominent technique for LLM-generated content\ndetection by embedding imperceptible patterns. Despite supreme performance, its\nrobustness against adversarial attacks remains underexplored. Previous work\ntypically considers a grey-box attack setting, where the specific type of\nwatermark is already known. Some even necessitates knowledge about\nhyperparameters of the watermarking method. Such prerequisites are unattainable\nin real-world scenarios. Targeting at a more realistic black-box threat model\nwith fewer assumptions, we here propose $B^4$, a black-box scrubbing attack on\nwatermarks. Specifically, we formulate the watermark scrubbing attack as a\nconstrained optimization problem by capturing its objectives with two\ndistributions, a Watermark Distribution and a Fidelity Distribution. This\noptimization problem can be approximately solved using two proxy distributions.\nExperimental results across 12 different settings demonstrate the superior\nperformance of $B^4$ compared with other baselines.\n","authors":["Baizhou Huang","Xiao Pu","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2411.01222v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06567v3","updated":"2024-11-07T00:54:30Z","published":"2024-07-09T05:52:26Z","title":"FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal\n  Reinforcement for Enhanced Financial Decision Making","summary":"  Large language models (LLMs) have demonstrated notable potential in\nconducting complex tasks and are increasingly utilized in various financial\napplications. However, high-quality sequential financial investment\ndecision-making remains challenging. These tasks require multiple interactions\nwith a volatile environment for every decision, demanding sufficient\nintelligence to maximize returns and manage risks. Although LLMs have been used\nto develop agent systems that surpass human teams and yield impressive\ninvestment returns, opportunities to enhance multi-sourced information\nsynthesis and optimize decision-making outcomes through timely experience\nrefinement remain unexplored. Here, we introduce the FinCon, an LLM-based\nmulti-agent framework with CONceptual verbal reinforcement tailored for diverse\nFINancial tasks. Inspired by effective real-world investment firm\norganizational structures, FinCon utilizes a manager-analyst communication\nhierarchy. This structure allows for synchronized cross-functional agent\ncollaboration towards unified goals through natural language interactions and\nequips each agent with greater memory capacity than humans. Additionally, a\nrisk-control component in FinCon enhances decision quality by episodically\ninitiating a self-critiquing mechanism to update systematic investment beliefs.\nThe conceptualized beliefs serve as verbal reinforcement for the future agent's\nbehavior and can be selectively propagated to the appropriate node that\nrequires knowledge updates. This feature significantly improves performance\nwhile reducing unnecessary peer-to-peer communication costs. Moreover, FinCon\ndemonstrates strong generalization capabilities in various financial tasks,\nincluding single stock trading and portfolio management.\n","authors":["Yangyang Yu","Zhiyuan Yao","Haohang Li","Zhiyang Deng","Yupeng Cao","Zhi Chen","Jordan W. Suchow","Rong Liu","Zhenyu Cui","Zhaozhuo Xu","Denghui Zhang","Koduvayur Subbalakshmi","Guojun Xiong","Yueru He","Jimin Huang","Dong Li","Qianqian Xie"],"pdf_url":"https://arxiv.org/pdf/2407.06567v3.pdf","comment":"LLM Applications, LLM Agents, Financial Technology, Quantitative\n  Finance, Algorithmic Trading, Cognitive Science"},{"id":"http://arxiv.org/abs/2411.01030v3","updated":"2024-11-07T00:23:14Z","published":"2024-11-01T21:01:13Z","title":"Birdie: Advancing State Space Models with Reward-Driven Objectives and\n  Curricula","summary":"  Efficient state space models (SSMs), such as linear recurrent neural networks\nand linear attention variants, offer computational advantages over Transformers\nbut struggle with tasks requiring long-range in-context retrieval-like text\ncopying, associative recall, and question answering over long contexts.\nPrevious efforts to address these challenges have focused on architectural\nmodifications, often reintroducing computational inefficiencies. In this paper,\nwe propose a novel training procedure, Birdie, that significantly enhances the\nin-context retrieval capabilities of SSMs without altering their architecture.\nOur approach combines bidirectional input processing with dynamic mixtures of\nspecialized pre-training objectives, optimized via reinforcement learning. We\nintroduce a new bidirectional SSM architecture that seamlessly transitions from\nbidirectional context processing to causal generation. Experimental evaluations\ndemonstrate that Birdie markedly improves performance on retrieval-intensive\ntasks such as multi-number phone book lookup, long paragraph\nquestion-answering, and infilling. This narrows the performance gap with\nTransformers, while retaining computational efficiency. Our findings highlight\nthe importance of training procedures in leveraging the fixed-state capacity of\nSSMs, offering a new direction to advance their capabilities. All code and\npre-trained models are available at https://www.github.com/samblouir/birdie,\nwith support for JAX and PyTorch.\n","authors":["Sam Blouir","Jimmy T. H. Smith","Antonios Anastasopoulos","Amarda Shehu"],"pdf_url":"https://arxiv.org/pdf/2411.01030v3.pdf","comment":"Accepted to EMNLP 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2411.04330v1","updated":"2024-11-07T00:10:10Z","published":"2024-11-07T00:10:10Z","title":"Scaling Laws for Precision","summary":"  Low precision training and inference affect both the quality and cost of\nlanguage models, but current scaling laws do not account for this. In this\nwork, we devise \"precision-aware\" scaling laws for both training and inference.\nWe propose that training in lower precision reduces the model's \"effective\nparameter count,\" allowing us to predict the additional loss incurred from\ntraining in low precision and post-train quantization. For inference, we find\nthat the degradation introduced by post-training quantization increases as\nmodels are trained on more data, eventually making additional pretraining data\nactively harmful. For training, our scaling laws allow us to predict the loss\nof a model with different parts in different precisions, and suggest that\ntraining larger models in lower precision may be compute optimal. We unify the\nscaling laws for post and pretraining quantization to arrive at a single\nfunctional form that predicts degradation from training and inference in varied\nprecisions. We fit on over 465 pretraining runs and validate our predictions on\nmodel sizes up to 1.7B parameters trained on up to 26B tokens.\n","authors":["Tanishq Kumar","Zachary Ankner","Benjamin F. Spector","Blake Bordelon","Niklas Muennighoff","Mansheej Paul","Cengiz Pehlevan","Christopher Ré","Aditi Raghunathan"],"pdf_url":"https://arxiv.org/pdf/2411.04330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04329v1","updated":"2024-11-07T00:09:54Z","published":"2024-11-07T00:09:54Z","title":"CodeTree: Agent-guided Tree Search for Code Generation with Large\n  Language Models","summary":"  Pre-trained on massive amounts of code and text data, large language models\n(LLMs) have demonstrated remarkable achievements in performing code generation\ntasks. With additional execution-based feedback, these models can act as agents\nwith capabilities to self-refine and improve generated code autonomously.\nHowever, on challenging coding tasks with extremely large search space, current\nagentic approaches still struggle with multi-stage planning, generating, and\ndebugging. To address this problem, we propose CodeTree, a framework for LLM\nagents to efficiently explore the search space in different stages of the code\ngeneration process. Specifically, we adopted a unified tree structure to\nexplicitly explore different coding strategies, generate corresponding coding\nsolutions, and subsequently refine the solutions. In each stage, critical\ndecision-making (ranking, termination, expanding) of the exploration process is\nguided by both the environmental execution-based feedback and\nLLM-agent-generated feedback. We comprehensively evaluated CodeTree on 7 code\ngeneration benchmarks and demonstrated the significant performance gains of\nCodeTree against strong baselines. Using GPT-4o as the base model, we\nconsistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0\non CodeContests. On the challenging SWEBench benchmark, our approach led to\nsignificant performance gains.\n","authors":["Jierui Li","Hung Le","Yinbo Zhou","Caiming Xiong","Silvio Savarese","Doyen Sahoo"],"pdf_url":"https://arxiv.org/pdf/2411.04329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04328v1","updated":"2024-11-07T00:09:18Z","published":"2024-11-07T00:09:18Z","title":"Balancing Transparency and Accuracy: A Comparative Analysis of\n  Rule-Based and Deep Learning Models in Political Bias Classification","summary":"  The unchecked spread of digital information, combined with increasing\npolitical polarization and the tendency of individuals to isolate themselves\nfrom opposing political viewpoints, has driven researchers to develop systems\nfor automatically detecting political bias in media. This trend has been\nfurther fueled by discussions on social media. We explore methods for\ncategorizing bias in US news articles, comparing rule-based and deep learning\napproaches. The study highlights the sensitivity of modern self-learning\nsystems to unconstrained data ingestion, while reconsidering the strengths of\ntraditional rule-based systems. Applying both models to left-leaning (CNN) and\nright-leaning (FOX) news articles, we assess their effectiveness on data beyond\nthe original training and test sets.This analysis highlights each model's\naccuracy, offers a framework for exploring deep-learning explainability, and\nsheds light on political bias in US news media. We contrast the opaque\narchitecture of a deep learning model with the transparency of a linguistically\ninformed rule-based model, showing that the rule-based model performs\nconsistently across different data conditions and offers greater transparency,\nwhereas the deep learning model is dependent on the training set and struggles\nwith unseen data.\n","authors":["Manuel Nunez Martinez","Sonja Schmer-Galunder","Zoey Liu","Sangpil Youm","Chathuri Jayaweera","Bonnie J. Dorr"],"pdf_url":"https://arxiv.org/pdf/2411.04328v1.pdf","comment":null}]}}